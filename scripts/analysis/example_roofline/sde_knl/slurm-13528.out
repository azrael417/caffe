total layers 26
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer13_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=13 -prof_forward_direction=1
I1109 00:07:29.056637 138105 caffe.cpp:444] Use CPU.
I1109 00:07:45.858052 138105 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:07:45.913633 138105 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:07:45.925106 138105 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:07:45.936039 138105 cpu_info.cpp:461] Total number of processors: 272
I1109 00:07:45.946918 138105 cpu_info.cpp:464] GPU is used: no
I1109 00:07:45.955348 138105 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:07:45.963680 138105 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:07:45.974323 138105 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:07:54.612699 138105 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:07:54.643745 138105 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:07:55.270922 138105 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:07:57.706321 138105 layer_factory.hpp:114] Creating layer data
I1109 00:07:57.853299 138105 net.cpp:160] Creating Layer data
I1109 00:07:57.901864 138105 net.cpp:570] data -> data
I1109 00:07:58.367013 138105 net.cpp:570] data -> label
I1109 00:08:05.389125 138105 net.cpp:210] Setting up data
I1109 00:08:05.472017 138105 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:08:05.577029 138105 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:08:05.584941 138105 net.cpp:225] Memory required for data: 19787264
I1109 00:08:05.654244 138105 layer_factory.hpp:114] Creating layer conv1
I1109 00:08:05.980303 138105 net.cpp:160] Creating Layer conv1
I1109 00:08:06.029875 138105 net.cpp:596] conv1 <- data
I1109 00:08:06.148408 138105 net.cpp:570] conv1 -> conv1
I1109 00:08:38.843832 138105 net.cpp:210] Setting up conv1
I1109 00:08:38.851538 138105 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:08:38.851964 138105 net.cpp:225] Memory required for data: 56958464
I1109 00:08:39.133616 138105 layer_factory.hpp:114] Creating layer relu1
I1109 00:08:39.253337 138105 net.cpp:160] Creating Layer relu1
I1109 00:08:39.257809 138105 net.cpp:596] relu1 <- conv1
I1109 00:08:39.289573 138105 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:08:39.476083 138105 net.cpp:210] Setting up relu1
I1109 00:08:39.478461 138105 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:08:39.478793 138105 net.cpp:225] Memory required for data: 94129664
I1109 00:08:39.478991 138105 layer_factory.hpp:114] Creating layer norm1
I1109 00:08:39.584364 138105 net.cpp:160] Creating Layer norm1
I1109 00:08:39.584700 138105 net.cpp:596] norm1 <- conv1
I1109 00:08:39.587512 138105 net.cpp:570] norm1 -> norm1
I1109 00:08:39.813889 138105 net.cpp:210] Setting up norm1
I1109 00:08:39.826650 138105 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:08:39.827028 138105 net.cpp:225] Memory required for data: 131300864
I1109 00:08:39.827356 138105 layer_factory.hpp:114] Creating layer pool1
I1109 00:08:39.921942 138105 net.cpp:160] Creating Layer pool1
I1109 00:08:39.922252 138105 net.cpp:596] pool1 <- norm1
I1109 00:08:39.936934 138105 net.cpp:570] pool1 -> pool1
I1109 00:08:40.235580 138105 net.cpp:210] Setting up pool1
I1109 00:08:40.238139 138105 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:08:40.238469 138105 net.cpp:225] Memory required for data: 140258816
I1109 00:08:40.238723 138105 layer_factory.hpp:114] Creating layer conv2
I1109 00:08:40.239094 138105 net.cpp:160] Creating Layer conv2
I1109 00:08:40.239338 138105 net.cpp:596] conv2 <- pool1
I1109 00:08:40.239574 138105 net.cpp:570] conv2 -> conv2
I1109 00:08:45.992660 138105 net.cpp:210] Setting up conv2
I1109 00:08:45.993036 138105 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:08:45.993502 138105 net.cpp:225] Memory required for data: 164146688
I1109 00:08:46.043599 138105 layer_factory.hpp:114] Creating layer relu2
I1109 00:08:46.044008 138105 net.cpp:160] Creating Layer relu2
I1109 00:08:46.044400 138105 net.cpp:596] relu2 <- conv2
I1109 00:08:46.044688 138105 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:08:46.045189 138105 net.cpp:210] Setting up relu2
I1109 00:08:46.045454 138105 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:08:46.045686 138105 net.cpp:225] Memory required for data: 188034560
I1109 00:08:46.045872 138105 layer_factory.hpp:114] Creating layer norm2
I1109 00:08:46.046115 138105 net.cpp:160] Creating Layer norm2
I1109 00:08:46.046317 138105 net.cpp:596] norm2 <- conv2
I1109 00:08:46.046577 138105 net.cpp:570] norm2 -> norm2
I1109 00:08:46.048624 138105 net.cpp:210] Setting up norm2
I1109 00:08:46.048979 138105 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:08:46.049216 138105 net.cpp:225] Memory required for data: 211922432
I1109 00:08:46.049399 138105 layer_factory.hpp:114] Creating layer pool2
I1109 00:08:46.049674 138105 net.cpp:160] Creating Layer pool2
I1109 00:08:46.049928 138105 net.cpp:596] pool2 <- norm2
I1109 00:08:46.050227 138105 net.cpp:570] pool2 -> pool2
I1109 00:08:46.050770 138105 net.cpp:210] Setting up pool2
I1109 00:08:46.051008 138105 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:08:46.051226 138105 net.cpp:225] Memory required for data: 217460224
I1109 00:08:46.051420 138105 layer_factory.hpp:114] Creating layer conv3
I1109 00:08:46.051744 138105 net.cpp:160] Creating Layer conv3
I1109 00:08:46.051959 138105 net.cpp:596] conv3 <- pool2
I1109 00:08:46.052196 138105 net.cpp:570] conv3 -> conv3
I1109 00:08:46.557006 138105 net.cpp:210] Setting up conv3
I1109 00:08:46.559361 138105 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:08:46.559705 138105 net.cpp:225] Memory required for data: 225766912
I1109 00:08:46.562690 138105 layer_factory.hpp:114] Creating layer relu3
I1109 00:08:46.563128 138105 net.cpp:160] Creating Layer relu3
I1109 00:08:46.563380 138105 net.cpp:596] relu3 <- conv3
I1109 00:08:46.563621 138105 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:08:46.567725 138105 net.cpp:210] Setting up relu3
I1109 00:08:46.568034 138105 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:08:46.568287 138105 net.cpp:225] Memory required for data: 234073600
I1109 00:08:46.568483 138105 layer_factory.hpp:114] Creating layer conv4
I1109 00:08:46.568886 138105 net.cpp:160] Creating Layer conv4
I1109 00:08:46.569277 138105 net.cpp:596] conv4 <- conv3
I1109 00:08:46.569589 138105 net.cpp:570] conv4 -> conv4
I1109 00:08:46.812029 138105 net.cpp:210] Setting up conv4
I1109 00:08:46.812422 138105 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:08:46.812857 138105 net.cpp:225] Memory required for data: 242380288
I1109 00:08:46.813217 138105 layer_factory.hpp:114] Creating layer relu4
I1109 00:08:46.813515 138105 net.cpp:160] Creating Layer relu4
I1109 00:08:46.813752 138105 net.cpp:596] relu4 <- conv4
I1109 00:08:46.813997 138105 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:08:46.826395 138105 net.cpp:210] Setting up relu4
I1109 00:08:46.826737 138105 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:08:46.827188 138105 net.cpp:225] Memory required for data: 250686976
I1109 00:08:46.827432 138105 layer_factory.hpp:114] Creating layer conv5
I1109 00:08:46.827805 138105 net.cpp:160] Creating Layer conv5
I1109 00:08:46.828053 138105 net.cpp:596] conv5 <- conv4
I1109 00:08:46.828307 138105 net.cpp:570] conv5 -> conv5
I1109 00:08:46.996471 138105 net.cpp:210] Setting up conv5
I1109 00:08:46.996930 138105 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:08:46.997340 138105 net.cpp:225] Memory required for data: 256224768
I1109 00:08:47.001994 138105 layer_factory.hpp:114] Creating layer relu5
I1109 00:08:47.004957 138105 net.cpp:160] Creating Layer relu5
I1109 00:08:47.005286 138105 net.cpp:596] relu5 <- conv5
I1109 00:08:47.005581 138105 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:08:47.006140 138105 net.cpp:210] Setting up relu5
I1109 00:08:47.006429 138105 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:08:47.006680 138105 net.cpp:225] Memory required for data: 261762560
I1109 00:08:47.006889 138105 layer_factory.hpp:114] Creating layer pool5
I1109 00:08:47.007153 138105 net.cpp:160] Creating Layer pool5
I1109 00:08:47.007369 138105 net.cpp:596] pool5 <- conv5
I1109 00:08:47.007597 138105 net.cpp:570] pool5 -> pool5
I1109 00:08:47.008039 138105 net.cpp:210] Setting up pool5
I1109 00:08:47.008309 138105 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:08:47.008545 138105 net.cpp:225] Memory required for data: 262942208
I1109 00:08:47.008901 138105 layer_factory.hpp:114] Creating layer fc6
I1109 00:08:47.062954 138105 net.cpp:160] Creating Layer fc6
I1109 00:08:47.063263 138105 net.cpp:596] fc6 <- pool5
I1109 00:08:47.063639 138105 net.cpp:570] fc6 -> fc6
I1109 00:08:51.173081 138105 net.cpp:210] Setting up fc6
I1109 00:08:51.173375 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:51.175422 138105 net.cpp:225] Memory required for data: 263466496
I1109 00:08:51.175734 138105 layer_factory.hpp:114] Creating layer relu6
I1109 00:08:51.178262 138105 net.cpp:160] Creating Layer relu6
I1109 00:08:51.178601 138105 net.cpp:596] relu6 <- fc6
I1109 00:08:51.178897 138105 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:08:51.179324 138105 net.cpp:210] Setting up relu6
I1109 00:08:51.179577 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:51.179806 138105 net.cpp:225] Memory required for data: 263990784
I1109 00:08:51.179994 138105 layer_factory.hpp:114] Creating layer drop6
I1109 00:08:51.200276 138105 net.cpp:160] Creating Layer drop6
I1109 00:08:51.200589 138105 net.cpp:596] drop6 <- fc6
I1109 00:08:51.201035 138105 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:08:51.305613 138105 net.cpp:210] Setting up drop6
I1109 00:08:51.305907 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:51.306251 138105 net.cpp:225] Memory required for data: 264515072
I1109 00:08:51.306498 138105 layer_factory.hpp:114] Creating layer fc7
I1109 00:08:51.306766 138105 net.cpp:160] Creating Layer fc7
I1109 00:08:51.306975 138105 net.cpp:596] fc7 <- fc6
I1109 00:08:51.307364 138105 net.cpp:570] fc7 -> fc7
I1109 00:08:53.029608 138105 net.cpp:210] Setting up fc7
I1109 00:08:53.029968 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:53.030457 138105 net.cpp:225] Memory required for data: 265039360
I1109 00:08:53.030824 138105 layer_factory.hpp:114] Creating layer relu7
I1109 00:08:53.031154 138105 net.cpp:160] Creating Layer relu7
I1109 00:08:53.031409 138105 net.cpp:596] relu7 <- fc7
I1109 00:08:53.031661 138105 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:08:53.032109 138105 net.cpp:210] Setting up relu7
I1109 00:08:53.032397 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:53.032652 138105 net.cpp:225] Memory required for data: 265563648
I1109 00:08:53.032954 138105 layer_factory.hpp:114] Creating layer drop7
I1109 00:08:53.033219 138105 net.cpp:160] Creating Layer drop7
I1109 00:08:53.033464 138105 net.cpp:596] drop7 <- fc7
I1109 00:08:53.033757 138105 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:08:53.034024 138105 net.cpp:210] Setting up drop7
I1109 00:08:53.034227 138105 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:08:53.034448 138105 net.cpp:225] Memory required for data: 266087936
I1109 00:08:53.034633 138105 layer_factory.hpp:114] Creating layer fc8
I1109 00:08:53.034911 138105 net.cpp:160] Creating Layer fc8
I1109 00:08:53.035122 138105 net.cpp:596] fc8 <- fc7
I1109 00:08:53.035351 138105 net.cpp:570] fc8 -> fc8
I1109 00:08:53.461021 138105 net.cpp:210] Setting up fc8
I1109 00:08:53.461375 138105 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:08:53.461881 138105 net.cpp:225] Memory required for data: 266215936
I1109 00:08:53.462189 138105 layer_factory.hpp:114] Creating layer loss
I1109 00:08:53.486910 138105 net.cpp:160] Creating Layer loss
I1109 00:08:53.487222 138105 net.cpp:596] loss <- fc8
I1109 00:08:53.488170 138105 net.cpp:596] loss <- label
I1109 00:08:53.515396 138105 net.cpp:570] loss -> loss
I1109 00:08:53.552968 138105 layer_factory.hpp:114] Creating layer loss
I1109 00:08:56.123536 138105 net.cpp:210] Setting up loss
I1109 00:08:56.173388 138105 net.cpp:217] Top shape: (1)
I1109 00:08:56.186175 138105 net.cpp:220]     with loss weight 1
I1109 00:08:56.319010 138105 net.cpp:225] Memory required for data: 266215940
I1109 00:08:56.358947 138105 net.cpp:287] loss needs backward computation.
I1109 00:08:56.445106 138105 net.cpp:287] fc8 needs backward computation.
I1109 00:08:56.452293 138105 net.cpp:287] drop7 needs backward computation.
I1109 00:08:56.463112 138105 net.cpp:287] relu7 needs backward computation.
I1109 00:08:56.463433 138105 net.cpp:287] fc7 needs backward computation.
I1109 00:08:56.465926 138105 net.cpp:287] drop6 needs backward computation.
I1109 00:08:56.466253 138105 net.cpp:287] relu6 needs backward computation.
I1109 00:08:56.466588 138105 net.cpp:287] fc6 needs backward computation.
I1109 00:08:56.467311 138105 net.cpp:287] pool5 needs backward computation.
I1109 00:08:56.468021 138105 net.cpp:287] relu5 needs backward computation.
I1109 00:08:56.468286 138105 net.cpp:287] conv5 needs backward computation.
I1109 00:08:56.468487 138105 net.cpp:287] relu4 needs backward computation.
I1109 00:08:56.468673 138105 net.cpp:287] conv4 needs backward computation.
I1109 00:08:56.468937 138105 net.cpp:287] relu3 needs backward computation.
I1109 00:08:56.469135 138105 net.cpp:287] conv3 needs backward computation.
I1109 00:08:56.481498 138105 net.cpp:287] pool2 needs backward computation.
I1109 00:08:56.481845 138105 net.cpp:287] norm2 needs backward computation.
I1109 00:08:56.482162 138105 net.cpp:287] relu2 needs backward computation.
I1109 00:08:56.482408 138105 net.cpp:287] conv2 needs backward computation.
I1109 00:08:56.482599 138105 net.cpp:287] pool1 needs backward computation.
I1109 00:08:56.482782 138105 net.cpp:287] norm1 needs backward computation.
I1109 00:08:56.482964 138105 net.cpp:287] relu1 needs backward computation.
I1109 00:08:56.483139 138105 net.cpp:287] conv1 needs backward computation.
I1109 00:08:56.495386 138105 net.cpp:289] data does not need backward computation.
I1109 00:08:56.519829 138105 net.cpp:331] This network produces output loss
I1109 00:08:56.590914 138105 net.cpp:345] Network initialization done.
I1109 00:08:56.760985 138105 caffe.cpp:452] Performing Forward
I1109 00:09:09.872315 138105 caffe.cpp:457] Initial loss: 6.80602
I1109 00:09:09.926271 138105 caffe.cpp:459] Performing Backward
I1109 00:09:14.833873 138105 caffe.cpp:468] *** Benchmark begins ***
I1109 00:09:14.844995 138105 caffe.cpp:469] Testing for 1 iterations.
I1109 00:09:14.991585 138105 caffe.cpp:482] Profiling Layer: conv5 forward
I1109 00:09:17.481252 138105 caffe.cpp:512] Iteration: 1 forward-backward time: 2477 ms.
I1109 00:09:17.637631 138105 caffe.cpp:519] Average time per layer: 
I1109 00:09:17.654851 138105 caffe.cpp:522]       data	forward: 570.126 ms.
I1109 00:09:17.728432 138105 caffe.cpp:526]       data	backward: 4.913 ms.
I1109 00:09:17.754508 138105 caffe.cpp:522]      conv1	forward: 130.593 ms.
I1109 00:09:17.768118 138105 caffe.cpp:526]      conv1	backward: 54.039 ms.
I1109 00:09:17.774565 138105 caffe.cpp:522]      relu1	forward: 13.697 ms.
I1109 00:09:17.783383 138105 caffe.cpp:526]      relu1	backward: 16.666 ms.
I1109 00:09:17.792910 138105 caffe.cpp:522]      norm1	forward: 29.607 ms.
I1109 00:09:17.802880 138105 caffe.cpp:526]      norm1	backward: 16.563 ms.
I1109 00:09:17.811590 138105 caffe.cpp:522]      pool1	forward: 17.767 ms.
I1109 00:09:17.819725 138105 caffe.cpp:526]      pool1	backward: 88.187 ms.
I1109 00:09:17.829257 138105 caffe.cpp:522]      conv2	forward: 66.382 ms.
I1109 00:09:17.830572 138105 caffe.cpp:526]      conv2	backward: 88.231 ms.
I1109 00:09:17.830843 138105 caffe.cpp:522]      relu2	forward: 18.113 ms.
I1109 00:09:17.831037 138105 caffe.cpp:526]      relu2	backward: 29.66 ms.
I1109 00:09:17.831229 138105 caffe.cpp:522]      norm2	forward: 23.646 ms.
I1109 00:09:17.831421 138105 caffe.cpp:526]      norm2	backward: 14.23 ms.
I1109 00:09:17.831612 138105 caffe.cpp:522]      pool2	forward: 15.69 ms.
I1109 00:09:17.831802 138105 caffe.cpp:526]      pool2	backward: 68.768 ms.
I1109 00:09:17.832028 138105 caffe.cpp:522]      conv3	forward: 33.958 ms.
I1109 00:09:17.832232 138105 caffe.cpp:526]      conv3	backward: 94.346 ms.
I1109 00:09:17.832520 138105 caffe.cpp:522]      relu3	forward: 22.61 ms.
I1109 00:09:17.832758 138105 caffe.cpp:526]      relu3	backward: 41.761 ms.
I1109 00:09:17.833055 138105 caffe.cpp:522]      conv4	forward: 33.398 ms.
I1109 00:09:17.833245 138105 caffe.cpp:526]      conv4	backward: 80.963 ms.
I1109 00:09:17.833436 138105 caffe.cpp:522]      relu4	forward: 16.313 ms.
I1109 00:09:17.833626 138105 caffe.cpp:526]      relu4	backward: 34.898 ms.
I1109 00:09:17.833817 138105 caffe.cpp:522]      conv5	forward: 44.603 ms.
I1109 00:09:17.834007 138105 caffe.cpp:526]      conv5	backward: 69.257 ms.
I1109 00:09:17.834198 138105 caffe.cpp:522]      relu5	forward: 19.305 ms.
I1109 00:09:17.834389 138105 caffe.cpp:526]      relu5	backward: 16.173 ms.
I1109 00:09:17.834579 138105 caffe.cpp:522]      pool5	forward: 10.038 ms.
I1109 00:09:17.837148 138105 caffe.cpp:526]      pool5	backward: 61.357 ms.
I1109 00:09:17.837399 138105 caffe.cpp:522]        fc6	forward: 52.12 ms.
I1109 00:09:17.837595 138105 caffe.cpp:526]        fc6	backward: 56.999 ms.
I1109 00:09:17.837831 138105 caffe.cpp:522]      relu6	forward: 30.929 ms.
I1109 00:09:17.838091 138105 caffe.cpp:526]      relu6	backward: 0.091 ms.
I1109 00:09:17.840672 138105 caffe.cpp:522]      drop6	forward: 30.542 ms.
I1109 00:09:17.841017 138105 caffe.cpp:526]      drop6	backward: 0.093 ms.
I1109 00:09:17.841279 138105 caffe.cpp:522]        fc7	forward: 15.848 ms.
I1109 00:09:17.841549 138105 caffe.cpp:526]        fc7	backward: 63.253 ms.
I1109 00:09:17.841779 138105 caffe.cpp:522]      relu7	forward: 15.56 ms.
I1109 00:09:17.841971 138105 caffe.cpp:526]      relu7	backward: 0.092 ms.
I1109 00:09:17.842161 138105 caffe.cpp:522]      drop7	forward: 34.451 ms.
I1109 00:09:17.842352 138105 caffe.cpp:526]      drop7	backward: 0.096 ms.
I1109 00:09:17.842541 138105 caffe.cpp:522]        fc8	forward: 20.389 ms.
I1109 00:09:17.842732 138105 caffe.cpp:526]        fc8	backward: 103.253 ms.
I1109 00:09:17.842924 138105 caffe.cpp:522]       loss	forward: 54.531 ms.
I1109 00:09:17.843149 138105 caffe.cpp:526]       loss	backward: 57.966 ms.
I1109 00:09:17.848584 138105 caffe.cpp:532] Average Forward pass: 1379.99 ms.
I1109 00:09:17.861805 138105 caffe.cpp:535] Average Backward pass: 1070.55 ms.
I1109 00:09:17.872627 138105 caffe.cpp:537] Average Forward-Backward: 2957 ms.
I1109 00:09:17.887521 138105 caffe.cpp:540] Total Time: 2957 ms.
I1109 00:09:17.900378 138105 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 2
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 270194688
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 4323115010
--->Total double-precision FLOPs = 0
--->Total FLOPs = 4323115010
mem-read-1 = 45996
mem-read-2 = 75
mem-read-4 = 135939904
mem-read-8 = 3746432
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 28337413
mem-write-1 = 114
mem-write-2 = 34
mem-write-4 = 81249
mem-write-8 = 2115920
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 1297696
--->Total Bytes read = 2387371714
--->Total Bytes written = 100305146
--->Total Bytes = 2487676860
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer14_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=14 -prof_forward_direction=1
I1109 00:13:08.531112 138227 caffe.cpp:444] Use CPU.
I1109 00:13:25.438035 138227 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:13:25.493477 138227 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:13:25.505009 138227 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:13:25.517349 138227 cpu_info.cpp:461] Total number of processors: 272
I1109 00:13:25.528295 138227 cpu_info.cpp:464] GPU is used: no
I1109 00:13:25.537317 138227 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:13:25.546159 138227 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:13:25.557389 138227 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:13:34.250186 138227 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:13:34.281325 138227 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:13:34.918927 138227 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:13:37.377408 138227 layer_factory.hpp:114] Creating layer data
I1109 00:13:37.524098 138227 net.cpp:160] Creating Layer data
I1109 00:13:37.571931 138227 net.cpp:570] data -> data
I1109 00:13:38.041154 138227 net.cpp:570] data -> label
I1109 00:13:45.100064 138227 net.cpp:210] Setting up data
I1109 00:13:45.189648 138227 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:13:45.293071 138227 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:13:45.300104 138227 net.cpp:225] Memory required for data: 19787264
I1109 00:13:45.367542 138227 layer_factory.hpp:114] Creating layer conv1
I1109 00:13:45.697146 138227 net.cpp:160] Creating Layer conv1
I1109 00:13:45.747350 138227 net.cpp:596] conv1 <- data
I1109 00:13:45.867130 138227 net.cpp:570] conv1 -> conv1
I1109 00:14:18.811393 138227 net.cpp:210] Setting up conv1
I1109 00:14:18.818219 138227 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:14:18.818612 138227 net.cpp:225] Memory required for data: 56958464
I1109 00:14:19.099093 138227 layer_factory.hpp:114] Creating layer relu1
I1109 00:14:19.223506 138227 net.cpp:160] Creating Layer relu1
I1109 00:14:19.228382 138227 net.cpp:596] relu1 <- conv1
I1109 00:14:19.261659 138227 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:14:19.453737 138227 net.cpp:210] Setting up relu1
I1109 00:14:19.456163 138227 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:14:19.456498 138227 net.cpp:225] Memory required for data: 94129664
I1109 00:14:19.456732 138227 layer_factory.hpp:114] Creating layer norm1
I1109 00:14:19.563138 138227 net.cpp:160] Creating Layer norm1
I1109 00:14:19.563467 138227 net.cpp:596] norm1 <- conv1
I1109 00:14:19.566150 138227 net.cpp:570] norm1 -> norm1
I1109 00:14:19.790024 138227 net.cpp:210] Setting up norm1
I1109 00:14:19.802891 138227 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:14:19.803274 138227 net.cpp:225] Memory required for data: 131300864
I1109 00:14:19.803611 138227 layer_factory.hpp:114] Creating layer pool1
I1109 00:14:19.897791 138227 net.cpp:160] Creating Layer pool1
I1109 00:14:19.898104 138227 net.cpp:596] pool1 <- norm1
I1109 00:14:19.912900 138227 net.cpp:570] pool1 -> pool1
I1109 00:14:20.216277 138227 net.cpp:210] Setting up pool1
I1109 00:14:20.218906 138227 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:14:20.219296 138227 net.cpp:225] Memory required for data: 140258816
I1109 00:14:20.219540 138227 layer_factory.hpp:114] Creating layer conv2
I1109 00:14:20.219956 138227 net.cpp:160] Creating Layer conv2
I1109 00:14:20.220201 138227 net.cpp:596] conv2 <- pool1
I1109 00:14:20.220458 138227 net.cpp:570] conv2 -> conv2
I1109 00:14:25.986338 138227 net.cpp:210] Setting up conv2
I1109 00:14:25.986673 138227 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:14:25.987068 138227 net.cpp:225] Memory required for data: 164146688
I1109 00:14:26.038014 138227 layer_factory.hpp:114] Creating layer relu2
I1109 00:14:26.038437 138227 net.cpp:160] Creating Layer relu2
I1109 00:14:26.038811 138227 net.cpp:596] relu2 <- conv2
I1109 00:14:26.039072 138227 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:14:26.039539 138227 net.cpp:210] Setting up relu2
I1109 00:14:26.039808 138227 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:14:26.040037 138227 net.cpp:225] Memory required for data: 188034560
I1109 00:14:26.040220 138227 layer_factory.hpp:114] Creating layer norm2
I1109 00:14:26.040462 138227 net.cpp:160] Creating Layer norm2
I1109 00:14:26.040660 138227 net.cpp:596] norm2 <- conv2
I1109 00:14:26.040971 138227 net.cpp:570] norm2 -> norm2
I1109 00:14:26.043033 138227 net.cpp:210] Setting up norm2
I1109 00:14:26.043341 138227 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:14:26.043573 138227 net.cpp:225] Memory required for data: 211922432
I1109 00:14:26.043761 138227 layer_factory.hpp:114] Creating layer pool2
I1109 00:14:26.044073 138227 net.cpp:160] Creating Layer pool2
I1109 00:14:26.044317 138227 net.cpp:596] pool2 <- norm2
I1109 00:14:26.044711 138227 net.cpp:570] pool2 -> pool2
I1109 00:14:26.045213 138227 net.cpp:210] Setting up pool2
I1109 00:14:26.045454 138227 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:14:26.045676 138227 net.cpp:225] Memory required for data: 217460224
I1109 00:14:26.045871 138227 layer_factory.hpp:114] Creating layer conv3
I1109 00:14:26.046196 138227 net.cpp:160] Creating Layer conv3
I1109 00:14:26.046413 138227 net.cpp:596] conv3 <- pool2
I1109 00:14:26.046653 138227 net.cpp:570] conv3 -> conv3
I1109 00:14:26.529115 138227 net.cpp:210] Setting up conv3
I1109 00:14:26.531582 138227 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:14:26.531947 138227 net.cpp:225] Memory required for data: 225766912
I1109 00:14:26.535118 138227 layer_factory.hpp:114] Creating layer relu3
I1109 00:14:26.535534 138227 net.cpp:160] Creating Layer relu3
I1109 00:14:26.535851 138227 net.cpp:596] relu3 <- conv3
I1109 00:14:26.536142 138227 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:14:26.540434 138227 net.cpp:210] Setting up relu3
I1109 00:14:26.540760 138227 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:14:26.541151 138227 net.cpp:225] Memory required for data: 234073600
I1109 00:14:26.541416 138227 layer_factory.hpp:114] Creating layer conv4
I1109 00:14:26.541807 138227 net.cpp:160] Creating Layer conv4
I1109 00:14:26.542083 138227 net.cpp:596] conv4 <- conv3
I1109 00:14:26.542393 138227 net.cpp:570] conv4 -> conv4
I1109 00:14:26.787066 138227 net.cpp:210] Setting up conv4
I1109 00:14:26.787457 138227 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:14:26.787928 138227 net.cpp:225] Memory required for data: 242380288
I1109 00:14:26.788282 138227 layer_factory.hpp:114] Creating layer relu4
I1109 00:14:26.788591 138227 net.cpp:160] Creating Layer relu4
I1109 00:14:26.788877 138227 net.cpp:596] relu4 <- conv4
I1109 00:14:26.789145 138227 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:14:26.801497 138227 net.cpp:210] Setting up relu4
I1109 00:14:26.801844 138227 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:14:26.802253 138227 net.cpp:225] Memory required for data: 250686976
I1109 00:14:26.802469 138227 layer_factory.hpp:114] Creating layer conv5
I1109 00:14:26.802835 138227 net.cpp:160] Creating Layer conv5
I1109 00:14:26.803084 138227 net.cpp:596] conv5 <- conv4
I1109 00:14:26.803331 138227 net.cpp:570] conv5 -> conv5
I1109 00:14:26.971882 138227 net.cpp:210] Setting up conv5
I1109 00:14:26.972270 138227 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:14:26.972698 138227 net.cpp:225] Memory required for data: 256224768
I1109 00:14:26.977475 138227 layer_factory.hpp:114] Creating layer relu5
I1109 00:14:26.977921 138227 net.cpp:160] Creating Layer relu5
I1109 00:14:26.978191 138227 net.cpp:596] relu5 <- conv5
I1109 00:14:26.978482 138227 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:14:26.979048 138227 net.cpp:210] Setting up relu5
I1109 00:14:26.979343 138227 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:14:26.979593 138227 net.cpp:225] Memory required for data: 261762560
I1109 00:14:26.979802 138227 layer_factory.hpp:114] Creating layer pool5
I1109 00:14:26.980067 138227 net.cpp:160] Creating Layer pool5
I1109 00:14:26.980285 138227 net.cpp:596] pool5 <- conv5
I1109 00:14:26.980514 138227 net.cpp:570] pool5 -> pool5
I1109 00:14:26.981001 138227 net.cpp:210] Setting up pool5
I1109 00:14:26.981341 138227 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:14:26.981577 138227 net.cpp:225] Memory required for data: 262942208
I1109 00:14:26.981763 138227 layer_factory.hpp:114] Creating layer fc6
I1109 00:14:27.036260 138227 net.cpp:160] Creating Layer fc6
I1109 00:14:27.036568 138227 net.cpp:596] fc6 <- pool5
I1109 00:14:27.036983 138227 net.cpp:570] fc6 -> fc6
I1109 00:14:31.176061 138227 net.cpp:210] Setting up fc6
I1109 00:14:31.176398 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:31.178603 138227 net.cpp:225] Memory required for data: 263466496
I1109 00:14:31.178920 138227 layer_factory.hpp:114] Creating layer relu6
I1109 00:14:31.181476 138227 net.cpp:160] Creating Layer relu6
I1109 00:14:31.181772 138227 net.cpp:596] relu6 <- fc6
I1109 00:14:31.182005 138227 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:14:31.182428 138227 net.cpp:210] Setting up relu6
I1109 00:14:31.182683 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:31.182907 138227 net.cpp:225] Memory required for data: 263990784
I1109 00:14:31.183092 138227 layer_factory.hpp:114] Creating layer drop6
I1109 00:14:31.203398 138227 net.cpp:160] Creating Layer drop6
I1109 00:14:31.203704 138227 net.cpp:596] drop6 <- fc6
I1109 00:14:31.204061 138227 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:14:31.307080 138227 net.cpp:210] Setting up drop6
I1109 00:14:31.307375 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:31.307714 138227 net.cpp:225] Memory required for data: 264515072
I1109 00:14:31.307958 138227 layer_factory.hpp:114] Creating layer fc7
I1109 00:14:31.308248 138227 net.cpp:160] Creating Layer fc7
I1109 00:14:31.308465 138227 net.cpp:596] fc7 <- fc6
I1109 00:14:31.308869 138227 net.cpp:570] fc7 -> fc7
I1109 00:14:33.033073 138227 net.cpp:210] Setting up fc7
I1109 00:14:33.033426 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:33.033823 138227 net.cpp:225] Memory required for data: 265039360
I1109 00:14:33.034173 138227 layer_factory.hpp:114] Creating layer relu7
I1109 00:14:33.034492 138227 net.cpp:160] Creating Layer relu7
I1109 00:14:33.034736 138227 net.cpp:596] relu7 <- fc7
I1109 00:14:33.034976 138227 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:14:33.035410 138227 net.cpp:210] Setting up relu7
I1109 00:14:33.035688 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:33.035926 138227 net.cpp:225] Memory required for data: 265563648
I1109 00:14:33.036151 138227 layer_factory.hpp:114] Creating layer drop7
I1109 00:14:33.036396 138227 net.cpp:160] Creating Layer drop7
I1109 00:14:33.036617 138227 net.cpp:596] drop7 <- fc7
I1109 00:14:33.036924 138227 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:14:33.037212 138227 net.cpp:210] Setting up drop7
I1109 00:14:33.037421 138227 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:14:33.037634 138227 net.cpp:225] Memory required for data: 266087936
I1109 00:14:33.037816 138227 layer_factory.hpp:114] Creating layer fc8
I1109 00:14:33.038086 138227 net.cpp:160] Creating Layer fc8
I1109 00:14:33.038290 138227 net.cpp:596] fc8 <- fc7
I1109 00:14:33.038518 138227 net.cpp:570] fc8 -> fc8
I1109 00:14:33.462442 138227 net.cpp:210] Setting up fc8
I1109 00:14:33.462785 138227 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:14:33.463162 138227 net.cpp:225] Memory required for data: 266215936
I1109 00:14:33.463485 138227 layer_factory.hpp:114] Creating layer loss
I1109 00:14:33.487959 138227 net.cpp:160] Creating Layer loss
I1109 00:14:33.488276 138227 net.cpp:596] loss <- fc8
I1109 00:14:33.489321 138227 net.cpp:596] loss <- label
I1109 00:14:33.516728 138227 net.cpp:570] loss -> loss
I1109 00:14:33.554787 138227 layer_factory.hpp:114] Creating layer loss
I1109 00:14:36.109774 138227 net.cpp:210] Setting up loss
I1109 00:14:36.160882 138227 net.cpp:217] Top shape: (1)
I1109 00:14:36.173784 138227 net.cpp:220]     with loss weight 1
I1109 00:14:36.299098 138227 net.cpp:225] Memory required for data: 266215940
I1109 00:14:36.343452 138227 net.cpp:287] loss needs backward computation.
I1109 00:14:36.431542 138227 net.cpp:287] fc8 needs backward computation.
I1109 00:14:36.438907 138227 net.cpp:287] drop7 needs backward computation.
I1109 00:14:36.450032 138227 net.cpp:287] relu7 needs backward computation.
I1109 00:14:36.450353 138227 net.cpp:287] fc7 needs backward computation.
I1109 00:14:36.452821 138227 net.cpp:287] drop6 needs backward computation.
I1109 00:14:36.453233 138227 net.cpp:287] relu6 needs backward computation.
I1109 00:14:36.453511 138227 net.cpp:287] fc6 needs backward computation.
I1109 00:14:36.454188 138227 net.cpp:287] pool5 needs backward computation.
I1109 00:14:36.454943 138227 net.cpp:287] relu5 needs backward computation.
I1109 00:14:36.455214 138227 net.cpp:287] conv5 needs backward computation.
I1109 00:14:36.455447 138227 net.cpp:287] relu4 needs backward computation.
I1109 00:14:36.455649 138227 net.cpp:287] conv4 needs backward computation.
I1109 00:14:36.455966 138227 net.cpp:287] relu3 needs backward computation.
I1109 00:14:36.456220 138227 net.cpp:287] conv3 needs backward computation.
I1109 00:14:36.468556 138227 net.cpp:287] pool2 needs backward computation.
I1109 00:14:36.468945 138227 net.cpp:287] norm2 needs backward computation.
I1109 00:14:36.469279 138227 net.cpp:287] relu2 needs backward computation.
I1109 00:14:36.469501 138227 net.cpp:287] conv2 needs backward computation.
I1109 00:14:36.469688 138227 net.cpp:287] pool1 needs backward computation.
I1109 00:14:36.469868 138227 net.cpp:287] norm1 needs backward computation.
I1109 00:14:36.470047 138227 net.cpp:287] relu1 needs backward computation.
I1109 00:14:36.470222 138227 net.cpp:287] conv1 needs backward computation.
I1109 00:14:36.482621 138227 net.cpp:289] data does not need backward computation.
I1109 00:14:36.507200 138227 net.cpp:331] This network produces output loss
I1109 00:14:36.578672 138227 net.cpp:345] Network initialization done.
I1109 00:14:36.747288 138227 caffe.cpp:452] Performing Forward
I1109 00:14:49.703694 138227 caffe.cpp:457] Initial loss: 6.80725
I1109 00:14:49.757824 138227 caffe.cpp:459] Performing Backward
I1109 00:14:54.393213 138227 caffe.cpp:468] *** Benchmark begins ***
I1109 00:14:54.404510 138227 caffe.cpp:469] Testing for 1 iterations.
I1109 00:14:54.546049 138227 caffe.cpp:482] Profiling Layer: relu5 forward
I1109 00:14:56.640915 138227 caffe.cpp:512] Iteration: 1 forward-backward time: 2083 ms.
I1109 00:14:56.802152 138227 caffe.cpp:519] Average time per layer: 
I1109 00:14:56.819448 138227 caffe.cpp:522]       data	forward: 548.628 ms.
I1109 00:14:56.894654 138227 caffe.cpp:526]       data	backward: 5.093 ms.
I1109 00:14:56.919772 138227 caffe.cpp:522]      conv1	forward: 131.248 ms.
I1109 00:14:56.929770 138227 caffe.cpp:526]      conv1	backward: 47.362 ms.
I1109 00:14:56.932312 138227 caffe.cpp:522]      relu1	forward: 16.218 ms.
I1109 00:14:56.934458 138227 caffe.cpp:526]      relu1	backward: 19.784 ms.
I1109 00:14:56.936883 138227 caffe.cpp:522]      norm1	forward: 21.501 ms.
I1109 00:14:56.940851 138227 caffe.cpp:526]      norm1	backward: 21.825 ms.
I1109 00:14:56.950522 138227 caffe.cpp:522]      pool1	forward: 19.178 ms.
I1109 00:14:56.960294 138227 caffe.cpp:526]      pool1	backward: 79.509 ms.
I1109 00:14:56.971456 138227 caffe.cpp:522]      conv2	forward: 68.737 ms.
I1109 00:14:56.977494 138227 caffe.cpp:526]      conv2	backward: 79.79 ms.
I1109 00:14:56.989898 138227 caffe.cpp:522]      relu2	forward: 14.812 ms.
I1109 00:14:56.996035 138227 caffe.cpp:526]      relu2	backward: 14.69 ms.
I1109 00:14:56.999953 138227 caffe.cpp:522]      norm2	forward: 16.654 ms.
I1109 00:14:57.007766 138227 caffe.cpp:526]      norm2	backward: 18.001 ms.
I1109 00:14:57.011215 138227 caffe.cpp:522]      pool2	forward: 14.455 ms.
I1109 00:14:57.011461 138227 caffe.cpp:526]      pool2	backward: 62.506 ms.
I1109 00:14:57.011660 138227 caffe.cpp:522]      conv3	forward: 42.064 ms.
I1109 00:14:57.011857 138227 caffe.cpp:526]      conv3	backward: 86.877 ms.
I1109 00:14:57.012053 138227 caffe.cpp:522]      relu3	forward: 13.06 ms.
I1109 00:14:57.012246 138227 caffe.cpp:526]      relu3	backward: 0.693 ms.
I1109 00:14:57.012456 138227 caffe.cpp:522]      conv4	forward: 28.926 ms.
I1109 00:14:57.012650 138227 caffe.cpp:526]      conv4	backward: 27.994 ms.
I1109 00:14:57.012886 138227 caffe.cpp:522]      relu4	forward: 16.955 ms.
I1109 00:14:57.013125 138227 caffe.cpp:526]      relu4	backward: 7.546 ms.
I1109 00:14:57.013350 138227 caffe.cpp:522]      conv5	forward: 35.411 ms.
I1109 00:14:57.013664 138227 caffe.cpp:526]      conv5	backward: 18.793 ms.
I1109 00:14:57.013898 138227 caffe.cpp:522]      relu5	forward: 32.422 ms.
I1109 00:14:57.014092 138227 caffe.cpp:526]      relu5	backward: 0.236 ms.
I1109 00:14:57.014283 138227 caffe.cpp:522]      pool5	forward: 13.759 ms.
I1109 00:14:57.014475 138227 caffe.cpp:526]      pool5	backward: 11.974 ms.
I1109 00:14:57.014667 138227 caffe.cpp:522]        fc6	forward: 47.198 ms.
I1109 00:14:57.014858 138227 caffe.cpp:526]        fc6	backward: 33.06 ms.
I1109 00:14:57.015049 138227 caffe.cpp:522]      relu6	forward: 14.55 ms.
I1109 00:14:57.015240 138227 caffe.cpp:526]      relu6	backward: 0.08 ms.
I1109 00:14:57.017873 138227 caffe.cpp:522]      drop6	forward: 31.632 ms.
I1109 00:14:57.018129 138227 caffe.cpp:526]      drop6	backward: 0.086 ms.
I1109 00:14:57.018333 138227 caffe.cpp:522]        fc7	forward: 13.592 ms.
I1109 00:14:57.018566 138227 caffe.cpp:526]        fc7	backward: 20.304 ms.
I1109 00:14:57.018779 138227 caffe.cpp:522]      relu7	forward: 14.4 ms.
I1109 00:14:57.019091 138227 caffe.cpp:526]      relu7	backward: 0.089 ms.
I1109 00:14:57.019335 138227 caffe.cpp:522]      drop7	forward: 34.839 ms.
I1109 00:14:57.019605 138227 caffe.cpp:526]      drop7	backward: 0.095 ms.
I1109 00:14:57.019829 138227 caffe.cpp:522]        fc8	forward: 18.497 ms.
I1109 00:14:57.020022 138227 caffe.cpp:526]        fc8	backward: 95.382 ms.
I1109 00:14:57.020215 138227 caffe.cpp:522]       loss	forward: 53.823 ms.
I1109 00:14:57.020406 138227 caffe.cpp:526]       loss	backward: 69.217 ms.
I1109 00:14:57.026073 138227 caffe.cpp:532] Average Forward pass: 1324.11 ms.
I1109 00:14:57.040618 138227 caffe.cpp:535] Average Backward pass: 729.76 ms.
I1109 00:14:57.051414 138227 caffe.cpp:537] Average Forward-Backward: 2579 ms.
I1109 00:14:57.066018 138227 caffe.cpp:540] Total Time: 2579 ms.
I1109 00:14:57.078101 138227 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 86528
elements_fp_double_1 = 0
elements_fp_double_2 = 86528
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 1384449
--->Total double-precision FLOPs = 173056
--->Total FLOPs = 1557505
mem-read-1 = 31052
mem-read-2 = 34
mem-read-4 = 249324
mem-read-8 = 345753
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 173073
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 568
mem-write-8 = 33174
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 86529
--->Total Bytes read = 14871144
--->Total Bytes written = 5805636
--->Total Bytes = 20676780
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer15_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=15 -prof_forward_direction=1
I1109 00:18:44.369244 138384 caffe.cpp:444] Use CPU.
I1109 00:19:01.311909 138384 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:19:01.367764 138384 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:19:01.379763 138384 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:19:01.392396 138384 cpu_info.cpp:461] Total number of processors: 272
I1109 00:19:01.403677 138384 cpu_info.cpp:464] GPU is used: no
I1109 00:19:01.412925 138384 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:19:01.421804 138384 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:19:01.432770 138384 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:19:10.233883 138384 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:19:10.265151 138384 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:19:10.896991 138384 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:19:13.355038 138384 layer_factory.hpp:114] Creating layer data
I1109 00:19:13.502166 138384 net.cpp:160] Creating Layer data
I1109 00:19:13.550218 138384 net.cpp:570] data -> data
I1109 00:19:14.018079 138384 net.cpp:570] data -> label
I1109 00:19:21.227663 138384 net.cpp:210] Setting up data
I1109 00:19:21.308966 138384 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:19:21.415326 138384 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:19:21.422505 138384 net.cpp:225] Memory required for data: 19787264
I1109 00:19:21.489734 138384 layer_factory.hpp:114] Creating layer conv1
I1109 00:19:21.816390 138384 net.cpp:160] Creating Layer conv1
I1109 00:19:21.868541 138384 net.cpp:596] conv1 <- data
I1109 00:19:21.993294 138384 net.cpp:570] conv1 -> conv1
I1109 00:19:54.794127 138384 net.cpp:210] Setting up conv1
I1109 00:19:54.801259 138384 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:19:54.801609 138384 net.cpp:225] Memory required for data: 56958464
I1109 00:19:55.079969 138384 layer_factory.hpp:114] Creating layer relu1
I1109 00:19:55.205312 138384 net.cpp:160] Creating Layer relu1
I1109 00:19:55.209931 138384 net.cpp:596] relu1 <- conv1
I1109 00:19:55.242673 138384 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:19:55.432699 138384 net.cpp:210] Setting up relu1
I1109 00:19:55.435207 138384 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:19:55.435547 138384 net.cpp:225] Memory required for data: 94129664
I1109 00:19:55.435788 138384 layer_factory.hpp:114] Creating layer norm1
I1109 00:19:55.544963 138384 net.cpp:160] Creating Layer norm1
I1109 00:19:55.545331 138384 net.cpp:596] norm1 <- conv1
I1109 00:19:55.547888 138384 net.cpp:570] norm1 -> norm1
I1109 00:19:55.774199 138384 net.cpp:210] Setting up norm1
I1109 00:19:55.787158 138384 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:19:55.787567 138384 net.cpp:225] Memory required for data: 131300864
I1109 00:19:55.787899 138384 layer_factory.hpp:114] Creating layer pool1
I1109 00:19:55.882357 138384 net.cpp:160] Creating Layer pool1
I1109 00:19:55.882671 138384 net.cpp:596] pool1 <- norm1
I1109 00:19:55.898257 138384 net.cpp:570] pool1 -> pool1
I1109 00:19:56.201455 138384 net.cpp:210] Setting up pool1
I1109 00:19:56.203912 138384 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:19:56.204237 138384 net.cpp:225] Memory required for data: 140258816
I1109 00:19:56.204447 138384 layer_factory.hpp:114] Creating layer conv2
I1109 00:19:56.204866 138384 net.cpp:160] Creating Layer conv2
I1109 00:19:56.205121 138384 net.cpp:596] conv2 <- pool1
I1109 00:19:56.205394 138384 net.cpp:570] conv2 -> conv2
I1109 00:20:01.990972 138384 net.cpp:210] Setting up conv2
I1109 00:20:01.991303 138384 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:20:01.991735 138384 net.cpp:225] Memory required for data: 164146688
I1109 00:20:02.041817 138384 layer_factory.hpp:114] Creating layer relu2
I1109 00:20:02.042233 138384 net.cpp:160] Creating Layer relu2
I1109 00:20:02.042589 138384 net.cpp:596] relu2 <- conv2
I1109 00:20:02.042839 138384 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:20:02.043279 138384 net.cpp:210] Setting up relu2
I1109 00:20:02.043545 138384 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:20:02.043769 138384 net.cpp:225] Memory required for data: 188034560
I1109 00:20:02.043956 138384 layer_factory.hpp:114] Creating layer norm2
I1109 00:20:02.044198 138384 net.cpp:160] Creating Layer norm2
I1109 00:20:02.044389 138384 net.cpp:596] norm2 <- conv2
I1109 00:20:02.044616 138384 net.cpp:570] norm2 -> norm2
I1109 00:20:02.046742 138384 net.cpp:210] Setting up norm2
I1109 00:20:02.047052 138384 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:20:02.047278 138384 net.cpp:225] Memory required for data: 211922432
I1109 00:20:02.047466 138384 layer_factory.hpp:114] Creating layer pool2
I1109 00:20:02.048403 138384 net.cpp:160] Creating Layer pool2
I1109 00:20:02.048750 138384 net.cpp:596] pool2 <- norm2
I1109 00:20:02.049059 138384 net.cpp:570] pool2 -> pool2
I1109 00:20:02.049470 138384 net.cpp:210] Setting up pool2
I1109 00:20:02.049713 138384 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:20:02.049933 138384 net.cpp:225] Memory required for data: 217460224
I1109 00:20:02.050132 138384 layer_factory.hpp:114] Creating layer conv3
I1109 00:20:02.050462 138384 net.cpp:160] Creating Layer conv3
I1109 00:20:02.050709 138384 net.cpp:596] conv3 <- pool2
I1109 00:20:02.050966 138384 net.cpp:570] conv3 -> conv3
I1109 00:20:02.526612 138384 net.cpp:210] Setting up conv3
I1109 00:20:02.529016 138384 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:20:02.529367 138384 net.cpp:225] Memory required for data: 225766912
I1109 00:20:02.532361 138384 layer_factory.hpp:114] Creating layer relu3
I1109 00:20:02.532759 138384 net.cpp:160] Creating Layer relu3
I1109 00:20:02.533069 138384 net.cpp:596] relu3 <- conv3
I1109 00:20:02.533313 138384 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:20:02.537447 138384 net.cpp:210] Setting up relu3
I1109 00:20:02.537782 138384 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:20:02.538023 138384 net.cpp:225] Memory required for data: 234073600
I1109 00:20:02.538218 138384 layer_factory.hpp:114] Creating layer conv4
I1109 00:20:02.538584 138384 net.cpp:160] Creating Layer conv4
I1109 00:20:02.538837 138384 net.cpp:596] conv4 <- conv3
I1109 00:20:02.539083 138384 net.cpp:570] conv4 -> conv4
I1109 00:20:02.810027 138384 net.cpp:210] Setting up conv4
I1109 00:20:02.810420 138384 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:20:02.810824 138384 net.cpp:225] Memory required for data: 242380288
I1109 00:20:02.811164 138384 layer_factory.hpp:114] Creating layer relu4
I1109 00:20:02.811465 138384 net.cpp:160] Creating Layer relu4
I1109 00:20:02.811693 138384 net.cpp:596] relu4 <- conv4
I1109 00:20:02.811939 138384 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:20:02.824352 138384 net.cpp:210] Setting up relu4
I1109 00:20:02.824702 138384 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:20:02.825125 138384 net.cpp:225] Memory required for data: 250686976
I1109 00:20:02.825353 138384 layer_factory.hpp:114] Creating layer conv5
I1109 00:20:02.825747 138384 net.cpp:160] Creating Layer conv5
I1109 00:20:02.826006 138384 net.cpp:596] conv5 <- conv4
I1109 00:20:02.826262 138384 net.cpp:570] conv5 -> conv5
I1109 00:20:02.994627 138384 net.cpp:210] Setting up conv5
I1109 00:20:02.995023 138384 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:20:02.995434 138384 net.cpp:225] Memory required for data: 256224768
I1109 00:20:03.000030 138384 layer_factory.hpp:114] Creating layer relu5
I1109 00:20:03.004724 138384 net.cpp:160] Creating Layer relu5
I1109 00:20:03.007061 138384 net.cpp:596] relu5 <- conv5
I1109 00:20:03.007380 138384 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:20:03.007874 138384 net.cpp:210] Setting up relu5
I1109 00:20:03.008183 138384 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:20:03.008445 138384 net.cpp:225] Memory required for data: 261762560
I1109 00:20:03.008672 138384 layer_factory.hpp:114] Creating layer pool5
I1109 00:20:03.009008 138384 net.cpp:160] Creating Layer pool5
I1109 00:20:03.009248 138384 net.cpp:596] pool5 <- conv5
I1109 00:20:03.009487 138384 net.cpp:570] pool5 -> pool5
I1109 00:20:03.009905 138384 net.cpp:210] Setting up pool5
I1109 00:20:03.010180 138384 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:20:03.010418 138384 net.cpp:225] Memory required for data: 262942208
I1109 00:20:03.010612 138384 layer_factory.hpp:114] Creating layer fc6
I1109 00:20:03.065033 138384 net.cpp:160] Creating Layer fc6
I1109 00:20:03.065342 138384 net.cpp:596] fc6 <- pool5
I1109 00:20:03.065699 138384 net.cpp:570] fc6 -> fc6
I1109 00:20:07.152760 138384 net.cpp:210] Setting up fc6
I1109 00:20:07.153111 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:07.155297 138384 net.cpp:225] Memory required for data: 263466496
I1109 00:20:07.155602 138384 layer_factory.hpp:114] Creating layer relu6
I1109 00:20:07.158116 138384 net.cpp:160] Creating Layer relu6
I1109 00:20:07.158417 138384 net.cpp:596] relu6 <- fc6
I1109 00:20:07.158646 138384 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:20:07.159057 138384 net.cpp:210] Setting up relu6
I1109 00:20:07.159312 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:07.159533 138384 net.cpp:225] Memory required for data: 263990784
I1109 00:20:07.159718 138384 layer_factory.hpp:114] Creating layer drop6
I1109 00:20:07.179693 138384 net.cpp:160] Creating Layer drop6
I1109 00:20:07.179999 138384 net.cpp:596] drop6 <- fc6
I1109 00:20:07.180398 138384 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:20:07.285024 138384 net.cpp:210] Setting up drop6
I1109 00:20:07.285316 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:07.285670 138384 net.cpp:225] Memory required for data: 264515072
I1109 00:20:07.285876 138384 layer_factory.hpp:114] Creating layer fc7
I1109 00:20:07.286144 138384 net.cpp:160] Creating Layer fc7
I1109 00:20:07.286348 138384 net.cpp:596] fc7 <- fc6
I1109 00:20:07.286722 138384 net.cpp:570] fc7 -> fc7
I1109 00:20:08.999181 138384 net.cpp:210] Setting up fc7
I1109 00:20:08.999559 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:09.000007 138384 net.cpp:225] Memory required for data: 265039360
I1109 00:20:09.000345 138384 layer_factory.hpp:114] Creating layer relu7
I1109 00:20:09.000684 138384 net.cpp:160] Creating Layer relu7
I1109 00:20:09.000996 138384 net.cpp:596] relu7 <- fc7
I1109 00:20:09.001272 138384 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:20:09.001729 138384 net.cpp:210] Setting up relu7
I1109 00:20:09.002029 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:09.002282 138384 net.cpp:225] Memory required for data: 265563648
I1109 00:20:09.002487 138384 layer_factory.hpp:114] Creating layer drop7
I1109 00:20:09.002764 138384 net.cpp:160] Creating Layer drop7
I1109 00:20:09.002991 138384 net.cpp:596] drop7 <- fc7
I1109 00:20:09.003259 138384 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:20:09.003640 138384 net.cpp:210] Setting up drop7
I1109 00:20:09.003854 138384 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:20:09.004078 138384 net.cpp:225] Memory required for data: 266087936
I1109 00:20:09.004271 138384 layer_factory.hpp:114] Creating layer fc8
I1109 00:20:09.004531 138384 net.cpp:160] Creating Layer fc8
I1109 00:20:09.004741 138384 net.cpp:596] fc8 <- fc7
I1109 00:20:09.005043 138384 net.cpp:570] fc8 -> fc8
I1109 00:20:09.426471 138384 net.cpp:210] Setting up fc8
I1109 00:20:09.426867 138384 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:20:09.427291 138384 net.cpp:225] Memory required for data: 266215936
I1109 00:20:09.427629 138384 layer_factory.hpp:114] Creating layer loss
I1109 00:20:09.452723 138384 net.cpp:160] Creating Layer loss
I1109 00:20:09.453090 138384 net.cpp:596] loss <- fc8
I1109 00:20:09.454119 138384 net.cpp:596] loss <- label
I1109 00:20:09.481933 138384 net.cpp:570] loss -> loss
I1109 00:20:09.520238 138384 layer_factory.hpp:114] Creating layer loss
I1109 00:20:12.154687 138384 net.cpp:210] Setting up loss
I1109 00:20:12.205910 138384 net.cpp:217] Top shape: (1)
I1109 00:20:12.216719 138384 net.cpp:220]     with loss weight 1
I1109 00:20:12.348991 138384 net.cpp:225] Memory required for data: 266215940
I1109 00:20:12.392137 138384 net.cpp:287] loss needs backward computation.
I1109 00:20:12.479451 138384 net.cpp:287] fc8 needs backward computation.
I1109 00:20:12.486726 138384 net.cpp:287] drop7 needs backward computation.
I1109 00:20:12.497740 138384 net.cpp:287] relu7 needs backward computation.
I1109 00:20:12.498067 138384 net.cpp:287] fc7 needs backward computation.
I1109 00:20:12.500463 138384 net.cpp:287] drop6 needs backward computation.
I1109 00:20:12.500851 138384 net.cpp:287] relu6 needs backward computation.
I1109 00:20:12.501072 138384 net.cpp:287] fc6 needs backward computation.
I1109 00:20:12.501900 138384 net.cpp:287] pool5 needs backward computation.
I1109 00:20:12.502671 138384 net.cpp:287] relu5 needs backward computation.
I1109 00:20:12.502938 138384 net.cpp:287] conv5 needs backward computation.
I1109 00:20:12.503136 138384 net.cpp:287] relu4 needs backward computation.
I1109 00:20:12.503326 138384 net.cpp:287] conv4 needs backward computation.
I1109 00:20:12.503515 138384 net.cpp:287] relu3 needs backward computation.
I1109 00:20:12.503695 138384 net.cpp:287] conv3 needs backward computation.
I1109 00:20:12.517400 138384 net.cpp:287] pool2 needs backward computation.
I1109 00:20:12.517771 138384 net.cpp:287] norm2 needs backward computation.
I1109 00:20:12.518122 138384 net.cpp:287] relu2 needs backward computation.
I1109 00:20:12.518334 138384 net.cpp:287] conv2 needs backward computation.
I1109 00:20:12.518528 138384 net.cpp:287] pool1 needs backward computation.
I1109 00:20:12.518712 138384 net.cpp:287] norm1 needs backward computation.
I1109 00:20:12.518893 138384 net.cpp:287] relu1 needs backward computation.
I1109 00:20:12.519069 138384 net.cpp:287] conv1 needs backward computation.
I1109 00:20:12.531613 138384 net.cpp:289] data does not need backward computation.
I1109 00:20:12.556715 138384 net.cpp:331] This network produces output loss
I1109 00:20:12.628934 138384 net.cpp:345] Network initialization done.
I1109 00:20:12.797371 138384 caffe.cpp:452] Performing Forward
I1109 00:20:25.692715 138384 caffe.cpp:457] Initial loss: 6.95742
I1109 00:20:25.746773 138384 caffe.cpp:459] Performing Backward
I1109 00:20:30.529038 138384 caffe.cpp:468] *** Benchmark begins ***
I1109 00:20:30.536903 138384 caffe.cpp:469] Testing for 1 iterations.
I1109 00:20:30.685796 138384 caffe.cpp:482] Profiling Layer: pool5 forward
I1109 00:20:32.904480 138384 caffe.cpp:512] Iteration: 1 forward-backward time: 2214 ms.
I1109 00:20:33.058917 138384 caffe.cpp:519] Average time per layer: 
I1109 00:20:33.074658 138384 caffe.cpp:522]       data	forward: 546.514 ms.
I1109 00:20:33.144459 138384 caffe.cpp:526]       data	backward: 3.661 ms.
I1109 00:20:33.167568 138384 caffe.cpp:522]      conv1	forward: 138.49 ms.
I1109 00:20:33.168368 138384 caffe.cpp:526]      conv1	backward: 21.4 ms.
I1109 00:20:33.172539 138384 caffe.cpp:522]      relu1	forward: 19.867 ms.
I1109 00:20:33.172837 138384 caffe.cpp:526]      relu1	backward: 1.169 ms.
I1109 00:20:33.173048 138384 caffe.cpp:522]      norm1	forward: 18.615 ms.
I1109 00:20:33.173250 138384 caffe.cpp:526]      norm1	backward: 3.116 ms.
I1109 00:20:33.173444 138384 caffe.cpp:522]      pool1	forward: 27.307 ms.
I1109 00:20:33.173640 138384 caffe.cpp:526]      pool1	backward: 35.741 ms.
I1109 00:20:33.173833 138384 caffe.cpp:522]      conv2	forward: 64.323 ms.
I1109 00:20:33.174520 138384 caffe.cpp:526]      conv2	backward: 31.536 ms.
I1109 00:20:33.174789 138384 caffe.cpp:522]      relu2	forward: 17.766 ms.
I1109 00:20:33.175055 138384 caffe.cpp:526]      relu2	backward: 0.797 ms.
I1109 00:20:33.175335 138384 caffe.cpp:522]      norm2	forward: 13.791 ms.
I1109 00:20:33.175571 138384 caffe.cpp:526]      norm2	backward: 2.171 ms.
I1109 00:20:33.175761 138384 caffe.cpp:522]      pool2	forward: 14.351 ms.
I1109 00:20:33.175956 138384 caffe.cpp:526]      pool2	backward: 22.308 ms.
I1109 00:20:33.176147 138384 caffe.cpp:522]      conv3	forward: 38.433 ms.
I1109 00:20:33.176338 138384 caffe.cpp:526]      conv3	backward: 36.259 ms.
I1109 00:20:33.176529 138384 caffe.cpp:522]      relu3	forward: 15.267 ms.
I1109 00:20:33.176720 138384 caffe.cpp:526]      relu3	backward: 0.736 ms.
I1109 00:20:33.176952 138384 caffe.cpp:522]      conv4	forward: 37.858 ms.
I1109 00:20:33.177145 138384 caffe.cpp:526]      conv4	backward: 50.974 ms.
I1109 00:20:33.177335 138384 caffe.cpp:522]      relu4	forward: 13.483 ms.
I1109 00:20:33.177526 138384 caffe.cpp:526]      relu4	backward: 35.148 ms.
I1109 00:20:33.178285 138384 caffe.cpp:522]      conv5	forward: 25.556 ms.
I1109 00:20:33.178623 138384 caffe.cpp:526]      conv5	backward: 65.469 ms.
I1109 00:20:33.178956 138384 caffe.cpp:522]      relu5	forward: 13.268 ms.
I1109 00:20:33.179154 138384 caffe.cpp:526]      relu5	backward: 17.087 ms.
I1109 00:20:33.179349 138384 caffe.cpp:522]      pool5	forward: 33.854 ms.
I1109 00:20:33.179543 138384 caffe.cpp:526]      pool5	backward: 58.661 ms.
I1109 00:20:33.179734 138384 caffe.cpp:522]        fc6	forward: 46.088 ms.
I1109 00:20:33.179926 138384 caffe.cpp:526]        fc6	backward: 116.888 ms.
I1109 00:20:33.180119 138384 caffe.cpp:522]      relu6	forward: 18.898 ms.
I1109 00:20:33.180310 138384 caffe.cpp:526]      relu6	backward: 11.852 ms.
I1109 00:20:33.180501 138384 caffe.cpp:522]      drop6	forward: 36.643 ms.
I1109 00:20:33.180692 138384 caffe.cpp:526]      drop6	backward: 12.753 ms.
I1109 00:20:33.180920 138384 caffe.cpp:522]        fc7	forward: 19.591 ms.
I1109 00:20:33.181145 138384 caffe.cpp:526]        fc7	backward: 95.736 ms.
I1109 00:20:33.181352 138384 caffe.cpp:522]      relu7	forward: 15.898 ms.
I1109 00:20:33.181653 138384 caffe.cpp:526]      relu7	backward: 13.27 ms.
I1109 00:20:33.181941 138384 caffe.cpp:522]      drop7	forward: 32.003 ms.
I1109 00:20:33.182152 138384 caffe.cpp:526]      drop7	backward: 17.532 ms.
I1109 00:20:33.182379 138384 caffe.cpp:522]        fc8	forward: 13.558 ms.
I1109 00:20:33.182574 138384 caffe.cpp:526]        fc8	backward: 127.423 ms.
I1109 00:20:33.182766 138384 caffe.cpp:522]       loss	forward: 50.838 ms.
I1109 00:20:33.182958 138384 caffe.cpp:526]       loss	backward: 71.249 ms.
I1109 00:20:33.189947 138384 caffe.cpp:532] Average Forward pass: 1327.53 ms.
I1109 00:20:33.204962 138384 caffe.cpp:535] Average Backward pass: 861.993 ms.
I1109 00:20:33.215989 138384 caffe.cpp:537] Average Forward-Backward: 2612 ms.
I1109 00:20:33.230715 138384 caffe.cpp:540] Total Time: 2612 ms.
I1109 00:20:33.242894 138384 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 25
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 165888
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 25
--->Total double-precision FLOPs = 331776
--->Total FLOPs = 331801
mem-read-1 = 27471
mem-read-2 = 35
mem-read-4 = 313780
mem-read-8 = 331101
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 497681
mem-write-1 = 52
mem-write-2 = 17
mem-write-4 = 13319
mem-write-8 = 29885
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 368641
--->Total Bytes read = 35783085
--->Total Bytes written = 23885498
--->Total Bytes = 59668583
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer16_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=16 -prof_forward_direction=1
I1109 00:24:28.343590 138496 caffe.cpp:444] Use CPU.
I1109 00:24:45.222465 138496 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:24:45.284059 138496 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:24:45.295810 138496 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:24:45.308328 138496 cpu_info.cpp:461] Total number of processors: 272
I1109 00:24:45.319506 138496 cpu_info.cpp:464] GPU is used: no
I1109 00:24:45.328614 138496 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:24:45.337570 138496 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:24:45.348429 138496 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:24:54.159312 138496 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:24:54.190634 138496 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:24:54.823436 138496 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:24:57.278214 138496 layer_factory.hpp:114] Creating layer data
I1109 00:24:57.426553 138496 net.cpp:160] Creating Layer data
I1109 00:24:57.474709 138496 net.cpp:570] data -> data
I1109 00:24:57.943174 138496 net.cpp:570] data -> label
I1109 00:25:05.008180 138496 net.cpp:210] Setting up data
I1109 00:25:05.089999 138496 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:25:05.193752 138496 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:25:05.201020 138496 net.cpp:225] Memory required for data: 19787264
I1109 00:25:05.273192 138496 layer_factory.hpp:114] Creating layer conv1
I1109 00:25:05.600709 138496 net.cpp:160] Creating Layer conv1
I1109 00:25:05.651026 138496 net.cpp:596] conv1 <- data
I1109 00:25:05.770422 138496 net.cpp:570] conv1 -> conv1
I1109 00:25:38.606298 138496 net.cpp:210] Setting up conv1
I1109 00:25:38.613085 138496 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:25:38.613461 138496 net.cpp:225] Memory required for data: 56958464
I1109 00:25:38.898960 138496 layer_factory.hpp:114] Creating layer relu1
I1109 00:25:39.019351 138496 net.cpp:160] Creating Layer relu1
I1109 00:25:39.023911 138496 net.cpp:596] relu1 <- conv1
I1109 00:25:39.057255 138496 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:25:39.249013 138496 net.cpp:210] Setting up relu1
I1109 00:25:39.251385 138496 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:25:39.251732 138496 net.cpp:225] Memory required for data: 94129664
I1109 00:25:39.251971 138496 layer_factory.hpp:114] Creating layer norm1
I1109 00:25:39.356086 138496 net.cpp:160] Creating Layer norm1
I1109 00:25:39.356405 138496 net.cpp:596] norm1 <- conv1
I1109 00:25:39.358973 138496 net.cpp:570] norm1 -> norm1
I1109 00:25:39.583981 138496 net.cpp:210] Setting up norm1
I1109 00:25:39.597123 138496 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:25:39.597512 138496 net.cpp:225] Memory required for data: 131300864
I1109 00:25:39.597828 138496 layer_factory.hpp:114] Creating layer pool1
I1109 00:25:39.692504 138496 net.cpp:160] Creating Layer pool1
I1109 00:25:39.692884 138496 net.cpp:596] pool1 <- norm1
I1109 00:25:39.707653 138496 net.cpp:570] pool1 -> pool1
I1109 00:25:40.008893 138496 net.cpp:210] Setting up pool1
I1109 00:25:40.011399 138496 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:25:40.011724 138496 net.cpp:225] Memory required for data: 140258816
I1109 00:25:40.011932 138496 layer_factory.hpp:114] Creating layer conv2
I1109 00:25:40.012312 138496 net.cpp:160] Creating Layer conv2
I1109 00:25:40.012545 138496 net.cpp:596] conv2 <- pool1
I1109 00:25:40.012863 138496 net.cpp:570] conv2 -> conv2
I1109 00:25:45.765436 138496 net.cpp:210] Setting up conv2
I1109 00:25:45.765795 138496 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:25:45.766192 138496 net.cpp:225] Memory required for data: 164146688
I1109 00:25:45.818853 138496 layer_factory.hpp:114] Creating layer relu2
I1109 00:25:45.819279 138496 net.cpp:160] Creating Layer relu2
I1109 00:25:45.819658 138496 net.cpp:596] relu2 <- conv2
I1109 00:25:45.819916 138496 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:25:45.820389 138496 net.cpp:210] Setting up relu2
I1109 00:25:45.820653 138496 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:25:45.820972 138496 net.cpp:225] Memory required for data: 188034560
I1109 00:25:45.821193 138496 layer_factory.hpp:114] Creating layer norm2
I1109 00:25:45.821432 138496 net.cpp:160] Creating Layer norm2
I1109 00:25:45.821629 138496 net.cpp:596] norm2 <- conv2
I1109 00:25:45.821853 138496 net.cpp:570] norm2 -> norm2
I1109 00:25:45.823974 138496 net.cpp:210] Setting up norm2
I1109 00:25:45.824281 138496 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:25:45.824511 138496 net.cpp:225] Memory required for data: 211922432
I1109 00:25:45.824697 138496 layer_factory.hpp:114] Creating layer pool2
I1109 00:25:45.825672 138496 net.cpp:160] Creating Layer pool2
I1109 00:25:45.826068 138496 net.cpp:596] pool2 <- norm2
I1109 00:25:45.826357 138496 net.cpp:570] pool2 -> pool2
I1109 00:25:45.826757 138496 net.cpp:210] Setting up pool2
I1109 00:25:45.826998 138496 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:25:45.827216 138496 net.cpp:225] Memory required for data: 217460224
I1109 00:25:45.827410 138496 layer_factory.hpp:114] Creating layer conv3
I1109 00:25:45.827736 138496 net.cpp:160] Creating Layer conv3
I1109 00:25:45.827950 138496 net.cpp:596] conv3 <- pool2
I1109 00:25:45.828183 138496 net.cpp:570] conv3 -> conv3
I1109 00:25:46.344203 138496 net.cpp:210] Setting up conv3
I1109 00:25:46.346652 138496 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:25:46.347009 138496 net.cpp:225] Memory required for data: 225766912
I1109 00:25:46.350178 138496 layer_factory.hpp:114] Creating layer relu3
I1109 00:25:46.350623 138496 net.cpp:160] Creating Layer relu3
I1109 00:25:46.350884 138496 net.cpp:596] relu3 <- conv3
I1109 00:25:46.351140 138496 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:25:46.355294 138496 net.cpp:210] Setting up relu3
I1109 00:25:46.355603 138496 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:25:46.355850 138496 net.cpp:225] Memory required for data: 234073600
I1109 00:25:46.356078 138496 layer_factory.hpp:114] Creating layer conv4
I1109 00:25:46.356454 138496 net.cpp:160] Creating Layer conv4
I1109 00:25:46.356748 138496 net.cpp:596] conv4 <- conv3
I1109 00:25:46.357106 138496 net.cpp:570] conv4 -> conv4
I1109 00:25:46.602262 138496 net.cpp:210] Setting up conv4
I1109 00:25:46.602651 138496 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:25:46.603076 138496 net.cpp:225] Memory required for data: 242380288
I1109 00:25:46.603391 138496 layer_factory.hpp:114] Creating layer relu4
I1109 00:25:46.603687 138496 net.cpp:160] Creating Layer relu4
I1109 00:25:46.603912 138496 net.cpp:596] relu4 <- conv4
I1109 00:25:46.604146 138496 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:25:46.616716 138496 net.cpp:210] Setting up relu4
I1109 00:25:46.617151 138496 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:25:46.617511 138496 net.cpp:225] Memory required for data: 250686976
I1109 00:25:46.617753 138496 layer_factory.hpp:114] Creating layer conv5
I1109 00:25:46.618113 138496 net.cpp:160] Creating Layer conv5
I1109 00:25:46.618356 138496 net.cpp:596] conv5 <- conv4
I1109 00:25:46.618597 138496 net.cpp:570] conv5 -> conv5
I1109 00:25:46.789381 138496 net.cpp:210] Setting up conv5
I1109 00:25:46.789772 138496 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:25:46.790182 138496 net.cpp:225] Memory required for data: 256224768
I1109 00:25:46.794788 138496 layer_factory.hpp:114] Creating layer relu5
I1109 00:25:46.795230 138496 net.cpp:160] Creating Layer relu5
I1109 00:25:46.795497 138496 net.cpp:596] relu5 <- conv5
I1109 00:25:46.795778 138496 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:25:46.796339 138496 net.cpp:210] Setting up relu5
I1109 00:25:46.796629 138496 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:25:46.796937 138496 net.cpp:225] Memory required for data: 261762560
I1109 00:25:46.797157 138496 layer_factory.hpp:114] Creating layer pool5
I1109 00:25:46.797418 138496 net.cpp:160] Creating Layer pool5
I1109 00:25:46.797636 138496 net.cpp:596] pool5 <- conv5
I1109 00:25:46.797857 138496 net.cpp:570] pool5 -> pool5
I1109 00:25:46.798305 138496 net.cpp:210] Setting up pool5
I1109 00:25:46.798598 138496 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:25:46.798818 138496 net.cpp:225] Memory required for data: 262942208
I1109 00:25:46.799000 138496 layer_factory.hpp:114] Creating layer fc6
I1109 00:25:46.854964 138496 net.cpp:160] Creating Layer fc6
I1109 00:25:46.855275 138496 net.cpp:596] fc6 <- pool5
I1109 00:25:46.855696 138496 net.cpp:570] fc6 -> fc6
I1109 00:25:50.939323 138496 net.cpp:210] Setting up fc6
I1109 00:25:50.939633 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:50.941735 138496 net.cpp:225] Memory required for data: 263466496
I1109 00:25:50.942044 138496 layer_factory.hpp:114] Creating layer relu6
I1109 00:25:50.944468 138496 net.cpp:160] Creating Layer relu6
I1109 00:25:50.944845 138496 net.cpp:596] relu6 <- fc6
I1109 00:25:50.945086 138496 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:25:50.945502 138496 net.cpp:210] Setting up relu6
I1109 00:25:50.945758 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:50.945978 138496 net.cpp:225] Memory required for data: 263990784
I1109 00:25:50.946161 138496 layer_factory.hpp:114] Creating layer drop6
I1109 00:25:50.965988 138496 net.cpp:160] Creating Layer drop6
I1109 00:25:50.966296 138496 net.cpp:596] drop6 <- fc6
I1109 00:25:50.966683 138496 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:25:51.070034 138496 net.cpp:210] Setting up drop6
I1109 00:25:51.070333 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:51.070662 138496 net.cpp:225] Memory required for data: 264515072
I1109 00:25:51.070905 138496 layer_factory.hpp:114] Creating layer fc7
I1109 00:25:51.071171 138496 net.cpp:160] Creating Layer fc7
I1109 00:25:51.071379 138496 net.cpp:596] fc7 <- fc6
I1109 00:25:51.071759 138496 net.cpp:570] fc7 -> fc7
I1109 00:25:52.783121 138496 net.cpp:210] Setting up fc7
I1109 00:25:52.783473 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:52.783870 138496 net.cpp:225] Memory required for data: 265039360
I1109 00:25:52.784227 138496 layer_factory.hpp:114] Creating layer relu7
I1109 00:25:52.784540 138496 net.cpp:160] Creating Layer relu7
I1109 00:25:52.784823 138496 net.cpp:596] relu7 <- fc7
I1109 00:25:52.785090 138496 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:25:52.785533 138496 net.cpp:210] Setting up relu7
I1109 00:25:52.785810 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:52.786051 138496 net.cpp:225] Memory required for data: 265563648
I1109 00:25:52.786281 138496 layer_factory.hpp:114] Creating layer drop7
I1109 00:25:52.786525 138496 net.cpp:160] Creating Layer drop7
I1109 00:25:52.786739 138496 net.cpp:596] drop7 <- fc7
I1109 00:25:52.787014 138496 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:25:52.787276 138496 net.cpp:210] Setting up drop7
I1109 00:25:52.787478 138496 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:25:52.787693 138496 net.cpp:225] Memory required for data: 266087936
I1109 00:25:52.787873 138496 layer_factory.hpp:114] Creating layer fc8
I1109 00:25:52.788117 138496 net.cpp:160] Creating Layer fc8
I1109 00:25:52.788310 138496 net.cpp:596] fc8 <- fc7
I1109 00:25:52.788529 138496 net.cpp:570] fc8 -> fc8
I1109 00:25:53.213567 138496 net.cpp:210] Setting up fc8
I1109 00:25:53.213946 138496 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:25:53.214393 138496 net.cpp:225] Memory required for data: 266215936
I1109 00:25:53.214721 138496 layer_factory.hpp:114] Creating layer loss
I1109 00:25:53.239761 138496 net.cpp:160] Creating Layer loss
I1109 00:25:53.240090 138496 net.cpp:596] loss <- fc8
I1109 00:25:53.241189 138496 net.cpp:596] loss <- label
I1109 00:25:53.268923 138496 net.cpp:570] loss -> loss
I1109 00:25:53.306946 138496 layer_factory.hpp:114] Creating layer loss
I1109 00:25:55.891743 138496 net.cpp:210] Setting up loss
I1109 00:25:55.941995 138496 net.cpp:217] Top shape: (1)
I1109 00:25:55.951906 138496 net.cpp:220]     with loss weight 1
I1109 00:25:56.085389 138496 net.cpp:225] Memory required for data: 266215940
I1109 00:25:56.132673 138496 net.cpp:287] loss needs backward computation.
I1109 00:25:56.230574 138496 net.cpp:287] fc8 needs backward computation.
I1109 00:25:56.238550 138496 net.cpp:287] drop7 needs backward computation.
I1109 00:25:56.249812 138496 net.cpp:287] relu7 needs backward computation.
I1109 00:25:56.250135 138496 net.cpp:287] fc7 needs backward computation.
I1109 00:25:56.252532 138496 net.cpp:287] drop6 needs backward computation.
I1109 00:25:56.252885 138496 net.cpp:287] relu6 needs backward computation.
I1109 00:25:56.253092 138496 net.cpp:287] fc6 needs backward computation.
I1109 00:25:56.253939 138496 net.cpp:287] pool5 needs backward computation.
I1109 00:25:56.254773 138496 net.cpp:287] relu5 needs backward computation.
I1109 00:25:56.255055 138496 net.cpp:287] conv5 needs backward computation.
I1109 00:25:56.255250 138496 net.cpp:287] relu4 needs backward computation.
I1109 00:25:56.255435 138496 net.cpp:287] conv4 needs backward computation.
I1109 00:25:56.255616 138496 net.cpp:287] relu3 needs backward computation.
I1109 00:25:56.255794 138496 net.cpp:287] conv3 needs backward computation.
I1109 00:25:56.267882 138496 net.cpp:287] pool2 needs backward computation.
I1109 00:25:56.268239 138496 net.cpp:287] norm2 needs backward computation.
I1109 00:25:56.268576 138496 net.cpp:287] relu2 needs backward computation.
I1109 00:25:56.268815 138496 net.cpp:287] conv2 needs backward computation.
I1109 00:25:56.269013 138496 net.cpp:287] pool1 needs backward computation.
I1109 00:25:56.269192 138496 net.cpp:287] norm1 needs backward computation.
I1109 00:25:56.269371 138496 net.cpp:287] relu1 needs backward computation.
I1109 00:25:56.269544 138496 net.cpp:287] conv1 needs backward computation.
I1109 00:25:56.281960 138496 net.cpp:289] data does not need backward computation.
I1109 00:25:56.306015 138496 net.cpp:331] This network produces output loss
I1109 00:25:56.379098 138496 net.cpp:345] Network initialization done.
I1109 00:25:56.544025 138496 caffe.cpp:452] Performing Forward
I1109 00:26:09.651836 138496 caffe.cpp:457] Initial loss: 6.94524
I1109 00:26:09.703718 138496 caffe.cpp:459] Performing Backward
I1109 00:26:14.345973 138496 caffe.cpp:468] *** Benchmark begins ***
I1109 00:26:14.359145 138496 caffe.cpp:469] Testing for 1 iterations.
I1109 00:26:14.504228 138496 caffe.cpp:482] Profiling Layer: fc6 forward
I1109 00:26:16.851207 138496 caffe.cpp:512] Iteration: 1 forward-backward time: 2342 ms.
I1109 00:26:17.011479 138496 caffe.cpp:519] Average time per layer: 
I1109 00:26:17.028581 138496 caffe.cpp:522]       data	forward: 548.745 ms.
I1109 00:26:17.100277 138496 caffe.cpp:526]       data	backward: 4.868 ms.
I1109 00:26:17.122607 138496 caffe.cpp:522]      conv1	forward: 133.372 ms.
I1109 00:26:17.130430 138496 caffe.cpp:526]      conv1	backward: 47.805 ms.
I1109 00:26:17.140509 138496 caffe.cpp:522]      relu1	forward: 11.828 ms.
I1109 00:26:17.148911 138496 caffe.cpp:526]      relu1	backward: 23.766 ms.
I1109 00:26:17.152936 138496 caffe.cpp:522]      norm1	forward: 18.809 ms.
I1109 00:26:17.162488 138496 caffe.cpp:526]      norm1	backward: 16.164 ms.
I1109 00:26:17.169715 138496 caffe.cpp:522]      pool1	forward: 15.791 ms.
I1109 00:26:17.176858 138496 caffe.cpp:526]      pool1	backward: 74.634 ms.
I1109 00:26:17.187516 138496 caffe.cpp:522]      conv2	forward: 65.49 ms.
I1109 00:26:17.194679 138496 caffe.cpp:526]      conv2	backward: 74.962 ms.
I1109 00:26:17.203477 138496 caffe.cpp:522]      relu2	forward: 11.591 ms.
I1109 00:26:17.207702 138496 caffe.cpp:526]      relu2	backward: 16.561 ms.
I1109 00:26:17.207998 138496 caffe.cpp:522]      norm2	forward: 19.521 ms.
I1109 00:26:17.208197 138496 caffe.cpp:526]      norm2	backward: 16.43 ms.
I1109 00:26:17.208392 138496 caffe.cpp:522]      pool2	forward: 12.987 ms.
I1109 00:26:17.208583 138496 caffe.cpp:526]      pool2	backward: 56.921 ms.
I1109 00:26:17.208775 138496 caffe.cpp:522]      conv3	forward: 32.53 ms.
I1109 00:26:17.209012 138496 caffe.cpp:526]      conv3	backward: 89.332 ms.
I1109 00:26:17.209240 138496 caffe.cpp:522]      relu3	forward: 17.837 ms.
I1109 00:26:17.209446 138496 caffe.cpp:526]      relu3	backward: 29.616 ms.
I1109 00:26:17.209767 138496 caffe.cpp:522]      conv4	forward: 35.995 ms.
I1109 00:26:17.210045 138496 caffe.cpp:526]      conv4	backward: 69.228 ms.
I1109 00:26:17.210306 138496 caffe.cpp:522]      relu4	forward: 19.63 ms.
I1109 00:26:17.210526 138496 caffe.cpp:526]      relu4	backward: 37.095 ms.
I1109 00:26:17.211257 138496 caffe.cpp:522]      conv5	forward: 26.129 ms.
I1109 00:26:17.211483 138496 caffe.cpp:526]      conv5	backward: 61.233 ms.
I1109 00:26:17.211674 138496 caffe.cpp:522]      relu5	forward: 11.107 ms.
I1109 00:26:17.211894 138496 caffe.cpp:526]      relu5	backward: 20.862 ms.
I1109 00:26:17.212097 138496 caffe.cpp:522]      pool5	forward: 21.42 ms.
I1109 00:26:17.212376 138496 caffe.cpp:526]      pool5	backward: 54.452 ms.
I1109 00:26:17.212622 138496 caffe.cpp:522]        fc6	forward: 56.674 ms.
I1109 00:26:17.212987 138496 caffe.cpp:526]        fc6	backward: 111.736 ms.
I1109 00:26:17.213201 138496 caffe.cpp:522]      relu6	forward: 11.528 ms.
I1109 00:26:17.213410 138496 caffe.cpp:526]      relu6	backward: 17.418 ms.
I1109 00:26:17.213616 138496 caffe.cpp:522]      drop6	forward: 40.457 ms.
I1109 00:26:17.213822 138496 caffe.cpp:526]      drop6	backward: 20.713 ms.
I1109 00:26:17.214028 138496 caffe.cpp:522]        fc7	forward: 13.357 ms.
I1109 00:26:17.214229 138496 caffe.cpp:526]        fc7	backward: 78.138 ms.
I1109 00:26:17.214432 138496 caffe.cpp:522]      relu7	forward: 14.391 ms.
I1109 00:26:17.214634 138496 caffe.cpp:526]      relu7	backward: 0.084 ms.
I1109 00:26:17.217222 138496 caffe.cpp:522]      drop7	forward: 19.99 ms.
I1109 00:26:17.217491 138496 caffe.cpp:526]      drop7	backward: 0.089 ms.
I1109 00:26:17.217715 138496 caffe.cpp:522]        fc8	forward: 4.53 ms.
I1109 00:26:17.217975 138496 caffe.cpp:526]        fc8	backward: 67.618 ms.
I1109 00:26:17.218266 138496 caffe.cpp:522]       loss	forward: 39.016 ms.
I1109 00:26:17.218493 138496 caffe.cpp:526]       loss	backward: 51.744 ms.
I1109 00:26:17.224117 138496 caffe.cpp:532] Average Forward pass: 1256.95 ms.
I1109 00:26:17.238039 138496 caffe.cpp:535] Average Backward pass: 1051.51 ms.
I1109 00:26:17.249120 138496 caffe.cpp:537] Average Forward-Backward: 2819 ms.
I1109 00:26:17.263844 138496 caffe.cpp:540] Total Time: 2819 ms.
I1109 00:26:17.276036 138496 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 7255
elements_fp_single_4 = 0
elements_fp_single_8 = 5382144
elements_fp_single_16 = 151232512
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2462784599
--->Total double-precision FLOPs = 0
--->Total FLOPs = 2462784599
mem-read-1 = 55752
mem-read-2 = 90
mem-read-4 = 76011163
mem-read-8 = 1666158
mem-read-16 = 10470251
mem-read-32 = 73729
mem-read-64 = 20922244
mem-write-1 = 112
mem-write-2 = 34
mem-write-4 = 2897
mem-write-8 = 454143
mem-write-16 = 148331
mem-write-32 = 5234689
mem-write-64 = 316292
--->Total Bytes read = 1826336808
--->Total Bytes written = 193770944
--->Total Bytes = 2020107752
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer17_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=17 -prof_forward_direction=1
I1109 00:32:46.473225 138669 caffe.cpp:444] Use CPU.
I1109 00:33:03.387949 138669 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:33:03.444345 138669 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:33:03.456027 138669 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:33:03.468437 138669 cpu_info.cpp:461] Total number of processors: 272
I1109 00:33:03.479580 138669 cpu_info.cpp:464] GPU is used: no
I1109 00:33:03.488831 138669 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:33:03.497643 138669 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:33:03.508545 138669 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:33:12.271688 138669 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:33:12.302609 138669 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:33:12.932909 138669 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:33:15.378710 138669 layer_factory.hpp:114] Creating layer data
I1109 00:33:15.525518 138669 net.cpp:160] Creating Layer data
I1109 00:33:15.575548 138669 net.cpp:570] data -> data
I1109 00:33:16.041283 138669 net.cpp:570] data -> label
I1109 00:33:23.082515 138669 net.cpp:210] Setting up data
I1109 00:33:23.162058 138669 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:33:23.265897 138669 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:33:23.273066 138669 net.cpp:225] Memory required for data: 19787264
I1109 00:33:23.343495 138669 layer_factory.hpp:114] Creating layer conv1
I1109 00:33:23.675642 138669 net.cpp:160] Creating Layer conv1
I1109 00:33:23.725392 138669 net.cpp:596] conv1 <- data
I1109 00:33:23.845011 138669 net.cpp:570] conv1 -> conv1
I1109 00:33:56.738620 138669 net.cpp:210] Setting up conv1
I1109 00:33:56.745708 138669 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:33:56.746106 138669 net.cpp:225] Memory required for data: 56958464
I1109 00:33:57.027050 138669 layer_factory.hpp:114] Creating layer relu1
I1109 00:33:57.147233 138669 net.cpp:160] Creating Layer relu1
I1109 00:33:57.151844 138669 net.cpp:596] relu1 <- conv1
I1109 00:33:57.184092 138669 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:33:57.372560 138669 net.cpp:210] Setting up relu1
I1109 00:33:57.374985 138669 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:33:57.375322 138669 net.cpp:225] Memory required for data: 94129664
I1109 00:33:57.375522 138669 layer_factory.hpp:114] Creating layer norm1
I1109 00:33:57.484690 138669 net.cpp:160] Creating Layer norm1
I1109 00:33:57.485064 138669 net.cpp:596] norm1 <- conv1
I1109 00:33:57.487629 138669 net.cpp:570] norm1 -> norm1
I1109 00:33:57.712618 138669 net.cpp:210] Setting up norm1
I1109 00:33:57.725611 138669 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:33:57.725986 138669 net.cpp:225] Memory required for data: 131300864
I1109 00:33:57.726290 138669 layer_factory.hpp:114] Creating layer pool1
I1109 00:33:57.819473 138669 net.cpp:160] Creating Layer pool1
I1109 00:33:57.819784 138669 net.cpp:596] pool1 <- norm1
I1109 00:33:57.834527 138669 net.cpp:570] pool1 -> pool1
I1109 00:33:58.135546 138669 net.cpp:210] Setting up pool1
I1109 00:33:58.138089 138669 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:33:58.138412 138669 net.cpp:225] Memory required for data: 140258816
I1109 00:33:58.138660 138669 layer_factory.hpp:114] Creating layer conv2
I1109 00:33:58.139035 138669 net.cpp:160] Creating Layer conv2
I1109 00:33:58.139291 138669 net.cpp:596] conv2 <- pool1
I1109 00:33:58.139523 138669 net.cpp:570] conv2 -> conv2
I1109 00:34:03.895375 138669 net.cpp:210] Setting up conv2
I1109 00:34:03.895711 138669 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:34:03.896114 138669 net.cpp:225] Memory required for data: 164146688
I1109 00:34:03.946535 138669 layer_factory.hpp:114] Creating layer relu2
I1109 00:34:03.946949 138669 net.cpp:160] Creating Layer relu2
I1109 00:34:03.947302 138669 net.cpp:596] relu2 <- conv2
I1109 00:34:03.947561 138669 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:34:03.948012 138669 net.cpp:210] Setting up relu2
I1109 00:34:03.948282 138669 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:34:03.948511 138669 net.cpp:225] Memory required for data: 188034560
I1109 00:34:03.948696 138669 layer_factory.hpp:114] Creating layer norm2
I1109 00:34:03.948988 138669 net.cpp:160] Creating Layer norm2
I1109 00:34:03.949188 138669 net.cpp:596] norm2 <- conv2
I1109 00:34:03.949419 138669 net.cpp:570] norm2 -> norm2
I1109 00:34:03.951534 138669 net.cpp:210] Setting up norm2
I1109 00:34:03.951840 138669 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:34:03.952069 138669 net.cpp:225] Memory required for data: 211922432
I1109 00:34:03.952256 138669 layer_factory.hpp:114] Creating layer pool2
I1109 00:34:03.953117 138669 net.cpp:160] Creating Layer pool2
I1109 00:34:03.953405 138669 net.cpp:596] pool2 <- norm2
I1109 00:34:03.953677 138669 net.cpp:570] pool2 -> pool2
I1109 00:34:03.954128 138669 net.cpp:210] Setting up pool2
I1109 00:34:03.954501 138669 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:34:03.954727 138669 net.cpp:225] Memory required for data: 217460224
I1109 00:34:03.954923 138669 layer_factory.hpp:114] Creating layer conv3
I1109 00:34:03.955257 138669 net.cpp:160] Creating Layer conv3
I1109 00:34:03.955482 138669 net.cpp:596] conv3 <- pool2
I1109 00:34:03.955724 138669 net.cpp:570] conv3 -> conv3
I1109 00:34:04.456323 138669 net.cpp:210] Setting up conv3
I1109 00:34:04.458767 138669 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:34:04.459131 138669 net.cpp:225] Memory required for data: 225766912
I1109 00:34:04.462167 138669 layer_factory.hpp:114] Creating layer relu3
I1109 00:34:04.462560 138669 net.cpp:160] Creating Layer relu3
I1109 00:34:04.462812 138669 net.cpp:596] relu3 <- conv3
I1109 00:34:04.463052 138669 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:34:04.467303 138669 net.cpp:210] Setting up relu3
I1109 00:34:04.467641 138669 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:34:04.467881 138669 net.cpp:225] Memory required for data: 234073600
I1109 00:34:04.468073 138669 layer_factory.hpp:114] Creating layer conv4
I1109 00:34:04.468436 138669 net.cpp:160] Creating Layer conv4
I1109 00:34:04.468690 138669 net.cpp:596] conv4 <- conv3
I1109 00:34:04.468994 138669 net.cpp:570] conv4 -> conv4
I1109 00:34:04.710831 138669 net.cpp:210] Setting up conv4
I1109 00:34:04.711212 138669 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:34:04.711596 138669 net.cpp:225] Memory required for data: 242380288
I1109 00:34:04.711933 138669 layer_factory.hpp:114] Creating layer relu4
I1109 00:34:04.712225 138669 net.cpp:160] Creating Layer relu4
I1109 00:34:04.712445 138669 net.cpp:596] relu4 <- conv4
I1109 00:34:04.712673 138669 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:34:04.724910 138669 net.cpp:210] Setting up relu4
I1109 00:34:04.725252 138669 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:34:04.725697 138669 net.cpp:225] Memory required for data: 250686976
I1109 00:34:04.725940 138669 layer_factory.hpp:114] Creating layer conv5
I1109 00:34:04.726306 138669 net.cpp:160] Creating Layer conv5
I1109 00:34:04.726541 138669 net.cpp:596] conv5 <- conv4
I1109 00:34:04.726783 138669 net.cpp:570] conv5 -> conv5
I1109 00:34:04.894877 138669 net.cpp:210] Setting up conv5
I1109 00:34:04.895269 138669 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:34:04.895673 138669 net.cpp:225] Memory required for data: 256224768
I1109 00:34:04.900319 138669 layer_factory.hpp:114] Creating layer relu5
I1109 00:34:04.900719 138669 net.cpp:160] Creating Layer relu5
I1109 00:34:04.901058 138669 net.cpp:596] relu5 <- conv5
I1109 00:34:04.901341 138669 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:34:04.901820 138669 net.cpp:210] Setting up relu5
I1109 00:34:04.902194 138669 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:34:04.902428 138669 net.cpp:225] Memory required for data: 261762560
I1109 00:34:04.902633 138669 layer_factory.hpp:114] Creating layer pool5
I1109 00:34:04.902890 138669 net.cpp:160] Creating Layer pool5
I1109 00:34:04.903101 138669 net.cpp:596] pool5 <- conv5
I1109 00:34:04.903321 138669 net.cpp:570] pool5 -> pool5
I1109 00:34:04.903720 138669 net.cpp:210] Setting up pool5
I1109 00:34:04.903975 138669 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:34:04.904237 138669 net.cpp:225] Memory required for data: 262942208
I1109 00:34:04.904433 138669 layer_factory.hpp:114] Creating layer fc6
I1109 00:34:04.959162 138669 net.cpp:160] Creating Layer fc6
I1109 00:34:04.959470 138669 net.cpp:596] fc6 <- pool5
I1109 00:34:04.959870 138669 net.cpp:570] fc6 -> fc6
I1109 00:34:09.050470 138669 net.cpp:210] Setting up fc6
I1109 00:34:09.050772 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:09.052938 138669 net.cpp:225] Memory required for data: 263466496
I1109 00:34:09.053253 138669 layer_factory.hpp:114] Creating layer relu6
I1109 00:34:09.055752 138669 net.cpp:160] Creating Layer relu6
I1109 00:34:09.056049 138669 net.cpp:596] relu6 <- fc6
I1109 00:34:09.056277 138669 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:34:09.056699 138669 net.cpp:210] Setting up relu6
I1109 00:34:09.057014 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:09.057241 138669 net.cpp:225] Memory required for data: 263990784
I1109 00:34:09.057425 138669 layer_factory.hpp:114] Creating layer drop6
I1109 00:34:09.077149 138669 net.cpp:160] Creating Layer drop6
I1109 00:34:09.077450 138669 net.cpp:596] drop6 <- fc6
I1109 00:34:09.077821 138669 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:34:09.182649 138669 net.cpp:210] Setting up drop6
I1109 00:34:09.182950 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:09.183341 138669 net.cpp:225] Memory required for data: 264515072
I1109 00:34:09.183588 138669 layer_factory.hpp:114] Creating layer fc7
I1109 00:34:09.183862 138669 net.cpp:160] Creating Layer fc7
I1109 00:34:09.184064 138669 net.cpp:596] fc7 <- fc6
I1109 00:34:09.184448 138669 net.cpp:570] fc7 -> fc7
I1109 00:34:10.894073 138669 net.cpp:210] Setting up fc7
I1109 00:34:10.894412 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:10.894778 138669 net.cpp:225] Memory required for data: 265039360
I1109 00:34:10.895112 138669 layer_factory.hpp:114] Creating layer relu7
I1109 00:34:10.895411 138669 net.cpp:160] Creating Layer relu7
I1109 00:34:10.895632 138669 net.cpp:596] relu7 <- fc7
I1109 00:34:10.895865 138669 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:34:10.896292 138669 net.cpp:210] Setting up relu7
I1109 00:34:10.896559 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:10.896826 138669 net.cpp:225] Memory required for data: 265563648
I1109 00:34:10.897027 138669 layer_factory.hpp:114] Creating layer drop7
I1109 00:34:10.897251 138669 net.cpp:160] Creating Layer drop7
I1109 00:34:10.897444 138669 net.cpp:596] drop7 <- fc7
I1109 00:34:10.897675 138669 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:34:10.897977 138669 net.cpp:210] Setting up drop7
I1109 00:34:10.898185 138669 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:34:10.898409 138669 net.cpp:225] Memory required for data: 266087936
I1109 00:34:10.898617 138669 layer_factory.hpp:114] Creating layer fc8
I1109 00:34:10.898859 138669 net.cpp:160] Creating Layer fc8
I1109 00:34:10.899046 138669 net.cpp:596] fc8 <- fc7
I1109 00:34:10.899266 138669 net.cpp:570] fc8 -> fc8
I1109 00:34:11.323036 138669 net.cpp:210] Setting up fc8
I1109 00:34:11.323403 138669 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:34:11.323870 138669 net.cpp:225] Memory required for data: 266215936
I1109 00:34:11.324200 138669 layer_factory.hpp:114] Creating layer loss
I1109 00:34:11.349272 138669 net.cpp:160] Creating Layer loss
I1109 00:34:11.349587 138669 net.cpp:596] loss <- fc8
I1109 00:34:11.350559 138669 net.cpp:596] loss <- label
I1109 00:34:11.377883 138669 net.cpp:570] loss -> loss
I1109 00:34:11.415694 138669 layer_factory.hpp:114] Creating layer loss
I1109 00:34:13.965836 138669 net.cpp:210] Setting up loss
I1109 00:34:14.017160 138669 net.cpp:217] Top shape: (1)
I1109 00:34:14.026803 138669 net.cpp:220]     with loss weight 1
I1109 00:34:14.152037 138669 net.cpp:225] Memory required for data: 266215940
I1109 00:34:14.198390 138669 net.cpp:287] loss needs backward computation.
I1109 00:34:14.284703 138669 net.cpp:287] fc8 needs backward computation.
I1109 00:34:14.291795 138669 net.cpp:287] drop7 needs backward computation.
I1109 00:34:14.302588 138669 net.cpp:287] relu7 needs backward computation.
I1109 00:34:14.302922 138669 net.cpp:287] fc7 needs backward computation.
I1109 00:34:14.305380 138669 net.cpp:287] drop6 needs backward computation.
I1109 00:34:14.305681 138669 net.cpp:287] relu6 needs backward computation.
I1109 00:34:14.305871 138669 net.cpp:287] fc6 needs backward computation.
I1109 00:34:14.306594 138669 net.cpp:287] pool5 needs backward computation.
I1109 00:34:14.307476 138669 net.cpp:287] relu5 needs backward computation.
I1109 00:34:14.307750 138669 net.cpp:287] conv5 needs backward computation.
I1109 00:34:14.307946 138669 net.cpp:287] relu4 needs backward computation.
I1109 00:34:14.308133 138669 net.cpp:287] conv4 needs backward computation.
I1109 00:34:14.308316 138669 net.cpp:287] relu3 needs backward computation.
I1109 00:34:14.308495 138669 net.cpp:287] conv3 needs backward computation.
I1109 00:34:14.320405 138669 net.cpp:287] pool2 needs backward computation.
I1109 00:34:14.320811 138669 net.cpp:287] norm2 needs backward computation.
I1109 00:34:14.321110 138669 net.cpp:287] relu2 needs backward computation.
I1109 00:34:14.321375 138669 net.cpp:287] conv2 needs backward computation.
I1109 00:34:14.321586 138669 net.cpp:287] pool1 needs backward computation.
I1109 00:34:14.321779 138669 net.cpp:287] norm1 needs backward computation.
I1109 00:34:14.321969 138669 net.cpp:287] relu1 needs backward computation.
I1109 00:34:14.322155 138669 net.cpp:287] conv1 needs backward computation.
I1109 00:34:14.334537 138669 net.cpp:289] data does not need backward computation.
I1109 00:34:14.360083 138669 net.cpp:331] This network produces output loss
I1109 00:34:14.434223 138669 net.cpp:345] Network initialization done.
I1109 00:34:14.607973 138669 caffe.cpp:452] Performing Forward
I1109 00:34:27.870164 138669 caffe.cpp:457] Initial loss: 6.85464
I1109 00:34:27.926937 138669 caffe.cpp:459] Performing Backward
I1109 00:34:32.842591 138669 caffe.cpp:468] *** Benchmark begins ***
I1109 00:34:32.855305 138669 caffe.cpp:469] Testing for 1 iterations.
I1109 00:34:32.997864 138669 caffe.cpp:482] Profiling Layer: relu6 forward
I1109 00:34:35.303077 138669 caffe.cpp:512] Iteration: 1 forward-backward time: 2299 ms.
I1109 00:34:35.459537 138669 caffe.cpp:519] Average time per layer: 
I1109 00:34:35.478274 138669 caffe.cpp:522]       data	forward: 539.685 ms.
I1109 00:34:35.549127 138669 caffe.cpp:526]       data	backward: 5.017 ms.
I1109 00:34:35.573570 138669 caffe.cpp:522]      conv1	forward: 109.664 ms.
I1109 00:34:35.592751 138669 caffe.cpp:526]      conv1	backward: 48.311 ms.
I1109 00:34:35.606299 138669 caffe.cpp:522]      relu1	forward: 1.358 ms.
I1109 00:34:35.615635 138669 caffe.cpp:526]      relu1	backward: 16.639 ms.
I1109 00:34:35.623340 138669 caffe.cpp:522]      norm1	forward: 6.972 ms.
I1109 00:34:35.628988 138669 caffe.cpp:526]      norm1	backward: 17.165 ms.
I1109 00:34:35.634496 138669 caffe.cpp:522]      pool1	forward: 3.547 ms.
I1109 00:34:35.641767 138669 caffe.cpp:526]      pool1	backward: 82.89 ms.
I1109 00:34:35.656368 138669 caffe.cpp:522]      conv2	forward: 40.828 ms.
I1109 00:34:35.667971 138669 caffe.cpp:526]      conv2	backward: 81.968 ms.
I1109 00:34:35.672230 138669 caffe.cpp:522]      relu2	forward: 0.521 ms.
I1109 00:34:35.672569 138669 caffe.cpp:526]      relu2	backward: 12.857 ms.
I1109 00:34:35.672845 138669 caffe.cpp:522]      norm2	forward: 3.314 ms.
I1109 00:34:35.673038 138669 caffe.cpp:526]      norm2	backward: 12.35 ms.
I1109 00:34:35.673230 138669 caffe.cpp:522]      pool2	forward: 1.178 ms.
I1109 00:34:35.673416 138669 caffe.cpp:526]      pool2	backward: 72.023 ms.
I1109 00:34:35.674165 138669 caffe.cpp:522]      conv3	forward: 9.968 ms.
I1109 00:34:35.674906 138669 caffe.cpp:526]      conv3	backward: 87.89 ms.
I1109 00:34:35.675245 138669 caffe.cpp:522]      relu3	forward: 0.241 ms.
I1109 00:34:35.675530 138669 caffe.cpp:526]      relu3	backward: 31.359 ms.
I1109 00:34:35.675760 138669 caffe.cpp:522]      conv4	forward: 7.606 ms.
I1109 00:34:35.675947 138669 caffe.cpp:526]      conv4	backward: 75.218 ms.
I1109 00:34:35.676138 138669 caffe.cpp:522]      relu4	forward: 0.249 ms.
I1109 00:34:35.676326 138669 caffe.cpp:526]      relu4	backward: 33.854 ms.
I1109 00:34:35.676515 138669 caffe.cpp:522]      conv5	forward: 5.253 ms.
I1109 00:34:35.676702 138669 caffe.cpp:526]      conv5	backward: 74.282 ms.
I1109 00:34:35.676929 138669 caffe.cpp:522]      relu5	forward: 0.194 ms.
I1109 00:34:35.677115 138669 caffe.cpp:526]      relu5	backward: 17.712 ms.
I1109 00:34:35.677306 138669 caffe.cpp:522]      pool5	forward: 0.299 ms.
I1109 00:34:35.677492 138669 caffe.cpp:526]      pool5	backward: 62.33 ms.
I1109 00:34:35.677716 138669 caffe.cpp:522]        fc6	forward: 16.583 ms.
I1109 00:34:35.677918 138669 caffe.cpp:526]        fc6	backward: 132.225 ms.
I1109 00:34:35.678205 138669 caffe.cpp:522]      relu6	forward: 12.745 ms.
I1109 00:34:35.678433 138669 caffe.cpp:526]      relu6	backward: 16.709 ms.
I1109 00:34:35.678724 138669 caffe.cpp:522]      drop6	forward: 1.432 ms.
I1109 00:34:35.678910 138669 caffe.cpp:526]      drop6	backward: 19.972 ms.
I1109 00:34:35.679101 138669 caffe.cpp:522]        fc7	forward: 18.57 ms.
I1109 00:34:35.679291 138669 caffe.cpp:526]        fc7	backward: 158.598 ms.
I1109 00:34:35.679483 138669 caffe.cpp:522]      relu7	forward: 17.44 ms.
I1109 00:34:35.679672 138669 caffe.cpp:526]      relu7	backward: 17.914 ms.
I1109 00:34:35.679863 138669 caffe.cpp:522]      drop7	forward: 28.552 ms.
I1109 00:34:35.680053 138669 caffe.cpp:526]      drop7	backward: 14.194 ms.
I1109 00:34:35.680244 138669 caffe.cpp:522]        fc8	forward: 14.581 ms.
I1109 00:34:35.680434 138669 caffe.cpp:526]        fc8	backward: 149.965 ms.
I1109 00:34:35.680626 138669 caffe.cpp:522]       loss	forward: 62.467 ms.
I1109 00:34:35.680874 138669 caffe.cpp:526]       loss	backward: 62.422 ms.
I1109 00:34:35.686575 138669 caffe.cpp:532] Average Forward pass: 958.452 ms.
I1109 00:34:35.699792 138669 caffe.cpp:535] Average Backward pass: 1312.75 ms.
I1109 00:34:35.710642 138669 caffe.cpp:537] Average Forward-Backward: 2787 ms.
I1109 00:34:35.725510 138669 caffe.cpp:540] Total Time: 2787 ms.
I1109 00:34:35.737838 138669 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 8192
elements_fp_double_1 = 0
elements_fp_double_2 = 8192
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 131073
--->Total double-precision FLOPs = 16384
--->Total FLOPs = 147457
mem-read-1 = 453653
mem-read-2 = 36
mem-read-4 = 3633362
mem-read-8 = 4999095
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 16401
mem-write-1 = 54
mem-write-2 = 17
mem-write-4 = 553
mem-write-8 = 457430
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 8193
--->Total Bytes read = 56029629
--->Total Bytes written = 4186124
--->Total Bytes = 60215753
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer18_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=18 -prof_forward_direction=1
I1109 00:38:07.591753 138786 caffe.cpp:444] Use CPU.
I1109 00:38:24.449777 138786 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:38:24.505378 138786 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:38:24.517199 138786 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:38:24.528488 138786 cpu_info.cpp:461] Total number of processors: 272
I1109 00:38:24.539641 138786 cpu_info.cpp:464] GPU is used: no
I1109 00:38:24.548349 138786 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:38:24.556646 138786 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:38:24.567638 138786 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:38:33.304162 138786 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:38:33.335407 138786 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:38:33.967399 138786 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:38:36.422721 138786 layer_factory.hpp:114] Creating layer data
I1109 00:38:36.568954 138786 net.cpp:160] Creating Layer data
I1109 00:38:36.616942 138786 net.cpp:570] data -> data
I1109 00:38:37.086020 138786 net.cpp:570] data -> label
I1109 00:38:44.137070 138786 net.cpp:210] Setting up data
I1109 00:38:44.216609 138786 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:38:44.320272 138786 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:38:44.328444 138786 net.cpp:225] Memory required for data: 19787264
I1109 00:38:44.397281 138786 layer_factory.hpp:114] Creating layer conv1
I1109 00:38:44.726205 138786 net.cpp:160] Creating Layer conv1
I1109 00:38:44.776579 138786 net.cpp:596] conv1 <- data
I1109 00:38:44.899840 138786 net.cpp:570] conv1 -> conv1
I1109 00:39:17.765936 138786 net.cpp:210] Setting up conv1
I1109 00:39:17.772732 138786 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:39:17.773200 138786 net.cpp:225] Memory required for data: 56958464
I1109 00:39:18.054190 138786 layer_factory.hpp:114] Creating layer relu1
I1109 00:39:18.175544 138786 net.cpp:160] Creating Layer relu1
I1109 00:39:18.180172 138786 net.cpp:596] relu1 <- conv1
I1109 00:39:18.212713 138786 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:39:18.404258 138786 net.cpp:210] Setting up relu1
I1109 00:39:18.406673 138786 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:39:18.407011 138786 net.cpp:225] Memory required for data: 94129664
I1109 00:39:18.407244 138786 layer_factory.hpp:114] Creating layer norm1
I1109 00:39:18.511684 138786 net.cpp:160] Creating Layer norm1
I1109 00:39:18.511996 138786 net.cpp:596] norm1 <- conv1
I1109 00:39:18.514538 138786 net.cpp:570] norm1 -> norm1
I1109 00:39:18.735666 138786 net.cpp:210] Setting up norm1
I1109 00:39:18.748405 138786 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:39:18.748836 138786 net.cpp:225] Memory required for data: 131300864
I1109 00:39:18.749127 138786 layer_factory.hpp:114] Creating layer pool1
I1109 00:39:18.841951 138786 net.cpp:160] Creating Layer pool1
I1109 00:39:18.842262 138786 net.cpp:596] pool1 <- norm1
I1109 00:39:18.857044 138786 net.cpp:570] pool1 -> pool1
I1109 00:39:19.159191 138786 net.cpp:210] Setting up pool1
I1109 00:39:19.161728 138786 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:39:19.162055 138786 net.cpp:225] Memory required for data: 140258816
I1109 00:39:19.162263 138786 layer_factory.hpp:114] Creating layer conv2
I1109 00:39:19.162659 138786 net.cpp:160] Creating Layer conv2
I1109 00:39:19.162889 138786 net.cpp:596] conv2 <- pool1
I1109 00:39:19.163147 138786 net.cpp:570] conv2 -> conv2
I1109 00:39:24.880244 138786 net.cpp:210] Setting up conv2
I1109 00:39:24.880594 138786 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:39:24.881062 138786 net.cpp:225] Memory required for data: 164146688
I1109 00:39:24.932164 138786 layer_factory.hpp:114] Creating layer relu2
I1109 00:39:24.932581 138786 net.cpp:160] Creating Layer relu2
I1109 00:39:24.933015 138786 net.cpp:596] relu2 <- conv2
I1109 00:39:24.933293 138786 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:39:24.933753 138786 net.cpp:210] Setting up relu2
I1109 00:39:24.934020 138786 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:39:24.934250 138786 net.cpp:225] Memory required for data: 188034560
I1109 00:39:24.934437 138786 layer_factory.hpp:114] Creating layer norm2
I1109 00:39:24.934675 138786 net.cpp:160] Creating Layer norm2
I1109 00:39:24.934870 138786 net.cpp:596] norm2 <- conv2
I1109 00:39:24.935094 138786 net.cpp:570] norm2 -> norm2
I1109 00:39:24.937377 138786 net.cpp:210] Setting up norm2
I1109 00:39:24.937685 138786 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:39:24.937916 138786 net.cpp:225] Memory required for data: 211922432
I1109 00:39:24.938107 138786 layer_factory.hpp:114] Creating layer pool2
I1109 00:39:24.938387 138786 net.cpp:160] Creating Layer pool2
I1109 00:39:24.938606 138786 net.cpp:596] pool2 <- norm2
I1109 00:39:24.938835 138786 net.cpp:570] pool2 -> pool2
I1109 00:39:24.939260 138786 net.cpp:210] Setting up pool2
I1109 00:39:24.939633 138786 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:39:24.939921 138786 net.cpp:225] Memory required for data: 217460224
I1109 00:39:24.940125 138786 layer_factory.hpp:114] Creating layer conv3
I1109 00:39:24.940461 138786 net.cpp:160] Creating Layer conv3
I1109 00:39:24.940685 138786 net.cpp:596] conv3 <- pool2
I1109 00:39:24.940973 138786 net.cpp:570] conv3 -> conv3
I1109 00:39:25.431728 138786 net.cpp:210] Setting up conv3
I1109 00:39:25.434236 138786 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:39:25.434589 138786 net.cpp:225] Memory required for data: 225766912
I1109 00:39:25.437765 138786 layer_factory.hpp:114] Creating layer relu3
I1109 00:39:25.438163 138786 net.cpp:160] Creating Layer relu3
I1109 00:39:25.438412 138786 net.cpp:596] relu3 <- conv3
I1109 00:39:25.438685 138786 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:39:25.442817 138786 net.cpp:210] Setting up relu3
I1109 00:39:25.443127 138786 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:39:25.443380 138786 net.cpp:225] Memory required for data: 234073600
I1109 00:39:25.443583 138786 layer_factory.hpp:114] Creating layer conv4
I1109 00:39:25.443948 138786 net.cpp:160] Creating Layer conv4
I1109 00:39:25.444205 138786 net.cpp:596] conv4 <- conv3
I1109 00:39:25.444453 138786 net.cpp:570] conv4 -> conv4
I1109 00:39:25.685781 138786 net.cpp:210] Setting up conv4
I1109 00:39:25.686167 138786 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:39:25.686560 138786 net.cpp:225] Memory required for data: 242380288
I1109 00:39:25.686902 138786 layer_factory.hpp:114] Creating layer relu4
I1109 00:39:25.687198 138786 net.cpp:160] Creating Layer relu4
I1109 00:39:25.687424 138786 net.cpp:596] relu4 <- conv4
I1109 00:39:25.687659 138786 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:39:25.699960 138786 net.cpp:210] Setting up relu4
I1109 00:39:25.700271 138786 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:39:25.700516 138786 net.cpp:225] Memory required for data: 250686976
I1109 00:39:25.700749 138786 layer_factory.hpp:114] Creating layer conv5
I1109 00:39:25.701192 138786 net.cpp:160] Creating Layer conv5
I1109 00:39:25.701444 138786 net.cpp:596] conv5 <- conv4
I1109 00:39:25.701719 138786 net.cpp:570] conv5 -> conv5
I1109 00:39:25.869577 138786 net.cpp:210] Setting up conv5
I1109 00:39:25.869973 138786 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:39:25.870419 138786 net.cpp:225] Memory required for data: 256224768
I1109 00:39:25.875133 138786 layer_factory.hpp:114] Creating layer relu5
I1109 00:39:25.875561 138786 net.cpp:160] Creating Layer relu5
I1109 00:39:25.875807 138786 net.cpp:596] relu5 <- conv5
I1109 00:39:25.876068 138786 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:39:25.876566 138786 net.cpp:210] Setting up relu5
I1109 00:39:25.876946 138786 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:39:25.877202 138786 net.cpp:225] Memory required for data: 261762560
I1109 00:39:25.877408 138786 layer_factory.hpp:114] Creating layer pool5
I1109 00:39:25.877670 138786 net.cpp:160] Creating Layer pool5
I1109 00:39:25.877876 138786 net.cpp:596] pool5 <- conv5
I1109 00:39:25.878093 138786 net.cpp:570] pool5 -> pool5
I1109 00:39:25.878485 138786 net.cpp:210] Setting up pool5
I1109 00:39:25.878739 138786 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:39:25.878962 138786 net.cpp:225] Memory required for data: 262942208
I1109 00:39:25.879179 138786 layer_factory.hpp:114] Creating layer fc6
I1109 00:39:25.934411 138786 net.cpp:160] Creating Layer fc6
I1109 00:39:25.934722 138786 net.cpp:596] fc6 <- pool5
I1109 00:39:25.935091 138786 net.cpp:570] fc6 -> fc6
I1109 00:39:30.074082 138786 net.cpp:210] Setting up fc6
I1109 00:39:30.074386 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:30.076479 138786 net.cpp:225] Memory required for data: 263466496
I1109 00:39:30.076828 138786 layer_factory.hpp:114] Creating layer relu6
I1109 00:39:30.079344 138786 net.cpp:160] Creating Layer relu6
I1109 00:39:30.079633 138786 net.cpp:596] relu6 <- fc6
I1109 00:39:30.079857 138786 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:39:30.080274 138786 net.cpp:210] Setting up relu6
I1109 00:39:30.080523 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:30.080745 138786 net.cpp:225] Memory required for data: 263990784
I1109 00:39:30.080988 138786 layer_factory.hpp:114] Creating layer drop6
I1109 00:39:30.100873 138786 net.cpp:160] Creating Layer drop6
I1109 00:39:30.101176 138786 net.cpp:596] drop6 <- fc6
I1109 00:39:30.101541 138786 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:39:30.204430 138786 net.cpp:210] Setting up drop6
I1109 00:39:30.204725 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:30.205112 138786 net.cpp:225] Memory required for data: 264515072
I1109 00:39:30.205377 138786 layer_factory.hpp:114] Creating layer fc7
I1109 00:39:30.205669 138786 net.cpp:160] Creating Layer fc7
I1109 00:39:30.205886 138786 net.cpp:596] fc7 <- fc6
I1109 00:39:30.206279 138786 net.cpp:570] fc7 -> fc7
I1109 00:39:31.927567 138786 net.cpp:210] Setting up fc7
I1109 00:39:31.927922 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:31.928319 138786 net.cpp:225] Memory required for data: 265039360
I1109 00:39:31.928668 138786 layer_factory.hpp:114] Creating layer relu7
I1109 00:39:31.929044 138786 net.cpp:160] Creating Layer relu7
I1109 00:39:31.929286 138786 net.cpp:596] relu7 <- fc7
I1109 00:39:31.929532 138786 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:39:31.929972 138786 net.cpp:210] Setting up relu7
I1109 00:39:31.930250 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:31.930490 138786 net.cpp:225] Memory required for data: 265563648
I1109 00:39:31.930686 138786 layer_factory.hpp:114] Creating layer drop7
I1109 00:39:31.930950 138786 net.cpp:160] Creating Layer drop7
I1109 00:39:31.931159 138786 net.cpp:596] drop7 <- fc7
I1109 00:39:31.931391 138786 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:39:31.931717 138786 net.cpp:210] Setting up drop7
I1109 00:39:31.931951 138786 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:39:31.932168 138786 net.cpp:225] Memory required for data: 266087936
I1109 00:39:31.932354 138786 layer_factory.hpp:114] Creating layer fc8
I1109 00:39:31.932623 138786 net.cpp:160] Creating Layer fc8
I1109 00:39:31.932870 138786 net.cpp:596] fc8 <- fc7
I1109 00:39:31.933114 138786 net.cpp:570] fc8 -> fc8
I1109 00:39:32.356950 138786 net.cpp:210] Setting up fc8
I1109 00:39:32.357301 138786 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:39:32.357698 138786 net.cpp:225] Memory required for data: 266215936
I1109 00:39:32.358005 138786 layer_factory.hpp:114] Creating layer loss
I1109 00:39:32.382381 138786 net.cpp:160] Creating Layer loss
I1109 00:39:32.382694 138786 net.cpp:596] loss <- fc8
I1109 00:39:32.383687 138786 net.cpp:596] loss <- label
I1109 00:39:32.411078 138786 net.cpp:570] loss -> loss
I1109 00:39:32.448604 138786 layer_factory.hpp:114] Creating layer loss
I1109 00:39:34.998252 138786 net.cpp:210] Setting up loss
I1109 00:39:35.045897 138786 net.cpp:217] Top shape: (1)
I1109 00:39:35.067200 138786 net.cpp:220]     with loss weight 1
I1109 00:39:35.199882 138786 net.cpp:225] Memory required for data: 266215940
I1109 00:39:35.238345 138786 net.cpp:287] loss needs backward computation.
I1109 00:39:35.327798 138786 net.cpp:287] fc8 needs backward computation.
I1109 00:39:35.335218 138786 net.cpp:287] drop7 needs backward computation.
I1109 00:39:35.346643 138786 net.cpp:287] relu7 needs backward computation.
I1109 00:39:35.346962 138786 net.cpp:287] fc7 needs backward computation.
I1109 00:39:35.349560 138786 net.cpp:287] drop6 needs backward computation.
I1109 00:39:35.349930 138786 net.cpp:287] relu6 needs backward computation.
I1109 00:39:35.350260 138786 net.cpp:287] fc6 needs backward computation.
I1109 00:39:35.350951 138786 net.cpp:287] pool5 needs backward computation.
I1109 00:39:35.351711 138786 net.cpp:287] relu5 needs backward computation.
I1109 00:39:35.351979 138786 net.cpp:287] conv5 needs backward computation.
I1109 00:39:35.352181 138786 net.cpp:287] relu4 needs backward computation.
I1109 00:39:35.352373 138786 net.cpp:287] conv4 needs backward computation.
I1109 00:39:35.352566 138786 net.cpp:287] relu3 needs backward computation.
I1109 00:39:35.352833 138786 net.cpp:287] conv3 needs backward computation.
I1109 00:39:35.365192 138786 net.cpp:287] pool2 needs backward computation.
I1109 00:39:35.365530 138786 net.cpp:287] norm2 needs backward computation.
I1109 00:39:35.365841 138786 net.cpp:287] relu2 needs backward computation.
I1109 00:39:35.366080 138786 net.cpp:287] conv2 needs backward computation.
I1109 00:39:35.366272 138786 net.cpp:287] pool1 needs backward computation.
I1109 00:39:35.366463 138786 net.cpp:287] norm1 needs backward computation.
I1109 00:39:35.366652 138786 net.cpp:287] relu1 needs backward computation.
I1109 00:39:35.366837 138786 net.cpp:287] conv1 needs backward computation.
I1109 00:39:35.379393 138786 net.cpp:289] data does not need backward computation.
I1109 00:39:35.404424 138786 net.cpp:331] This network produces output loss
I1109 00:39:35.485728 138786 net.cpp:345] Network initialization done.
I1109 00:39:35.655592 138786 caffe.cpp:452] Performing Forward
I1109 00:39:48.899852 138786 caffe.cpp:457] Initial loss: 6.80948
I1109 00:39:48.952395 138786 caffe.cpp:459] Performing Backward
I1109 00:39:53.589550 138786 caffe.cpp:468] *** Benchmark begins ***
I1109 00:39:53.598834 138786 caffe.cpp:469] Testing for 1 iterations.
I1109 00:39:53.740180 138786 caffe.cpp:482] Profiling Layer: drop6 forward
I1109 00:39:55.941421 138786 caffe.cpp:512] Iteration: 1 forward-backward time: 2195 ms.
I1109 00:39:56.096535 138786 caffe.cpp:519] Average time per layer: 
I1109 00:39:56.112035 138786 caffe.cpp:522]       data	forward: 550.143 ms.
I1109 00:39:56.184286 138786 caffe.cpp:526]       data	backward: 4.949 ms.
I1109 00:39:56.208117 138786 caffe.cpp:522]      conv1	forward: 128.595 ms.
I1109 00:39:56.218683 138786 caffe.cpp:526]      conv1	backward: 45.794 ms.
I1109 00:39:56.228085 138786 caffe.cpp:522]      relu1	forward: 18.508 ms.
I1109 00:39:56.234062 138786 caffe.cpp:526]      relu1	backward: 8.469 ms.
I1109 00:39:56.242494 138786 caffe.cpp:522]      norm1	forward: 23.172 ms.
I1109 00:39:56.246561 138786 caffe.cpp:526]      norm1	backward: 12.166 ms.
I1109 00:39:56.254817 138786 caffe.cpp:522]      pool1	forward: 16.696 ms.
I1109 00:39:56.259033 138786 caffe.cpp:526]      pool1	backward: 73.632 ms.
I1109 00:39:56.270495 138786 caffe.cpp:522]      conv2	forward: 63.362 ms.
I1109 00:39:56.276983 138786 caffe.cpp:526]      conv2	backward: 86.6 ms.
I1109 00:39:56.284549 138786 caffe.cpp:522]      relu2	forward: 16.91 ms.
I1109 00:39:56.288408 138786 caffe.cpp:526]      relu2	backward: 15.679 ms.
I1109 00:39:56.290290 138786 caffe.cpp:522]      norm2	forward: 14.784 ms.
I1109 00:39:56.290552 138786 caffe.cpp:526]      norm2	backward: 14.677 ms.
I1109 00:39:56.290750 138786 caffe.cpp:522]      pool2	forward: 14.463 ms.
I1109 00:39:56.290941 138786 caffe.cpp:526]      pool2	backward: 60.461 ms.
I1109 00:39:56.291132 138786 caffe.cpp:522]      conv3	forward: 34.656 ms.
I1109 00:39:56.291323 138786 caffe.cpp:526]      conv3	backward: 80.55 ms.
I1109 00:39:56.291514 138786 caffe.cpp:522]      relu3	forward: 15.866 ms.
I1109 00:39:56.291705 138786 caffe.cpp:526]      relu3	backward: 28.764 ms.
I1109 00:39:56.291934 138786 caffe.cpp:522]      conv4	forward: 38.092 ms.
I1109 00:39:56.292986 138786 caffe.cpp:526]      conv4	backward: 68.947 ms.
I1109 00:39:56.293261 138786 caffe.cpp:522]      relu4	forward: 12.131 ms.
I1109 00:39:56.293457 138786 caffe.cpp:526]      relu4	backward: 44.359 ms.
I1109 00:39:56.293650 138786 caffe.cpp:522]      conv5	forward: 17.576 ms.
I1109 00:39:56.293844 138786 caffe.cpp:526]      conv5	backward: 72.822 ms.
I1109 00:39:56.294035 138786 caffe.cpp:522]      relu5	forward: 0.196 ms.
I1109 00:39:56.294225 138786 caffe.cpp:526]      relu5	backward: 13.274 ms.
I1109 00:39:56.294416 138786 caffe.cpp:522]      pool5	forward: 0.284 ms.
I1109 00:39:56.294605 138786 caffe.cpp:526]      pool5	backward: 41.743 ms.
I1109 00:39:56.294827 138786 caffe.cpp:522]        fc6	forward: 16.453 ms.
I1109 00:39:56.295032 138786 caffe.cpp:526]        fc6	backward: 125.843 ms.
I1109 00:39:56.295323 138786 caffe.cpp:522]      relu6	forward: 0.803 ms.
I1109 00:39:56.295584 138786 caffe.cpp:526]      relu6	backward: 9.082 ms.
I1109 00:39:56.295779 138786 caffe.cpp:522]      drop6	forward: 13.478 ms.
I1109 00:39:56.295972 138786 caffe.cpp:526]      drop6	backward: 9.926 ms.
I1109 00:39:56.296164 138786 caffe.cpp:522]        fc7	forward: 4.59 ms.
I1109 00:39:56.296351 138786 caffe.cpp:526]        fc7	backward: 87.275 ms.
I1109 00:39:56.296543 138786 caffe.cpp:522]      relu7	forward: 0.136 ms.
I1109 00:39:56.296731 138786 caffe.cpp:526]      relu7	backward: 11.872 ms.
I1109 00:39:56.296953 138786 caffe.cpp:522]      drop7	forward: 0.309 ms.
I1109 00:39:56.297143 138786 caffe.cpp:526]      drop7	backward: 12.887 ms.
I1109 00:39:56.297372 138786 caffe.cpp:522]        fc8	forward: 1.925 ms.
I1109 00:39:56.297590 138786 caffe.cpp:526]        fc8	backward: 90.03 ms.
I1109 00:39:56.297781 138786 caffe.cpp:522]       loss	forward: 40.942 ms.
I1109 00:39:56.297972 138786 caffe.cpp:526]       loss	backward: 37.368 ms.
I1109 00:39:56.303459 138786 caffe.cpp:532] Average Forward pass: 1099.86 ms.
I1109 00:39:56.316148 138786 caffe.cpp:535] Average Backward pass: 1067.05 ms.
I1109 00:39:56.326900 138786 caffe.cpp:537] Average Forward-Backward: 2662 ms.
I1109 00:39:56.341665 138786 caffe.cpp:540] Total Time: 2662 ms.
I1109 00:39:56.353756 138786 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 16384
elements_fp_double_1 = 33
elements_fp_double_2 = 196832
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 262147
--->Total double-precision FLOPs = 393697
--->Total FLOPs = 655844
mem-read-1 = 480312
mem-read-2 = 71
mem-read-4 = 3864574
mem-read-8 = 5297524
mem-read-16 = 655376
mem-read-32 = 0
mem-read-64 = 24592
mem-write-1 = 138
mem-write-2 = 50
mem-write-4 = 1877
mem-write-8 = 553180
mem-write-16 = 32
mem-write-32 = 0
mem-write-64 = 16384
--->Total Bytes read = 70378846
--->Total Bytes written = 5482274
--->Total Bytes = 75861120
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer19_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=19 -prof_forward_direction=1
I1109 00:45:18.304345 138939 caffe.cpp:444] Use CPU.
I1109 00:45:35.219615 138939 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:45:35.276360 138939 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:45:35.288522 138939 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:45:35.301755 138939 cpu_info.cpp:461] Total number of processors: 272
I1109 00:45:35.313587 138939 cpu_info.cpp:464] GPU is used: no
I1109 00:45:35.322861 138939 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:45:35.331792 138939 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:45:35.342854 138939 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:45:44.153791 138939 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:45:44.185250 138939 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:45:44.818606 138939 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:45:47.268435 138939 layer_factory.hpp:114] Creating layer data
I1109 00:45:47.416934 138939 net.cpp:160] Creating Layer data
I1109 00:45:47.465157 138939 net.cpp:570] data -> data
I1109 00:45:47.934255 138939 net.cpp:570] data -> label
I1109 00:45:54.940994 138939 net.cpp:210] Setting up data
I1109 00:45:55.019340 138939 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:45:55.123291 138939 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:45:55.130396 138939 net.cpp:225] Memory required for data: 19787264
I1109 00:45:55.197382 138939 layer_factory.hpp:114] Creating layer conv1
I1109 00:45:55.529948 138939 net.cpp:160] Creating Layer conv1
I1109 00:45:55.581516 138939 net.cpp:596] conv1 <- data
I1109 00:45:55.701776 138939 net.cpp:570] conv1 -> conv1
I1109 00:46:28.310817 138939 net.cpp:210] Setting up conv1
I1109 00:46:28.317952 138939 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:46:28.318315 138939 net.cpp:225] Memory required for data: 56958464
I1109 00:46:28.596132 138939 layer_factory.hpp:114] Creating layer relu1
I1109 00:46:28.716874 138939 net.cpp:160] Creating Layer relu1
I1109 00:46:28.721423 138939 net.cpp:596] relu1 <- conv1
I1109 00:46:28.755019 138939 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:46:28.944243 138939 net.cpp:210] Setting up relu1
I1109 00:46:28.946712 138939 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:46:28.947053 138939 net.cpp:225] Memory required for data: 94129664
I1109 00:46:28.947259 138939 layer_factory.hpp:114] Creating layer norm1
I1109 00:46:29.051231 138939 net.cpp:160] Creating Layer norm1
I1109 00:46:29.051547 138939 net.cpp:596] norm1 <- conv1
I1109 00:46:29.054121 138939 net.cpp:570] norm1 -> norm1
I1109 00:46:29.276345 138939 net.cpp:210] Setting up norm1
I1109 00:46:29.289314 138939 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:46:29.289697 138939 net.cpp:225] Memory required for data: 131300864
I1109 00:46:29.290035 138939 layer_factory.hpp:114] Creating layer pool1
I1109 00:46:29.383070 138939 net.cpp:160] Creating Layer pool1
I1109 00:46:29.383383 138939 net.cpp:596] pool1 <- norm1
I1109 00:46:29.398159 138939 net.cpp:570] pool1 -> pool1
I1109 00:46:29.698921 138939 net.cpp:210] Setting up pool1
I1109 00:46:29.701463 138939 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:46:29.701829 138939 net.cpp:225] Memory required for data: 140258816
I1109 00:46:29.702054 138939 layer_factory.hpp:114] Creating layer conv2
I1109 00:46:29.702420 138939 net.cpp:160] Creating Layer conv2
I1109 00:46:29.702648 138939 net.cpp:596] conv2 <- pool1
I1109 00:46:29.702898 138939 net.cpp:570] conv2 -> conv2
I1109 00:46:35.489891 138939 net.cpp:210] Setting up conv2
I1109 00:46:35.490211 138939 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:46:35.490535 138939 net.cpp:225] Memory required for data: 164146688
I1109 00:46:35.540391 138939 layer_factory.hpp:114] Creating layer relu2
I1109 00:46:35.540915 138939 net.cpp:160] Creating Layer relu2
I1109 00:46:35.541252 138939 net.cpp:596] relu2 <- conv2
I1109 00:46:35.541537 138939 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:46:35.542035 138939 net.cpp:210] Setting up relu2
I1109 00:46:35.542331 138939 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:46:35.542585 138939 net.cpp:225] Memory required for data: 188034560
I1109 00:46:35.542812 138939 layer_factory.hpp:114] Creating layer norm2
I1109 00:46:35.543056 138939 net.cpp:160] Creating Layer norm2
I1109 00:46:35.543253 138939 net.cpp:596] norm2 <- conv2
I1109 00:46:35.543520 138939 net.cpp:570] norm2 -> norm2
I1109 00:46:35.545758 138939 net.cpp:210] Setting up norm2
I1109 00:46:35.546068 138939 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:46:35.546308 138939 net.cpp:225] Memory required for data: 211922432
I1109 00:46:35.546496 138939 layer_factory.hpp:114] Creating layer pool2
I1109 00:46:35.547502 138939 net.cpp:160] Creating Layer pool2
I1109 00:46:35.547791 138939 net.cpp:596] pool2 <- norm2
I1109 00:46:35.548038 138939 net.cpp:570] pool2 -> pool2
I1109 00:46:35.548431 138939 net.cpp:210] Setting up pool2
I1109 00:46:35.548681 138939 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:46:35.548969 138939 net.cpp:225] Memory required for data: 217460224
I1109 00:46:35.549173 138939 layer_factory.hpp:114] Creating layer conv3
I1109 00:46:35.549543 138939 net.cpp:160] Creating Layer conv3
I1109 00:46:35.549830 138939 net.cpp:596] conv3 <- pool2
I1109 00:46:35.550246 138939 net.cpp:570] conv3 -> conv3
I1109 00:46:36.003036 138939 net.cpp:210] Setting up conv3
I1109 00:46:36.009558 138939 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:46:36.009917 138939 net.cpp:225] Memory required for data: 225766912
I1109 00:46:36.012928 138939 layer_factory.hpp:114] Creating layer relu3
I1109 00:46:36.013335 138939 net.cpp:160] Creating Layer relu3
I1109 00:46:36.013633 138939 net.cpp:596] relu3 <- conv3
I1109 00:46:36.013887 138939 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:46:36.018009 138939 net.cpp:210] Setting up relu3
I1109 00:46:36.018318 138939 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:46:36.018575 138939 net.cpp:225] Memory required for data: 234073600
I1109 00:46:36.018769 138939 layer_factory.hpp:114] Creating layer conv4
I1109 00:46:36.019129 138939 net.cpp:160] Creating Layer conv4
I1109 00:46:36.019381 138939 net.cpp:596] conv4 <- conv3
I1109 00:46:36.019667 138939 net.cpp:570] conv4 -> conv4
I1109 00:46:36.260149 138939 net.cpp:210] Setting up conv4
I1109 00:46:36.260536 138939 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:46:36.261070 138939 net.cpp:225] Memory required for data: 242380288
I1109 00:46:36.261391 138939 layer_factory.hpp:114] Creating layer relu4
I1109 00:46:36.261695 138939 net.cpp:160] Creating Layer relu4
I1109 00:46:36.261932 138939 net.cpp:596] relu4 <- conv4
I1109 00:46:36.262171 138939 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:46:36.274530 138939 net.cpp:210] Setting up relu4
I1109 00:46:36.274875 138939 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:46:36.275280 138939 net.cpp:225] Memory required for data: 250686976
I1109 00:46:36.275496 138939 layer_factory.hpp:114] Creating layer conv5
I1109 00:46:36.275861 138939 net.cpp:160] Creating Layer conv5
I1109 00:46:36.276103 138939 net.cpp:596] conv5 <- conv4
I1109 00:46:36.276348 138939 net.cpp:570] conv5 -> conv5
I1109 00:46:36.471426 138939 net.cpp:210] Setting up conv5
I1109 00:46:36.471825 138939 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:46:36.472287 138939 net.cpp:225] Memory required for data: 256224768
I1109 00:46:36.477025 138939 layer_factory.hpp:114] Creating layer relu5
I1109 00:46:36.477437 138939 net.cpp:160] Creating Layer relu5
I1109 00:46:36.477699 138939 net.cpp:596] relu5 <- conv5
I1109 00:46:36.477974 138939 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:46:36.478484 138939 net.cpp:210] Setting up relu5
I1109 00:46:36.478785 138939 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:46:36.479107 138939 net.cpp:225] Memory required for data: 261762560
I1109 00:46:36.479347 138939 layer_factory.hpp:114] Creating layer pool5
I1109 00:46:36.479611 138939 net.cpp:160] Creating Layer pool5
I1109 00:46:36.479833 138939 net.cpp:596] pool5 <- conv5
I1109 00:46:36.480057 138939 net.cpp:570] pool5 -> pool5
I1109 00:46:36.480448 138939 net.cpp:210] Setting up pool5
I1109 00:46:36.480715 138939 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:46:36.481003 138939 net.cpp:225] Memory required for data: 262942208
I1109 00:46:36.481194 138939 layer_factory.hpp:114] Creating layer fc6
I1109 00:46:36.535789 138939 net.cpp:160] Creating Layer fc6
I1109 00:46:36.536097 138939 net.cpp:596] fc6 <- pool5
I1109 00:46:36.536481 138939 net.cpp:570] fc6 -> fc6
I1109 00:46:40.621651 138939 net.cpp:210] Setting up fc6
I1109 00:46:40.621958 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:40.624018 138939 net.cpp:225] Memory required for data: 263466496
I1109 00:46:40.624328 138939 layer_factory.hpp:114] Creating layer relu6
I1109 00:46:40.626811 138939 net.cpp:160] Creating Layer relu6
I1109 00:46:40.627107 138939 net.cpp:596] relu6 <- fc6
I1109 00:46:40.627336 138939 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:46:40.627750 138939 net.cpp:210] Setting up relu6
I1109 00:46:40.628003 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:40.628228 138939 net.cpp:225] Memory required for data: 263990784
I1109 00:46:40.628417 138939 layer_factory.hpp:114] Creating layer drop6
I1109 00:46:40.648049 138939 net.cpp:160] Creating Layer drop6
I1109 00:46:40.648352 138939 net.cpp:596] drop6 <- fc6
I1109 00:46:40.648730 138939 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:46:40.752163 138939 net.cpp:210] Setting up drop6
I1109 00:46:40.752460 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:40.752831 138939 net.cpp:225] Memory required for data: 264515072
I1109 00:46:40.753087 138939 layer_factory.hpp:114] Creating layer fc7
I1109 00:46:40.753357 138939 net.cpp:160] Creating Layer fc7
I1109 00:46:40.753561 138939 net.cpp:596] fc7 <- fc6
I1109 00:46:40.753926 138939 net.cpp:570] fc7 -> fc7
I1109 00:46:42.466941 138939 net.cpp:210] Setting up fc7
I1109 00:46:42.467309 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:42.467737 138939 net.cpp:225] Memory required for data: 265039360
I1109 00:46:42.468103 138939 layer_factory.hpp:114] Creating layer relu7
I1109 00:46:42.468443 138939 net.cpp:160] Creating Layer relu7
I1109 00:46:42.468694 138939 net.cpp:596] relu7 <- fc7
I1109 00:46:42.469012 138939 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:46:42.469473 138939 net.cpp:210] Setting up relu7
I1109 00:46:42.469761 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:42.470016 138939 net.cpp:225] Memory required for data: 265563648
I1109 00:46:42.470259 138939 layer_factory.hpp:114] Creating layer drop7
I1109 00:46:42.470515 138939 net.cpp:160] Creating Layer drop7
I1109 00:46:42.470737 138939 net.cpp:596] drop7 <- fc7
I1109 00:46:42.471009 138939 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:46:42.471277 138939 net.cpp:210] Setting up drop7
I1109 00:46:42.471489 138939 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:46:42.471709 138939 net.cpp:225] Memory required for data: 266087936
I1109 00:46:42.471896 138939 layer_factory.hpp:114] Creating layer fc8
I1109 00:46:42.472151 138939 net.cpp:160] Creating Layer fc8
I1109 00:46:42.472347 138939 net.cpp:596] fc8 <- fc7
I1109 00:46:42.472571 138939 net.cpp:570] fc8 -> fc8
I1109 00:46:42.894155 138939 net.cpp:210] Setting up fc8
I1109 00:46:42.894506 138939 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:46:42.894898 138939 net.cpp:225] Memory required for data: 266215936
I1109 00:46:42.895233 138939 layer_factory.hpp:114] Creating layer loss
I1109 00:46:42.919967 138939 net.cpp:160] Creating Layer loss
I1109 00:46:42.920279 138939 net.cpp:596] loss <- fc8
I1109 00:46:42.921332 138939 net.cpp:596] loss <- label
I1109 00:46:42.948745 138939 net.cpp:570] loss -> loss
I1109 00:46:42.986717 138939 layer_factory.hpp:114] Creating layer loss
I1109 00:46:45.521453 138939 net.cpp:210] Setting up loss
I1109 00:46:45.569030 138939 net.cpp:217] Top shape: (1)
I1109 00:46:45.583094 138939 net.cpp:220]     with loss weight 1
I1109 00:46:45.710487 138939 net.cpp:225] Memory required for data: 266215940
I1109 00:46:45.758507 138939 net.cpp:287] loss needs backward computation.
I1109 00:46:45.846611 138939 net.cpp:287] fc8 needs backward computation.
I1109 00:46:45.853766 138939 net.cpp:287] drop7 needs backward computation.
I1109 00:46:45.864701 138939 net.cpp:287] relu7 needs backward computation.
I1109 00:46:45.865066 138939 net.cpp:287] fc7 needs backward computation.
I1109 00:46:45.867457 138939 net.cpp:287] drop6 needs backward computation.
I1109 00:46:45.867760 138939 net.cpp:287] relu6 needs backward computation.
I1109 00:46:45.868001 138939 net.cpp:287] fc6 needs backward computation.
I1109 00:46:45.868856 138939 net.cpp:287] pool5 needs backward computation.
I1109 00:46:45.869635 138939 net.cpp:287] relu5 needs backward computation.
I1109 00:46:45.869910 138939 net.cpp:287] conv5 needs backward computation.
I1109 00:46:45.870110 138939 net.cpp:287] relu4 needs backward computation.
I1109 00:46:45.870306 138939 net.cpp:287] conv4 needs backward computation.
I1109 00:46:45.870491 138939 net.cpp:287] relu3 needs backward computation.
I1109 00:46:45.870673 138939 net.cpp:287] conv3 needs backward computation.
I1109 00:46:45.882695 138939 net.cpp:287] pool2 needs backward computation.
I1109 00:46:45.883046 138939 net.cpp:287] norm2 needs backward computation.
I1109 00:46:45.883358 138939 net.cpp:287] relu2 needs backward computation.
I1109 00:46:45.883604 138939 net.cpp:287] conv2 needs backward computation.
I1109 00:46:45.883802 138939 net.cpp:287] pool1 needs backward computation.
I1109 00:46:45.883996 138939 net.cpp:287] norm1 needs backward computation.
I1109 00:46:45.884182 138939 net.cpp:287] relu1 needs backward computation.
I1109 00:46:45.884363 138939 net.cpp:287] conv1 needs backward computation.
I1109 00:46:45.897521 138939 net.cpp:289] data does not need backward computation.
I1109 00:46:45.922238 138939 net.cpp:331] This network produces output loss
I1109 00:46:45.994325 138939 net.cpp:345] Network initialization done.
I1109 00:46:46.161288 138939 caffe.cpp:452] Performing Forward
I1109 00:46:59.067812 138939 caffe.cpp:457] Initial loss: 6.98733
I1109 00:46:59.121578 138939 caffe.cpp:459] Performing Backward
I1109 00:47:04.002724 138939 caffe.cpp:468] *** Benchmark begins ***
I1109 00:47:04.015919 138939 caffe.cpp:469] Testing for 1 iterations.
I1109 00:47:04.160351 138939 caffe.cpp:482] Profiling Layer: fc7 forward
I1109 00:47:06.199748 138939 caffe.cpp:512] Iteration: 1 forward-backward time: 2030 ms.
I1109 00:47:06.359289 138939 caffe.cpp:519] Average time per layer: 
I1109 00:47:06.374714 138939 caffe.cpp:522]       data	forward: 546.954 ms.
I1109 00:47:06.443084 138939 caffe.cpp:526]       data	backward: 5.04 ms.
I1109 00:47:06.473100 138939 caffe.cpp:522]      conv1	forward: 136.753 ms.
I1109 00:47:06.484509 138939 caffe.cpp:526]      conv1	backward: 36.212 ms.
I1109 00:47:06.494390 138939 caffe.cpp:522]      relu1	forward: 15.572 ms.
I1109 00:47:06.500473 138939 caffe.cpp:526]      relu1	backward: 14.758 ms.
I1109 00:47:06.504576 138939 caffe.cpp:522]      norm1	forward: 17.202 ms.
I1109 00:47:06.514556 138939 caffe.cpp:526]      norm1	backward: 21.005 ms.
I1109 00:47:06.521674 138939 caffe.cpp:522]      pool1	forward: 19.499 ms.
I1109 00:47:06.527802 138939 caffe.cpp:526]      pool1	backward: 100.76 ms.
I1109 00:47:06.532449 138939 caffe.cpp:522]      conv2	forward: 67.721 ms.
I1109 00:47:06.533223 138939 caffe.cpp:526]      conv2	backward: 80.351 ms.
I1109 00:47:06.533496 138939 caffe.cpp:522]      relu2	forward: 18.835 ms.
I1109 00:47:06.533766 138939 caffe.cpp:526]      relu2	backward: 20.055 ms.
I1109 00:47:06.534049 138939 caffe.cpp:522]      norm2	forward: 15.22 ms.
I1109 00:47:06.534278 138939 caffe.cpp:526]      norm2	backward: 18.878 ms.
I1109 00:47:06.534474 138939 caffe.cpp:522]      pool2	forward: 12.347 ms.
I1109 00:47:06.534668 138939 caffe.cpp:526]      pool2	backward: 63.533 ms.
I1109 00:47:06.534860 138939 caffe.cpp:522]      conv3	forward: 33.468 ms.
I1109 00:47:06.535053 138939 caffe.cpp:526]      conv3	backward: 61.785 ms.
I1109 00:47:06.535244 138939 caffe.cpp:522]      relu3	forward: 9.802 ms.
I1109 00:47:06.536010 138939 caffe.cpp:526]      relu3	backward: 0.631 ms.
I1109 00:47:06.536236 138939 caffe.cpp:522]      conv4	forward: 29.229 ms.
I1109 00:47:06.536468 138939 caffe.cpp:526]      conv4	backward: 28.127 ms.
I1109 00:47:06.536676 138939 caffe.cpp:522]      relu4	forward: 6.666 ms.
I1109 00:47:06.537008 138939 caffe.cpp:526]      relu4	backward: 7.654 ms.
I1109 00:47:06.537230 138939 caffe.cpp:522]      conv5	forward: 29.38 ms.
I1109 00:47:06.537446 138939 caffe.cpp:526]      conv5	backward: 18.939 ms.
I1109 00:47:06.537653 138939 caffe.cpp:522]      relu5	forward: 15.19 ms.
I1109 00:47:06.537859 138939 caffe.cpp:526]      relu5	backward: 0.251 ms.
I1109 00:47:06.538060 138939 caffe.cpp:522]      pool5	forward: 19.485 ms.
I1109 00:47:06.538264 138939 caffe.cpp:526]      pool5	backward: 12.217 ms.
I1109 00:47:06.538467 138939 caffe.cpp:522]        fc6	forward: 42.688 ms.
I1109 00:47:06.538671 138939 caffe.cpp:526]        fc6	backward: 29.457 ms.
I1109 00:47:06.538873 138939 caffe.cpp:522]      relu6	forward: 19.725 ms.
I1109 00:47:06.539077 138939 caffe.cpp:526]      relu6	backward: 0.079 ms.
I1109 00:47:06.539886 138939 caffe.cpp:522]      drop6	forward: 32.133 ms.
I1109 00:47:06.540154 138939 caffe.cpp:526]      drop6	backward: 0.084 ms.
I1109 00:47:06.542284 138939 caffe.cpp:522]        fc7	forward: 27.841 ms.
I1109 00:47:06.542572 138939 caffe.cpp:526]        fc7	backward: 19.213 ms.
I1109 00:47:06.542877 138939 caffe.cpp:522]      relu7	forward: 11.749 ms.
I1109 00:47:06.543155 138939 caffe.cpp:526]      relu7	backward: 0.086 ms.
I1109 00:47:06.543359 138939 caffe.cpp:522]      drop7	forward: 33.293 ms.
I1109 00:47:06.543557 138939 caffe.cpp:526]      drop7	backward: 0.097 ms.
I1109 00:47:06.543750 138939 caffe.cpp:522]        fc8	forward: 17.56 ms.
I1109 00:47:06.543942 138939 caffe.cpp:526]        fc8	backward: 104.941 ms.
I1109 00:47:06.544134 138939 caffe.cpp:522]       loss	forward: 58.02 ms.
I1109 00:47:06.544324 138939 caffe.cpp:526]       loss	backward: 61.956 ms.
I1109 00:47:06.550029 138939 caffe.cpp:532] Average Forward pass: 1290.68 ms.
I1109 00:47:06.563745 138939 caffe.cpp:535] Average Backward pass: 714.9 ms.
I1109 00:47:06.574846 138939 caffe.cpp:537] Average Forward-Backward: 2487 ms.
I1109 00:47:06.589668 138939 caffe.cpp:540] Total Time: 2487 ms.
I1109 00:47:06.601802 138939 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3415
elements_fp_single_4 = 0
elements_fp_single_8 = 2392064
elements_fp_single_16 = 67223552
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 1094716759
--->Total double-precision FLOPs = 0
--->Total FLOPs = 1094716759
mem-read-1 = 23679
mem-read-2 = 56
mem-read-4 = 33753117
mem-read-8 = 508451
mem-read-16 = 4653930
mem-read-32 = 32768
mem-read-64 = 9261731
mem-write-1 = 62
mem-write-2 = 17
mem-write-4 = 1884
mem-write-8 = 161659
mem-write-16 = 66410
mem-write-32 = 2326528
mem-write-64 = 128419
--->Total Bytes read = 807366107
--->Total Bytes written = 85031176
--->Total Bytes = 892397283
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer20_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=20 -prof_forward_direction=1
I1109 00:52:45.376983 139123 caffe.cpp:444] Use CPU.
I1109 00:53:02.394609 139123 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:53:02.450670 139123 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:53:02.462771 139123 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:53:02.475459 139123 cpu_info.cpp:461] Total number of processors: 272
I1109 00:53:02.486775 139123 cpu_info.cpp:464] GPU is used: no
I1109 00:53:02.495769 139123 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:53:02.504649 139123 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:53:02.515640 139123 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:53:11.322090 139123 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:53:11.353778 139123 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:53:11.994807 139123 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:53:14.449437 139123 layer_factory.hpp:114] Creating layer data
I1109 00:53:14.596408 139123 net.cpp:160] Creating Layer data
I1109 00:53:14.644435 139123 net.cpp:570] data -> data
I1109 00:53:15.110832 139123 net.cpp:570] data -> label
I1109 00:53:22.165705 139123 net.cpp:210] Setting up data
I1109 00:53:22.245875 139123 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:53:22.350203 139123 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:53:22.357409 139123 net.cpp:225] Memory required for data: 19787264
I1109 00:53:22.425081 139123 layer_factory.hpp:114] Creating layer conv1
I1109 00:53:22.750427 139123 net.cpp:160] Creating Layer conv1
I1109 00:53:22.800252 139123 net.cpp:596] conv1 <- data
I1109 00:53:22.920492 139123 net.cpp:570] conv1 -> conv1
I1109 00:53:55.622194 139123 net.cpp:210] Setting up conv1
I1109 00:53:55.629060 139123 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:53:55.629446 139123 net.cpp:225] Memory required for data: 56958464
I1109 00:53:55.913588 139123 layer_factory.hpp:114] Creating layer relu1
I1109 00:53:56.033771 139123 net.cpp:160] Creating Layer relu1
I1109 00:53:56.038295 139123 net.cpp:596] relu1 <- conv1
I1109 00:53:56.071640 139123 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:53:56.262043 139123 net.cpp:210] Setting up relu1
I1109 00:53:56.264508 139123 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:53:56.264920 139123 net.cpp:225] Memory required for data: 94129664
I1109 00:53:56.265138 139123 layer_factory.hpp:114] Creating layer norm1
I1109 00:53:56.369513 139123 net.cpp:160] Creating Layer norm1
I1109 00:53:56.369827 139123 net.cpp:596] norm1 <- conv1
I1109 00:53:56.372356 139123 net.cpp:570] norm1 -> norm1
I1109 00:53:56.595115 139123 net.cpp:210] Setting up norm1
I1109 00:53:56.607972 139123 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:53:56.608341 139123 net.cpp:225] Memory required for data: 131300864
I1109 00:53:56.608640 139123 layer_factory.hpp:114] Creating layer pool1
I1109 00:53:56.702090 139123 net.cpp:160] Creating Layer pool1
I1109 00:53:56.702399 139123 net.cpp:596] pool1 <- norm1
I1109 00:53:56.717241 139123 net.cpp:570] pool1 -> pool1
I1109 00:53:57.017510 139123 net.cpp:210] Setting up pool1
I1109 00:53:57.019945 139123 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:53:57.020264 139123 net.cpp:225] Memory required for data: 140258816
I1109 00:53:57.020501 139123 layer_factory.hpp:114] Creating layer conv2
I1109 00:53:57.020912 139123 net.cpp:160] Creating Layer conv2
I1109 00:53:57.021184 139123 net.cpp:596] conv2 <- pool1
I1109 00:53:57.021415 139123 net.cpp:570] conv2 -> conv2
I1109 00:54:02.759673 139123 net.cpp:210] Setting up conv2
I1109 00:54:02.760012 139123 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:54:02.760406 139123 net.cpp:225] Memory required for data: 164146688
I1109 00:54:02.811148 139123 layer_factory.hpp:114] Creating layer relu2
I1109 00:54:02.811560 139123 net.cpp:160] Creating Layer relu2
I1109 00:54:02.811916 139123 net.cpp:596] relu2 <- conv2
I1109 00:54:02.812160 139123 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:54:02.812604 139123 net.cpp:210] Setting up relu2
I1109 00:54:02.812924 139123 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:54:02.813160 139123 net.cpp:225] Memory required for data: 188034560
I1109 00:54:02.813341 139123 layer_factory.hpp:114] Creating layer norm2
I1109 00:54:02.813578 139123 net.cpp:160] Creating Layer norm2
I1109 00:54:02.813772 139123 net.cpp:596] norm2 <- conv2
I1109 00:54:02.813999 139123 net.cpp:570] norm2 -> norm2
I1109 00:54:02.816210 139123 net.cpp:210] Setting up norm2
I1109 00:54:02.816517 139123 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:54:02.816740 139123 net.cpp:225] Memory required for data: 211922432
I1109 00:54:02.816972 139123 layer_factory.hpp:114] Creating layer pool2
I1109 00:54:02.817828 139123 net.cpp:160] Creating Layer pool2
I1109 00:54:02.818208 139123 net.cpp:596] pool2 <- norm2
I1109 00:54:02.818548 139123 net.cpp:570] pool2 -> pool2
I1109 00:54:02.818949 139123 net.cpp:210] Setting up pool2
I1109 00:54:02.819187 139123 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:54:02.819403 139123 net.cpp:225] Memory required for data: 217460224
I1109 00:54:02.819598 139123 layer_factory.hpp:114] Creating layer conv3
I1109 00:54:02.819921 139123 net.cpp:160] Creating Layer conv3
I1109 00:54:02.820137 139123 net.cpp:596] conv3 <- pool2
I1109 00:54:02.820374 139123 net.cpp:570] conv3 -> conv3
I1109 00:54:03.296545 139123 net.cpp:210] Setting up conv3
I1109 00:54:03.298966 139123 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:54:03.299310 139123 net.cpp:225] Memory required for data: 225766912
I1109 00:54:03.302407 139123 layer_factory.hpp:114] Creating layer relu3
I1109 00:54:03.302829 139123 net.cpp:160] Creating Layer relu3
I1109 00:54:03.303091 139123 net.cpp:596] relu3 <- conv3
I1109 00:54:03.303342 139123 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:54:03.307488 139123 net.cpp:210] Setting up relu3
I1109 00:54:03.307796 139123 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:54:03.308038 139123 net.cpp:225] Memory required for data: 234073600
I1109 00:54:03.308230 139123 layer_factory.hpp:114] Creating layer conv4
I1109 00:54:03.308588 139123 net.cpp:160] Creating Layer conv4
I1109 00:54:03.308889 139123 net.cpp:596] conv4 <- conv3
I1109 00:54:03.309237 139123 net.cpp:570] conv4 -> conv4
I1109 00:54:03.580381 139123 net.cpp:210] Setting up conv4
I1109 00:54:03.580838 139123 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:54:03.581254 139123 net.cpp:225] Memory required for data: 242380288
I1109 00:54:03.581593 139123 layer_factory.hpp:114] Creating layer relu4
I1109 00:54:03.581903 139123 net.cpp:160] Creating Layer relu4
I1109 00:54:03.582144 139123 net.cpp:596] relu4 <- conv4
I1109 00:54:03.582396 139123 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:54:03.594749 139123 net.cpp:210] Setting up relu4
I1109 00:54:03.595099 139123 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:54:03.595481 139123 net.cpp:225] Memory required for data: 250686976
I1109 00:54:03.595823 139123 layer_factory.hpp:114] Creating layer conv5
I1109 00:54:03.596215 139123 net.cpp:160] Creating Layer conv5
I1109 00:54:03.596457 139123 net.cpp:596] conv5 <- conv4
I1109 00:54:03.596700 139123 net.cpp:570] conv5 -> conv5
I1109 00:54:03.764489 139123 net.cpp:210] Setting up conv5
I1109 00:54:03.764924 139123 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:54:03.765374 139123 net.cpp:225] Memory required for data: 256224768
I1109 00:54:03.769953 139123 layer_factory.hpp:114] Creating layer relu5
I1109 00:54:03.770359 139123 net.cpp:160] Creating Layer relu5
I1109 00:54:03.770609 139123 net.cpp:596] relu5 <- conv5
I1109 00:54:03.770875 139123 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:54:03.771384 139123 net.cpp:210] Setting up relu5
I1109 00:54:03.771682 139123 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:54:03.771986 139123 net.cpp:225] Memory required for data: 261762560
I1109 00:54:03.772222 139123 layer_factory.hpp:114] Creating layer pool5
I1109 00:54:03.772476 139123 net.cpp:160] Creating Layer pool5
I1109 00:54:03.772686 139123 net.cpp:596] pool5 <- conv5
I1109 00:54:03.772965 139123 net.cpp:570] pool5 -> pool5
I1109 00:54:03.773371 139123 net.cpp:210] Setting up pool5
I1109 00:54:03.773625 139123 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:54:03.773843 139123 net.cpp:225] Memory required for data: 262942208
I1109 00:54:03.774024 139123 layer_factory.hpp:114] Creating layer fc6
I1109 00:54:03.828264 139123 net.cpp:160] Creating Layer fc6
I1109 00:54:03.828577 139123 net.cpp:596] fc6 <- pool5
I1109 00:54:03.828989 139123 net.cpp:570] fc6 -> fc6
I1109 00:54:07.917268 139123 net.cpp:210] Setting up fc6
I1109 00:54:07.917570 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:07.919620 139123 net.cpp:225] Memory required for data: 263466496
I1109 00:54:07.919924 139123 layer_factory.hpp:114] Creating layer relu6
I1109 00:54:07.922442 139123 net.cpp:160] Creating Layer relu6
I1109 00:54:07.922739 139123 net.cpp:596] relu6 <- fc6
I1109 00:54:07.922961 139123 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:54:07.923380 139123 net.cpp:210] Setting up relu6
I1109 00:54:07.923638 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:07.923861 139123 net.cpp:225] Memory required for data: 263990784
I1109 00:54:07.924042 139123 layer_factory.hpp:114] Creating layer drop6
I1109 00:54:07.943961 139123 net.cpp:160] Creating Layer drop6
I1109 00:54:07.944265 139123 net.cpp:596] drop6 <- fc6
I1109 00:54:07.944622 139123 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:54:08.048827 139123 net.cpp:210] Setting up drop6
I1109 00:54:08.049127 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:08.049490 139123 net.cpp:225] Memory required for data: 264515072
I1109 00:54:08.049698 139123 layer_factory.hpp:114] Creating layer fc7
I1109 00:54:08.049963 139123 net.cpp:160] Creating Layer fc7
I1109 00:54:08.050168 139123 net.cpp:596] fc7 <- fc6
I1109 00:54:08.050547 139123 net.cpp:570] fc7 -> fc7
I1109 00:54:09.762320 139123 net.cpp:210] Setting up fc7
I1109 00:54:09.762681 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:09.763123 139123 net.cpp:225] Memory required for data: 265039360
I1109 00:54:09.763476 139123 layer_factory.hpp:114] Creating layer relu7
I1109 00:54:09.763830 139123 net.cpp:160] Creating Layer relu7
I1109 00:54:09.764070 139123 net.cpp:596] relu7 <- fc7
I1109 00:54:09.764318 139123 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:54:09.764766 139123 net.cpp:210] Setting up relu7
I1109 00:54:09.765103 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:09.765380 139123 net.cpp:225] Memory required for data: 265563648
I1109 00:54:09.765584 139123 layer_factory.hpp:114] Creating layer drop7
I1109 00:54:09.765830 139123 net.cpp:160] Creating Layer drop7
I1109 00:54:09.766041 139123 net.cpp:596] drop7 <- fc7
I1109 00:54:09.766373 139123 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:54:09.766644 139123 net.cpp:210] Setting up drop7
I1109 00:54:09.766849 139123 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:54:09.767058 139123 net.cpp:225] Memory required for data: 266087936
I1109 00:54:09.767237 139123 layer_factory.hpp:114] Creating layer fc8
I1109 00:54:09.767483 139123 net.cpp:160] Creating Layer fc8
I1109 00:54:09.767676 139123 net.cpp:596] fc8 <- fc7
I1109 00:54:09.767900 139123 net.cpp:570] fc8 -> fc8
I1109 00:54:10.191875 139123 net.cpp:210] Setting up fc8
I1109 00:54:10.192230 139123 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:54:10.192617 139123 net.cpp:225] Memory required for data: 266215936
I1109 00:54:10.192991 139123 layer_factory.hpp:114] Creating layer loss
I1109 00:54:10.217691 139123 net.cpp:160] Creating Layer loss
I1109 00:54:10.218003 139123 net.cpp:596] loss <- fc8
I1109 00:54:10.218998 139123 net.cpp:596] loss <- label
I1109 00:54:10.246464 139123 net.cpp:570] loss -> loss
I1109 00:54:10.284370 139123 layer_factory.hpp:114] Creating layer loss
I1109 00:54:12.853221 139123 net.cpp:210] Setting up loss
I1109 00:54:12.902384 139123 net.cpp:217] Top shape: (1)
I1109 00:54:12.914535 139123 net.cpp:220]     with loss weight 1
I1109 00:54:13.046543 139123 net.cpp:225] Memory required for data: 266215940
I1109 00:54:13.086066 139123 net.cpp:287] loss needs backward computation.
I1109 00:54:13.173213 139123 net.cpp:287] fc8 needs backward computation.
I1109 00:54:13.180407 139123 net.cpp:287] drop7 needs backward computation.
I1109 00:54:13.191462 139123 net.cpp:287] relu7 needs backward computation.
I1109 00:54:13.191782 139123 net.cpp:287] fc7 needs backward computation.
I1109 00:54:13.194257 139123 net.cpp:287] drop6 needs backward computation.
I1109 00:54:13.194602 139123 net.cpp:287] relu6 needs backward computation.
I1109 00:54:13.194910 139123 net.cpp:287] fc6 needs backward computation.
I1109 00:54:13.195660 139123 net.cpp:287] pool5 needs backward computation.
I1109 00:54:13.196403 139123 net.cpp:287] relu5 needs backward computation.
I1109 00:54:13.196662 139123 net.cpp:287] conv5 needs backward computation.
I1109 00:54:13.196902 139123 net.cpp:287] relu4 needs backward computation.
I1109 00:54:13.197098 139123 net.cpp:287] conv4 needs backward computation.
I1109 00:54:13.197284 139123 net.cpp:287] relu3 needs backward computation.
I1109 00:54:13.197504 139123 net.cpp:287] conv3 needs backward computation.
I1109 00:54:13.209606 139123 net.cpp:287] pool2 needs backward computation.
I1109 00:54:13.209959 139123 net.cpp:287] norm2 needs backward computation.
I1109 00:54:13.210265 139123 net.cpp:287] relu2 needs backward computation.
I1109 00:54:13.210500 139123 net.cpp:287] conv2 needs backward computation.
I1109 00:54:13.210691 139123 net.cpp:287] pool1 needs backward computation.
I1109 00:54:13.210872 139123 net.cpp:287] norm1 needs backward computation.
I1109 00:54:13.211053 139123 net.cpp:287] relu1 needs backward computation.
I1109 00:54:13.211228 139123 net.cpp:287] conv1 needs backward computation.
I1109 00:54:13.223717 139123 net.cpp:289] data does not need backward computation.
I1109 00:54:13.248513 139123 net.cpp:331] This network produces output loss
I1109 00:54:13.322439 139123 net.cpp:345] Network initialization done.
I1109 00:54:13.491044 139123 caffe.cpp:452] Performing Forward
I1109 00:54:26.692065 139123 caffe.cpp:457] Initial loss: 6.93731
I1109 00:54:26.748697 139123 caffe.cpp:459] Performing Backward
I1109 00:54:31.556066 139123 caffe.cpp:468] *** Benchmark begins ***
I1109 00:54:31.569175 139123 caffe.cpp:469] Testing for 1 iterations.
I1109 00:54:31.713796 139123 caffe.cpp:482] Profiling Layer: relu7 forward
I1109 00:54:33.938448 139123 caffe.cpp:512] Iteration: 1 forward-backward time: 2221 ms.
I1109 00:54:34.101606 139123 caffe.cpp:519] Average time per layer: 
I1109 00:54:34.122328 139123 caffe.cpp:522]       data	forward: 556.057 ms.
I1109 00:54:34.192463 139123 caffe.cpp:526]       data	backward: 5.304 ms.
I1109 00:54:34.215312 139123 caffe.cpp:522]      conv1	forward: 125.159 ms.
I1109 00:54:34.225332 139123 caffe.cpp:526]      conv1	backward: 44.001 ms.
I1109 00:54:34.235347 139123 caffe.cpp:522]      relu1	forward: 19.026 ms.
I1109 00:54:34.242503 139123 caffe.cpp:526]      relu1	backward: 15.615 ms.
I1109 00:54:34.246402 139123 caffe.cpp:522]      norm1	forward: 17.664 ms.
I1109 00:54:34.252111 139123 caffe.cpp:526]      norm1	backward: 19.518 ms.
I1109 00:54:34.258291 139123 caffe.cpp:522]      pool1	forward: 20.371 ms.
I1109 00:54:34.267603 139123 caffe.cpp:526]      pool1	backward: 75.375 ms.
I1109 00:54:34.271801 139123 caffe.cpp:522]      conv2	forward: 67.331 ms.
I1109 00:54:34.272032 139123 caffe.cpp:526]      conv2	backward: 77.805 ms.
I1109 00:54:34.272228 139123 caffe.cpp:522]      relu2	forward: 14.257 ms.
I1109 00:54:34.272420 139123 caffe.cpp:526]      relu2	backward: 15.732 ms.
I1109 00:54:34.272611 139123 caffe.cpp:522]      norm2	forward: 12.118 ms.
I1109 00:54:34.272855 139123 caffe.cpp:526]      norm2	backward: 17.895 ms.
I1109 00:54:34.273051 139123 caffe.cpp:522]      pool2	forward: 24.578 ms.
I1109 00:54:34.273241 139123 caffe.cpp:526]      pool2	backward: 63.546 ms.
I1109 00:54:34.273471 139123 caffe.cpp:522]      conv3	forward: 30.063 ms.
I1109 00:54:34.273684 139123 caffe.cpp:526]      conv3	backward: 78.015 ms.
I1109 00:54:34.273993 139123 caffe.cpp:522]      relu3	forward: 13.511 ms.
I1109 00:54:34.274230 139123 caffe.cpp:526]      relu3	backward: 25.781 ms.
I1109 00:54:34.274422 139123 caffe.cpp:522]      conv4	forward: 31.159 ms.
I1109 00:54:34.274613 139123 caffe.cpp:526]      conv4	backward: 70.576 ms.
I1109 00:54:34.274804 139123 caffe.cpp:522]      relu4	forward: 19.073 ms.
I1109 00:54:34.274996 139123 caffe.cpp:526]      relu4	backward: 40.801 ms.
I1109 00:54:34.275185 139123 caffe.cpp:522]      conv5	forward: 22.085 ms.
I1109 00:54:34.275377 139123 caffe.cpp:526]      conv5	backward: 66.692 ms.
I1109 00:54:34.275568 139123 caffe.cpp:522]      relu5	forward: 0.201 ms.
I1109 00:54:34.275758 139123 caffe.cpp:526]      relu5	backward: 16.085 ms.
I1109 00:54:34.275950 139123 caffe.cpp:522]      pool5	forward: 0.282 ms.
I1109 00:54:34.276139 139123 caffe.cpp:526]      pool5	backward: 51.184 ms.
I1109 00:54:34.276365 139123 caffe.cpp:522]        fc6	forward: 16.339 ms.
I1109 00:54:34.276571 139123 caffe.cpp:526]        fc6	backward: 113.415 ms.
I1109 00:54:34.276893 139123 caffe.cpp:522]      relu6	forward: 0.8 ms.
I1109 00:54:34.277104 139123 caffe.cpp:526]      relu6	backward: 26.809 ms.
I1109 00:54:34.277390 139123 caffe.cpp:522]      drop6	forward: 1.458 ms.
I1109 00:54:34.277577 139123 caffe.cpp:526]      drop6	backward: 12.264 ms.
I1109 00:54:34.277768 139123 caffe.cpp:522]        fc7	forward: 4.522 ms.
I1109 00:54:34.277954 139123 caffe.cpp:526]        fc7	backward: 107.083 ms.
I1109 00:54:34.280464 139123 caffe.cpp:522]      relu7	forward: 12.201 ms.
I1109 00:54:34.280715 139123 caffe.cpp:526]      relu7	backward: 12.792 ms.
I1109 00:54:34.280966 139123 caffe.cpp:522]      drop7	forward: 0.323 ms.
I1109 00:54:34.281159 139123 caffe.cpp:526]      drop7	backward: 16.457 ms.
I1109 00:54:34.281352 139123 caffe.cpp:522]        fc8	forward: 1.905 ms.
I1109 00:54:34.281538 139123 caffe.cpp:526]        fc8	backward: 64.836 ms.
I1109 00:54:34.281730 139123 caffe.cpp:522]       loss	forward: 41.456 ms.
I1109 00:54:34.281921 139123 caffe.cpp:526]       loss	backward: 39.67 ms.
I1109 00:54:34.287528 139123 caffe.cpp:532] Average Forward pass: 1106.69 ms.
I1109 00:54:34.300671 139123 caffe.cpp:535] Average Backward pass: 1087.3 ms.
I1109 00:54:34.311825 139123 caffe.cpp:537] Average Forward-Backward: 2673 ms.
I1109 00:54:34.326462 139123 caffe.cpp:540] Total Time: 2673 ms.
I1109 00:54:34.338667 139123 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 8192
elements_fp_double_1 = 0
elements_fp_double_2 = 8192
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 131073
--->Total double-precision FLOPs = 16384
--->Total FLOPs = 147457
mem-read-1 = 411342
mem-read-2 = 36
mem-read-4 = 3294546
mem-read-8 = 4533184
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 16401
mem-write-1 = 54
mem-write-2 = 17
mem-write-4 = 549
mem-write-8 = 414951
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 8193
--->Total Bytes read = 50904766
--->Total Bytes written = 3846276
--->Total Bytes = 54751042
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer21_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=21 -prof_forward_direction=1
I1109 00:58:06.534312 139240 caffe.cpp:444] Use CPU.
I1109 00:58:23.500011 139240 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:58:23.557376 139240 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:58:23.569295 139240 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:58:23.581889 139240 cpu_info.cpp:461] Total number of processors: 272
I1109 00:58:23.592890 139240 cpu_info.cpp:464] GPU is used: no
I1109 00:58:23.602089 139240 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:58:23.611032 139240 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:58:23.622131 139240 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:58:32.423354 139240 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:58:32.454643 139240 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:58:33.091648 139240 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:58:35.550050 139240 layer_factory.hpp:114] Creating layer data
I1109 00:58:35.707164 139240 net.cpp:160] Creating Layer data
I1109 00:58:35.754880 139240 net.cpp:570] data -> data
I1109 00:58:36.222326 139240 net.cpp:570] data -> label
I1109 00:58:43.286242 139240 net.cpp:210] Setting up data
I1109 00:58:43.367027 139240 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:58:43.471271 139240 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:58:43.478377 139240 net.cpp:225] Memory required for data: 19787264
I1109 00:58:43.546778 139240 layer_factory.hpp:114] Creating layer conv1
I1109 00:58:43.877825 139240 net.cpp:160] Creating Layer conv1
I1109 00:58:43.928663 139240 net.cpp:596] conv1 <- data
I1109 00:58:44.047598 139240 net.cpp:570] conv1 -> conv1
I1109 00:59:16.654431 139240 net.cpp:210] Setting up conv1
I1109 00:59:16.660928 139240 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:59:16.661336 139240 net.cpp:225] Memory required for data: 56958464
I1109 00:59:16.958458 139240 layer_factory.hpp:114] Creating layer relu1
I1109 00:59:17.087543 139240 net.cpp:160] Creating Layer relu1
I1109 00:59:17.092207 139240 net.cpp:596] relu1 <- conv1
I1109 00:59:17.125540 139240 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:59:17.318588 139240 net.cpp:210] Setting up relu1
I1109 00:59:17.321095 139240 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:59:17.321431 139240 net.cpp:225] Memory required for data: 94129664
I1109 00:59:17.321665 139240 layer_factory.hpp:114] Creating layer norm1
I1109 00:59:17.427691 139240 net.cpp:160] Creating Layer norm1
I1109 00:59:17.428000 139240 net.cpp:596] norm1 <- conv1
I1109 00:59:17.430625 139240 net.cpp:570] norm1 -> norm1
I1109 00:59:17.657583 139240 net.cpp:210] Setting up norm1
I1109 00:59:17.670603 139240 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:59:17.670979 139240 net.cpp:225] Memory required for data: 131300864
I1109 00:59:17.671273 139240 layer_factory.hpp:114] Creating layer pool1
I1109 00:59:17.769793 139240 net.cpp:160] Creating Layer pool1
I1109 00:59:17.770108 139240 net.cpp:596] pool1 <- norm1
I1109 00:59:17.785344 139240 net.cpp:570] pool1 -> pool1
I1109 00:59:18.095650 139240 net.cpp:210] Setting up pool1
I1109 00:59:18.098245 139240 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:59:18.098572 139240 net.cpp:225] Memory required for data: 140258816
I1109 00:59:18.098814 139240 layer_factory.hpp:114] Creating layer conv2
I1109 00:59:18.099179 139240 net.cpp:160] Creating Layer conv2
I1109 00:59:18.099496 139240 net.cpp:596] conv2 <- pool1
I1109 00:59:18.099726 139240 net.cpp:570] conv2 -> conv2
I1109 00:59:23.879118 139240 net.cpp:210] Setting up conv2
I1109 00:59:23.879463 139240 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:59:23.879855 139240 net.cpp:225] Memory required for data: 164146688
I1109 00:59:23.930843 139240 layer_factory.hpp:114] Creating layer relu2
I1109 00:59:23.931841 139240 net.cpp:160] Creating Layer relu2
I1109 00:59:23.932129 139240 net.cpp:596] relu2 <- conv2
I1109 00:59:23.932369 139240 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:59:23.932860 139240 net.cpp:210] Setting up relu2
I1109 00:59:23.933146 139240 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:59:23.933379 139240 net.cpp:225] Memory required for data: 188034560
I1109 00:59:23.933564 139240 layer_factory.hpp:114] Creating layer norm2
I1109 00:59:23.933835 139240 net.cpp:160] Creating Layer norm2
I1109 00:59:23.934049 139240 net.cpp:596] norm2 <- conv2
I1109 00:59:23.934389 139240 net.cpp:570] norm2 -> norm2
I1109 00:59:23.936406 139240 net.cpp:210] Setting up norm2
I1109 00:59:23.936712 139240 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:59:23.937039 139240 net.cpp:225] Memory required for data: 211922432
I1109 00:59:23.937302 139240 layer_factory.hpp:114] Creating layer pool2
I1109 00:59:23.937716 139240 net.cpp:160] Creating Layer pool2
I1109 00:59:23.937932 139240 net.cpp:596] pool2 <- norm2
I1109 00:59:23.938160 139240 net.cpp:570] pool2 -> pool2
I1109 00:59:23.938549 139240 net.cpp:210] Setting up pool2
I1109 00:59:23.938783 139240 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:59:23.938999 139240 net.cpp:225] Memory required for data: 217460224
I1109 00:59:23.939191 139240 layer_factory.hpp:114] Creating layer conv3
I1109 00:59:23.939509 139240 net.cpp:160] Creating Layer conv3
I1109 00:59:23.939718 139240 net.cpp:596] conv3 <- pool2
I1109 00:59:23.939985 139240 net.cpp:570] conv3 -> conv3
I1109 00:59:24.389659 139240 net.cpp:210] Setting up conv3
I1109 00:59:24.392030 139240 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:59:24.392364 139240 net.cpp:225] Memory required for data: 225766912
I1109 00:59:24.395431 139240 layer_factory.hpp:114] Creating layer relu3
I1109 00:59:24.395823 139240 net.cpp:160] Creating Layer relu3
I1109 00:59:24.396064 139240 net.cpp:596] relu3 <- conv3
I1109 00:59:24.396332 139240 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:59:24.400527 139240 net.cpp:210] Setting up relu3
I1109 00:59:24.400879 139240 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:59:24.401130 139240 net.cpp:225] Memory required for data: 234073600
I1109 00:59:24.401319 139240 layer_factory.hpp:114] Creating layer conv4
I1109 00:59:24.401672 139240 net.cpp:160] Creating Layer conv4
I1109 00:59:24.401922 139240 net.cpp:596] conv4 <- conv3
I1109 00:59:24.402158 139240 net.cpp:570] conv4 -> conv4
I1109 00:59:24.642750 139240 net.cpp:210] Setting up conv4
I1109 00:59:24.643134 139240 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:59:24.643527 139240 net.cpp:225] Memory required for data: 242380288
I1109 00:59:24.643863 139240 layer_factory.hpp:114] Creating layer relu4
I1109 00:59:24.644150 139240 net.cpp:160] Creating Layer relu4
I1109 00:59:24.644373 139240 net.cpp:596] relu4 <- conv4
I1109 00:59:24.644599 139240 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:59:24.656826 139240 net.cpp:210] Setting up relu4
I1109 00:59:24.657183 139240 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:59:24.657589 139240 net.cpp:225] Memory required for data: 250686976
I1109 00:59:24.657809 139240 layer_factory.hpp:114] Creating layer conv5
I1109 00:59:24.658185 139240 net.cpp:160] Creating Layer conv5
I1109 00:59:24.658440 139240 net.cpp:596] conv5 <- conv4
I1109 00:59:24.658689 139240 net.cpp:570] conv5 -> conv5
I1109 00:59:24.852258 139240 net.cpp:210] Setting up conv5
I1109 00:59:24.852653 139240 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:59:24.853178 139240 net.cpp:225] Memory required for data: 256224768
I1109 00:59:24.858705 139240 layer_factory.hpp:114] Creating layer relu5
I1109 00:59:24.859292 139240 net.cpp:160] Creating Layer relu5
I1109 00:59:24.859737 139240 net.cpp:596] relu5 <- conv5
I1109 00:59:24.860147 139240 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:59:24.860678 139240 net.cpp:210] Setting up relu5
I1109 00:59:24.861060 139240 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:59:24.861367 139240 net.cpp:225] Memory required for data: 261762560
I1109 00:59:24.861616 139240 layer_factory.hpp:114] Creating layer pool5
I1109 00:59:24.861912 139240 net.cpp:160] Creating Layer pool5
I1109 00:59:24.862193 139240 net.cpp:596] pool5 <- conv5
I1109 00:59:24.862453 139240 net.cpp:570] pool5 -> pool5
I1109 00:59:24.862921 139240 net.cpp:210] Setting up pool5
I1109 00:59:24.863198 139240 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:59:24.863436 139240 net.cpp:225] Memory required for data: 262942208
I1109 00:59:24.863631 139240 layer_factory.hpp:114] Creating layer fc6
I1109 00:59:24.920984 139240 net.cpp:160] Creating Layer fc6
I1109 00:59:24.921303 139240 net.cpp:596] fc6 <- pool5
I1109 00:59:24.921708 139240 net.cpp:570] fc6 -> fc6
I1109 00:59:29.006284 139240 net.cpp:210] Setting up fc6
I1109 00:59:29.008827 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:29.011261 139240 net.cpp:225] Memory required for data: 263466496
I1109 00:59:29.011628 139240 layer_factory.hpp:114] Creating layer relu6
I1109 00:59:29.014827 139240 net.cpp:160] Creating Layer relu6
I1109 00:59:29.015246 139240 net.cpp:596] relu6 <- fc6
I1109 00:59:29.015595 139240 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:59:29.016137 139240 net.cpp:210] Setting up relu6
I1109 00:59:29.016510 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:29.016932 139240 net.cpp:225] Memory required for data: 263990784
I1109 00:59:29.017156 139240 layer_factory.hpp:114] Creating layer drop6
I1109 00:59:29.038004 139240 net.cpp:160] Creating Layer drop6
I1109 00:59:29.038318 139240 net.cpp:596] drop6 <- fc6
I1109 00:59:29.038733 139240 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:59:29.144158 139240 net.cpp:210] Setting up drop6
I1109 00:59:29.144454 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:29.144860 139240 net.cpp:225] Memory required for data: 264515072
I1109 00:59:29.145074 139240 layer_factory.hpp:114] Creating layer fc7
I1109 00:59:29.145340 139240 net.cpp:160] Creating Layer fc7
I1109 00:59:29.145551 139240 net.cpp:596] fc7 <- fc6
I1109 00:59:29.145923 139240 net.cpp:570] fc7 -> fc7
I1109 00:59:30.854986 139240 net.cpp:210] Setting up fc7
I1109 00:59:30.855351 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:30.855770 139240 net.cpp:225] Memory required for data: 265039360
I1109 00:59:30.856130 139240 layer_factory.hpp:114] Creating layer relu7
I1109 00:59:30.856454 139240 net.cpp:160] Creating Layer relu7
I1109 00:59:30.856695 139240 net.cpp:596] relu7 <- fc7
I1109 00:59:30.857004 139240 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:59:30.857458 139240 net.cpp:210] Setting up relu7
I1109 00:59:30.857741 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:30.857980 139240 net.cpp:225] Memory required for data: 265563648
I1109 00:59:30.858173 139240 layer_factory.hpp:114] Creating layer drop7
I1109 00:59:30.858408 139240 net.cpp:160] Creating Layer drop7
I1109 00:59:30.858652 139240 net.cpp:596] drop7 <- fc7
I1109 00:59:30.858906 139240 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:59:30.859189 139240 net.cpp:210] Setting up drop7
I1109 00:59:30.859426 139240 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:59:30.859638 139240 net.cpp:225] Memory required for data: 266087936
I1109 00:59:30.859822 139240 layer_factory.hpp:114] Creating layer fc8
I1109 00:59:30.860074 139240 net.cpp:160] Creating Layer fc8
I1109 00:59:30.860273 139240 net.cpp:596] fc8 <- fc7
I1109 00:59:30.860497 139240 net.cpp:570] fc8 -> fc8
I1109 00:59:31.281785 139240 net.cpp:210] Setting up fc8
I1109 00:59:31.282133 139240 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:59:31.282510 139240 net.cpp:225] Memory required for data: 266215936
I1109 00:59:31.282836 139240 layer_factory.hpp:114] Creating layer loss
I1109 00:59:31.307610 139240 net.cpp:160] Creating Layer loss
I1109 00:59:31.307926 139240 net.cpp:596] loss <- fc8
I1109 00:59:31.308981 139240 net.cpp:596] loss <- label
I1109 00:59:31.336468 139240 net.cpp:570] loss -> loss
I1109 00:59:31.377723 139240 layer_factory.hpp:114] Creating layer loss
I1109 00:59:33.954969 139240 net.cpp:210] Setting up loss
I1109 00:59:34.001924 139240 net.cpp:217] Top shape: (1)
I1109 00:59:34.011360 139240 net.cpp:220]     with loss weight 1
I1109 00:59:34.142664 139240 net.cpp:225] Memory required for data: 266215940
I1109 00:59:34.185200 139240 net.cpp:287] loss needs backward computation.
I1109 00:59:34.272547 139240 net.cpp:287] fc8 needs backward computation.
I1109 00:59:34.279893 139240 net.cpp:287] drop7 needs backward computation.
I1109 00:59:34.290879 139240 net.cpp:287] relu7 needs backward computation.
I1109 00:59:34.291196 139240 net.cpp:287] fc7 needs backward computation.
I1109 00:59:34.293674 139240 net.cpp:287] drop6 needs backward computation.
I1109 00:59:34.293972 139240 net.cpp:287] relu6 needs backward computation.
I1109 00:59:34.294198 139240 net.cpp:287] fc6 needs backward computation.
I1109 00:59:34.295020 139240 net.cpp:287] pool5 needs backward computation.
I1109 00:59:34.295807 139240 net.cpp:287] relu5 needs backward computation.
I1109 00:59:34.296084 139240 net.cpp:287] conv5 needs backward computation.
I1109 00:59:34.296281 139240 net.cpp:287] relu4 needs backward computation.
I1109 00:59:34.296466 139240 net.cpp:287] conv4 needs backward computation.
I1109 00:59:34.296649 139240 net.cpp:287] relu3 needs backward computation.
I1109 00:59:34.296881 139240 net.cpp:287] conv3 needs backward computation.
I1109 00:59:34.309134 139240 net.cpp:287] pool2 needs backward computation.
I1109 00:59:34.309486 139240 net.cpp:287] norm2 needs backward computation.
I1109 00:59:34.309851 139240 net.cpp:287] relu2 needs backward computation.
I1109 00:59:34.310081 139240 net.cpp:287] conv2 needs backward computation.
I1109 00:59:34.310268 139240 net.cpp:287] pool1 needs backward computation.
I1109 00:59:34.310452 139240 net.cpp:287] norm1 needs backward computation.
I1109 00:59:34.310633 139240 net.cpp:287] relu1 needs backward computation.
I1109 00:59:34.310809 139240 net.cpp:287] conv1 needs backward computation.
I1109 00:59:34.323338 139240 net.cpp:289] data does not need backward computation.
I1109 00:59:34.348345 139240 net.cpp:331] This network produces output loss
I1109 00:59:34.420963 139240 net.cpp:345] Network initialization done.
I1109 00:59:34.588553 139240 caffe.cpp:452] Performing Forward
I1109 00:59:47.685071 139240 caffe.cpp:457] Initial loss: 7.05841
I1109 00:59:47.756585 139240 caffe.cpp:459] Performing Backward
I1109 00:59:52.336930 139240 caffe.cpp:468] *** Benchmark begins ***
I1109 00:59:52.349798 139240 caffe.cpp:469] Testing for 1 iterations.
I1109 00:59:52.491405 139240 caffe.cpp:482] Profiling Layer: drop7 forward
I1109 00:59:54.539724 139240 caffe.cpp:512] Iteration: 1 forward-backward time: 2044 ms.
I1109 00:59:54.704881 139240 caffe.cpp:519] Average time per layer: 
I1109 00:59:54.725529 139240 caffe.cpp:522]       data	forward: 547.245 ms.
I1109 00:59:54.794069 139240 caffe.cpp:526]       data	backward: 4.892 ms.
I1109 00:59:54.820657 139240 caffe.cpp:522]      conv1	forward: 123.788 ms.
I1109 00:59:54.824858 139240 caffe.cpp:526]      conv1	backward: 46.087 ms.
I1109 00:59:54.825959 139240 caffe.cpp:522]      relu1	forward: 22.692 ms.
I1109 00:59:54.826210 139240 caffe.cpp:526]      relu1	backward: 18.579 ms.
I1109 00:59:54.826418 139240 caffe.cpp:522]      norm1	forward: 15.944 ms.
I1109 00:59:54.826623 139240 caffe.cpp:526]      norm1	backward: 23.651 ms.
I1109 00:59:54.826828 139240 caffe.cpp:522]      pool1	forward: 18.166 ms.
I1109 00:59:54.827030 139240 caffe.cpp:526]      pool1	backward: 79.646 ms.
I1109 00:59:54.827725 139240 caffe.cpp:522]      conv2	forward: 64.248 ms.
I1109 00:59:54.827993 139240 caffe.cpp:526]      conv2	backward: 75.194 ms.
I1109 00:59:54.828203 139240 caffe.cpp:522]      relu2	forward: 15.856 ms.
I1109 00:59:54.828408 139240 caffe.cpp:526]      relu2	backward: 12.923 ms.
I1109 00:59:54.828610 139240 caffe.cpp:522]      norm2	forward: 22.276 ms.
I1109 00:59:54.828872 139240 caffe.cpp:526]      norm2	backward: 13.236 ms.
I1109 00:59:54.829066 139240 caffe.cpp:522]      pool2	forward: 12.912 ms.
I1109 00:59:54.829257 139240 caffe.cpp:526]      pool2	backward: 71.657 ms.
I1109 00:59:54.829447 139240 caffe.cpp:522]      conv3	forward: 32.002 ms.
I1109 00:59:54.829635 139240 caffe.cpp:526]      conv3	backward: 51.817 ms.
I1109 00:59:54.829825 139240 caffe.cpp:522]      relu3	forward: 17.752 ms.
I1109 00:59:54.830015 139240 caffe.cpp:526]      relu3	backward: 0.735 ms.
I1109 00:59:54.830220 139240 caffe.cpp:522]      conv4	forward: 34.348 ms.
I1109 00:59:54.830452 139240 caffe.cpp:526]      conv4	backward: 27.882 ms.
I1109 00:59:54.830667 139240 caffe.cpp:522]      relu4	forward: 18.33 ms.
I1109 00:59:54.830965 139240 caffe.cpp:526]      relu4	backward: 7.284 ms.
I1109 00:59:54.831223 139240 caffe.cpp:522]      conv5	forward: 32.201 ms.
I1109 00:59:54.831513 139240 caffe.cpp:526]      conv5	backward: 18.955 ms.
I1109 00:59:54.831703 139240 caffe.cpp:522]      relu5	forward: 20.243 ms.
I1109 00:59:54.831892 139240 caffe.cpp:526]      relu5	backward: 0.223 ms.
I1109 00:59:54.832080 139240 caffe.cpp:522]      pool5	forward: 17.465 ms.
I1109 00:59:54.832270 139240 caffe.cpp:526]      pool5	backward: 9.067 ms.
I1109 00:59:54.833096 139240 caffe.cpp:522]        fc6	forward: 39.689 ms.
I1109 00:59:54.833360 139240 caffe.cpp:526]        fc6	backward: 31.385 ms.
I1109 00:59:54.833567 139240 caffe.cpp:522]      relu6	forward: 18.46 ms.
I1109 00:59:54.833871 139240 caffe.cpp:526]      relu6	backward: 0.081 ms.
I1109 00:59:54.836346 139240 caffe.cpp:522]      drop6	forward: 31.366 ms.
I1109 00:59:54.836673 139240 caffe.cpp:526]      drop6	backward: 0.088 ms.
I1109 00:59:54.837039 139240 caffe.cpp:522]        fc7	forward: 11.365 ms.
I1109 00:59:54.837239 139240 caffe.cpp:526]        fc7	backward: 38.036 ms.
I1109 00:59:54.837432 139240 caffe.cpp:522]      relu7	forward: 18.328 ms.
I1109 00:59:54.837622 139240 caffe.cpp:526]      relu7	backward: 0.085 ms.
I1109 00:59:54.837810 139240 caffe.cpp:522]      drop7	forward: 38.034 ms.
I1109 00:59:54.838001 139240 caffe.cpp:526]      drop7	backward: 0.11 ms.
I1109 00:59:54.838752 139240 caffe.cpp:522]        fc8	forward: 24.82 ms.
I1109 00:59:54.838976 139240 caffe.cpp:526]        fc8	backward: 101.666 ms.
I1109 00:59:54.839171 139240 caffe.cpp:522]       loss	forward: 49.491 ms.
I1109 00:59:54.839397 139240 caffe.cpp:526]       loss	backward: 71.249 ms.
I1109 00:59:54.844893 139240 caffe.cpp:532] Average Forward pass: 1301.9 ms.
I1109 00:59:54.858134 139240 caffe.cpp:535] Average Backward pass: 713.351 ms.
I1109 00:59:54.868866 139240 caffe.cpp:537] Average Forward-Backward: 2452 ms.
I1109 00:59:54.883435 139240 caffe.cpp:540] Total Time: 2452 ms.
I1109 00:59:54.895689 139240 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 16384
elements_fp_double_1 = 33
elements_fp_double_2 = 196832
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 262147
--->Total double-precision FLOPs = 393697
--->Total FLOPs = 655844
mem-read-1 = 40142
mem-read-2 = 71
mem-read-4 = 339896
mem-read-8 = 450759
mem-read-16 = 655376
mem-read-32 = 0
mem-read-64 = 24592
mem-write-1 = 138
mem-write-2 = 50
mem-write-4 = 1917
mem-write-8 = 111346
mem-write-16 = 32
mem-write-32 = 0
mem-write-64 = 16384
--->Total Bytes read = 17065844
--->Total Bytes written = 1947762
--->Total Bytes = 19013606
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer22_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=22 -prof_forward_direction=1
I1109 01:05:20.940774 139398 caffe.cpp:444] Use CPU.
I1109 01:05:37.851802 139398 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:05:37.907738 139398 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:05:37.919173 139398 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:05:37.931387 139398 cpu_info.cpp:461] Total number of processors: 272
I1109 01:05:37.942466 139398 cpu_info.cpp:464] GPU is used: no
I1109 01:05:37.951444 139398 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:05:37.960156 139398 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:05:37.970952 139398 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:05:46.744981 139398 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:05:46.777665 139398 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:05:47.407905 139398 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:05:49.854411 139398 layer_factory.hpp:114] Creating layer data
I1109 01:05:50.001531 139398 net.cpp:160] Creating Layer data
I1109 01:05:50.053915 139398 net.cpp:570] data -> data
I1109 01:05:50.517240 139398 net.cpp:570] data -> label
I1109 01:05:57.558506 139398 net.cpp:210] Setting up data
I1109 01:05:57.637676 139398 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:05:57.741070 139398 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:05:57.749694 139398 net.cpp:225] Memory required for data: 19787264
I1109 01:05:57.817173 139398 layer_factory.hpp:114] Creating layer conv1
I1109 01:05:58.144606 139398 net.cpp:160] Creating Layer conv1
I1109 01:05:58.194352 139398 net.cpp:596] conv1 <- data
I1109 01:05:58.313441 139398 net.cpp:570] conv1 -> conv1
I1109 01:06:30.922826 139398 net.cpp:210] Setting up conv1
I1109 01:06:30.929150 139398 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:06:30.929522 139398 net.cpp:225] Memory required for data: 56958464
I1109 01:06:31.211264 139398 layer_factory.hpp:114] Creating layer relu1
I1109 01:06:31.330607 139398 net.cpp:160] Creating Layer relu1
I1109 01:06:31.335224 139398 net.cpp:596] relu1 <- conv1
I1109 01:06:31.367156 139398 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:06:31.557564 139398 net.cpp:210] Setting up relu1
I1109 01:06:31.559989 139398 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:06:31.560333 139398 net.cpp:225] Memory required for data: 94129664
I1109 01:06:31.560572 139398 layer_factory.hpp:114] Creating layer norm1
I1109 01:06:31.665736 139398 net.cpp:160] Creating Layer norm1
I1109 01:06:31.666050 139398 net.cpp:596] norm1 <- conv1
I1109 01:06:31.668558 139398 net.cpp:570] norm1 -> norm1
I1109 01:06:31.892691 139398 net.cpp:210] Setting up norm1
I1109 01:06:31.905674 139398 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:06:31.906055 139398 net.cpp:225] Memory required for data: 131300864
I1109 01:06:31.906363 139398 layer_factory.hpp:114] Creating layer pool1
I1109 01:06:31.999116 139398 net.cpp:160] Creating Layer pool1
I1109 01:06:31.999428 139398 net.cpp:596] pool1 <- norm1
I1109 01:06:32.014127 139398 net.cpp:570] pool1 -> pool1
I1109 01:06:32.312963 139398 net.cpp:210] Setting up pool1
I1109 01:06:32.315425 139398 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:06:32.315752 139398 net.cpp:225] Memory required for data: 140258816
I1109 01:06:32.315997 139398 layer_factory.hpp:114] Creating layer conv2
I1109 01:06:32.316359 139398 net.cpp:160] Creating Layer conv2
I1109 01:06:32.316676 139398 net.cpp:596] conv2 <- pool1
I1109 01:06:32.316962 139398 net.cpp:570] conv2 -> conv2
I1109 01:06:38.095021 139398 net.cpp:210] Setting up conv2
I1109 01:06:38.095335 139398 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:06:38.095778 139398 net.cpp:225] Memory required for data: 164146688
I1109 01:06:38.148170 139398 layer_factory.hpp:114] Creating layer relu2
I1109 01:06:38.148597 139398 net.cpp:160] Creating Layer relu2
I1109 01:06:38.149010 139398 net.cpp:596] relu2 <- conv2
I1109 01:06:38.149327 139398 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:06:38.149811 139398 net.cpp:210] Setting up relu2
I1109 01:06:38.150074 139398 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:06:38.150305 139398 net.cpp:225] Memory required for data: 188034560
I1109 01:06:38.150487 139398 layer_factory.hpp:114] Creating layer norm2
I1109 01:06:38.150727 139398 net.cpp:160] Creating Layer norm2
I1109 01:06:38.150923 139398 net.cpp:596] norm2 <- conv2
I1109 01:06:38.151147 139398 net.cpp:570] norm2 -> norm2
I1109 01:06:38.153319 139398 net.cpp:210] Setting up norm2
I1109 01:06:38.153627 139398 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:06:38.153856 139398 net.cpp:225] Memory required for data: 211922432
I1109 01:06:38.154043 139398 layer_factory.hpp:114] Creating layer pool2
I1109 01:06:38.154325 139398 net.cpp:160] Creating Layer pool2
I1109 01:06:38.154573 139398 net.cpp:596] pool2 <- norm2
I1109 01:06:38.154817 139398 net.cpp:570] pool2 -> pool2
I1109 01:06:38.155359 139398 net.cpp:210] Setting up pool2
I1109 01:06:38.155658 139398 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:06:38.155880 139398 net.cpp:225] Memory required for data: 217460224
I1109 01:06:38.156077 139398 layer_factory.hpp:114] Creating layer conv3
I1109 01:06:38.156994 139398 net.cpp:160] Creating Layer conv3
I1109 01:06:38.157292 139398 net.cpp:596] conv3 <- pool2
I1109 01:06:38.157582 139398 net.cpp:570] conv3 -> conv3
I1109 01:06:38.663244 139398 net.cpp:210] Setting up conv3
I1109 01:06:38.665690 139398 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:06:38.666038 139398 net.cpp:225] Memory required for data: 225766912
I1109 01:06:38.669109 139398 layer_factory.hpp:114] Creating layer relu3
I1109 01:06:38.669541 139398 net.cpp:160] Creating Layer relu3
I1109 01:06:38.669807 139398 net.cpp:596] relu3 <- conv3
I1109 01:06:38.670059 139398 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:06:38.674159 139398 net.cpp:210] Setting up relu3
I1109 01:06:38.674481 139398 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:06:38.674743 139398 net.cpp:225] Memory required for data: 234073600
I1109 01:06:38.674948 139398 layer_factory.hpp:114] Creating layer conv4
I1109 01:06:38.675330 139398 net.cpp:160] Creating Layer conv4
I1109 01:06:38.675603 139398 net.cpp:596] conv4 <- conv3
I1109 01:06:38.675871 139398 net.cpp:570] conv4 -> conv4
I1109 01:06:38.918915 139398 net.cpp:210] Setting up conv4
I1109 01:06:38.919298 139398 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:06:38.919688 139398 net.cpp:225] Memory required for data: 242380288
I1109 01:06:38.920044 139398 layer_factory.hpp:114] Creating layer relu4
I1109 01:06:38.920336 139398 net.cpp:160] Creating Layer relu4
I1109 01:06:38.920562 139398 net.cpp:596] relu4 <- conv4
I1109 01:06:38.920867 139398 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:06:38.933285 139398 net.cpp:210] Setting up relu4
I1109 01:06:38.933660 139398 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:06:38.934069 139398 net.cpp:225] Memory required for data: 250686976
I1109 01:06:38.934311 139398 layer_factory.hpp:114] Creating layer conv5
I1109 01:06:38.934681 139398 net.cpp:160] Creating Layer conv5
I1109 01:06:38.934926 139398 net.cpp:596] conv5 <- conv4
I1109 01:06:38.935171 139398 net.cpp:570] conv5 -> conv5
I1109 01:06:39.106359 139398 net.cpp:210] Setting up conv5
I1109 01:06:39.106788 139398 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:06:39.107344 139398 net.cpp:225] Memory required for data: 256224768
I1109 01:06:39.112246 139398 layer_factory.hpp:114] Creating layer relu5
I1109 01:06:39.112686 139398 net.cpp:160] Creating Layer relu5
I1109 01:06:39.113039 139398 net.cpp:596] relu5 <- conv5
I1109 01:06:39.113435 139398 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:06:39.113922 139398 net.cpp:210] Setting up relu5
I1109 01:06:39.114228 139398 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:06:39.114495 139398 net.cpp:225] Memory required for data: 261762560
I1109 01:06:39.114713 139398 layer_factory.hpp:114] Creating layer pool5
I1109 01:06:39.114987 139398 net.cpp:160] Creating Layer pool5
I1109 01:06:39.115217 139398 net.cpp:596] pool5 <- conv5
I1109 01:06:39.115496 139398 net.cpp:570] pool5 -> pool5
I1109 01:06:39.115926 139398 net.cpp:210] Setting up pool5
I1109 01:06:39.116224 139398 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:06:39.116456 139398 net.cpp:225] Memory required for data: 262942208
I1109 01:06:39.116644 139398 layer_factory.hpp:114] Creating layer fc6
I1109 01:06:39.172055 139398 net.cpp:160] Creating Layer fc6
I1109 01:06:39.172366 139398 net.cpp:596] fc6 <- pool5
I1109 01:06:39.172775 139398 net.cpp:570] fc6 -> fc6
I1109 01:06:43.258538 139398 net.cpp:210] Setting up fc6
I1109 01:06:43.258843 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:43.260891 139398 net.cpp:225] Memory required for data: 263466496
I1109 01:06:43.261210 139398 layer_factory.hpp:114] Creating layer relu6
I1109 01:06:43.263659 139398 net.cpp:160] Creating Layer relu6
I1109 01:06:43.263955 139398 net.cpp:596] relu6 <- fc6
I1109 01:06:43.264179 139398 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:06:43.264660 139398 net.cpp:210] Setting up relu6
I1109 01:06:43.264961 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:43.265190 139398 net.cpp:225] Memory required for data: 263990784
I1109 01:06:43.265377 139398 layer_factory.hpp:114] Creating layer drop6
I1109 01:06:43.285102 139398 net.cpp:160] Creating Layer drop6
I1109 01:06:43.285406 139398 net.cpp:596] drop6 <- fc6
I1109 01:06:43.285778 139398 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:06:43.388603 139398 net.cpp:210] Setting up drop6
I1109 01:06:43.388953 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:43.389305 139398 net.cpp:225] Memory required for data: 264515072
I1109 01:06:43.389545 139398 layer_factory.hpp:114] Creating layer fc7
I1109 01:06:43.389817 139398 net.cpp:160] Creating Layer fc7
I1109 01:06:43.390027 139398 net.cpp:596] fc7 <- fc6
I1109 01:06:43.390415 139398 net.cpp:570] fc7 -> fc7
I1109 01:06:45.102655 139398 net.cpp:210] Setting up fc7
I1109 01:06:45.103024 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:45.103479 139398 net.cpp:225] Memory required for data: 265039360
I1109 01:06:45.103814 139398 layer_factory.hpp:114] Creating layer relu7
I1109 01:06:45.104146 139398 net.cpp:160] Creating Layer relu7
I1109 01:06:45.104400 139398 net.cpp:596] relu7 <- fc7
I1109 01:06:45.104645 139398 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:06:45.105147 139398 net.cpp:210] Setting up relu7
I1109 01:06:45.105443 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:45.105690 139398 net.cpp:225] Memory required for data: 265563648
I1109 01:06:45.105892 139398 layer_factory.hpp:114] Creating layer drop7
I1109 01:06:45.106163 139398 net.cpp:160] Creating Layer drop7
I1109 01:06:45.106384 139398 net.cpp:596] drop7 <- fc7
I1109 01:06:45.106627 139398 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:06:45.106986 139398 net.cpp:210] Setting up drop7
I1109 01:06:45.107195 139398 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:06:45.107416 139398 net.cpp:225] Memory required for data: 266087936
I1109 01:06:45.107604 139398 layer_factory.hpp:114] Creating layer fc8
I1109 01:06:45.107877 139398 net.cpp:160] Creating Layer fc8
I1109 01:06:45.108086 139398 net.cpp:596] fc8 <- fc7
I1109 01:06:45.108317 139398 net.cpp:570] fc8 -> fc8
I1109 01:06:45.531306 139398 net.cpp:210] Setting up fc8
I1109 01:06:45.531677 139398 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:06:45.532095 139398 net.cpp:225] Memory required for data: 266215936
I1109 01:06:45.532446 139398 layer_factory.hpp:114] Creating layer loss
I1109 01:06:45.557659 139398 net.cpp:160] Creating Layer loss
I1109 01:06:45.557979 139398 net.cpp:596] loss <- fc8
I1109 01:06:45.559026 139398 net.cpp:596] loss <- label
I1109 01:06:45.586690 139398 net.cpp:570] loss -> loss
I1109 01:06:45.624981 139398 layer_factory.hpp:114] Creating layer loss
I1109 01:06:48.180536 139398 net.cpp:210] Setting up loss
I1109 01:06:48.234715 139398 net.cpp:217] Top shape: (1)
I1109 01:06:48.246357 139398 net.cpp:220]     with loss weight 1
I1109 01:06:48.381229 139398 net.cpp:225] Memory required for data: 266215940
I1109 01:06:48.421725 139398 net.cpp:287] loss needs backward computation.
I1109 01:06:48.507648 139398 net.cpp:287] fc8 needs backward computation.
I1109 01:06:48.514910 139398 net.cpp:287] drop7 needs backward computation.
I1109 01:06:48.525856 139398 net.cpp:287] relu7 needs backward computation.
I1109 01:06:48.526175 139398 net.cpp:287] fc7 needs backward computation.
I1109 01:06:48.528647 139398 net.cpp:287] drop6 needs backward computation.
I1109 01:06:48.529027 139398 net.cpp:287] relu6 needs backward computation.
I1109 01:06:48.529249 139398 net.cpp:287] fc6 needs backward computation.
I1109 01:06:48.530076 139398 net.cpp:287] pool5 needs backward computation.
I1109 01:06:48.530791 139398 net.cpp:287] relu5 needs backward computation.
I1109 01:06:48.531056 139398 net.cpp:287] conv5 needs backward computation.
I1109 01:06:48.531250 139398 net.cpp:287] relu4 needs backward computation.
I1109 01:06:48.531432 139398 net.cpp:287] conv4 needs backward computation.
I1109 01:06:48.531615 139398 net.cpp:287] relu3 needs backward computation.
I1109 01:06:48.531828 139398 net.cpp:287] conv3 needs backward computation.
I1109 01:06:48.543984 139398 net.cpp:287] pool2 needs backward computation.
I1109 01:06:48.544342 139398 net.cpp:287] norm2 needs backward computation.
I1109 01:06:48.544647 139398 net.cpp:287] relu2 needs backward computation.
I1109 01:06:48.544960 139398 net.cpp:287] conv2 needs backward computation.
I1109 01:06:48.545164 139398 net.cpp:287] pool1 needs backward computation.
I1109 01:06:48.545380 139398 net.cpp:287] norm1 needs backward computation.
I1109 01:06:48.545562 139398 net.cpp:287] relu1 needs backward computation.
I1109 01:06:48.545737 139398 net.cpp:287] conv1 needs backward computation.
I1109 01:06:48.558240 139398 net.cpp:289] data does not need backward computation.
I1109 01:06:48.582885 139398 net.cpp:331] This network produces output loss
I1109 01:06:48.653954 139398 net.cpp:345] Network initialization done.
I1109 01:06:48.820025 139398 caffe.cpp:452] Performing Forward
I1109 01:07:01.729063 139398 caffe.cpp:457] Initial loss: 6.96292
I1109 01:07:01.787626 139398 caffe.cpp:459] Performing Backward
I1109 01:07:06.621858 139398 caffe.cpp:468] *** Benchmark begins ***
I1109 01:07:06.635130 139398 caffe.cpp:469] Testing for 1 iterations.
I1109 01:07:06.778601 139398 caffe.cpp:482] Profiling Layer: fc8 forward
I1109 01:07:09.005163 139398 caffe.cpp:512] Iteration: 1 forward-backward time: 2220 ms.
I1109 01:07:09.161263 139398 caffe.cpp:519] Average time per layer: 
I1109 01:07:09.179788 139398 caffe.cpp:522]       data	forward: 548.049 ms.
I1109 01:07:09.253491 139398 caffe.cpp:526]       data	backward: 5.272 ms.
I1109 01:07:09.276461 139398 caffe.cpp:522]      conv1	forward: 129.761 ms.
I1109 01:07:09.280740 139398 caffe.cpp:526]      conv1	backward: 38.941 ms.
I1109 01:07:09.288153 139398 caffe.cpp:522]      relu1	forward: 15.807 ms.
I1109 01:07:09.294421 139398 caffe.cpp:526]      relu1	backward: 20.228 ms.
I1109 01:07:09.305763 139398 caffe.cpp:522]      norm1	forward: 15.184 ms.
I1109 01:07:09.310401 139398 caffe.cpp:526]      norm1	backward: 19.941 ms.
I1109 01:07:09.315752 139398 caffe.cpp:522]      pool1	forward: 19.131 ms.
I1109 01:07:09.321898 139398 caffe.cpp:526]      pool1	backward: 77.143 ms.
I1109 01:07:09.328443 139398 caffe.cpp:522]      conv2	forward: 66.084 ms.
I1109 01:07:09.334628 139398 caffe.cpp:526]      conv2	backward: 78.164 ms.
I1109 01:07:09.341625 139398 caffe.cpp:522]      relu2	forward: 17.637 ms.
I1109 01:07:09.353524 139398 caffe.cpp:526]      relu2	backward: 13.506 ms.
I1109 01:07:09.355417 139398 caffe.cpp:522]      norm2	forward: 19.454 ms.
I1109 01:07:09.355734 139398 caffe.cpp:526]      norm2	backward: 11.13 ms.
I1109 01:07:09.355931 139398 caffe.cpp:522]      pool2	forward: 16.09 ms.
I1109 01:07:09.356156 139398 caffe.cpp:526]      pool2	backward: 64.507 ms.
I1109 01:07:09.356360 139398 caffe.cpp:522]      conv3	forward: 35.828 ms.
I1109 01:07:09.356637 139398 caffe.cpp:526]      conv3	backward: 85.482 ms.
I1109 01:07:09.356909 139398 caffe.cpp:522]      relu3	forward: 15.552 ms.
I1109 01:07:09.357133 139398 caffe.cpp:526]      relu3	backward: 31.129 ms.
I1109 01:07:09.357323 139398 caffe.cpp:522]      conv4	forward: 31.965 ms.
I1109 01:07:09.357513 139398 caffe.cpp:526]      conv4	backward: 74.67 ms.
I1109 01:07:09.357703 139398 caffe.cpp:522]      relu4	forward: 11.784 ms.
I1109 01:07:09.357892 139398 caffe.cpp:526]      relu4	backward: 41.665 ms.
I1109 01:07:09.358081 139398 caffe.cpp:522]      conv5	forward: 35.645 ms.
I1109 01:07:09.358271 139398 caffe.cpp:526]      conv5	backward: 18.921 ms.
I1109 01:07:09.358460 139398 caffe.cpp:522]      relu5	forward: 12.539 ms.
I1109 01:07:09.358649 139398 caffe.cpp:526]      relu5	backward: 0.239 ms.
I1109 01:07:09.358839 139398 caffe.cpp:522]      pool5	forward: 15.505 ms.
I1109 01:07:09.359027 139398 caffe.cpp:526]      pool5	backward: 9.19 ms.
I1109 01:07:09.360067 139398 caffe.cpp:522]        fc6	forward: 41.556 ms.
I1109 01:07:09.360402 139398 caffe.cpp:526]        fc6	backward: 28.881 ms.
I1109 01:07:09.360599 139398 caffe.cpp:522]      relu6	forward: 12.55 ms.
I1109 01:07:09.360829 139398 caffe.cpp:526]      relu6	backward: 0.087 ms.
I1109 01:07:09.363409 139398 caffe.cpp:522]      drop6	forward: 26.825 ms.
I1109 01:07:09.363658 139398 caffe.cpp:526]      drop6	backward: 0.087 ms.
I1109 01:07:09.363860 139398 caffe.cpp:522]        fc7	forward: 18.432 ms.
I1109 01:07:09.364054 139398 caffe.cpp:526]        fc7	backward: 31.757 ms.
I1109 01:07:09.364249 139398 caffe.cpp:522]      relu7	forward: 10.493 ms.
I1109 01:07:09.366909 139398 caffe.cpp:526]      relu7	backward: 0.088 ms.
I1109 01:07:09.367157 139398 caffe.cpp:522]      drop7	forward: 38.902 ms.
I1109 01:07:09.367357 139398 caffe.cpp:526]      drop7	backward: 0.099 ms.
I1109 01:07:09.367550 139398 caffe.cpp:522]        fc8	forward: 29.556 ms.
I1109 01:07:09.367743 139398 caffe.cpp:526]        fc8	backward: 168.951 ms.
I1109 01:07:09.367975 139398 caffe.cpp:522]       loss	forward: 55.909 ms.
I1109 01:07:09.368186 139398 caffe.cpp:526]       loss	backward: 66.756 ms.
I1109 01:07:09.373782 139398 caffe.cpp:532] Average Forward pass: 1295.82 ms.
I1109 01:07:09.386936 139398 caffe.cpp:535] Average Backward pass: 895.703 ms.
I1109 01:07:09.397650 139398 caffe.cpp:537] Average Forward-Backward: 2694 ms.
I1109 01:07:09.412514 139398 caffe.cpp:540] Total Time: 2694 ms.
I1109 01:07:09.424850 139398 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 906
elements_fp_single_4 = 0
elements_fp_single_8 = 807296
elements_fp_single_16 = 16542912
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 271145866
--->Total double-precision FLOPs = 0
--->Total FLOPs = 271145866
mem-read-1 = 26751
mem-read-2 = 56
mem-read-4 = 8475764
mem-read-8 = 366717
mem-read-16 = 1483626
mem-read-32 = 33152
mem-read-64 = 2532434
mem-write-1 = 62
mem-write-2 = 17
mem-write-4 = 1888
mem-write-8 = 69403
mem-write-16 = 66410
mem-write-32 = 741792
mem-write-64 = 31503
--->Total Bytes read = 223738311
--->Total Bytes written = 27378968
--->Total Bytes = 251117279
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer23_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=23 -prof_forward_direction=1
I1109 01:13:15.050696 139536 caffe.cpp:444] Use CPU.
I1109 01:13:31.893908 139536 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:13:31.949542 139536 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:13:31.961448 139536 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:13:31.973960 139536 cpu_info.cpp:461] Total number of processors: 272
I1109 01:13:31.985115 139536 cpu_info.cpp:464] GPU is used: no
I1109 01:13:31.994259 139536 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:13:32.004497 139536 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:13:32.018231 139536 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:13:40.741670 139536 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:13:40.774411 139536 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:13:41.410280 139536 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:13:43.858948 139536 layer_factory.hpp:114] Creating layer data
I1109 01:13:44.006649 139536 net.cpp:160] Creating Layer data
I1109 01:13:44.054519 139536 net.cpp:570] data -> data
I1109 01:13:44.525921 139536 net.cpp:570] data -> label
I1109 01:13:51.564754 139536 net.cpp:210] Setting up data
I1109 01:13:51.648720 139536 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:13:51.753885 139536 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:13:51.761104 139536 net.cpp:225] Memory required for data: 19787264
I1109 01:13:51.828585 139536 layer_factory.hpp:114] Creating layer conv1
I1109 01:13:52.157866 139536 net.cpp:160] Creating Layer conv1
I1109 01:13:52.210969 139536 net.cpp:596] conv1 <- data
I1109 01:13:52.331924 139536 net.cpp:570] conv1 -> conv1
I1109 01:14:25.265671 139536 net.cpp:210] Setting up conv1
I1109 01:14:25.272076 139536 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:14:25.272467 139536 net.cpp:225] Memory required for data: 56958464
I1109 01:14:25.558161 139536 layer_factory.hpp:114] Creating layer relu1
I1109 01:14:25.678241 139536 net.cpp:160] Creating Layer relu1
I1109 01:14:25.682862 139536 net.cpp:596] relu1 <- conv1
I1109 01:14:25.714993 139536 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:14:25.914957 139536 net.cpp:210] Setting up relu1
I1109 01:14:25.917414 139536 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:14:25.917757 139536 net.cpp:225] Memory required for data: 94129664
I1109 01:14:25.917970 139536 layer_factory.hpp:114] Creating layer norm1
I1109 01:14:26.022686 139536 net.cpp:160] Creating Layer norm1
I1109 01:14:26.023001 139536 net.cpp:596] norm1 <- conv1
I1109 01:14:26.025563 139536 net.cpp:570] norm1 -> norm1
I1109 01:14:26.246850 139536 net.cpp:210] Setting up norm1
I1109 01:14:26.259629 139536 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:14:26.260010 139536 net.cpp:225] Memory required for data: 131300864
I1109 01:14:26.260313 139536 layer_factory.hpp:114] Creating layer pool1
I1109 01:14:26.354768 139536 net.cpp:160] Creating Layer pool1
I1109 01:14:26.355082 139536 net.cpp:596] pool1 <- norm1
I1109 01:14:26.369810 139536 net.cpp:570] pool1 -> pool1
I1109 01:14:26.669605 139536 net.cpp:210] Setting up pool1
I1109 01:14:26.672052 139536 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:14:26.672381 139536 net.cpp:225] Memory required for data: 140258816
I1109 01:14:26.672600 139536 layer_factory.hpp:114] Creating layer conv2
I1109 01:14:26.672997 139536 net.cpp:160] Creating Layer conv2
I1109 01:14:26.673271 139536 net.cpp:596] conv2 <- pool1
I1109 01:14:26.673524 139536 net.cpp:570] conv2 -> conv2
I1109 01:14:32.418443 139536 net.cpp:210] Setting up conv2
I1109 01:14:32.418798 139536 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:14:32.419266 139536 net.cpp:225] Memory required for data: 164146688
I1109 01:14:32.470099 139536 layer_factory.hpp:114] Creating layer relu2
I1109 01:14:32.470533 139536 net.cpp:160] Creating Layer relu2
I1109 01:14:32.470897 139536 net.cpp:596] relu2 <- conv2
I1109 01:14:32.471165 139536 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:14:32.471659 139536 net.cpp:210] Setting up relu2
I1109 01:14:32.471926 139536 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:14:32.472159 139536 net.cpp:225] Memory required for data: 188034560
I1109 01:14:32.472350 139536 layer_factory.hpp:114] Creating layer norm2
I1109 01:14:32.472595 139536 net.cpp:160] Creating Layer norm2
I1109 01:14:32.472828 139536 net.cpp:596] norm2 <- conv2
I1109 01:14:32.473120 139536 net.cpp:570] norm2 -> norm2
I1109 01:14:32.475188 139536 net.cpp:210] Setting up norm2
I1109 01:14:32.475494 139536 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:14:32.475734 139536 net.cpp:225] Memory required for data: 211922432
I1109 01:14:32.475929 139536 layer_factory.hpp:114] Creating layer pool2
I1109 01:14:32.476807 139536 net.cpp:160] Creating Layer pool2
I1109 01:14:32.477157 139536 net.cpp:596] pool2 <- norm2
I1109 01:14:32.477454 139536 net.cpp:570] pool2 -> pool2
I1109 01:14:32.477885 139536 net.cpp:210] Setting up pool2
I1109 01:14:32.478137 139536 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:14:32.478375 139536 net.cpp:225] Memory required for data: 217460224
I1109 01:14:32.478590 139536 layer_factory.hpp:114] Creating layer conv3
I1109 01:14:32.478947 139536 net.cpp:160] Creating Layer conv3
I1109 01:14:32.479178 139536 net.cpp:596] conv3 <- pool2
I1109 01:14:32.479437 139536 net.cpp:570] conv3 -> conv3
I1109 01:14:32.960449 139536 net.cpp:210] Setting up conv3
I1109 01:14:32.963486 139536 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:14:32.964006 139536 net.cpp:225] Memory required for data: 225766912
I1109 01:14:32.967401 139536 layer_factory.hpp:114] Creating layer relu3
I1109 01:14:32.967834 139536 net.cpp:160] Creating Layer relu3
I1109 01:14:32.968164 139536 net.cpp:596] relu3 <- conv3
I1109 01:14:32.968459 139536 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:14:32.972834 139536 net.cpp:210] Setting up relu3
I1109 01:14:32.973177 139536 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:14:32.973453 139536 net.cpp:225] Memory required for data: 234073600
I1109 01:14:32.973666 139536 layer_factory.hpp:114] Creating layer conv4
I1109 01:14:32.974048 139536 net.cpp:160] Creating Layer conv4
I1109 01:14:32.974319 139536 net.cpp:596] conv4 <- conv3
I1109 01:14:32.974583 139536 net.cpp:570] conv4 -> conv4
I1109 01:14:33.243438 139536 net.cpp:210] Setting up conv4
I1109 01:14:33.243870 139536 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:14:33.244279 139536 net.cpp:225] Memory required for data: 242380288
I1109 01:14:33.244633 139536 layer_factory.hpp:114] Creating layer relu4
I1109 01:14:33.244997 139536 net.cpp:160] Creating Layer relu4
I1109 01:14:33.245245 139536 net.cpp:596] relu4 <- conv4
I1109 01:14:33.245496 139536 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:14:33.257664 139536 net.cpp:210] Setting up relu4
I1109 01:14:33.257998 139536 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:14:33.258272 139536 net.cpp:225] Memory required for data: 250686976
I1109 01:14:33.258491 139536 layer_factory.hpp:114] Creating layer conv5
I1109 01:14:33.258882 139536 net.cpp:160] Creating Layer conv5
I1109 01:14:33.259141 139536 net.cpp:596] conv5 <- conv4
I1109 01:14:33.259412 139536 net.cpp:570] conv5 -> conv5
I1109 01:14:33.427460 139536 net.cpp:210] Setting up conv5
I1109 01:14:33.427857 139536 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:14:33.428319 139536 net.cpp:225] Memory required for data: 256224768
I1109 01:14:33.433009 139536 layer_factory.hpp:114] Creating layer relu5
I1109 01:14:33.433420 139536 net.cpp:160] Creating Layer relu5
I1109 01:14:33.433717 139536 net.cpp:596] relu5 <- conv5
I1109 01:14:33.434015 139536 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:14:33.434541 139536 net.cpp:210] Setting up relu5
I1109 01:14:33.434900 139536 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:14:33.435164 139536 net.cpp:225] Memory required for data: 261762560
I1109 01:14:33.435382 139536 layer_factory.hpp:114] Creating layer pool5
I1109 01:14:33.435652 139536 net.cpp:160] Creating Layer pool5
I1109 01:14:33.435873 139536 net.cpp:596] pool5 <- conv5
I1109 01:14:33.436105 139536 net.cpp:570] pool5 -> pool5
I1109 01:14:33.436501 139536 net.cpp:210] Setting up pool5
I1109 01:14:33.436758 139536 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:14:33.437088 139536 net.cpp:225] Memory required for data: 262942208
I1109 01:14:33.437299 139536 layer_factory.hpp:114] Creating layer fc6
I1109 01:14:33.491490 139536 net.cpp:160] Creating Layer fc6
I1109 01:14:33.491803 139536 net.cpp:596] fc6 <- pool5
I1109 01:14:33.492197 139536 net.cpp:570] fc6 -> fc6
I1109 01:14:37.579253 139536 net.cpp:210] Setting up fc6
I1109 01:14:37.579563 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:37.581662 139536 net.cpp:225] Memory required for data: 263466496
I1109 01:14:37.581977 139536 layer_factory.hpp:114] Creating layer relu6
I1109 01:14:37.584440 139536 net.cpp:160] Creating Layer relu6
I1109 01:14:37.584738 139536 net.cpp:596] relu6 <- fc6
I1109 01:14:37.585029 139536 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:14:37.585458 139536 net.cpp:210] Setting up relu6
I1109 01:14:37.585714 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:37.585943 139536 net.cpp:225] Memory required for data: 263990784
I1109 01:14:37.586134 139536 layer_factory.hpp:114] Creating layer drop6
I1109 01:14:37.606515 139536 net.cpp:160] Creating Layer drop6
I1109 01:14:37.606838 139536 net.cpp:596] drop6 <- fc6
I1109 01:14:37.607190 139536 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:14:37.710752 139536 net.cpp:210] Setting up drop6
I1109 01:14:37.711050 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:37.711391 139536 net.cpp:225] Memory required for data: 264515072
I1109 01:14:37.711637 139536 layer_factory.hpp:114] Creating layer fc7
I1109 01:14:37.711915 139536 net.cpp:160] Creating Layer fc7
I1109 01:14:37.712126 139536 net.cpp:596] fc7 <- fc6
I1109 01:14:37.712517 139536 net.cpp:570] fc7 -> fc7
I1109 01:14:39.425382 139536 net.cpp:210] Setting up fc7
I1109 01:14:39.425752 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:39.426182 139536 net.cpp:225] Memory required for data: 265039360
I1109 01:14:39.426551 139536 layer_factory.hpp:114] Creating layer relu7
I1109 01:14:39.426890 139536 net.cpp:160] Creating Layer relu7
I1109 01:14:39.427144 139536 net.cpp:596] relu7 <- fc7
I1109 01:14:39.427404 139536 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:14:39.427862 139536 net.cpp:210] Setting up relu7
I1109 01:14:39.428154 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:39.428411 139536 net.cpp:225] Memory required for data: 265563648
I1109 01:14:39.428617 139536 layer_factory.hpp:114] Creating layer drop7
I1109 01:14:39.428905 139536 net.cpp:160] Creating Layer drop7
I1109 01:14:39.429172 139536 net.cpp:596] drop7 <- fc7
I1109 01:14:39.429441 139536 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:14:39.429739 139536 net.cpp:210] Setting up drop7
I1109 01:14:39.430042 139536 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:14:39.430270 139536 net.cpp:225] Memory required for data: 266087936
I1109 01:14:39.430464 139536 layer_factory.hpp:114] Creating layer fc8
I1109 01:14:39.430729 139536 net.cpp:160] Creating Layer fc8
I1109 01:14:39.430938 139536 net.cpp:596] fc8 <- fc7
I1109 01:14:39.431174 139536 net.cpp:570] fc8 -> fc8
I1109 01:14:39.855365 139536 net.cpp:210] Setting up fc8
I1109 01:14:39.855734 139536 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:14:39.856151 139536 net.cpp:225] Memory required for data: 266215936
I1109 01:14:39.856508 139536 layer_factory.hpp:114] Creating layer loss
I1109 01:14:39.881235 139536 net.cpp:160] Creating Layer loss
I1109 01:14:39.881556 139536 net.cpp:596] loss <- fc8
I1109 01:14:39.882469 139536 net.cpp:596] loss <- label
I1109 01:14:39.910682 139536 net.cpp:570] loss -> loss
I1109 01:14:39.948699 139536 layer_factory.hpp:114] Creating layer loss
I1109 01:14:42.497375 139536 net.cpp:210] Setting up loss
I1109 01:14:42.551065 139536 net.cpp:217] Top shape: (1)
I1109 01:14:42.558923 139536 net.cpp:220]     with loss weight 1
I1109 01:14:42.685067 139536 net.cpp:225] Memory required for data: 266215940
I1109 01:14:42.733191 139536 net.cpp:287] loss needs backward computation.
I1109 01:14:42.822013 139536 net.cpp:287] fc8 needs backward computation.
I1109 01:14:42.829200 139536 net.cpp:287] drop7 needs backward computation.
I1109 01:14:42.840096 139536 net.cpp:287] relu7 needs backward computation.
I1109 01:14:42.840427 139536 net.cpp:287] fc7 needs backward computation.
I1109 01:14:42.842875 139536 net.cpp:287] drop6 needs backward computation.
I1109 01:14:42.843205 139536 net.cpp:287] relu6 needs backward computation.
I1109 01:14:42.843541 139536 net.cpp:287] fc6 needs backward computation.
I1109 01:14:42.844405 139536 net.cpp:287] pool5 needs backward computation.
I1109 01:14:42.845201 139536 net.cpp:287] relu5 needs backward computation.
I1109 01:14:42.845484 139536 net.cpp:287] conv5 needs backward computation.
I1109 01:14:42.845693 139536 net.cpp:287] relu4 needs backward computation.
I1109 01:14:42.845893 139536 net.cpp:287] conv4 needs backward computation.
I1109 01:14:42.846087 139536 net.cpp:287] relu3 needs backward computation.
I1109 01:14:42.846276 139536 net.cpp:287] conv3 needs backward computation.
I1109 01:14:42.858427 139536 net.cpp:287] pool2 needs backward computation.
I1109 01:14:42.858788 139536 net.cpp:287] norm2 needs backward computation.
I1109 01:14:42.859113 139536 net.cpp:287] relu2 needs backward computation.
I1109 01:14:42.859359 139536 net.cpp:287] conv2 needs backward computation.
I1109 01:14:42.859557 139536 net.cpp:287] pool1 needs backward computation.
I1109 01:14:42.859746 139536 net.cpp:287] norm1 needs backward computation.
I1109 01:14:42.859935 139536 net.cpp:287] relu1 needs backward computation.
I1109 01:14:42.860119 139536 net.cpp:287] conv1 needs backward computation.
I1109 01:14:42.872656 139536 net.cpp:289] data does not need backward computation.
I1109 01:14:42.897239 139536 net.cpp:331] This network produces output loss
I1109 01:14:42.969476 139536 net.cpp:345] Network initialization done.
I1109 01:14:43.135900 139536 caffe.cpp:452] Performing Forward
I1109 01:14:56.239434 139536 caffe.cpp:457] Initial loss: 6.78582
I1109 01:14:56.299706 139536 caffe.cpp:459] Performing Backward
I1109 01:15:01.529135 139536 caffe.cpp:468] *** Benchmark begins ***
I1109 01:15:01.545447 139536 caffe.cpp:469] Testing for 1 iterations.
I1109 01:15:01.702329 139536 caffe.cpp:482] Profiling Layer: loss forward
I1109 01:15:04.446882 139536 caffe.cpp:512] Iteration: 1 forward-backward time: 2730 ms.
I1109 01:15:04.604312 139536 caffe.cpp:519] Average time per layer: 
I1109 01:15:04.620895 139536 caffe.cpp:522]       data	forward: 564.267 ms.
I1109 01:15:04.694356 139536 caffe.cpp:526]       data	backward: 3.652 ms.
I1109 01:15:04.717241 139536 caffe.cpp:522]      conv1	forward: 129.636 ms.
I1109 01:15:04.728875 139536 caffe.cpp:526]      conv1	backward: 21.301 ms.
I1109 01:15:04.737610 139536 caffe.cpp:522]      relu1	forward: 24.308 ms.
I1109 01:15:04.743544 139536 caffe.cpp:526]      relu1	backward: 1.083 ms.
I1109 01:15:04.749408 139536 caffe.cpp:522]      norm1	forward: 17.483 ms.
I1109 01:15:04.757004 139536 caffe.cpp:526]      norm1	backward: 3.059 ms.
I1109 01:15:04.765202 139536 caffe.cpp:522]      pool1	forward: 27.898 ms.
I1109 01:15:04.772949 139536 caffe.cpp:526]      pool1	backward: 76.364 ms.
I1109 01:15:04.777379 139536 caffe.cpp:522]      conv2	forward: 67.175 ms.
I1109 01:15:04.783502 139536 caffe.cpp:526]      conv2	backward: 81.017 ms.
I1109 01:15:04.796181 139536 caffe.cpp:522]      relu2	forward: 17.17 ms.
I1109 01:15:04.798050 139536 caffe.cpp:526]      relu2	backward: 13.323 ms.
I1109 01:15:04.798307 139536 caffe.cpp:522]      norm2	forward: 12.255 ms.
I1109 01:15:04.798507 139536 caffe.cpp:526]      norm2	backward: 15.638 ms.
I1109 01:15:04.798704 139536 caffe.cpp:522]      pool2	forward: 23.36 ms.
I1109 01:15:04.798900 139536 caffe.cpp:526]      pool2	backward: 60.716 ms.
I1109 01:15:04.799099 139536 caffe.cpp:522]      conv3	forward: 40.265 ms.
I1109 01:15:04.799295 139536 caffe.cpp:526]      conv3	backward: 76.335 ms.
I1109 01:15:04.799489 139536 caffe.cpp:522]      relu3	forward: 13.986 ms.
I1109 01:15:04.799680 139536 caffe.cpp:526]      relu3	backward: 31.323 ms.
I1109 01:15:04.799903 139536 caffe.cpp:522]      conv4	forward: 37.192 ms.
I1109 01:15:04.800107 139536 caffe.cpp:526]      conv4	backward: 77.466 ms.
I1109 01:15:04.800389 139536 caffe.cpp:522]      relu4	forward: 10.37 ms.
I1109 01:15:04.802773 139536 caffe.cpp:526]      relu4	backward: 44.183 ms.
I1109 01:15:04.803032 139536 caffe.cpp:522]      conv5	forward: 29.567 ms.
I1109 01:15:04.803272 139536 caffe.cpp:526]      conv5	backward: 74.793 ms.
I1109 01:15:04.803490 139536 caffe.cpp:522]      relu5	forward: 13.726 ms.
I1109 01:15:04.803799 139536 caffe.cpp:526]      relu5	backward: 12.513 ms.
I1109 01:15:04.804057 139536 caffe.cpp:522]      pool5	forward: 9.816 ms.
I1109 01:15:04.805063 139536 caffe.cpp:526]      pool5	backward: 52.782 ms.
I1109 01:15:04.805300 139536 caffe.cpp:522]        fc6	forward: 32.578 ms.
I1109 01:15:04.805505 139536 caffe.cpp:526]        fc6	backward: 194.965 ms.
I1109 01:15:04.805711 139536 caffe.cpp:522]      relu6	forward: 20.854 ms.
I1109 01:15:04.805914 139536 caffe.cpp:526]      relu6	backward: 9.874 ms.
I1109 01:15:04.806113 139536 caffe.cpp:522]      drop6	forward: 39.138 ms.
I1109 01:15:04.806349 139536 caffe.cpp:526]      drop6	backward: 17.54 ms.
I1109 01:15:04.806566 139536 caffe.cpp:522]        fc7	forward: 11.962 ms.
I1109 01:15:04.806882 139536 caffe.cpp:526]        fc7	backward: 238.801 ms.
I1109 01:15:04.807137 139536 caffe.cpp:522]      relu7	forward: 13.285 ms.
I1109 01:15:04.807339 139536 caffe.cpp:526]      relu7	backward: 14.929 ms.
I1109 01:15:04.807541 139536 caffe.cpp:522]      drop7	forward: 25.488 ms.
I1109 01:15:04.807741 139536 caffe.cpp:526]      drop7	backward: 14.679 ms.
I1109 01:15:04.807940 139536 caffe.cpp:522]        fc8	forward: 15.309 ms.
I1109 01:15:04.808140 139536 caffe.cpp:526]        fc8	backward: 190.399 ms.
I1109 01:15:04.808337 139536 caffe.cpp:522]       loss	forward: 52.458 ms.
I1109 01:15:04.808534 139536 caffe.cpp:526]       loss	backward: 63.584 ms.
I1109 01:15:04.813750 139536 caffe.cpp:532] Average Forward pass: 1306.33 ms.
I1109 01:15:04.827003 139536 caffe.cpp:535] Average Backward pass: 1399.39 ms.
I1109 01:15:04.837729 139536 caffe.cpp:537] Average Forward-Backward: 3220 ms.
I1109 01:15:04.852277 139536 caffe.cpp:540] Total Time: 3220 ms.
I1109 01:15:04.864392 139536 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 128023
elements_fp_single_4 = 20
elements_fp_single_8 = 4
elements_fp_single_16 = 64847
elements_fp_double_1 = 32
elements_fp_double_2 = 2016
elements_fp_double_4 = 0
elements_fp_double_8 = 864
--->Total single-precision FLOPs = 1165687
--->Total double-precision FLOPs = 10976
--->Total FLOPs = 1176663
mem-read-1 = 76086
mem-read-2 = 129
mem-read-4 = 781312
mem-read-8 = 2742869
mem-read-16 = 17
mem-read-32 = 32
mem-read-64 = 109289
mem-write-1 = 71463
mem-write-2 = 26
mem-write-4 = 258508
mem-write-8 = 1325153
mem-write-16 = 0
mem-write-32 = 32
mem-write-64 = 36352
--->Total Bytes read = 32140336
--->Total Bytes written = 14034323
--->Total Bytes = 46174659
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer24_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=24 -prof_forward_direction=1
I1109 01:20:28.506775 139703 caffe.cpp:444] Use CPU.
I1109 01:20:45.560919 139703 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:20:45.617195 139703 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:20:45.629086 139703 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:20:45.641511 139703 cpu_info.cpp:461] Total number of processors: 272
I1109 01:20:45.652659 139703 cpu_info.cpp:464] GPU is used: no
I1109 01:20:45.661754 139703 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:20:45.670555 139703 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:20:45.681546 139703 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:20:54.503298 139703 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:20:54.536658 139703 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:20:55.177603 139703 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:20:57.650545 139703 layer_factory.hpp:114] Creating layer data
I1109 01:20:57.798069 139703 net.cpp:160] Creating Layer data
I1109 01:20:57.846462 139703 net.cpp:570] data -> data
I1109 01:20:58.322226 139703 net.cpp:570] data -> label
I1109 01:21:05.399832 139703 net.cpp:210] Setting up data
I1109 01:21:05.482992 139703 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:21:05.588116 139703 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:21:05.595371 139703 net.cpp:225] Memory required for data: 19787264
I1109 01:21:05.662866 139703 layer_factory.hpp:114] Creating layer conv1
I1109 01:21:05.999861 139703 net.cpp:160] Creating Layer conv1
I1109 01:21:06.051584 139703 net.cpp:596] conv1 <- data
I1109 01:21:06.171309 139703 net.cpp:570] conv1 -> conv1
I1109 01:21:39.046774 139703 net.cpp:210] Setting up conv1
I1109 01:21:39.053683 139703 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:21:39.054083 139703 net.cpp:225] Memory required for data: 56958464
I1109 01:21:39.338126 139703 layer_factory.hpp:114] Creating layer relu1
I1109 01:21:39.458930 139703 net.cpp:160] Creating Layer relu1
I1109 01:21:39.463506 139703 net.cpp:596] relu1 <- conv1
I1109 01:21:39.495920 139703 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:21:39.690055 139703 net.cpp:210] Setting up relu1
I1109 01:21:39.692533 139703 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:21:39.692971 139703 net.cpp:225] Memory required for data: 94129664
I1109 01:21:39.693198 139703 layer_factory.hpp:114] Creating layer norm1
I1109 01:21:39.798123 139703 net.cpp:160] Creating Layer norm1
I1109 01:21:39.798439 139703 net.cpp:596] norm1 <- conv1
I1109 01:21:39.800992 139703 net.cpp:570] norm1 -> norm1
I1109 01:21:40.024272 139703 net.cpp:210] Setting up norm1
I1109 01:21:40.037111 139703 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:21:40.037494 139703 net.cpp:225] Memory required for data: 131300864
I1109 01:21:40.037827 139703 layer_factory.hpp:114] Creating layer pool1
I1109 01:21:40.131479 139703 net.cpp:160] Creating Layer pool1
I1109 01:21:40.131796 139703 net.cpp:596] pool1 <- norm1
I1109 01:21:40.146596 139703 net.cpp:570] pool1 -> pool1
I1109 01:21:40.452167 139703 net.cpp:210] Setting up pool1
I1109 01:21:40.454776 139703 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:21:40.455122 139703 net.cpp:225] Memory required for data: 140258816
I1109 01:21:40.455356 139703 layer_factory.hpp:114] Creating layer conv2
I1109 01:21:40.455780 139703 net.cpp:160] Creating Layer conv2
I1109 01:21:40.456068 139703 net.cpp:596] conv2 <- pool1
I1109 01:21:40.456322 139703 net.cpp:570] conv2 -> conv2
I1109 01:21:46.259366 139703 net.cpp:210] Setting up conv2
I1109 01:21:46.259711 139703 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:21:46.260107 139703 net.cpp:225] Memory required for data: 164146688
I1109 01:21:46.310607 139703 layer_factory.hpp:114] Creating layer relu2
I1109 01:21:46.311034 139703 net.cpp:160] Creating Layer relu2
I1109 01:21:46.311417 139703 net.cpp:596] relu2 <- conv2
I1109 01:21:46.311686 139703 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:21:46.312146 139703 net.cpp:210] Setting up relu2
I1109 01:21:46.312404 139703 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:21:46.312641 139703 net.cpp:225] Memory required for data: 188034560
I1109 01:21:46.312882 139703 layer_factory.hpp:114] Creating layer norm2
I1109 01:21:46.313144 139703 net.cpp:160] Creating Layer norm2
I1109 01:21:46.313347 139703 net.cpp:596] norm2 <- conv2
I1109 01:21:46.313617 139703 net.cpp:570] norm2 -> norm2
I1109 01:21:46.315690 139703 net.cpp:210] Setting up norm2
I1109 01:21:46.315997 139703 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:21:46.316236 139703 net.cpp:225] Memory required for data: 211922432
I1109 01:21:46.316427 139703 layer_factory.hpp:114] Creating layer pool2
I1109 01:21:46.317356 139703 net.cpp:160] Creating Layer pool2
I1109 01:21:46.317754 139703 net.cpp:596] pool2 <- norm2
I1109 01:21:46.318017 139703 net.cpp:570] pool2 -> pool2
I1109 01:21:46.318428 139703 net.cpp:210] Setting up pool2
I1109 01:21:46.318667 139703 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:21:46.318892 139703 net.cpp:225] Memory required for data: 217460224
I1109 01:21:46.319095 139703 layer_factory.hpp:114] Creating layer conv3
I1109 01:21:46.319424 139703 net.cpp:160] Creating Layer conv3
I1109 01:21:46.319648 139703 net.cpp:596] conv3 <- pool2
I1109 01:21:46.319921 139703 net.cpp:570] conv3 -> conv3
I1109 01:21:46.797487 139703 net.cpp:210] Setting up conv3
I1109 01:21:46.799926 139703 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:21:46.800323 139703 net.cpp:225] Memory required for data: 225766912
I1109 01:21:46.803427 139703 layer_factory.hpp:114] Creating layer relu3
I1109 01:21:46.803870 139703 net.cpp:160] Creating Layer relu3
I1109 01:21:46.804149 139703 net.cpp:596] relu3 <- conv3
I1109 01:21:46.804419 139703 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:21:46.808719 139703 net.cpp:210] Setting up relu3
I1109 01:21:46.809183 139703 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:21:46.809509 139703 net.cpp:225] Memory required for data: 234073600
I1109 01:21:46.809725 139703 layer_factory.hpp:114] Creating layer conv4
I1109 01:21:46.810148 139703 net.cpp:160] Creating Layer conv4
I1109 01:21:46.810428 139703 net.cpp:596] conv4 <- conv3
I1109 01:21:46.810766 139703 net.cpp:570] conv4 -> conv4
I1109 01:21:47.051949 139703 net.cpp:210] Setting up conv4
I1109 01:21:47.052341 139703 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:21:47.052742 139703 net.cpp:225] Memory required for data: 242380288
I1109 01:21:47.053139 139703 layer_factory.hpp:114] Creating layer relu4
I1109 01:21:47.053478 139703 net.cpp:160] Creating Layer relu4
I1109 01:21:47.053714 139703 net.cpp:596] relu4 <- conv4
I1109 01:21:47.053956 139703 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:21:47.066248 139703 net.cpp:210] Setting up relu4
I1109 01:21:47.066601 139703 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:21:47.067013 139703 net.cpp:225] Memory required for data: 250686976
I1109 01:21:47.067236 139703 layer_factory.hpp:114] Creating layer conv5
I1109 01:21:47.067611 139703 net.cpp:160] Creating Layer conv5
I1109 01:21:47.067860 139703 net.cpp:596] conv5 <- conv4
I1109 01:21:47.068115 139703 net.cpp:570] conv5 -> conv5
I1109 01:21:47.236109 139703 net.cpp:210] Setting up conv5
I1109 01:21:47.236510 139703 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:21:47.236995 139703 net.cpp:225] Memory required for data: 256224768
I1109 01:21:47.241596 139703 layer_factory.hpp:114] Creating layer relu5
I1109 01:21:47.242013 139703 net.cpp:160] Creating Layer relu5
I1109 01:21:47.242280 139703 net.cpp:596] relu5 <- conv5
I1109 01:21:47.242561 139703 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:21:47.243033 139703 net.cpp:210] Setting up relu5
I1109 01:21:47.243327 139703 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:21:47.243592 139703 net.cpp:225] Memory required for data: 261762560
I1109 01:21:47.243813 139703 layer_factory.hpp:114] Creating layer pool5
I1109 01:21:47.244091 139703 net.cpp:160] Creating Layer pool5
I1109 01:21:47.244319 139703 net.cpp:596] pool5 <- conv5
I1109 01:21:47.244554 139703 net.cpp:570] pool5 -> pool5
I1109 01:21:47.245003 139703 net.cpp:210] Setting up pool5
I1109 01:21:47.245278 139703 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:21:47.245548 139703 net.cpp:225] Memory required for data: 262942208
I1109 01:21:47.245753 139703 layer_factory.hpp:114] Creating layer fc6
I1109 01:21:47.300737 139703 net.cpp:160] Creating Layer fc6
I1109 01:21:47.301158 139703 net.cpp:596] fc6 <- pool5
I1109 01:21:47.301535 139703 net.cpp:570] fc6 -> fc6
I1109 01:21:51.418635 139703 net.cpp:210] Setting up fc6
I1109 01:21:51.418944 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:51.421049 139703 net.cpp:225] Memory required for data: 263466496
I1109 01:21:51.421371 139703 layer_factory.hpp:114] Creating layer relu6
I1109 01:21:51.423835 139703 net.cpp:160] Creating Layer relu6
I1109 01:21:51.424134 139703 net.cpp:596] relu6 <- fc6
I1109 01:21:51.424371 139703 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:21:51.424834 139703 net.cpp:210] Setting up relu6
I1109 01:21:51.425106 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:51.425341 139703 net.cpp:225] Memory required for data: 263990784
I1109 01:21:51.425535 139703 layer_factory.hpp:114] Creating layer drop6
I1109 01:21:51.445535 139703 net.cpp:160] Creating Layer drop6
I1109 01:21:51.445844 139703 net.cpp:596] drop6 <- fc6
I1109 01:21:51.446216 139703 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:21:51.551390 139703 net.cpp:210] Setting up drop6
I1109 01:21:51.551699 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:51.552062 139703 net.cpp:225] Memory required for data: 264515072
I1109 01:21:51.552319 139703 layer_factory.hpp:114] Creating layer fc7
I1109 01:21:51.552605 139703 net.cpp:160] Creating Layer fc7
I1109 01:21:51.552878 139703 net.cpp:596] fc7 <- fc6
I1109 01:21:51.553302 139703 net.cpp:570] fc7 -> fc7
I1109 01:21:53.267392 139703 net.cpp:210] Setting up fc7
I1109 01:21:53.267757 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:53.268236 139703 net.cpp:225] Memory required for data: 265039360
I1109 01:21:53.268615 139703 layer_factory.hpp:114] Creating layer relu7
I1109 01:21:53.269009 139703 net.cpp:160] Creating Layer relu7
I1109 01:21:53.269273 139703 net.cpp:596] relu7 <- fc7
I1109 01:21:53.269543 139703 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:21:53.269997 139703 net.cpp:210] Setting up relu7
I1109 01:21:53.270290 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:53.270591 139703 net.cpp:225] Memory required for data: 265563648
I1109 01:21:53.270817 139703 layer_factory.hpp:114] Creating layer drop7
I1109 01:21:53.271106 139703 net.cpp:160] Creating Layer drop7
I1109 01:21:53.271322 139703 net.cpp:596] drop7 <- fc7
I1109 01:21:53.271575 139703 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:21:53.271862 139703 net.cpp:210] Setting up drop7
I1109 01:21:53.272071 139703 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:21:53.272303 139703 net.cpp:225] Memory required for data: 266087936
I1109 01:21:53.272498 139703 layer_factory.hpp:114] Creating layer fc8
I1109 01:21:53.272758 139703 net.cpp:160] Creating Layer fc8
I1109 01:21:53.273027 139703 net.cpp:596] fc8 <- fc7
I1109 01:21:53.273272 139703 net.cpp:570] fc8 -> fc8
I1109 01:21:53.695668 139703 net.cpp:210] Setting up fc8
I1109 01:21:53.696022 139703 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:21:53.696405 139703 net.cpp:225] Memory required for data: 266215936
I1109 01:21:53.696743 139703 layer_factory.hpp:114] Creating layer loss
I1109 01:21:53.721493 139703 net.cpp:160] Creating Layer loss
I1109 01:21:53.721812 139703 net.cpp:596] loss <- fc8
I1109 01:21:53.722781 139703 net.cpp:596] loss <- label
I1109 01:21:53.750458 139703 net.cpp:570] loss -> loss
I1109 01:21:53.788259 139703 layer_factory.hpp:114] Creating layer loss
I1109 01:21:56.413312 139703 net.cpp:210] Setting up loss
I1109 01:21:56.461941 139703 net.cpp:217] Top shape: (1)
I1109 01:21:56.474117 139703 net.cpp:220]     with loss weight 1
I1109 01:21:56.604352 139703 net.cpp:225] Memory required for data: 266215940
I1109 01:21:56.647328 139703 net.cpp:287] loss needs backward computation.
I1109 01:21:56.734618 139703 net.cpp:287] fc8 needs backward computation.
I1109 01:21:56.741811 139703 net.cpp:287] drop7 needs backward computation.
I1109 01:21:56.752908 139703 net.cpp:287] relu7 needs backward computation.
I1109 01:21:56.753227 139703 net.cpp:287] fc7 needs backward computation.
I1109 01:21:56.755616 139703 net.cpp:287] drop6 needs backward computation.
I1109 01:21:56.755915 139703 net.cpp:287] relu6 needs backward computation.
I1109 01:21:56.756117 139703 net.cpp:287] fc6 needs backward computation.
I1109 01:21:56.756816 139703 net.cpp:287] pool5 needs backward computation.
I1109 01:21:56.757688 139703 net.cpp:287] relu5 needs backward computation.
I1109 01:21:56.757987 139703 net.cpp:287] conv5 needs backward computation.
I1109 01:21:56.758204 139703 net.cpp:287] relu4 needs backward computation.
I1109 01:21:56.758417 139703 net.cpp:287] conv4 needs backward computation.
I1109 01:21:56.758622 139703 net.cpp:287] relu3 needs backward computation.
I1109 01:21:56.758851 139703 net.cpp:287] conv3 needs backward computation.
I1109 01:21:56.771036 139703 net.cpp:287] pool2 needs backward computation.
I1109 01:21:56.771390 139703 net.cpp:287] norm2 needs backward computation.
I1109 01:21:56.771708 139703 net.cpp:287] relu2 needs backward computation.
I1109 01:21:56.771953 139703 net.cpp:287] conv2 needs backward computation.
I1109 01:21:56.772156 139703 net.cpp:287] pool1 needs backward computation.
I1109 01:21:56.772347 139703 net.cpp:287] norm1 needs backward computation.
I1109 01:21:56.772534 139703 net.cpp:287] relu1 needs backward computation.
I1109 01:21:56.772718 139703 net.cpp:287] conv1 needs backward computation.
I1109 01:21:56.785110 139703 net.cpp:289] data does not need backward computation.
I1109 01:21:56.809700 139703 net.cpp:331] This network produces output loss
I1109 01:21:56.884649 139703 net.cpp:345] Network initialization done.
I1109 01:21:57.051919 139703 caffe.cpp:452] Performing Forward
I1109 01:22:09.971607 139703 caffe.cpp:457] Initial loss: 6.92983
I1109 01:22:10.027041 139703 caffe.cpp:459] Performing Backward
I1109 01:22:14.962414 139703 caffe.cpp:468] *** Benchmark begins ***
I1109 01:22:14.973937 139703 caffe.cpp:469] Testing for 1 iterations.
I1109 01:22:17.370102 139703 caffe.cpp:512] Iteration: 1 forward-backward time: 2268 ms.
I1109 01:22:17.532207 139703 caffe.cpp:519] Average time per layer: 
I1109 01:22:17.550786 139703 caffe.cpp:522]       data	forward: 555.461 ms.
I1109 01:22:17.630195 139703 caffe.cpp:526]       data	backward: 4.897 ms.
I1109 01:22:17.646198 139703 caffe.cpp:522]      conv1	forward: 136.191 ms.
I1109 01:22:17.646533 139703 caffe.cpp:526]      conv1	backward: 52.718 ms.
I1109 01:22:17.646756 139703 caffe.cpp:522]      relu1	forward: 18.869 ms.
I1109 01:22:17.646967 139703 caffe.cpp:526]      relu1	backward: 11.879 ms.
I1109 01:22:17.647218 139703 caffe.cpp:522]      norm1	forward: 28.557 ms.
I1109 01:22:17.647544 139703 caffe.cpp:526]      norm1	backward: 16.392 ms.
I1109 01:22:17.647830 139703 caffe.cpp:522]      pool1	forward: 16.512 ms.
I1109 01:22:17.648041 139703 caffe.cpp:526]      pool1	backward: 67.592 ms.
I1109 01:22:17.648847 139703 caffe.cpp:522]      conv2	forward: 69.224 ms.
I1109 01:22:17.649097 139703 caffe.cpp:526]      conv2	backward: 31.559 ms.
I1109 01:22:17.651326 139703 caffe.cpp:522]      relu2	forward: 10.667 ms.
I1109 01:22:17.653769 139703 caffe.cpp:526]      relu2	backward: 0.712 ms.
I1109 01:22:17.654065 139703 caffe.cpp:522]      norm2	forward: 15.422 ms.
I1109 01:22:17.654429 139703 caffe.cpp:526]      norm2	backward: 2.111 ms.
I1109 01:22:17.654636 139703 caffe.cpp:522]      pool2	forward: 14.51 ms.
I1109 01:22:17.654842 139703 caffe.cpp:526]      pool2	backward: 22.347 ms.
I1109 01:22:17.655046 139703 caffe.cpp:522]      conv3	forward: 36.376 ms.
I1109 01:22:17.655249 139703 caffe.cpp:526]      conv3	backward: 36.491 ms.
I1109 01:22:17.655452 139703 caffe.cpp:522]      relu3	forward: 10.089 ms.
I1109 01:22:17.656183 139703 caffe.cpp:526]      relu3	backward: 0.587 ms.
I1109 01:22:17.656414 139703 caffe.cpp:522]      conv4	forward: 32.808 ms.
I1109 01:22:17.656620 139703 caffe.cpp:526]      conv4	backward: 27.943 ms.
I1109 01:22:17.656867 139703 caffe.cpp:522]      relu4	forward: 16.396 ms.
I1109 01:22:17.657076 139703 caffe.cpp:526]      relu4	backward: 7.374 ms.
I1109 01:22:17.657308 139703 caffe.cpp:522]      conv5	forward: 24.425 ms.
I1109 01:22:17.657539 139703 caffe.cpp:526]      conv5	backward: 18.815 ms.
I1109 01:22:17.657862 139703 caffe.cpp:522]      relu5	forward: 13.297 ms.
I1109 01:22:17.658104 139703 caffe.cpp:526]      relu5	backward: 0.226 ms.
I1109 01:22:17.658300 139703 caffe.cpp:522]      pool5	forward: 14.926 ms.
I1109 01:22:17.658499 139703 caffe.cpp:526]      pool5	backward: 11.892 ms.
I1109 01:22:17.658695 139703 caffe.cpp:522]        fc6	forward: 40.444 ms.
I1109 01:22:17.658893 139703 caffe.cpp:526]        fc6	backward: 119.566 ms.
I1109 01:22:17.659091 139703 caffe.cpp:522]      relu6	forward: 16.924 ms.
I1109 01:22:17.659291 139703 caffe.cpp:526]      relu6	backward: 17.885 ms.
I1109 01:22:17.659488 139703 caffe.cpp:522]      drop6	forward: 30.649 ms.
I1109 01:22:17.659687 139703 caffe.cpp:526]      drop6	backward: 15.655 ms.
I1109 01:22:17.659883 139703 caffe.cpp:522]        fc7	forward: 16.141 ms.
I1109 01:22:17.660120 139703 caffe.cpp:526]        fc7	backward: 195.326 ms.
I1109 01:22:17.662544 139703 caffe.cpp:522]      relu7	forward: 11.282 ms.
I1109 01:22:17.662808 139703 caffe.cpp:526]      relu7	backward: 18.785 ms.
I1109 01:22:17.663017 139703 caffe.cpp:522]      drop7	forward: 35.606 ms.
I1109 01:22:17.663220 139703 caffe.cpp:526]      drop7	backward: 10.101 ms.
I1109 01:22:17.663421 139703 caffe.cpp:522]        fc8	forward: 20.188 ms.
I1109 01:22:17.663621 139703 caffe.cpp:526]        fc8	backward: 184.557 ms.
I1109 01:22:17.663823 139703 caffe.cpp:522]       loss	forward: 55.562 ms.
I1109 01:22:17.664058 139703 caffe.cpp:526]       loss	backward: 56.549 ms.
I1109 01:22:17.669631 139703 caffe.cpp:532] Average Forward pass: 1295.88 ms.
I1109 01:22:17.682538 139703 caffe.cpp:535] Average Backward pass: 940.679 ms.
I1109 01:22:17.693359 139703 caffe.cpp:537] Average Forward-Backward: 2644 ms.
I1109 01:22:17.708106 139703 caffe.cpp:540] Total Time: 2644 ms.
I1109 01:22:17.720237 139703 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 0
mem-read-2 = 0
mem-read-4 = 0
mem-read-8 = 0
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 0
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 0
--->Total Bytes written = 0
--->Total Bytes = 0
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer25_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=25 -prof_forward_direction=1
I1109 01:24:20.909334 139813 caffe.cpp:444] Use CPU.
I1109 01:24:37.826119 139813 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:24:37.881701 139813 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:24:37.893631 139813 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:24:37.906162 139813 cpu_info.cpp:461] Total number of processors: 272
I1109 01:24:37.917289 139813 cpu_info.cpp:464] GPU is used: no
I1109 01:24:37.926465 139813 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:24:37.935302 139813 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:24:37.946198 139813 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:24:46.699723 139813 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:24:46.732359 139813 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:24:47.363842 139813 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:24:49.819540 139813 layer_factory.hpp:114] Creating layer data
I1109 01:24:49.967087 139813 net.cpp:160] Creating Layer data
I1109 01:24:50.014999 139813 net.cpp:570] data -> data
I1109 01:24:50.482455 139813 net.cpp:570] data -> label
I1109 01:24:57.531096 139813 net.cpp:210] Setting up data
I1109 01:24:57.610280 139813 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:24:57.714340 139813 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:24:57.721526 139813 net.cpp:225] Memory required for data: 19787264
I1109 01:24:57.789233 139813 layer_factory.hpp:114] Creating layer conv1
I1109 01:24:58.117097 139813 net.cpp:160] Creating Layer conv1
I1109 01:24:58.166926 139813 net.cpp:596] conv1 <- data
I1109 01:24:58.287406 139813 net.cpp:570] conv1 -> conv1
I1109 01:25:31.353404 139813 net.cpp:210] Setting up conv1
I1109 01:25:31.360270 139813 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:25:31.360637 139813 net.cpp:225] Memory required for data: 56958464
I1109 01:25:31.648849 139813 layer_factory.hpp:114] Creating layer relu1
I1109 01:25:31.770650 139813 net.cpp:160] Creating Layer relu1
I1109 01:25:31.775288 139813 net.cpp:596] relu1 <- conv1
I1109 01:25:31.807564 139813 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:25:31.998281 139813 net.cpp:210] Setting up relu1
I1109 01:25:32.000669 139813 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:25:32.005173 139813 net.cpp:225] Memory required for data: 94129664
I1109 01:25:32.005548 139813 layer_factory.hpp:114] Creating layer norm1
I1109 01:25:32.111893 139813 net.cpp:160] Creating Layer norm1
I1109 01:25:32.112207 139813 net.cpp:596] norm1 <- conv1
I1109 01:25:32.114750 139813 net.cpp:570] norm1 -> norm1
I1109 01:25:32.338102 139813 net.cpp:210] Setting up norm1
I1109 01:25:32.352362 139813 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:25:32.352742 139813 net.cpp:225] Memory required for data: 131300864
I1109 01:25:32.353097 139813 layer_factory.hpp:114] Creating layer pool1
I1109 01:25:32.446727 139813 net.cpp:160] Creating Layer pool1
I1109 01:25:32.447038 139813 net.cpp:596] pool1 <- norm1
I1109 01:25:32.462069 139813 net.cpp:570] pool1 -> pool1
I1109 01:25:32.763501 139813 net.cpp:210] Setting up pool1
I1109 01:25:32.766029 139813 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:25:32.766391 139813 net.cpp:225] Memory required for data: 140258816
I1109 01:25:32.766614 139813 layer_factory.hpp:114] Creating layer conv2
I1109 01:25:32.767050 139813 net.cpp:160] Creating Layer conv2
I1109 01:25:32.767364 139813 net.cpp:596] conv2 <- pool1
I1109 01:25:32.767594 139813 net.cpp:570] conv2 -> conv2
I1109 01:25:38.537320 139813 net.cpp:210] Setting up conv2
I1109 01:25:38.537663 139813 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:25:38.538067 139813 net.cpp:225] Memory required for data: 164146688
I1109 01:25:38.588531 139813 layer_factory.hpp:114] Creating layer relu2
I1109 01:25:38.589063 139813 net.cpp:160] Creating Layer relu2
I1109 01:25:38.589388 139813 net.cpp:596] relu2 <- conv2
I1109 01:25:38.589661 139813 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:25:38.590142 139813 net.cpp:210] Setting up relu2
I1109 01:25:38.590425 139813 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:25:38.590679 139813 net.cpp:225] Memory required for data: 188034560
I1109 01:25:38.590885 139813 layer_factory.hpp:114] Creating layer norm2
I1109 01:25:38.591148 139813 net.cpp:160] Creating Layer norm2
I1109 01:25:38.591365 139813 net.cpp:596] norm2 <- conv2
I1109 01:25:38.591619 139813 net.cpp:570] norm2 -> norm2
I1109 01:25:38.593781 139813 net.cpp:210] Setting up norm2
I1109 01:25:38.594094 139813 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:25:38.594328 139813 net.cpp:225] Memory required for data: 211922432
I1109 01:25:38.594521 139813 layer_factory.hpp:114] Creating layer pool2
I1109 01:25:38.595460 139813 net.cpp:160] Creating Layer pool2
I1109 01:25:38.595814 139813 net.cpp:596] pool2 <- norm2
I1109 01:25:38.596070 139813 net.cpp:570] pool2 -> pool2
I1109 01:25:38.596479 139813 net.cpp:210] Setting up pool2
I1109 01:25:38.596729 139813 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:25:38.597002 139813 net.cpp:225] Memory required for data: 217460224
I1109 01:25:38.597208 139813 layer_factory.hpp:114] Creating layer conv3
I1109 01:25:38.597543 139813 net.cpp:160] Creating Layer conv3
I1109 01:25:38.597774 139813 net.cpp:596] conv3 <- pool2
I1109 01:25:38.598053 139813 net.cpp:570] conv3 -> conv3
I1109 01:25:39.074322 139813 net.cpp:210] Setting up conv3
I1109 01:25:39.076721 139813 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:25:39.077178 139813 net.cpp:225] Memory required for data: 225766912
I1109 01:25:39.080325 139813 layer_factory.hpp:114] Creating layer relu3
I1109 01:25:39.080734 139813 net.cpp:160] Creating Layer relu3
I1109 01:25:39.081100 139813 net.cpp:596] relu3 <- conv3
I1109 01:25:39.081377 139813 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:25:39.085675 139813 net.cpp:210] Setting up relu3
I1109 01:25:39.085997 139813 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:25:39.086266 139813 net.cpp:225] Memory required for data: 234073600
I1109 01:25:39.086475 139813 layer_factory.hpp:114] Creating layer conv4
I1109 01:25:39.086853 139813 net.cpp:160] Creating Layer conv4
I1109 01:25:39.087127 139813 net.cpp:596] conv4 <- conv3
I1109 01:25:39.087393 139813 net.cpp:570] conv4 -> conv4
I1109 01:25:39.328981 139813 net.cpp:210] Setting up conv4
I1109 01:25:39.329366 139813 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:25:39.329819 139813 net.cpp:225] Memory required for data: 242380288
I1109 01:25:39.330163 139813 layer_factory.hpp:114] Creating layer relu4
I1109 01:25:39.330461 139813 net.cpp:160] Creating Layer relu4
I1109 01:25:39.330698 139813 net.cpp:596] relu4 <- conv4
I1109 01:25:39.330936 139813 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:25:39.343147 139813 net.cpp:210] Setting up relu4
I1109 01:25:39.343489 139813 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:25:39.343885 139813 net.cpp:225] Memory required for data: 250686976
I1109 01:25:39.344099 139813 layer_factory.hpp:114] Creating layer conv5
I1109 01:25:39.344475 139813 net.cpp:160] Creating Layer conv5
I1109 01:25:39.344719 139813 net.cpp:596] conv5 <- conv4
I1109 01:25:39.345018 139813 net.cpp:570] conv5 -> conv5
I1109 01:25:39.514010 139813 net.cpp:210] Setting up conv5
I1109 01:25:39.514391 139813 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:25:39.514793 139813 net.cpp:225] Memory required for data: 256224768
I1109 01:25:39.519402 139813 layer_factory.hpp:114] Creating layer relu5
I1109 01:25:39.519801 139813 net.cpp:160] Creating Layer relu5
I1109 01:25:39.520052 139813 net.cpp:596] relu5 <- conv5
I1109 01:25:39.520316 139813 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:25:39.520815 139813 net.cpp:210] Setting up relu5
I1109 01:25:39.521162 139813 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:25:39.521430 139813 net.cpp:225] Memory required for data: 261762560
I1109 01:25:39.521647 139813 layer_factory.hpp:114] Creating layer pool5
I1109 01:25:39.521953 139813 net.cpp:160] Creating Layer pool5
I1109 01:25:39.522171 139813 net.cpp:596] pool5 <- conv5
I1109 01:25:39.522397 139813 net.cpp:570] pool5 -> pool5
I1109 01:25:39.522796 139813 net.cpp:210] Setting up pool5
I1109 01:25:39.523057 139813 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:25:39.523284 139813 net.cpp:225] Memory required for data: 262942208
I1109 01:25:39.523469 139813 layer_factory.hpp:114] Creating layer fc6
I1109 01:25:39.582960 139813 net.cpp:160] Creating Layer fc6
I1109 01:25:39.583277 139813 net.cpp:596] fc6 <- pool5
I1109 01:25:39.583676 139813 net.cpp:570] fc6 -> fc6
I1109 01:25:43.696128 139813 net.cpp:210] Setting up fc6
I1109 01:25:43.696431 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:43.698604 139813 net.cpp:225] Memory required for data: 263466496
I1109 01:25:43.698937 139813 layer_factory.hpp:114] Creating layer relu6
I1109 01:25:43.701505 139813 net.cpp:160] Creating Layer relu6
I1109 01:25:43.701804 139813 net.cpp:596] relu6 <- fc6
I1109 01:25:43.702034 139813 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:25:43.702457 139813 net.cpp:210] Setting up relu6
I1109 01:25:43.702714 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:43.702939 139813 net.cpp:225] Memory required for data: 263990784
I1109 01:25:43.703162 139813 layer_factory.hpp:114] Creating layer drop6
I1109 01:25:43.723989 139813 net.cpp:160] Creating Layer drop6
I1109 01:25:43.724308 139813 net.cpp:596] drop6 <- fc6
I1109 01:25:43.724660 139813 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:25:43.828543 139813 net.cpp:210] Setting up drop6
I1109 01:25:43.828908 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:43.829238 139813 net.cpp:225] Memory required for data: 264515072
I1109 01:25:43.829466 139813 layer_factory.hpp:114] Creating layer fc7
I1109 01:25:43.829754 139813 net.cpp:160] Creating Layer fc7
I1109 01:25:43.829977 139813 net.cpp:596] fc7 <- fc6
I1109 01:25:43.830387 139813 net.cpp:570] fc7 -> fc7
I1109 01:25:45.542440 139813 net.cpp:210] Setting up fc7
I1109 01:25:45.542781 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:45.543151 139813 net.cpp:225] Memory required for data: 265039360
I1109 01:25:45.543501 139813 layer_factory.hpp:114] Creating layer relu7
I1109 01:25:45.543812 139813 net.cpp:160] Creating Layer relu7
I1109 01:25:45.544046 139813 net.cpp:596] relu7 <- fc7
I1109 01:25:45.544286 139813 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:25:45.544719 139813 net.cpp:210] Setting up relu7
I1109 01:25:45.545047 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:45.545286 139813 net.cpp:225] Memory required for data: 265563648
I1109 01:25:45.545480 139813 layer_factory.hpp:114] Creating layer drop7
I1109 01:25:45.545711 139813 net.cpp:160] Creating Layer drop7
I1109 01:25:45.545938 139813 net.cpp:596] drop7 <- fc7
I1109 01:25:45.546183 139813 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:25:45.546461 139813 net.cpp:210] Setting up drop7
I1109 01:25:45.546730 139813 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:25:45.546972 139813 net.cpp:225] Memory required for data: 266087936
I1109 01:25:45.547150 139813 layer_factory.hpp:114] Creating layer fc8
I1109 01:25:45.547399 139813 net.cpp:160] Creating Layer fc8
I1109 01:25:45.547590 139813 net.cpp:596] fc8 <- fc7
I1109 01:25:45.547809 139813 net.cpp:570] fc8 -> fc8
I1109 01:25:45.972055 139813 net.cpp:210] Setting up fc8
I1109 01:25:45.972429 139813 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:25:45.972920 139813 net.cpp:225] Memory required for data: 266215936
I1109 01:25:45.973264 139813 layer_factory.hpp:114] Creating layer loss
I1109 01:25:45.998667 139813 net.cpp:160] Creating Layer loss
I1109 01:25:45.998986 139813 net.cpp:596] loss <- fc8
I1109 01:25:45.999879 139813 net.cpp:596] loss <- label
I1109 01:25:46.027796 139813 net.cpp:570] loss -> loss
I1109 01:25:46.066149 139813 layer_factory.hpp:114] Creating layer loss
I1109 01:25:48.732578 139813 net.cpp:210] Setting up loss
I1109 01:25:48.782624 139813 net.cpp:217] Top shape: (1)
I1109 01:25:48.792157 139813 net.cpp:220]     with loss weight 1
I1109 01:25:48.925591 139813 net.cpp:225] Memory required for data: 266215940
I1109 01:25:48.974318 139813 net.cpp:287] loss needs backward computation.
I1109 01:25:49.061336 139813 net.cpp:287] fc8 needs backward computation.
I1109 01:25:49.068584 139813 net.cpp:287] drop7 needs backward computation.
I1109 01:25:49.079630 139813 net.cpp:287] relu7 needs backward computation.
I1109 01:25:49.079954 139813 net.cpp:287] fc7 needs backward computation.
I1109 01:25:49.082404 139813 net.cpp:287] drop6 needs backward computation.
I1109 01:25:49.082710 139813 net.cpp:287] relu6 needs backward computation.
I1109 01:25:49.082949 139813 net.cpp:287] fc6 needs backward computation.
I1109 01:25:49.083801 139813 net.cpp:287] pool5 needs backward computation.
I1109 01:25:49.084599 139813 net.cpp:287] relu5 needs backward computation.
I1109 01:25:49.084936 139813 net.cpp:287] conv5 needs backward computation.
I1109 01:25:49.085161 139813 net.cpp:287] relu4 needs backward computation.
I1109 01:25:49.085371 139813 net.cpp:287] conv4 needs backward computation.
I1109 01:25:49.085574 139813 net.cpp:287] relu3 needs backward computation.
I1109 01:25:49.085772 139813 net.cpp:287] conv3 needs backward computation.
I1109 01:25:49.098160 139813 net.cpp:287] pool2 needs backward computation.
I1109 01:25:49.098513 139813 net.cpp:287] norm2 needs backward computation.
I1109 01:25:49.098829 139813 net.cpp:287] relu2 needs backward computation.
I1109 01:25:49.099069 139813 net.cpp:287] conv2 needs backward computation.
I1109 01:25:49.099266 139813 net.cpp:287] pool1 needs backward computation.
I1109 01:25:49.099452 139813 net.cpp:287] norm1 needs backward computation.
I1109 01:25:49.099634 139813 net.cpp:287] relu1 needs backward computation.
I1109 01:25:49.099812 139813 net.cpp:287] conv1 needs backward computation.
I1109 01:25:49.112393 139813 net.cpp:289] data does not need backward computation.
I1109 01:25:49.137217 139813 net.cpp:331] This network produces output loss
I1109 01:25:49.209707 139813 net.cpp:345] Network initialization done.
I1109 01:25:49.378958 139813 caffe.cpp:452] Performing Forward
I1109 01:26:02.674561 139813 caffe.cpp:457] Initial loss: 6.91587
I1109 01:26:02.735396 139813 caffe.cpp:459] Performing Backward
I1109 01:26:07.341620 139813 caffe.cpp:468] *** Benchmark begins ***
I1109 01:26:07.357959 139813 caffe.cpp:469] Testing for 1 iterations.
I1109 01:26:09.581787 139813 caffe.cpp:512] Iteration: 1 forward-backward time: 2089 ms.
I1109 01:26:09.749706 139813 caffe.cpp:519] Average time per layer: 
I1109 01:26:09.768632 139813 caffe.cpp:522]       data	forward: 551.172 ms.
I1109 01:26:09.844848 139813 caffe.cpp:526]       data	backward: 5.268 ms.
I1109 01:26:09.868914 139813 caffe.cpp:522]      conv1	forward: 125.39 ms.
I1109 01:26:09.877696 139813 caffe.cpp:526]      conv1	backward: 33.858 ms.
I1109 01:26:09.886018 139813 caffe.cpp:522]      relu1	forward: 18.243 ms.
I1109 01:26:09.893674 139813 caffe.cpp:526]      relu1	backward: 1.032 ms.
I1109 01:26:09.902163 139813 caffe.cpp:522]      norm1	forward: 28.131 ms.
I1109 01:26:09.911288 139813 caffe.cpp:526]      norm1	backward: 3.112 ms.
I1109 01:26:09.919572 139813 caffe.cpp:522]      pool1	forward: 22.793 ms.
I1109 01:26:09.927346 139813 caffe.cpp:526]      pool1	backward: 35.881 ms.
I1109 01:26:09.935796 139813 caffe.cpp:522]      conv2	forward: 74.309 ms.
I1109 01:26:09.950049 139813 caffe.cpp:526]      conv2	backward: 31.515 ms.
I1109 01:26:09.959091 139813 caffe.cpp:522]      relu2	forward: 17.359 ms.
I1109 01:26:09.959828 139813 caffe.cpp:526]      relu2	backward: 0.701 ms.
I1109 01:26:09.960067 139813 caffe.cpp:522]      norm2	forward: 10.796 ms.
I1109 01:26:09.962625 139813 caffe.cpp:526]      norm2	backward: 2.159 ms.
I1109 01:26:09.962868 139813 caffe.cpp:522]      pool2	forward: 9.146 ms.
I1109 01:26:09.963577 139813 caffe.cpp:526]      pool2	backward: 22.431 ms.
I1109 01:26:09.963805 139813 caffe.cpp:522]      conv3	forward: 36.926 ms.
I1109 01:26:09.964001 139813 caffe.cpp:526]      conv3	backward: 36.503 ms.
I1109 01:26:09.964196 139813 caffe.cpp:522]      relu3	forward: 13.622 ms.
I1109 01:26:09.964421 139813 caffe.cpp:526]      relu3	backward: 0.717 ms.
I1109 01:26:09.964625 139813 caffe.cpp:522]      conv4	forward: 38.959 ms.
I1109 01:26:09.964973 139813 caffe.cpp:526]      conv4	backward: 27.808 ms.
I1109 01:26:09.965226 139813 caffe.cpp:522]      relu4	forward: 16.025 ms.
I1109 01:26:09.965440 139813 caffe.cpp:526]      relu4	backward: 6.831 ms.
I1109 01:26:09.965643 139813 caffe.cpp:522]      conv5	forward: 28.932 ms.
I1109 01:26:09.965847 139813 caffe.cpp:526]      conv5	backward: 18.926 ms.
I1109 01:26:09.966051 139813 caffe.cpp:522]      relu5	forward: 13.117 ms.
I1109 01:26:09.966255 139813 caffe.cpp:526]      relu5	backward: 0.215 ms.
I1109 01:26:09.966456 139813 caffe.cpp:522]      pool5	forward: 24.243 ms.
I1109 01:26:09.966660 139813 caffe.cpp:526]      pool5	backward: 29.62 ms.
I1109 01:26:09.966862 139813 caffe.cpp:522]        fc6	forward: 48.711 ms.
I1109 01:26:09.967067 139813 caffe.cpp:526]        fc6	backward: 123.829 ms.
I1109 01:26:09.967272 139813 caffe.cpp:522]      relu6	forward: 16.629 ms.
I1109 01:26:09.967475 139813 caffe.cpp:526]      relu6	backward: 14.843 ms.
I1109 01:26:09.967679 139813 caffe.cpp:522]      drop6	forward: 32.326 ms.
I1109 01:26:09.967908 139813 caffe.cpp:526]      drop6	backward: 20.147 ms.
I1109 01:26:09.968147 139813 caffe.cpp:522]        fc7	forward: 13.339 ms.
I1109 01:26:09.968358 139813 caffe.cpp:526]        fc7	backward: 85.036 ms.
I1109 01:26:09.968583 139813 caffe.cpp:522]      relu7	forward: 22.776 ms.
I1109 01:26:09.968803 139813 caffe.cpp:526]      relu7	backward: 20.706 ms.
I1109 01:26:09.969002 139813 caffe.cpp:522]      drop7	forward: 29.998 ms.
I1109 01:26:09.969193 139813 caffe.cpp:526]      drop7	backward: 20.299 ms.
I1109 01:26:09.969383 139813 caffe.cpp:522]        fc8	forward: 16.003 ms.
I1109 01:26:09.969574 139813 caffe.cpp:526]        fc8	backward: 140.039 ms.
I1109 01:26:09.969768 139813 caffe.cpp:522]       loss	forward: 41.93 ms.
I1109 01:26:09.969957 139813 caffe.cpp:526]       loss	backward: 64.59 ms.
I1109 01:26:09.975608 139813 caffe.cpp:532] Average Forward pass: 1306.48 ms.
I1109 01:26:09.988129 139813 caffe.cpp:535] Average Backward pass: 754.797 ms.
I1109 01:26:09.999279 139813 caffe.cpp:537] Average Forward-Backward: 2570 ms.
I1109 01:26:10.013960 139813 caffe.cpp:540] Total Time: 2570 ms.
I1109 01:26:10.026191 139813 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 0
mem-read-2 = 0
mem-read-4 = 0
mem-read-8 = 0
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 0
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 0
--->Total Bytes written = 0
--->Total Bytes = 0

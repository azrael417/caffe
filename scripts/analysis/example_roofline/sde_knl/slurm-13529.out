total layers 26
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer0_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=0 -prof_forward_direction=0
I1109 01:28:33.834050 141011 caffe.cpp:444] Use CPU.
I1109 01:28:50.906008 141011 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:28:50.962020 141011 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:28:50.973642 141011 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:28:50.986044 141011 cpu_info.cpp:461] Total number of processors: 272
I1109 01:28:50.997225 141011 cpu_info.cpp:464] GPU is used: no
I1109 01:28:51.007694 141011 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:28:51.019614 141011 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:28:51.030889 141011 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:28:59.809362 141011 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:28:59.842469 141011 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:29:00.482465 141011 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:29:02.938961 141011 layer_factory.hpp:114] Creating layer data
I1109 01:29:03.087328 141011 net.cpp:160] Creating Layer data
I1109 01:29:03.135694 141011 net.cpp:570] data -> data
I1109 01:29:03.609202 141011 net.cpp:570] data -> label
I1109 01:29:10.654505 141011 net.cpp:210] Setting up data
I1109 01:29:10.732995 141011 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:29:10.840477 141011 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:29:10.847816 141011 net.cpp:225] Memory required for data: 19787264
I1109 01:29:10.915567 141011 layer_factory.hpp:114] Creating layer conv1
I1109 01:29:11.241705 141011 net.cpp:160] Creating Layer conv1
I1109 01:29:11.291889 141011 net.cpp:596] conv1 <- data
I1109 01:29:11.411635 141011 net.cpp:570] conv1 -> conv1
I1109 01:29:44.594503 141011 net.cpp:210] Setting up conv1
I1109 01:29:44.602617 141011 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:29:44.603054 141011 net.cpp:225] Memory required for data: 56958464
I1109 01:29:44.900087 141011 layer_factory.hpp:114] Creating layer relu1
I1109 01:29:45.022022 141011 net.cpp:160] Creating Layer relu1
I1109 01:29:45.026617 141011 net.cpp:596] relu1 <- conv1
I1109 01:29:45.059006 141011 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:29:45.246822 141011 net.cpp:210] Setting up relu1
I1109 01:29:45.249179 141011 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:29:45.249512 141011 net.cpp:225] Memory required for data: 94129664
I1109 01:29:45.249709 141011 layer_factory.hpp:114] Creating layer norm1
I1109 01:29:45.353747 141011 net.cpp:160] Creating Layer norm1
I1109 01:29:45.354071 141011 net.cpp:596] norm1 <- conv1
I1109 01:29:45.356431 141011 net.cpp:570] norm1 -> norm1
I1109 01:29:45.577953 141011 net.cpp:210] Setting up norm1
I1109 01:29:45.590360 141011 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:29:45.590745 141011 net.cpp:225] Memory required for data: 131300864
I1109 01:29:45.590952 141011 layer_factory.hpp:114] Creating layer pool1
I1109 01:29:45.682909 141011 net.cpp:160] Creating Layer pool1
I1109 01:29:45.683219 141011 net.cpp:596] pool1 <- norm1
I1109 01:29:45.698009 141011 net.cpp:570] pool1 -> pool1
I1109 01:29:46.015720 141011 net.cpp:210] Setting up pool1
I1109 01:29:46.018177 141011 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:29:46.018492 141011 net.cpp:225] Memory required for data: 140258816
I1109 01:29:46.018700 141011 layer_factory.hpp:114] Creating layer conv2
I1109 01:29:46.019085 141011 net.cpp:160] Creating Layer conv2
I1109 01:29:46.019306 141011 net.cpp:596] conv2 <- pool1
I1109 01:29:46.019547 141011 net.cpp:570] conv2 -> conv2
I1109 01:29:51.781090 141011 net.cpp:210] Setting up conv2
I1109 01:29:51.781424 141011 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:29:51.781821 141011 net.cpp:225] Memory required for data: 164146688
I1109 01:29:51.831754 141011 layer_factory.hpp:114] Creating layer relu2
I1109 01:29:51.832170 141011 net.cpp:160] Creating Layer relu2
I1109 01:29:51.832530 141011 net.cpp:596] relu2 <- conv2
I1109 01:29:51.832819 141011 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:29:51.833276 141011 net.cpp:210] Setting up relu2
I1109 01:29:51.833539 141011 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:29:51.833765 141011 net.cpp:225] Memory required for data: 188034560
I1109 01:29:51.833948 141011 layer_factory.hpp:114] Creating layer norm2
I1109 01:29:51.834187 141011 net.cpp:160] Creating Layer norm2
I1109 01:29:51.834378 141011 net.cpp:596] norm2 <- conv2
I1109 01:29:51.834601 141011 net.cpp:570] norm2 -> norm2
I1109 01:29:51.836691 141011 net.cpp:210] Setting up norm2
I1109 01:29:51.837049 141011 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:29:51.837280 141011 net.cpp:225] Memory required for data: 211922432
I1109 01:29:51.837465 141011 layer_factory.hpp:114] Creating layer pool2
I1109 01:29:51.838276 141011 net.cpp:160] Creating Layer pool2
I1109 01:29:51.838598 141011 net.cpp:596] pool2 <- norm2
I1109 01:29:51.838955 141011 net.cpp:570] pool2 -> pool2
I1109 01:29:51.839459 141011 net.cpp:210] Setting up pool2
I1109 01:29:51.839699 141011 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:29:51.839915 141011 net.cpp:225] Memory required for data: 217460224
I1109 01:29:51.840108 141011 layer_factory.hpp:114] Creating layer conv3
I1109 01:29:51.840433 141011 net.cpp:160] Creating Layer conv3
I1109 01:29:51.840646 141011 net.cpp:596] conv3 <- pool2
I1109 01:29:51.840932 141011 net.cpp:570] conv3 -> conv3
I1109 01:29:52.293092 141011 net.cpp:210] Setting up conv3
I1109 01:29:52.295454 141011 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:29:52.295806 141011 net.cpp:225] Memory required for data: 225766912
I1109 01:29:52.298933 141011 layer_factory.hpp:114] Creating layer relu3
I1109 01:29:52.299337 141011 net.cpp:160] Creating Layer relu3
I1109 01:29:52.299597 141011 net.cpp:596] relu3 <- conv3
I1109 01:29:52.299876 141011 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:29:52.303921 141011 net.cpp:210] Setting up relu3
I1109 01:29:52.304229 141011 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:29:52.304477 141011 net.cpp:225] Memory required for data: 234073600
I1109 01:29:52.304669 141011 layer_factory.hpp:114] Creating layer conv4
I1109 01:29:52.305097 141011 net.cpp:160] Creating Layer conv4
I1109 01:29:52.305419 141011 net.cpp:596] conv4 <- conv3
I1109 01:29:52.305692 141011 net.cpp:570] conv4 -> conv4
I1109 01:29:52.547852 141011 net.cpp:210] Setting up conv4
I1109 01:29:52.548274 141011 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:29:52.548666 141011 net.cpp:225] Memory required for data: 242380288
I1109 01:29:52.549055 141011 layer_factory.hpp:114] Creating layer relu4
I1109 01:29:52.549358 141011 net.cpp:160] Creating Layer relu4
I1109 01:29:52.549584 141011 net.cpp:596] relu4 <- conv4
I1109 01:29:52.549819 141011 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:29:52.562150 141011 net.cpp:210] Setting up relu4
I1109 01:29:52.562495 141011 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:29:52.562898 141011 net.cpp:225] Memory required for data: 250686976
I1109 01:29:52.563112 141011 layer_factory.hpp:114] Creating layer conv5
I1109 01:29:52.563480 141011 net.cpp:160] Creating Layer conv5
I1109 01:29:52.563725 141011 net.cpp:596] conv5 <- conv4
I1109 01:29:52.563968 141011 net.cpp:570] conv5 -> conv5
I1109 01:29:52.732295 141011 net.cpp:210] Setting up conv5
I1109 01:29:52.732693 141011 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:29:52.733173 141011 net.cpp:225] Memory required for data: 256224768
I1109 01:29:52.737952 141011 layer_factory.hpp:114] Creating layer relu5
I1109 01:29:52.738395 141011 net.cpp:160] Creating Layer relu5
I1109 01:29:52.738662 141011 net.cpp:596] relu5 <- conv5
I1109 01:29:52.738943 141011 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:29:52.739436 141011 net.cpp:210] Setting up relu5
I1109 01:29:52.739722 141011 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:29:52.739966 141011 net.cpp:225] Memory required for data: 261762560
I1109 01:29:52.740175 141011 layer_factory.hpp:114] Creating layer pool5
I1109 01:29:52.740435 141011 net.cpp:160] Creating Layer pool5
I1109 01:29:52.740651 141011 net.cpp:596] pool5 <- conv5
I1109 01:29:52.740922 141011 net.cpp:570] pool5 -> pool5
I1109 01:29:52.741392 141011 net.cpp:210] Setting up pool5
I1109 01:29:52.741717 141011 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:29:52.742012 141011 net.cpp:225] Memory required for data: 262942208
I1109 01:29:52.742228 141011 layer_factory.hpp:114] Creating layer fc6
I1109 01:29:52.796442 141011 net.cpp:160] Creating Layer fc6
I1109 01:29:52.796743 141011 net.cpp:596] fc6 <- pool5
I1109 01:29:52.797158 141011 net.cpp:570] fc6 -> fc6
I1109 01:29:56.933096 141011 net.cpp:210] Setting up fc6
I1109 01:29:56.933393 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:56.935442 141011 net.cpp:225] Memory required for data: 263466496
I1109 01:29:56.935742 141011 layer_factory.hpp:114] Creating layer relu6
I1109 01:29:56.938315 141011 net.cpp:160] Creating Layer relu6
I1109 01:29:56.938606 141011 net.cpp:596] relu6 <- fc6
I1109 01:29:56.938825 141011 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:29:56.939239 141011 net.cpp:210] Setting up relu6
I1109 01:29:56.939483 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:56.939702 141011 net.cpp:225] Memory required for data: 263990784
I1109 01:29:56.939919 141011 layer_factory.hpp:114] Creating layer drop6
I1109 01:29:56.960105 141011 net.cpp:160] Creating Layer drop6
I1109 01:29:56.960400 141011 net.cpp:596] drop6 <- fc6
I1109 01:29:56.960759 141011 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:29:57.063621 141011 net.cpp:210] Setting up drop6
I1109 01:29:57.063910 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:57.064239 141011 net.cpp:225] Memory required for data: 264515072
I1109 01:29:57.064479 141011 layer_factory.hpp:114] Creating layer fc7
I1109 01:29:57.064746 141011 net.cpp:160] Creating Layer fc7
I1109 01:29:57.065002 141011 net.cpp:596] fc7 <- fc6
I1109 01:29:57.065385 141011 net.cpp:570] fc7 -> fc7
I1109 01:29:58.777618 141011 net.cpp:210] Setting up fc7
I1109 01:29:58.777978 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:58.778389 141011 net.cpp:225] Memory required for data: 265039360
I1109 01:29:58.778753 141011 layer_factory.hpp:114] Creating layer relu7
I1109 01:29:58.779084 141011 net.cpp:160] Creating Layer relu7
I1109 01:29:58.779335 141011 net.cpp:596] relu7 <- fc7
I1109 01:29:58.779587 141011 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:29:58.780035 141011 net.cpp:210] Setting up relu7
I1109 01:29:58.780319 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:58.780597 141011 net.cpp:225] Memory required for data: 265563648
I1109 01:29:58.780850 141011 layer_factory.hpp:114] Creating layer drop7
I1109 01:29:58.781122 141011 net.cpp:160] Creating Layer drop7
I1109 01:29:58.781396 141011 net.cpp:596] drop7 <- fc7
I1109 01:29:58.781672 141011 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:29:58.781946 141011 net.cpp:210] Setting up drop7
I1109 01:29:58.782146 141011 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:29:58.782363 141011 net.cpp:225] Memory required for data: 266087936
I1109 01:29:58.782547 141011 layer_factory.hpp:114] Creating layer fc8
I1109 01:29:58.782799 141011 net.cpp:160] Creating Layer fc8
I1109 01:29:58.782997 141011 net.cpp:596] fc8 <- fc7
I1109 01:29:58.783224 141011 net.cpp:570] fc8 -> fc8
I1109 01:29:59.204943 141011 net.cpp:210] Setting up fc8
I1109 01:29:59.205293 141011 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:29:59.205726 141011 net.cpp:225] Memory required for data: 266215936
I1109 01:29:59.206022 141011 layer_factory.hpp:114] Creating layer loss
I1109 01:29:59.230689 141011 net.cpp:160] Creating Layer loss
I1109 01:29:59.230996 141011 net.cpp:596] loss <- fc8
I1109 01:29:59.231921 141011 net.cpp:596] loss <- label
I1109 01:29:59.259536 141011 net.cpp:570] loss -> loss
I1109 01:29:59.297499 141011 layer_factory.hpp:114] Creating layer loss
I1109 01:30:01.911687 141011 net.cpp:210] Setting up loss
I1109 01:30:01.965890 141011 net.cpp:217] Top shape: (1)
I1109 01:30:01.973817 141011 net.cpp:220]     with loss weight 1
I1109 01:30:02.123476 141011 net.cpp:225] Memory required for data: 266215940
I1109 01:30:02.162163 141011 net.cpp:287] loss needs backward computation.
I1109 01:30:02.248483 141011 net.cpp:287] fc8 needs backward computation.
I1109 01:30:02.255733 141011 net.cpp:287] drop7 needs backward computation.
I1109 01:30:02.266734 141011 net.cpp:287] relu7 needs backward computation.
I1109 01:30:02.267053 141011 net.cpp:287] fc7 needs backward computation.
I1109 01:30:02.269500 141011 net.cpp:287] drop6 needs backward computation.
I1109 01:30:02.269842 141011 net.cpp:287] relu6 needs backward computation.
I1109 01:30:02.270107 141011 net.cpp:287] fc6 needs backward computation.
I1109 01:30:02.270933 141011 net.cpp:287] pool5 needs backward computation.
I1109 01:30:02.271659 141011 net.cpp:287] relu5 needs backward computation.
I1109 01:30:02.271917 141011 net.cpp:287] conv5 needs backward computation.
I1109 01:30:02.272114 141011 net.cpp:287] relu4 needs backward computation.
I1109 01:30:02.272302 141011 net.cpp:287] conv4 needs backward computation.
I1109 01:30:02.272488 141011 net.cpp:287] relu3 needs backward computation.
I1109 01:30:02.272668 141011 net.cpp:287] conv3 needs backward computation.
I1109 01:30:02.284662 141011 net.cpp:287] pool2 needs backward computation.
I1109 01:30:02.285058 141011 net.cpp:287] norm2 needs backward computation.
I1109 01:30:02.285369 141011 net.cpp:287] relu2 needs backward computation.
I1109 01:30:02.285607 141011 net.cpp:287] conv2 needs backward computation.
I1109 01:30:02.285794 141011 net.cpp:287] pool1 needs backward computation.
I1109 01:30:02.285972 141011 net.cpp:287] norm1 needs backward computation.
I1109 01:30:02.286151 141011 net.cpp:287] relu1 needs backward computation.
I1109 01:30:02.286326 141011 net.cpp:287] conv1 needs backward computation.
I1109 01:30:02.298694 141011 net.cpp:289] data does not need backward computation.
I1109 01:30:02.324002 141011 net.cpp:331] This network produces output loss
I1109 01:30:02.395680 141011 net.cpp:345] Network initialization done.
I1109 01:30:02.563283 141011 caffe.cpp:452] Performing Forward
I1109 01:30:15.819241 141011 caffe.cpp:457] Initial loss: 6.9843
I1109 01:30:15.867396 141011 caffe.cpp:459] Performing Backward
I1109 01:30:20.489151 141011 caffe.cpp:468] *** Benchmark begins ***
I1109 01:30:20.500548 141011 caffe.cpp:469] Testing for 1 iterations.
I1109 01:30:20.645560 141011 caffe.cpp:485] Profiling Layer: data backward
I1109 01:30:22.828111 141011 caffe.cpp:512] Iteration: 1 forward-backward time: 2182 ms.
I1109 01:30:22.985896 141011 caffe.cpp:519] Average time per layer: 
I1109 01:30:23.000746 141011 caffe.cpp:522]       data	forward: 549.173 ms.
I1109 01:30:23.073787 141011 caffe.cpp:526]       data	backward: 19.009 ms.
I1109 01:30:23.102634 141011 caffe.cpp:522]      conv1	forward: 109.966 ms.
I1109 01:30:23.115931 141011 caffe.cpp:526]      conv1	backward: 43.145 ms.
I1109 01:30:23.124016 141011 caffe.cpp:522]      relu1	forward: 1.299 ms.
I1109 01:30:23.131780 141011 caffe.cpp:526]      relu1	backward: 17.438 ms.
I1109 01:30:23.141309 141011 caffe.cpp:522]      norm1	forward: 6.965 ms.
I1109 01:30:23.147241 141011 caffe.cpp:526]      norm1	backward: 14.066 ms.
I1109 01:30:23.153381 141011 caffe.cpp:522]      pool1	forward: 3.593 ms.
I1109 01:30:23.155647 141011 caffe.cpp:526]      pool1	backward: 89.35 ms.
I1109 01:30:23.168161 141011 caffe.cpp:522]      conv2	forward: 40.561 ms.
I1109 01:30:23.176241 141011 caffe.cpp:526]      conv2	backward: 78.578 ms.
I1109 01:30:23.183477 141011 caffe.cpp:522]      relu2	forward: 0.52 ms.
I1109 01:30:23.190402 141011 caffe.cpp:526]      relu2	backward: 15.154 ms.
I1109 01:30:23.191676 141011 caffe.cpp:522]      norm2	forward: 3.306 ms.
I1109 01:30:23.191933 141011 caffe.cpp:526]      norm2	backward: 14.048 ms.
I1109 01:30:23.192138 141011 caffe.cpp:522]      pool2	forward: 1.217 ms.
I1109 01:30:23.192327 141011 caffe.cpp:526]      pool2	backward: 58.361 ms.
I1109 01:30:23.192518 141011 caffe.cpp:522]      conv3	forward: 9.805 ms.
I1109 01:30:23.193614 141011 caffe.cpp:526]      conv3	backward: 77.97 ms.
I1109 01:30:23.193895 141011 caffe.cpp:522]      relu3	forward: 0.252 ms.
I1109 01:30:23.194092 141011 caffe.cpp:526]      relu3	backward: 31.029 ms.
I1109 01:30:23.194288 141011 caffe.cpp:522]      conv4	forward: 7.563 ms.
I1109 01:30:23.194478 141011 caffe.cpp:526]      conv4	backward: 68.658 ms.
I1109 01:30:23.194674 141011 caffe.cpp:522]      relu4	forward: 0.241 ms.
I1109 01:30:23.194862 141011 caffe.cpp:526]      relu4	backward: 35.621 ms.
I1109 01:30:23.195055 141011 caffe.cpp:522]      conv5	forward: 5.359 ms.
I1109 01:30:23.195242 141011 caffe.cpp:526]      conv5	backward: 71.067 ms.
I1109 01:30:23.195436 141011 caffe.cpp:522]      relu5	forward: 0.191 ms.
I1109 01:30:23.195623 141011 caffe.cpp:526]      relu5	backward: 13.159 ms.
I1109 01:30:23.195814 141011 caffe.cpp:522]      pool5	forward: 0.292 ms.
I1109 01:30:23.196043 141011 caffe.cpp:526]      pool5	backward: 60.564 ms.
I1109 01:30:23.196260 141011 caffe.cpp:522]        fc6	forward: 16.707 ms.
I1109 01:30:23.196564 141011 caffe.cpp:526]        fc6	backward: 123.244 ms.
I1109 01:30:23.196929 141011 caffe.cpp:522]      relu6	forward: 0.798 ms.
I1109 01:30:23.197159 141011 caffe.cpp:526]      relu6	backward: 13.024 ms.
I1109 01:30:23.197351 141011 caffe.cpp:522]      drop6	forward: 1.39 ms.
I1109 01:30:23.197538 141011 caffe.cpp:526]      drop6	backward: 12.517 ms.
I1109 01:30:23.197729 141011 caffe.cpp:522]        fc7	forward: 4.501 ms.
I1109 01:30:23.197916 141011 caffe.cpp:526]        fc7	backward: 95.001 ms.
I1109 01:30:23.198107 141011 caffe.cpp:522]      relu7	forward: 18.078 ms.
I1109 01:30:23.198297 141011 caffe.cpp:526]      relu7	backward: 15.637 ms.
I1109 01:30:23.198487 141011 caffe.cpp:522]      drop7	forward: 42.617 ms.
I1109 01:30:23.198678 141011 caffe.cpp:526]      drop7	backward: 16.865 ms.
I1109 01:30:23.198905 141011 caffe.cpp:522]        fc8	forward: 21.747 ms.
I1109 01:30:23.199111 141011 caffe.cpp:526]        fc8	backward: 124.196 ms.
I1109 01:30:23.199404 141011 caffe.cpp:522]       loss	forward: 70.551 ms.
I1109 01:30:23.199614 141011 caffe.cpp:526]       loss	backward: 66.473 ms.
I1109 01:30:23.205080 141011 caffe.cpp:532] Average Forward pass: 969.913 ms.
I1109 01:30:23.217828 141011 caffe.cpp:535] Average Backward pass: 1183.18 ms.
I1109 01:30:23.228724 141011 caffe.cpp:537] Average Forward-Backward: 2660 ms.
I1109 01:30:23.243352 141011 caffe.cpp:540] Total Time: 2660 ms.
I1109 01:30:23.255453 141011 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 2049
mem-read-2 = 0
mem-read-4 = 16406
mem-read-8 = 22624
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 2082
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 248665
--->Total Bytes written = 16656
--->Total Bytes = 265321
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer1_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=1 -prof_forward_direction=0
I1109 01:32:37.820744 141166 caffe.cpp:444] Use CPU.
I1109 01:32:54.678506 141166 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:32:54.734396 141166 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:32:54.746017 141166 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:32:54.758430 141166 cpu_info.cpp:461] Total number of processors: 272
I1109 01:32:54.769773 141166 cpu_info.cpp:464] GPU is used: no
I1109 01:32:54.778830 141166 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:32:54.787684 141166 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:32:54.798643 141166 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:33:03.490967 141166 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:33:03.523555 141166 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:33:04.156601 141166 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:33:06.576746 141166 layer_factory.hpp:114] Creating layer data
I1109 01:33:06.723291 141166 net.cpp:160] Creating Layer data
I1109 01:33:06.771066 141166 net.cpp:570] data -> data
I1109 01:33:07.231252 141166 net.cpp:570] data -> label
I1109 01:33:14.220018 141166 net.cpp:210] Setting up data
I1109 01:33:14.299793 141166 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:33:14.403326 141166 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:33:14.412051 141166 net.cpp:225] Memory required for data: 19787264
I1109 01:33:14.479348 141166 layer_factory.hpp:114] Creating layer conv1
I1109 01:33:14.803413 141166 net.cpp:160] Creating Layer conv1
I1109 01:33:14.853618 141166 net.cpp:596] conv1 <- data
I1109 01:33:14.972394 141166 net.cpp:570] conv1 -> conv1
I1109 01:33:47.767792 141166 net.cpp:210] Setting up conv1
I1109 01:33:47.774602 141166 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:33:47.774960 141166 net.cpp:225] Memory required for data: 56958464
I1109 01:33:48.055377 141166 layer_factory.hpp:114] Creating layer relu1
I1109 01:33:48.175009 141166 net.cpp:160] Creating Layer relu1
I1109 01:33:48.179554 141166 net.cpp:596] relu1 <- conv1
I1109 01:33:48.211732 141166 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:33:48.399852 141166 net.cpp:210] Setting up relu1
I1109 01:33:48.402331 141166 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:33:48.402680 141166 net.cpp:225] Memory required for data: 94129664
I1109 01:33:48.402931 141166 layer_factory.hpp:114] Creating layer norm1
I1109 01:33:48.506903 141166 net.cpp:160] Creating Layer norm1
I1109 01:33:48.507228 141166 net.cpp:596] norm1 <- conv1
I1109 01:33:48.509764 141166 net.cpp:570] norm1 -> norm1
I1109 01:33:48.733343 141166 net.cpp:210] Setting up norm1
I1109 01:33:48.746119 141166 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:33:48.746511 141166 net.cpp:225] Memory required for data: 131300864
I1109 01:33:48.746855 141166 layer_factory.hpp:114] Creating layer pool1
I1109 01:33:48.839448 141166 net.cpp:160] Creating Layer pool1
I1109 01:33:48.839769 141166 net.cpp:596] pool1 <- norm1
I1109 01:33:48.854497 141166 net.cpp:570] pool1 -> pool1
I1109 01:33:49.153240 141166 net.cpp:210] Setting up pool1
I1109 01:33:49.155697 141166 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:33:49.156028 141166 net.cpp:225] Memory required for data: 140258816
I1109 01:33:49.156247 141166 layer_factory.hpp:114] Creating layer conv2
I1109 01:33:49.156646 141166 net.cpp:160] Creating Layer conv2
I1109 01:33:49.156955 141166 net.cpp:596] conv2 <- pool1
I1109 01:33:49.157201 141166 net.cpp:570] conv2 -> conv2
I1109 01:33:54.869616 141166 net.cpp:210] Setting up conv2
I1109 01:33:54.869936 141166 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:33:54.870318 141166 net.cpp:225] Memory required for data: 164146688
I1109 01:33:54.920485 141166 layer_factory.hpp:114] Creating layer relu2
I1109 01:33:54.920979 141166 net.cpp:160] Creating Layer relu2
I1109 01:33:54.921344 141166 net.cpp:596] relu2 <- conv2
I1109 01:33:54.921664 141166 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:33:54.922138 141166 net.cpp:210] Setting up relu2
I1109 01:33:54.922425 141166 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:33:54.922684 141166 net.cpp:225] Memory required for data: 188034560
I1109 01:33:54.922896 141166 layer_factory.hpp:114] Creating layer norm2
I1109 01:33:54.923163 141166 net.cpp:160] Creating Layer norm2
I1109 01:33:54.923382 141166 net.cpp:596] norm2 <- conv2
I1109 01:33:54.923638 141166 net.cpp:570] norm2 -> norm2
I1109 01:33:54.925750 141166 net.cpp:210] Setting up norm2
I1109 01:33:54.926064 141166 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:33:54.926311 141166 net.cpp:225] Memory required for data: 211922432
I1109 01:33:54.926507 141166 layer_factory.hpp:114] Creating layer pool2
I1109 01:33:54.927355 141166 net.cpp:160] Creating Layer pool2
I1109 01:33:54.927764 141166 net.cpp:596] pool2 <- norm2
I1109 01:33:54.928092 141166 net.cpp:570] pool2 -> pool2
I1109 01:33:54.928504 141166 net.cpp:210] Setting up pool2
I1109 01:33:54.928746 141166 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:33:54.929024 141166 net.cpp:225] Memory required for data: 217460224
I1109 01:33:54.929227 141166 layer_factory.hpp:114] Creating layer conv3
I1109 01:33:54.929561 141166 net.cpp:160] Creating Layer conv3
I1109 01:33:54.929777 141166 net.cpp:596] conv3 <- pool2
I1109 01:33:54.930053 141166 net.cpp:570] conv3 -> conv3
I1109 01:33:55.406697 141166 net.cpp:210] Setting up conv3
I1109 01:33:55.409219 141166 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:33:55.409579 141166 net.cpp:225] Memory required for data: 225766912
I1109 01:33:55.412690 141166 layer_factory.hpp:114] Creating layer relu3
I1109 01:33:55.413161 141166 net.cpp:160] Creating Layer relu3
I1109 01:33:55.413427 141166 net.cpp:596] relu3 <- conv3
I1109 01:33:55.413712 141166 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:33:55.417788 141166 net.cpp:210] Setting up relu3
I1109 01:33:55.418175 141166 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:33:55.418530 141166 net.cpp:225] Memory required for data: 234073600
I1109 01:33:55.418735 141166 layer_factory.hpp:114] Creating layer conv4
I1109 01:33:55.419106 141166 net.cpp:160] Creating Layer conv4
I1109 01:33:55.419358 141166 net.cpp:596] conv4 <- conv3
I1109 01:33:55.419608 141166 net.cpp:570] conv4 -> conv4
I1109 01:33:55.662287 141166 net.cpp:210] Setting up conv4
I1109 01:33:55.662686 141166 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:33:55.663153 141166 net.cpp:225] Memory required for data: 242380288
I1109 01:33:55.663507 141166 layer_factory.hpp:114] Creating layer relu4
I1109 01:33:55.663817 141166 net.cpp:160] Creating Layer relu4
I1109 01:33:55.664057 141166 net.cpp:596] relu4 <- conv4
I1109 01:33:55.664299 141166 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:33:55.676429 141166 net.cpp:210] Setting up relu4
I1109 01:33:55.676910 141166 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:33:55.677291 141166 net.cpp:225] Memory required for data: 250686976
I1109 01:33:55.677530 141166 layer_factory.hpp:114] Creating layer conv5
I1109 01:33:55.677928 141166 net.cpp:160] Creating Layer conv5
I1109 01:33:55.678190 141166 net.cpp:596] conv5 <- conv4
I1109 01:33:55.678457 141166 net.cpp:570] conv5 -> conv5
I1109 01:33:55.849308 141166 net.cpp:210] Setting up conv5
I1109 01:33:55.849717 141166 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:33:55.850189 141166 net.cpp:225] Memory required for data: 256224768
I1109 01:33:55.854869 141166 layer_factory.hpp:114] Creating layer relu5
I1109 01:33:55.855288 141166 net.cpp:160] Creating Layer relu5
I1109 01:33:55.855554 141166 net.cpp:596] relu5 <- conv5
I1109 01:33:55.855845 141166 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:33:55.856355 141166 net.cpp:210] Setting up relu5
I1109 01:33:55.856670 141166 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:33:55.857072 141166 net.cpp:225] Memory required for data: 261762560
I1109 01:33:55.857339 141166 layer_factory.hpp:114] Creating layer pool5
I1109 01:33:55.857617 141166 net.cpp:160] Creating Layer pool5
I1109 01:33:55.857847 141166 net.cpp:596] pool5 <- conv5
I1109 01:33:55.858088 141166 net.cpp:570] pool5 -> pool5
I1109 01:33:55.858506 141166 net.cpp:210] Setting up pool5
I1109 01:33:55.858772 141166 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:33:55.859005 141166 net.cpp:225] Memory required for data: 262942208
I1109 01:33:55.859199 141166 layer_factory.hpp:114] Creating layer fc6
I1109 01:33:55.915098 141166 net.cpp:160] Creating Layer fc6
I1109 01:33:55.915422 141166 net.cpp:596] fc6 <- pool5
I1109 01:33:55.915820 141166 net.cpp:570] fc6 -> fc6
I1109 01:34:00.010112 141166 net.cpp:210] Setting up fc6
I1109 01:34:00.010422 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:00.012461 141166 net.cpp:225] Memory required for data: 263466496
I1109 01:34:00.012822 141166 layer_factory.hpp:114] Creating layer relu6
I1109 01:34:00.015306 141166 net.cpp:160] Creating Layer relu6
I1109 01:34:00.015605 141166 net.cpp:596] relu6 <- fc6
I1109 01:34:00.015838 141166 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:34:00.016261 141166 net.cpp:210] Setting up relu6
I1109 01:34:00.016516 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:00.016822 141166 net.cpp:225] Memory required for data: 263990784
I1109 01:34:00.017045 141166 layer_factory.hpp:114] Creating layer drop6
I1109 01:34:00.037515 141166 net.cpp:160] Creating Layer drop6
I1109 01:34:00.037842 141166 net.cpp:596] drop6 <- fc6
I1109 01:34:00.038198 141166 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:34:00.141927 141166 net.cpp:210] Setting up drop6
I1109 01:34:00.142231 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:00.142576 141166 net.cpp:225] Memory required for data: 264515072
I1109 01:34:00.142838 141166 layer_factory.hpp:114] Creating layer fc7
I1109 01:34:00.143113 141166 net.cpp:160] Creating Layer fc7
I1109 01:34:00.143323 141166 net.cpp:596] fc7 <- fc6
I1109 01:34:00.143707 141166 net.cpp:570] fc7 -> fc7
I1109 01:34:01.854648 141166 net.cpp:210] Setting up fc7
I1109 01:34:01.855026 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:01.855391 141166 net.cpp:225] Memory required for data: 265039360
I1109 01:34:01.855700 141166 layer_factory.hpp:114] Creating layer relu7
I1109 01:34:01.856004 141166 net.cpp:160] Creating Layer relu7
I1109 01:34:01.856225 141166 net.cpp:596] relu7 <- fc7
I1109 01:34:01.856456 141166 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:34:01.856917 141166 net.cpp:210] Setting up relu7
I1109 01:34:01.857200 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:01.857437 141166 net.cpp:225] Memory required for data: 265563648
I1109 01:34:01.857632 141166 layer_factory.hpp:114] Creating layer drop7
I1109 01:34:01.857858 141166 net.cpp:160] Creating Layer drop7
I1109 01:34:01.858050 141166 net.cpp:596] drop7 <- fc7
I1109 01:34:01.858325 141166 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:34:01.858600 141166 net.cpp:210] Setting up drop7
I1109 01:34:01.858834 141166 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:34:01.859046 141166 net.cpp:225] Memory required for data: 266087936
I1109 01:34:01.859228 141166 layer_factory.hpp:114] Creating layer fc8
I1109 01:34:01.859469 141166 net.cpp:160] Creating Layer fc8
I1109 01:34:01.859654 141166 net.cpp:596] fc8 <- fc7
I1109 01:34:01.859871 141166 net.cpp:570] fc8 -> fc8
I1109 01:34:02.284296 141166 net.cpp:210] Setting up fc8
I1109 01:34:02.284646 141166 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:34:02.285061 141166 net.cpp:225] Memory required for data: 266215936
I1109 01:34:02.285378 141166 layer_factory.hpp:114] Creating layer loss
I1109 01:34:02.310006 141166 net.cpp:160] Creating Layer loss
I1109 01:34:02.310328 141166 net.cpp:596] loss <- fc8
I1109 01:34:02.311266 141166 net.cpp:596] loss <- label
I1109 01:34:02.338699 141166 net.cpp:570] loss -> loss
I1109 01:34:02.376466 141166 layer_factory.hpp:114] Creating layer loss
I1109 01:34:04.854944 141166 net.cpp:210] Setting up loss
I1109 01:34:04.899687 141166 net.cpp:217] Top shape: (1)
I1109 01:34:04.913230 141166 net.cpp:220]     with loss weight 1
I1109 01:34:05.043201 141166 net.cpp:225] Memory required for data: 266215940
I1109 01:34:05.090842 141166 net.cpp:287] loss needs backward computation.
I1109 01:34:05.183120 141166 net.cpp:287] fc8 needs backward computation.
I1109 01:34:05.190337 141166 net.cpp:287] drop7 needs backward computation.
I1109 01:34:05.201347 141166 net.cpp:287] relu7 needs backward computation.
I1109 01:34:05.201663 141166 net.cpp:287] fc7 needs backward computation.
I1109 01:34:05.204051 141166 net.cpp:287] drop6 needs backward computation.
I1109 01:34:05.204387 141166 net.cpp:287] relu6 needs backward computation.
I1109 01:34:05.204602 141166 net.cpp:287] fc6 needs backward computation.
I1109 01:34:05.205463 141166 net.cpp:287] pool5 needs backward computation.
I1109 01:34:05.206225 141166 net.cpp:287] relu5 needs backward computation.
I1109 01:34:05.206492 141166 net.cpp:287] conv5 needs backward computation.
I1109 01:34:05.206701 141166 net.cpp:287] relu4 needs backward computation.
I1109 01:34:05.206897 141166 net.cpp:287] conv4 needs backward computation.
I1109 01:34:05.207093 141166 net.cpp:287] relu3 needs backward computation.
I1109 01:34:05.207283 141166 net.cpp:287] conv3 needs backward computation.
I1109 01:34:05.219750 141166 net.cpp:287] pool2 needs backward computation.
I1109 01:34:05.220093 141166 net.cpp:287] norm2 needs backward computation.
I1109 01:34:05.220404 141166 net.cpp:287] relu2 needs backward computation.
I1109 01:34:05.220640 141166 net.cpp:287] conv2 needs backward computation.
I1109 01:34:05.220870 141166 net.cpp:287] pool1 needs backward computation.
I1109 01:34:05.221065 141166 net.cpp:287] norm1 needs backward computation.
I1109 01:34:05.221251 141166 net.cpp:287] relu1 needs backward computation.
I1109 01:34:05.221431 141166 net.cpp:287] conv1 needs backward computation.
I1109 01:34:05.233997 141166 net.cpp:289] data does not need backward computation.
I1109 01:34:05.257938 141166 net.cpp:331] This network produces output loss
I1109 01:34:05.330070 141166 net.cpp:345] Network initialization done.
I1109 01:34:05.494649 141166 caffe.cpp:452] Performing Forward
I1109 01:34:18.341635 141166 caffe.cpp:457] Initial loss: 6.97641
I1109 01:34:18.389885 141166 caffe.cpp:459] Performing Backward
I1109 01:34:23.028110 141166 caffe.cpp:468] *** Benchmark begins ***
I1109 01:34:23.041040 141166 caffe.cpp:469] Testing for 1 iterations.
I1109 01:34:23.191242 141166 caffe.cpp:485] Profiling Layer: conv1 backward
I1109 01:34:25.286561 141166 caffe.cpp:512] Iteration: 1 forward-backward time: 2085 ms.
I1109 01:34:25.448920 141166 caffe.cpp:519] Average time per layer: 
I1109 01:34:25.467526 141166 caffe.cpp:522]       data	forward: 548.583 ms.
I1109 01:34:25.539367 141166 caffe.cpp:526]       data	backward: 3.363 ms.
I1109 01:34:25.568542 141166 caffe.cpp:522]      conv1	forward: 129.044 ms.
I1109 01:34:25.577383 141166 caffe.cpp:526]      conv1	backward: 57.477 ms.
I1109 01:34:25.580191 141166 caffe.cpp:522]      relu1	forward: 20.395 ms.
I1109 01:34:25.592067 141166 caffe.cpp:526]      relu1	backward: 1.079 ms.
I1109 01:34:25.600306 141166 caffe.cpp:522]      norm1	forward: 21.673 ms.
I1109 01:34:25.610258 141166 caffe.cpp:526]      norm1	backward: 3.278 ms.
I1109 01:34:25.616194 141166 caffe.cpp:522]      pool1	forward: 32.309 ms.
I1109 01:34:25.618463 141166 caffe.cpp:526]      pool1	backward: 35.64 ms.
I1109 01:34:25.620448 141166 caffe.cpp:522]      conv2	forward: 64.097 ms.
I1109 01:34:25.631232 141166 caffe.cpp:526]      conv2	backward: 31.763 ms.
I1109 01:34:25.642268 141166 caffe.cpp:522]      relu2	forward: 17.686 ms.
I1109 01:34:25.654199 141166 caffe.cpp:526]      relu2	backward: 0.754 ms.
I1109 01:34:25.656159 141166 caffe.cpp:522]      norm2	forward: 15.29 ms.
I1109 01:34:25.658879 141166 caffe.cpp:526]      norm2	backward: 2.099 ms.
I1109 01:34:25.659255 141166 caffe.cpp:522]      pool2	forward: 11.225 ms.
I1109 01:34:25.659502 141166 caffe.cpp:526]      pool2	backward: 22.368 ms.
I1109 01:34:25.659703 141166 caffe.cpp:522]      conv3	forward: 44.723 ms.
I1109 01:34:25.659899 141166 caffe.cpp:526]      conv3	backward: 38.846 ms.
I1109 01:34:25.660094 141166 caffe.cpp:522]      relu3	forward: 18.034 ms.
I1109 01:34:25.660286 141166 caffe.cpp:526]      relu3	backward: 0.703 ms.
I1109 01:34:25.660476 141166 caffe.cpp:522]      conv4	forward: 35.545 ms.
I1109 01:34:25.660667 141166 caffe.cpp:526]      conv4	backward: 27.906 ms.
I1109 01:34:25.660935 141166 caffe.cpp:522]      relu4	forward: 22.302 ms.
I1109 01:34:25.661195 141166 caffe.cpp:526]      relu4	backward: 6.917 ms.
I1109 01:34:25.661401 141166 caffe.cpp:522]      conv5	forward: 28.453 ms.
I1109 01:34:25.661718 141166 caffe.cpp:526]      conv5	backward: 18.729 ms.
I1109 01:34:25.661938 141166 caffe.cpp:522]      relu5	forward: 13.33 ms.
I1109 01:34:25.662232 141166 caffe.cpp:526]      relu5	backward: 0.211 ms.
I1109 01:34:25.662425 141166 caffe.cpp:522]      pool5	forward: 8.326 ms.
I1109 01:34:25.663213 141166 caffe.cpp:526]      pool5	backward: 42.384 ms.
I1109 01:34:25.663449 141166 caffe.cpp:522]        fc6	forward: 40.487 ms.
I1109 01:34:25.663650 141166 caffe.cpp:526]        fc6	backward: 93.286 ms.
I1109 01:34:25.663884 141166 caffe.cpp:522]      relu6	forward: 16.33 ms.
I1109 01:34:25.664096 141166 caffe.cpp:526]      relu6	backward: 19.444 ms.
I1109 01:34:25.664419 141166 caffe.cpp:522]      drop6	forward: 24.598 ms.
I1109 01:34:25.664669 141166 caffe.cpp:526]      drop6	backward: 18.424 ms.
I1109 01:34:25.664947 141166 caffe.cpp:522]        fc7	forward: 10.932 ms.
I1109 01:34:25.667537 141166 caffe.cpp:526]        fc7	backward: 89.562 ms.
I1109 01:34:25.667798 141166 caffe.cpp:522]      relu7	forward: 16.898 ms.
I1109 01:34:25.668004 141166 caffe.cpp:526]      relu7	backward: 13.428 ms.
I1109 01:34:25.668208 141166 caffe.cpp:522]      drop7	forward: 36.177 ms.
I1109 01:34:25.668409 141166 caffe.cpp:526]      drop7	backward: 8.812 ms.
I1109 01:34:25.668606 141166 caffe.cpp:522]        fc8	forward: 19.076 ms.
I1109 01:34:25.668879 141166 caffe.cpp:526]        fc8	backward: 131.129 ms.
I1109 01:34:25.669123 141166 caffe.cpp:522]       loss	forward: 55.753 ms.
I1109 01:34:25.669358 141166 caffe.cpp:526]       loss	backward: 72.009 ms.
I1109 01:34:25.674794 141166 caffe.cpp:532] Average Forward pass: 1308.81 ms.
I1109 01:34:25.687852 141166 caffe.cpp:535] Average Backward pass: 748.729 ms.
I1109 01:34:25.698604 141166 caffe.cpp:537] Average Forward-Backward: 2584 ms.
I1109 01:34:25.713027 141166 caffe.cpp:540] Total Time: 2584 ms.
I1109 01:34:25.725160 141166 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 422243790
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 6755900640
--->Total double-precision FLOPs = 0
--->Total FLOPs = 6755900640
mem-read-1 = 107827
mem-read-2 = 71
mem-read-4 = 212382950
mem-read-8 = 1667584
mem-read-16 = 1
mem-read-32 = 2
mem-read-64 = 39456532
mem-write-1 = 102
mem-write-2 = 34
mem-write-4 = 12456
mem-write-8 = 117683
mem-write-16 = 5
mem-write-32 = 2
mem-write-64 = 545116
--->Total Bytes read = 3388198569
--->Total Bytes written = 35879026
--->Total Bytes = 3424077595
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer2_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=2 -prof_forward_direction=0
I1109 01:38:20.330608 141286 caffe.cpp:444] Use CPU.
I1109 01:38:37.235738 141286 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:38:37.291560 141286 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:38:37.303143 141286 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:38:37.315579 141286 cpu_info.cpp:461] Total number of processors: 272
I1109 01:38:37.326795 141286 cpu_info.cpp:464] GPU is used: no
I1109 01:38:37.335775 141286 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:38:37.344568 141286 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:38:37.355440 141286 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:38:46.136363 141286 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:38:46.169034 141286 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:38:46.801648 141286 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:38:49.256521 141286 layer_factory.hpp:114] Creating layer data
I1109 01:38:49.403642 141286 net.cpp:160] Creating Layer data
I1109 01:38:49.451733 141286 net.cpp:570] data -> data
I1109 01:38:49.918670 141286 net.cpp:570] data -> label
I1109 01:38:56.973260 141286 net.cpp:210] Setting up data
I1109 01:38:57.051735 141286 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:38:57.155789 141286 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:38:57.162926 141286 net.cpp:225] Memory required for data: 19787264
I1109 01:38:57.230531 141286 layer_factory.hpp:114] Creating layer conv1
I1109 01:38:57.558456 141286 net.cpp:160] Creating Layer conv1
I1109 01:38:57.608664 141286 net.cpp:596] conv1 <- data
I1109 01:38:57.728816 141286 net.cpp:570] conv1 -> conv1
I1109 01:39:30.856158 141286 net.cpp:210] Setting up conv1
I1109 01:39:30.862701 141286 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:39:30.863080 141286 net.cpp:225] Memory required for data: 56958464
I1109 01:39:31.144558 141286 layer_factory.hpp:114] Creating layer relu1
I1109 01:39:31.264209 141286 net.cpp:160] Creating Layer relu1
I1109 01:39:31.268739 141286 net.cpp:596] relu1 <- conv1
I1109 01:39:31.300920 141286 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:39:31.489519 141286 net.cpp:210] Setting up relu1
I1109 01:39:31.491915 141286 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:39:31.492254 141286 net.cpp:225] Memory required for data: 94129664
I1109 01:39:31.492460 141286 layer_factory.hpp:114] Creating layer norm1
I1109 01:39:31.599510 141286 net.cpp:160] Creating Layer norm1
I1109 01:39:31.599825 141286 net.cpp:596] norm1 <- conv1
I1109 01:39:31.602426 141286 net.cpp:570] norm1 -> norm1
I1109 01:39:31.826122 141286 net.cpp:210] Setting up norm1
I1109 01:39:31.838912 141286 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:39:31.839296 141286 net.cpp:225] Memory required for data: 131300864
I1109 01:39:31.839603 141286 layer_factory.hpp:114] Creating layer pool1
I1109 01:39:31.935940 141286 net.cpp:160] Creating Layer pool1
I1109 01:39:31.936257 141286 net.cpp:596] pool1 <- norm1
I1109 01:39:31.951227 141286 net.cpp:570] pool1 -> pool1
I1109 01:39:32.254812 141286 net.cpp:210] Setting up pool1
I1109 01:39:32.257313 141286 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:39:32.257638 141286 net.cpp:225] Memory required for data: 140258816
I1109 01:39:32.257850 141286 layer_factory.hpp:114] Creating layer conv2
I1109 01:39:32.258194 141286 net.cpp:160] Creating Layer conv2
I1109 01:39:32.258417 141286 net.cpp:596] conv2 <- pool1
I1109 01:39:32.258682 141286 net.cpp:570] conv2 -> conv2
I1109 01:39:38.031550 141286 net.cpp:210] Setting up conv2
I1109 01:39:38.031886 141286 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:39:38.032269 141286 net.cpp:225] Memory required for data: 164146688
I1109 01:39:38.082370 141286 layer_factory.hpp:114] Creating layer relu2
I1109 01:39:38.082774 141286 net.cpp:160] Creating Layer relu2
I1109 01:39:38.083139 141286 net.cpp:596] relu2 <- conv2
I1109 01:39:38.083387 141286 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:39:38.083828 141286 net.cpp:210] Setting up relu2
I1109 01:39:38.084084 141286 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:39:38.084311 141286 net.cpp:225] Memory required for data: 188034560
I1109 01:39:38.084497 141286 layer_factory.hpp:114] Creating layer norm2
I1109 01:39:38.084738 141286 net.cpp:160] Creating Layer norm2
I1109 01:39:38.084990 141286 net.cpp:596] norm2 <- conv2
I1109 01:39:38.085247 141286 net.cpp:570] norm2 -> norm2
I1109 01:39:38.087316 141286 net.cpp:210] Setting up norm2
I1109 01:39:38.087616 141286 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:39:38.087843 141286 net.cpp:225] Memory required for data: 211922432
I1109 01:39:38.088029 141286 layer_factory.hpp:114] Creating layer pool2
I1109 01:39:38.088910 141286 net.cpp:160] Creating Layer pool2
I1109 01:39:38.089315 141286 net.cpp:596] pool2 <- norm2
I1109 01:39:38.089632 141286 net.cpp:570] pool2 -> pool2
I1109 01:39:38.090035 141286 net.cpp:210] Setting up pool2
I1109 01:39:38.090278 141286 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:39:38.090498 141286 net.cpp:225] Memory required for data: 217460224
I1109 01:39:38.090693 141286 layer_factory.hpp:114] Creating layer conv3
I1109 01:39:38.091014 141286 net.cpp:160] Creating Layer conv3
I1109 01:39:38.091228 141286 net.cpp:596] conv3 <- pool2
I1109 01:39:38.091465 141286 net.cpp:570] conv3 -> conv3
I1109 01:39:38.568121 141286 net.cpp:210] Setting up conv3
I1109 01:39:38.570588 141286 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:39:38.570943 141286 net.cpp:225] Memory required for data: 225766912
I1109 01:39:38.574059 141286 layer_factory.hpp:114] Creating layer relu3
I1109 01:39:38.574493 141286 net.cpp:160] Creating Layer relu3
I1109 01:39:38.574771 141286 net.cpp:596] relu3 <- conv3
I1109 01:39:38.575026 141286 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:39:38.579244 141286 net.cpp:210] Setting up relu3
I1109 01:39:38.579548 141286 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:39:38.579798 141286 net.cpp:225] Memory required for data: 234073600
I1109 01:39:38.579994 141286 layer_factory.hpp:114] Creating layer conv4
I1109 01:39:38.580389 141286 net.cpp:160] Creating Layer conv4
I1109 01:39:38.580656 141286 net.cpp:596] conv4 <- conv3
I1109 01:39:38.580970 141286 net.cpp:570] conv4 -> conv4
I1109 01:39:38.822510 141286 net.cpp:210] Setting up conv4
I1109 01:39:38.822896 141286 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:39:38.823292 141286 net.cpp:225] Memory required for data: 242380288
I1109 01:39:38.823637 141286 layer_factory.hpp:114] Creating layer relu4
I1109 01:39:38.823936 141286 net.cpp:160] Creating Layer relu4
I1109 01:39:38.824163 141286 net.cpp:596] relu4 <- conv4
I1109 01:39:38.824401 141286 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:39:38.836616 141286 net.cpp:210] Setting up relu4
I1109 01:39:38.837007 141286 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:39:38.837378 141286 net.cpp:225] Memory required for data: 250686976
I1109 01:39:38.837656 141286 layer_factory.hpp:114] Creating layer conv5
I1109 01:39:38.838047 141286 net.cpp:160] Creating Layer conv5
I1109 01:39:38.838286 141286 net.cpp:596] conv5 <- conv4
I1109 01:39:38.838529 141286 net.cpp:570] conv5 -> conv5
I1109 01:39:39.007102 141286 net.cpp:210] Setting up conv5
I1109 01:39:39.010082 141286 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:39:39.010540 141286 net.cpp:225] Memory required for data: 256224768
I1109 01:39:39.015270 141286 layer_factory.hpp:114] Creating layer relu5
I1109 01:39:39.015671 141286 net.cpp:160] Creating Layer relu5
I1109 01:39:39.015923 141286 net.cpp:596] relu5 <- conv5
I1109 01:39:39.016187 141286 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:39:39.016679 141286 net.cpp:210] Setting up relu5
I1109 01:39:39.017031 141286 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:39:39.017300 141286 net.cpp:225] Memory required for data: 261762560
I1109 01:39:39.017583 141286 layer_factory.hpp:114] Creating layer pool5
I1109 01:39:39.017877 141286 net.cpp:160] Creating Layer pool5
I1109 01:39:39.018093 141286 net.cpp:596] pool5 <- conv5
I1109 01:39:39.018314 141286 net.cpp:570] pool5 -> pool5
I1109 01:39:39.018710 141286 net.cpp:210] Setting up pool5
I1109 01:39:39.018966 141286 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:39:39.019189 141286 net.cpp:225] Memory required for data: 262942208
I1109 01:39:39.019373 141286 layer_factory.hpp:114] Creating layer fc6
I1109 01:39:39.074128 141286 net.cpp:160] Creating Layer fc6
I1109 01:39:39.074437 141286 net.cpp:596] fc6 <- pool5
I1109 01:39:39.074810 141286 net.cpp:570] fc6 -> fc6
I1109 01:39:43.163564 141286 net.cpp:210] Setting up fc6
I1109 01:39:43.163867 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:43.166049 141286 net.cpp:225] Memory required for data: 263466496
I1109 01:39:43.166357 141286 layer_factory.hpp:114] Creating layer relu6
I1109 01:39:43.168869 141286 net.cpp:160] Creating Layer relu6
I1109 01:39:43.169176 141286 net.cpp:596] relu6 <- fc6
I1109 01:39:43.169404 141286 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:39:43.169824 141286 net.cpp:210] Setting up relu6
I1109 01:39:43.170073 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:43.170296 141286 net.cpp:225] Memory required for data: 263990784
I1109 01:39:43.170483 141286 layer_factory.hpp:114] Creating layer drop6
I1109 01:39:43.190407 141286 net.cpp:160] Creating Layer drop6
I1109 01:39:43.190711 141286 net.cpp:596] drop6 <- fc6
I1109 01:39:43.191105 141286 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:39:43.294332 141286 net.cpp:210] Setting up drop6
I1109 01:39:43.294626 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:43.294991 141286 net.cpp:225] Memory required for data: 264515072
I1109 01:39:43.295204 141286 layer_factory.hpp:114] Creating layer fc7
I1109 01:39:43.295475 141286 net.cpp:160] Creating Layer fc7
I1109 01:39:43.295686 141286 net.cpp:596] fc7 <- fc6
I1109 01:39:43.296061 141286 net.cpp:570] fc7 -> fc7
I1109 01:39:45.009621 141286 net.cpp:210] Setting up fc7
I1109 01:39:45.009999 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:45.010455 141286 net.cpp:225] Memory required for data: 265039360
I1109 01:39:45.010793 141286 layer_factory.hpp:114] Creating layer relu7
I1109 01:39:45.011137 141286 net.cpp:160] Creating Layer relu7
I1109 01:39:45.011394 141286 net.cpp:596] relu7 <- fc7
I1109 01:39:45.011656 141286 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:39:45.012187 141286 net.cpp:210] Setting up relu7
I1109 01:39:45.012477 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:45.012727 141286 net.cpp:225] Memory required for data: 265563648
I1109 01:39:45.012995 141286 layer_factory.hpp:114] Creating layer drop7
I1109 01:39:45.013285 141286 net.cpp:160] Creating Layer drop7
I1109 01:39:45.013516 141286 net.cpp:596] drop7 <- fc7
I1109 01:39:45.013837 141286 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:39:45.014185 141286 net.cpp:210] Setting up drop7
I1109 01:39:45.014451 141286 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:39:45.014670 141286 net.cpp:225] Memory required for data: 266087936
I1109 01:39:45.014858 141286 layer_factory.hpp:114] Creating layer fc8
I1109 01:39:45.015110 141286 net.cpp:160] Creating Layer fc8
I1109 01:39:45.015313 141286 net.cpp:596] fc8 <- fc7
I1109 01:39:45.015540 141286 net.cpp:570] fc8 -> fc8
I1109 01:39:45.443354 141286 net.cpp:210] Setting up fc8
I1109 01:39:45.443711 141286 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:39:45.444102 141286 net.cpp:225] Memory required for data: 266215936
I1109 01:39:45.444438 141286 layer_factory.hpp:114] Creating layer loss
I1109 01:39:45.470782 141286 net.cpp:160] Creating Layer loss
I1109 01:39:45.471101 141286 net.cpp:596] loss <- fc8
I1109 01:39:45.472108 141286 net.cpp:596] loss <- label
I1109 01:39:45.500036 141286 net.cpp:570] loss -> loss
I1109 01:39:45.538322 141286 layer_factory.hpp:114] Creating layer loss
I1109 01:39:48.132621 141286 net.cpp:210] Setting up loss
I1109 01:39:48.187415 141286 net.cpp:217] Top shape: (1)
I1109 01:39:48.201808 141286 net.cpp:220]     with loss weight 1
I1109 01:39:48.328349 141286 net.cpp:225] Memory required for data: 266215940
I1109 01:39:48.371332 141286 net.cpp:287] loss needs backward computation.
I1109 01:39:48.459095 141286 net.cpp:287] fc8 needs backward computation.
I1109 01:39:48.466529 141286 net.cpp:287] drop7 needs backward computation.
I1109 01:39:48.477396 141286 net.cpp:287] relu7 needs backward computation.
I1109 01:39:48.477713 141286 net.cpp:287] fc7 needs backward computation.
I1109 01:39:48.480134 141286 net.cpp:287] drop6 needs backward computation.
I1109 01:39:48.480475 141286 net.cpp:287] relu6 needs backward computation.
I1109 01:39:48.480769 141286 net.cpp:287] fc6 needs backward computation.
I1109 01:39:48.481590 141286 net.cpp:287] pool5 needs backward computation.
I1109 01:39:48.482341 141286 net.cpp:287] relu5 needs backward computation.
I1109 01:39:48.482614 141286 net.cpp:287] conv5 needs backward computation.
I1109 01:39:48.482806 141286 net.cpp:287] relu4 needs backward computation.
I1109 01:39:48.482992 141286 net.cpp:287] conv4 needs backward computation.
I1109 01:39:48.483175 141286 net.cpp:287] relu3 needs backward computation.
I1109 01:39:48.483353 141286 net.cpp:287] conv3 needs backward computation.
I1109 01:39:48.495591 141286 net.cpp:287] pool2 needs backward computation.
I1109 01:39:48.495944 141286 net.cpp:287] norm2 needs backward computation.
I1109 01:39:48.496285 141286 net.cpp:287] relu2 needs backward computation.
I1109 01:39:48.496493 141286 net.cpp:287] conv2 needs backward computation.
I1109 01:39:48.496681 141286 net.cpp:287] pool1 needs backward computation.
I1109 01:39:48.496899 141286 net.cpp:287] norm1 needs backward computation.
I1109 01:39:48.497082 141286 net.cpp:287] relu1 needs backward computation.
I1109 01:39:48.497258 141286 net.cpp:287] conv1 needs backward computation.
I1109 01:39:48.509604 141286 net.cpp:289] data does not need backward computation.
I1109 01:39:48.534591 141286 net.cpp:331] This network produces output loss
I1109 01:39:48.606391 141286 net.cpp:345] Network initialization done.
I1109 01:39:48.774328 141286 caffe.cpp:452] Performing Forward
I1109 01:40:01.987344 141286 caffe.cpp:457] Initial loss: 6.8445
I1109 01:40:02.041188 141286 caffe.cpp:459] Performing Backward
I1109 01:40:06.926704 141286 caffe.cpp:468] *** Benchmark begins ***
I1109 01:40:06.941815 141286 caffe.cpp:469] Testing for 1 iterations.
I1109 01:40:07.088879 141286 caffe.cpp:485] Profiling Layer: relu1 backward
I1109 01:40:09.177489 141286 caffe.cpp:512] Iteration: 1 forward-backward time: 2085 ms.
I1109 01:40:09.333946 141286 caffe.cpp:519] Average time per layer: 
I1109 01:40:09.351536 141286 caffe.cpp:522]       data	forward: 552.119 ms.
I1109 01:40:09.424434 141286 caffe.cpp:526]       data	backward: 5.27 ms.
I1109 01:40:09.451603 141286 caffe.cpp:522]      conv1	forward: 129.983 ms.
I1109 01:40:09.457456 141286 caffe.cpp:526]      conv1	backward: 36.195 ms.
I1109 01:40:09.461781 141286 caffe.cpp:522]      relu1	forward: 17.183 ms.
I1109 01:40:09.476215 141286 caffe.cpp:526]      relu1	backward: 11.802 ms.
I1109 01:40:09.486330 141286 caffe.cpp:522]      norm1	forward: 19.897 ms.
I1109 01:40:09.495635 141286 caffe.cpp:526]      norm1	backward: 3.096 ms.
I1109 01:40:09.508762 141286 caffe.cpp:522]      pool1	forward: 22.196 ms.
I1109 01:40:09.516894 141286 caffe.cpp:526]      pool1	backward: 35.606 ms.
I1109 01:40:09.521132 141286 caffe.cpp:522]      conv2	forward: 63.034 ms.
I1109 01:40:09.528419 141286 caffe.cpp:526]      conv2	backward: 31.591 ms.
I1109 01:40:09.534584 141286 caffe.cpp:522]      relu2	forward: 12.931 ms.
I1109 01:40:09.542402 141286 caffe.cpp:526]      relu2	backward: 0.781 ms.
I1109 01:40:09.545047 141286 caffe.cpp:522]      norm2	forward: 15.609 ms.
I1109 01:40:09.546602 141286 caffe.cpp:526]      norm2	backward: 2.103 ms.
I1109 01:40:09.546890 141286 caffe.cpp:522]      pool2	forward: 11.482 ms.
I1109 01:40:09.547103 141286 caffe.cpp:526]      pool2	backward: 22.419 ms.
I1109 01:40:09.547309 141286 caffe.cpp:522]      conv3	forward: 38.097 ms.
I1109 01:40:09.547513 141286 caffe.cpp:526]      conv3	backward: 36.295 ms.
I1109 01:40:09.547715 141286 caffe.cpp:522]      relu3	forward: 20.199 ms.
I1109 01:40:09.547919 141286 caffe.cpp:526]      relu3	backward: 0.739 ms.
I1109 01:40:09.548120 141286 caffe.cpp:522]      conv4	forward: 33.309 ms.
I1109 01:40:09.548322 141286 caffe.cpp:526]      conv4	backward: 30.601 ms.
I1109 01:40:09.548526 141286 caffe.cpp:522]      relu4	forward: 14.376 ms.
I1109 01:40:09.548727 141286 caffe.cpp:526]      relu4	backward: 6.868 ms.
I1109 01:40:09.548969 141286 caffe.cpp:522]      conv5	forward: 32.516 ms.
I1109 01:40:09.549171 141286 caffe.cpp:526]      conv5	backward: 18.849 ms.
I1109 01:40:09.549373 141286 caffe.cpp:522]      relu5	forward: 16.892 ms.
I1109 01:40:09.549579 141286 caffe.cpp:526]      relu5	backward: 11.242 ms.
I1109 01:40:09.549818 141286 caffe.cpp:522]      pool5	forward: 16.026 ms.
I1109 01:40:09.550040 141286 caffe.cpp:526]      pool5	backward: 56.368 ms.
I1109 01:40:09.550246 141286 caffe.cpp:522]        fc6	forward: 42.656 ms.
I1109 01:40:09.550452 141286 caffe.cpp:526]        fc6	backward: 131.005 ms.
I1109 01:40:09.552888 141286 caffe.cpp:522]      relu6	forward: 22.14 ms.
I1109 01:40:09.553252 141286 caffe.cpp:526]      relu6	backward: 15.963 ms.
I1109 01:40:09.553506 141286 caffe.cpp:522]      drop6	forward: 28.353 ms.
I1109 01:40:09.553833 141286 caffe.cpp:526]      drop6	backward: 12.558 ms.
I1109 01:40:09.554062 141286 caffe.cpp:522]        fc7	forward: 10.76 ms.
I1109 01:40:09.556305 141286 caffe.cpp:526]        fc7	backward: 87.073 ms.
I1109 01:40:09.557117 141286 caffe.cpp:522]      relu7	forward: 9.006 ms.
I1109 01:40:09.557860 141286 caffe.cpp:526]      relu7	backward: 9.173 ms.
I1109 01:40:09.558200 141286 caffe.cpp:522]      drop7	forward: 31.356 ms.
I1109 01:40:09.558475 141286 caffe.cpp:526]      drop7	backward: 11.418 ms.
I1109 01:40:09.558778 141286 caffe.cpp:522]        fc8	forward: 13.163 ms.
I1109 01:40:09.559007 141286 caffe.cpp:526]        fc8	backward: 121.758 ms.
I1109 01:40:09.559203 141286 caffe.cpp:522]       loss	forward: 58.814 ms.
I1109 01:40:09.559396 141286 caffe.cpp:526]       loss	backward: 63.872 ms.
I1109 01:40:09.564847 141286 caffe.cpp:532] Average Forward pass: 1287.74 ms.
I1109 01:40:09.577769 141286 caffe.cpp:535] Average Backward pass: 771.489 ms.
I1109 01:40:09.588565 141286 caffe.cpp:537] Average Forward-Backward: 2580 ms.
I1109 01:40:09.603227 141286 caffe.cpp:540] Total Time: 2580 ms.
I1109 01:40:09.615401 141286 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 580800
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 1161600
--->Total FLOPs = 1161600
mem-read-1 = 379925
mem-read-2 = 34
mem-read-4 = 3043036
mem-read-8 = 4187463
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 1161601
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 564
mem-write-8 = 383462
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 580801
--->Total Bytes read = 120394337
--->Total Bytes written = 40241332
--->Total Bytes = 160635669
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer3_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=3 -prof_forward_direction=0
I1109 01:43:54.987978 141405 caffe.cpp:444] Use CPU.
I1109 01:44:11.841202 141405 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:44:11.897337 141405 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:44:11.909304 141405 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:44:11.921850 141405 cpu_info.cpp:461] Total number of processors: 272
I1109 01:44:11.933225 141405 cpu_info.cpp:464] GPU is used: no
I1109 01:44:11.942255 141405 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:44:11.951189 141405 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:44:11.962160 141405 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:44:20.891499 141405 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:44:20.924243 141405 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:44:21.555542 141405 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:44:24.008569 141405 layer_factory.hpp:114] Creating layer data
I1109 01:44:24.158547 141405 net.cpp:160] Creating Layer data
I1109 01:44:24.209161 141405 net.cpp:570] data -> data
I1109 01:44:24.675463 141405 net.cpp:570] data -> label
I1109 01:44:31.722272 141405 net.cpp:210] Setting up data
I1109 01:44:31.801367 141405 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:44:31.908041 141405 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:44:31.915814 141405 net.cpp:225] Memory required for data: 19787264
I1109 01:44:31.985592 141405 layer_factory.hpp:114] Creating layer conv1
I1109 01:44:32.313904 141405 net.cpp:160] Creating Layer conv1
I1109 01:44:32.363801 141405 net.cpp:596] conv1 <- data
I1109 01:44:32.482764 141405 net.cpp:570] conv1 -> conv1
I1109 01:45:05.404870 141405 net.cpp:210] Setting up conv1
I1109 01:45:05.412394 141405 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:45:05.412773 141405 net.cpp:225] Memory required for data: 56958464
I1109 01:45:05.701063 141405 layer_factory.hpp:114] Creating layer relu1
I1109 01:45:05.822016 141405 net.cpp:160] Creating Layer relu1
I1109 01:45:05.826578 141405 net.cpp:596] relu1 <- conv1
I1109 01:45:05.859052 141405 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:45:06.049090 141405 net.cpp:210] Setting up relu1
I1109 01:45:06.051492 141405 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:45:06.051827 141405 net.cpp:225] Memory required for data: 94129664
I1109 01:45:06.052026 141405 layer_factory.hpp:114] Creating layer norm1
I1109 01:45:06.162981 141405 net.cpp:160] Creating Layer norm1
I1109 01:45:06.163287 141405 net.cpp:596] norm1 <- conv1
I1109 01:45:06.165817 141405 net.cpp:570] norm1 -> norm1
I1109 01:45:06.387711 141405 net.cpp:210] Setting up norm1
I1109 01:45:06.400598 141405 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:45:06.401011 141405 net.cpp:225] Memory required for data: 131300864
I1109 01:45:06.401305 141405 layer_factory.hpp:114] Creating layer pool1
I1109 01:45:06.498571 141405 net.cpp:160] Creating Layer pool1
I1109 01:45:06.498893 141405 net.cpp:596] pool1 <- norm1
I1109 01:45:06.514186 141405 net.cpp:570] pool1 -> pool1
I1109 01:45:06.818172 141405 net.cpp:210] Setting up pool1
I1109 01:45:06.820652 141405 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:45:06.821022 141405 net.cpp:225] Memory required for data: 140258816
I1109 01:45:06.821228 141405 layer_factory.hpp:114] Creating layer conv2
I1109 01:45:06.821614 141405 net.cpp:160] Creating Layer conv2
I1109 01:45:06.821838 141405 net.cpp:596] conv2 <- pool1
I1109 01:45:06.822100 141405 net.cpp:570] conv2 -> conv2
I1109 01:45:12.589051 141405 net.cpp:210] Setting up conv2
I1109 01:45:12.589395 141405 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:45:12.589766 141405 net.cpp:225] Memory required for data: 164146688
I1109 01:45:12.640430 141405 layer_factory.hpp:114] Creating layer relu2
I1109 01:45:12.640911 141405 net.cpp:160] Creating Layer relu2
I1109 01:45:12.641222 141405 net.cpp:596] relu2 <- conv2
I1109 01:45:12.641490 141405 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:45:12.641963 141405 net.cpp:210] Setting up relu2
I1109 01:45:12.642237 141405 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:45:12.642473 141405 net.cpp:225] Memory required for data: 188034560
I1109 01:45:12.642668 141405 layer_factory.hpp:114] Creating layer norm2
I1109 01:45:12.642920 141405 net.cpp:160] Creating Layer norm2
I1109 01:45:12.643120 141405 net.cpp:596] norm2 <- conv2
I1109 01:45:12.643362 141405 net.cpp:570] norm2 -> norm2
I1109 01:45:12.645483 141405 net.cpp:210] Setting up norm2
I1109 01:45:12.645793 141405 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:45:12.646023 141405 net.cpp:225] Memory required for data: 211922432
I1109 01:45:12.646208 141405 layer_factory.hpp:114] Creating layer pool2
I1109 01:45:12.647011 141405 net.cpp:160] Creating Layer pool2
I1109 01:45:12.647294 141405 net.cpp:596] pool2 <- norm2
I1109 01:45:12.647529 141405 net.cpp:570] pool2 -> pool2
I1109 01:45:12.647953 141405 net.cpp:210] Setting up pool2
I1109 01:45:12.648262 141405 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:45:12.648608 141405 net.cpp:225] Memory required for data: 217460224
I1109 01:45:12.648908 141405 layer_factory.hpp:114] Creating layer conv3
I1109 01:45:12.649245 141405 net.cpp:160] Creating Layer conv3
I1109 01:45:12.649456 141405 net.cpp:596] conv3 <- pool2
I1109 01:45:12.649695 141405 net.cpp:570] conv3 -> conv3
I1109 01:45:13.154336 141405 net.cpp:210] Setting up conv3
I1109 01:45:13.156733 141405 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:45:13.157135 141405 net.cpp:225] Memory required for data: 225766912
I1109 01:45:13.160133 141405 layer_factory.hpp:114] Creating layer relu3
I1109 01:45:13.160534 141405 net.cpp:160] Creating Layer relu3
I1109 01:45:13.160825 141405 net.cpp:596] relu3 <- conv3
I1109 01:45:13.161134 141405 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:45:13.165261 141405 net.cpp:210] Setting up relu3
I1109 01:45:13.165573 141405 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:45:13.165819 141405 net.cpp:225] Memory required for data: 234073600
I1109 01:45:13.166012 141405 layer_factory.hpp:114] Creating layer conv4
I1109 01:45:13.166368 141405 net.cpp:160] Creating Layer conv4
I1109 01:45:13.166616 141405 net.cpp:596] conv4 <- conv3
I1109 01:45:13.166862 141405 net.cpp:570] conv4 -> conv4
I1109 01:45:13.407212 141405 net.cpp:210] Setting up conv4
I1109 01:45:13.407594 141405 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:45:13.407984 141405 net.cpp:225] Memory required for data: 242380288
I1109 01:45:13.408311 141405 layer_factory.hpp:114] Creating layer relu4
I1109 01:45:13.408592 141405 net.cpp:160] Creating Layer relu4
I1109 01:45:13.408849 141405 net.cpp:596] relu4 <- conv4
I1109 01:45:13.409098 141405 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:45:13.421315 141405 net.cpp:210] Setting up relu4
I1109 01:45:13.421663 141405 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:45:13.422036 141405 net.cpp:225] Memory required for data: 250686976
I1109 01:45:13.422274 141405 layer_factory.hpp:114] Creating layer conv5
I1109 01:45:13.422631 141405 net.cpp:160] Creating Layer conv5
I1109 01:45:13.422864 141405 net.cpp:596] conv5 <- conv4
I1109 01:45:13.423105 141405 net.cpp:570] conv5 -> conv5
I1109 01:45:13.591648 141405 net.cpp:210] Setting up conv5
I1109 01:45:13.592036 141405 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:45:13.592444 141405 net.cpp:225] Memory required for data: 256224768
I1109 01:45:13.597192 141405 layer_factory.hpp:114] Creating layer relu5
I1109 01:45:13.597594 141405 net.cpp:160] Creating Layer relu5
I1109 01:45:13.597838 141405 net.cpp:596] relu5 <- conv5
I1109 01:45:13.598098 141405 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:45:13.598592 141405 net.cpp:210] Setting up relu5
I1109 01:45:13.598898 141405 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:45:13.599205 141405 net.cpp:225] Memory required for data: 261762560
I1109 01:45:13.599441 141405 layer_factory.hpp:114] Creating layer pool5
I1109 01:45:13.599699 141405 net.cpp:160] Creating Layer pool5
I1109 01:45:13.599907 141405 net.cpp:596] pool5 <- conv5
I1109 01:45:13.600126 141405 net.cpp:570] pool5 -> pool5
I1109 01:45:13.600509 141405 net.cpp:210] Setting up pool5
I1109 01:45:13.600754 141405 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:45:13.601038 141405 net.cpp:225] Memory required for data: 262942208
I1109 01:45:13.601227 141405 layer_factory.hpp:114] Creating layer fc6
I1109 01:45:13.655690 141405 net.cpp:160] Creating Layer fc6
I1109 01:45:13.655997 141405 net.cpp:596] fc6 <- pool5
I1109 01:45:13.656386 141405 net.cpp:570] fc6 -> fc6
I1109 01:45:17.746808 141405 net.cpp:210] Setting up fc6
I1109 01:45:17.747112 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:17.749177 141405 net.cpp:225] Memory required for data: 263466496
I1109 01:45:17.749481 141405 layer_factory.hpp:114] Creating layer relu6
I1109 01:45:17.751945 141405 net.cpp:160] Creating Layer relu6
I1109 01:45:17.752239 141405 net.cpp:596] relu6 <- fc6
I1109 01:45:17.752465 141405 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:45:17.752923 141405 net.cpp:210] Setting up relu6
I1109 01:45:17.753191 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:17.753412 141405 net.cpp:225] Memory required for data: 263990784
I1109 01:45:17.753594 141405 layer_factory.hpp:114] Creating layer drop6
I1109 01:45:17.773461 141405 net.cpp:160] Creating Layer drop6
I1109 01:45:17.773764 141405 net.cpp:596] drop6 <- fc6
I1109 01:45:17.774127 141405 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:45:17.879071 141405 net.cpp:210] Setting up drop6
I1109 01:45:17.879370 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:17.879729 141405 net.cpp:225] Memory required for data: 264515072
I1109 01:45:17.879935 141405 layer_factory.hpp:114] Creating layer fc7
I1109 01:45:17.880197 141405 net.cpp:160] Creating Layer fc7
I1109 01:45:17.880395 141405 net.cpp:596] fc7 <- fc6
I1109 01:45:17.880903 141405 net.cpp:570] fc7 -> fc7
I1109 01:45:19.594070 141405 net.cpp:210] Setting up fc7
I1109 01:45:19.594424 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:19.594830 141405 net.cpp:225] Memory required for data: 265039360
I1109 01:45:19.595180 141405 layer_factory.hpp:114] Creating layer relu7
I1109 01:45:19.595490 141405 net.cpp:160] Creating Layer relu7
I1109 01:45:19.595726 141405 net.cpp:596] relu7 <- fc7
I1109 01:45:19.595968 141405 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:45:19.596396 141405 net.cpp:210] Setting up relu7
I1109 01:45:19.596683 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:19.596976 141405 net.cpp:225] Memory required for data: 265563648
I1109 01:45:19.597172 141405 layer_factory.hpp:114] Creating layer drop7
I1109 01:45:19.597431 141405 net.cpp:160] Creating Layer drop7
I1109 01:45:19.597645 141405 net.cpp:596] drop7 <- fc7
I1109 01:45:19.597899 141405 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:45:19.598177 141405 net.cpp:210] Setting up drop7
I1109 01:45:19.598462 141405 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:45:19.598671 141405 net.cpp:225] Memory required for data: 266087936
I1109 01:45:19.598852 141405 layer_factory.hpp:114] Creating layer fc8
I1109 01:45:19.599098 141405 net.cpp:160] Creating Layer fc8
I1109 01:45:19.599293 141405 net.cpp:596] fc8 <- fc7
I1109 01:45:19.599517 141405 net.cpp:570] fc8 -> fc8
I1109 01:45:20.023433 141405 net.cpp:210] Setting up fc8
I1109 01:45:20.023787 141405 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:45:20.024183 141405 net.cpp:225] Memory required for data: 266215936
I1109 01:45:20.024520 141405 layer_factory.hpp:114] Creating layer loss
I1109 01:45:20.049679 141405 net.cpp:160] Creating Layer loss
I1109 01:45:20.050000 141405 net.cpp:596] loss <- fc8
I1109 01:45:20.050896 141405 net.cpp:596] loss <- label
I1109 01:45:20.078897 141405 net.cpp:570] loss -> loss
I1109 01:45:20.117446 141405 layer_factory.hpp:114] Creating layer loss
I1109 01:45:22.702150 141405 net.cpp:210] Setting up loss
I1109 01:45:22.760234 141405 net.cpp:217] Top shape: (1)
I1109 01:45:22.771947 141405 net.cpp:220]     with loss weight 1
I1109 01:45:22.907855 141405 net.cpp:225] Memory required for data: 266215940
I1109 01:45:22.949268 141405 net.cpp:287] loss needs backward computation.
I1109 01:45:23.036749 141405 net.cpp:287] fc8 needs backward computation.
I1109 01:45:23.043997 141405 net.cpp:287] drop7 needs backward computation.
I1109 01:45:23.055078 141405 net.cpp:287] relu7 needs backward computation.
I1109 01:45:23.055397 141405 net.cpp:287] fc7 needs backward computation.
I1109 01:45:23.057934 141405 net.cpp:287] drop6 needs backward computation.
I1109 01:45:23.058264 141405 net.cpp:287] relu6 needs backward computation.
I1109 01:45:23.058579 141405 net.cpp:287] fc6 needs backward computation.
I1109 01:45:23.059427 141405 net.cpp:287] pool5 needs backward computation.
I1109 01:45:23.060164 141405 net.cpp:287] relu5 needs backward computation.
I1109 01:45:23.060428 141405 net.cpp:287] conv5 needs backward computation.
I1109 01:45:23.060618 141405 net.cpp:287] relu4 needs backward computation.
I1109 01:45:23.060843 141405 net.cpp:287] conv4 needs backward computation.
I1109 01:45:23.061069 141405 net.cpp:287] relu3 needs backward computation.
I1109 01:45:23.061264 141405 net.cpp:287] conv3 needs backward computation.
I1109 01:45:23.073850 141405 net.cpp:287] pool2 needs backward computation.
I1109 01:45:23.074237 141405 net.cpp:287] norm2 needs backward computation.
I1109 01:45:23.074509 141405 net.cpp:287] relu2 needs backward computation.
I1109 01:45:23.074743 141405 net.cpp:287] conv2 needs backward computation.
I1109 01:45:23.074931 141405 net.cpp:287] pool1 needs backward computation.
I1109 01:45:23.075114 141405 net.cpp:287] norm1 needs backward computation.
I1109 01:45:23.075294 141405 net.cpp:287] relu1 needs backward computation.
I1109 01:45:23.075470 141405 net.cpp:287] conv1 needs backward computation.
I1109 01:45:23.087931 141405 net.cpp:289] data does not need backward computation.
I1109 01:45:23.113111 141405 net.cpp:331] This network produces output loss
I1109 01:45:23.183388 141405 net.cpp:345] Network initialization done.
I1109 01:45:23.351019 141405 caffe.cpp:452] Performing Forward
I1109 01:45:36.595263 141405 caffe.cpp:457] Initial loss: 6.83485
I1109 01:45:36.646847 141405 caffe.cpp:459] Performing Backward
I1109 01:45:41.692306 141405 caffe.cpp:468] *** Benchmark begins ***
I1109 01:45:41.703820 141405 caffe.cpp:469] Testing for 1 iterations.
I1109 01:45:41.847724 141405 caffe.cpp:485] Profiling Layer: norm1 backward
I1109 01:45:44.114727 141405 caffe.cpp:512] Iteration: 1 forward-backward time: 2266 ms.
I1109 01:45:44.275061 141405 caffe.cpp:519] Average time per layer: 
I1109 01:45:44.292531 141405 caffe.cpp:522]       data	forward: 546.305 ms.
I1109 01:45:44.368144 141405 caffe.cpp:526]       data	backward: 5.486 ms.
I1109 01:45:44.391347 141405 caffe.cpp:522]      conv1	forward: 111.377 ms.
I1109 01:45:44.396014 141405 caffe.cpp:526]      conv1	backward: 44.679 ms.
I1109 01:45:44.398233 141405 caffe.cpp:522]      relu1	forward: 1.309 ms.
I1109 01:45:44.398473 141405 caffe.cpp:526]      relu1	backward: 21.01 ms.
I1109 01:45:44.399152 141405 caffe.cpp:522]      norm1	forward: 7.005 ms.
I1109 01:45:44.399380 141405 caffe.cpp:526]      norm1	backward: 29.874 ms.
I1109 01:45:44.399694 141405 caffe.cpp:522]      pool1	forward: 3.611 ms.
I1109 01:45:44.400012 141405 caffe.cpp:526]      pool1	backward: 88.498 ms.
I1109 01:45:44.400753 141405 caffe.cpp:522]      conv2	forward: 40.56 ms.
I1109 01:45:44.401026 141405 caffe.cpp:526]      conv2	backward: 82.871 ms.
I1109 01:45:44.401221 141405 caffe.cpp:522]      relu2	forward: 0.516 ms.
I1109 01:45:44.401430 141405 caffe.cpp:526]      relu2	backward: 17.859 ms.
I1109 01:45:44.401623 141405 caffe.cpp:522]      norm2	forward: 3.336 ms.
I1109 01:45:44.401809 141405 caffe.cpp:526]      norm2	backward: 21.637 ms.
I1109 01:45:44.402000 141405 caffe.cpp:522]      pool2	forward: 1.174 ms.
I1109 01:45:44.402187 141405 caffe.cpp:526]      pool2	backward: 73.196 ms.
I1109 01:45:44.402379 141405 caffe.cpp:522]      conv3	forward: 9.915 ms.
I1109 01:45:44.403239 141405 caffe.cpp:526]      conv3	backward: 86.191 ms.
I1109 01:45:44.403544 141405 caffe.cpp:522]      relu3	forward: 0.29 ms.
I1109 01:45:44.403740 141405 caffe.cpp:526]      relu3	backward: 34.374 ms.
I1109 01:45:44.403934 141405 caffe.cpp:522]      conv4	forward: 7.517 ms.
I1109 01:45:44.404121 141405 caffe.cpp:526]      conv4	backward: 73.989 ms.
I1109 01:45:44.404314 141405 caffe.cpp:522]      relu4	forward: 0.252 ms.
I1109 01:45:44.404502 141405 caffe.cpp:526]      relu4	backward: 37.249 ms.
I1109 01:45:44.404695 141405 caffe.cpp:522]      conv5	forward: 5.244 ms.
I1109 01:45:44.404959 141405 caffe.cpp:526]      conv5	backward: 58.03 ms.
I1109 01:45:44.405164 141405 caffe.cpp:522]      relu5	forward: 0.194 ms.
I1109 01:45:44.405365 141405 caffe.cpp:526]      relu5	backward: 15.771 ms.
I1109 01:45:44.405570 141405 caffe.cpp:522]      pool5	forward: 0.306 ms.
I1109 01:45:44.405796 141405 caffe.cpp:526]      pool5	backward: 57.405 ms.
I1109 01:45:44.405987 141405 caffe.cpp:522]        fc6	forward: 25.233 ms.
I1109 01:45:44.406213 141405 caffe.cpp:526]        fc6	backward: 123.537 ms.
I1109 01:45:44.406422 141405 caffe.cpp:522]      relu6	forward: 16.726 ms.
I1109 01:45:44.406673 141405 caffe.cpp:526]      relu6	backward: 15.026 ms.
I1109 01:45:44.406914 141405 caffe.cpp:522]      drop6	forward: 26.115 ms.
I1109 01:45:44.407109 141405 caffe.cpp:526]      drop6	backward: 22.307 ms.
I1109 01:45:44.407300 141405 caffe.cpp:522]        fc7	forward: 18.739 ms.
I1109 01:45:44.407492 141405 caffe.cpp:526]        fc7	backward: 106.505 ms.
I1109 01:45:44.407685 141405 caffe.cpp:522]      relu7	forward: 13.348 ms.
I1109 01:45:44.407876 141405 caffe.cpp:526]      relu7	backward: 17.714 ms.
I1109 01:45:44.408068 141405 caffe.cpp:522]      drop7	forward: 31.538 ms.
I1109 01:45:44.408259 141405 caffe.cpp:526]      drop7	backward: 21.78 ms.
I1109 01:45:44.408452 141405 caffe.cpp:522]        fc8	forward: 17.316 ms.
I1109 01:45:44.408643 141405 caffe.cpp:526]        fc8	backward: 113.24 ms.
I1109 01:45:44.408867 141405 caffe.cpp:522]       loss	forward: 52.876 ms.
I1109 01:45:44.409060 141405 caffe.cpp:526]       loss	backward: 61.371 ms.
I1109 01:45:44.414592 141405 caffe.cpp:532] Average Forward pass: 997.077 ms.
I1109 01:45:44.427537 141405 caffe.cpp:535] Average Backward pass: 1238.65 ms.
I1109 01:45:44.438400 141405 caffe.cpp:537] Average Forward-Backward: 2667 ms.
I1109 01:45:44.453342 141405 caffe.cpp:540] Total Time: 2667 ms.
I1109 01:45:44.465584 141405 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 5808032
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 92928512
--->Total double-precision FLOPs = 0
--->Total FLOPs = 92928512
mem-read-1 = 23402
mem-read-2 = 34
mem-read-4 = 1668554
mem-read-8 = 560829
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 6388804
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 495465
mem-write-8 = 29194
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 1742401
--->Total Bytes read = 420067806
--->Total Bytes written = 113729192
--->Total Bytes = 533796998
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer4_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=4 -prof_forward_direction=0
I1109 01:49:36.824904 141575 caffe.cpp:444] Use CPU.
I1109 01:49:53.707603 141575 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:49:53.763474 141575 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:49:53.775622 141575 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:49:53.788173 141575 cpu_info.cpp:461] Total number of processors: 272
I1109 01:49:53.799422 141575 cpu_info.cpp:464] GPU is used: no
I1109 01:49:53.808534 141575 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:49:53.817433 141575 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:49:53.828446 141575 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:50:02.575101 141575 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:50:02.607748 141575 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:50:03.241459 141575 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:50:05.681687 141575 layer_factory.hpp:114] Creating layer data
I1109 01:50:05.828696 141575 net.cpp:160] Creating Layer data
I1109 01:50:05.879951 141575 net.cpp:570] data -> data
I1109 01:50:06.354598 141575 net.cpp:570] data -> label
I1109 01:50:13.378502 141575 net.cpp:210] Setting up data
I1109 01:50:13.458515 141575 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:50:13.562352 141575 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:50:13.569596 141575 net.cpp:225] Memory required for data: 19787264
I1109 01:50:13.636616 141575 layer_factory.hpp:114] Creating layer conv1
I1109 01:50:13.965064 141575 net.cpp:160] Creating Layer conv1
I1109 01:50:14.016628 141575 net.cpp:596] conv1 <- data
I1109 01:50:14.139891 141575 net.cpp:570] conv1 -> conv1
I1109 01:50:46.822548 141575 net.cpp:210] Setting up conv1
I1109 01:50:46.828742 141575 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:50:46.829176 141575 net.cpp:225] Memory required for data: 56958464
I1109 01:50:47.109963 141575 layer_factory.hpp:114] Creating layer relu1
I1109 01:50:47.233031 141575 net.cpp:160] Creating Layer relu1
I1109 01:50:47.237845 141575 net.cpp:596] relu1 <- conv1
I1109 01:50:47.271423 141575 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:50:47.461195 141575 net.cpp:210] Setting up relu1
I1109 01:50:47.463578 141575 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:50:47.463923 141575 net.cpp:225] Memory required for data: 94129664
I1109 01:50:47.464124 141575 layer_factory.hpp:114] Creating layer norm1
I1109 01:50:47.571138 141575 net.cpp:160] Creating Layer norm1
I1109 01:50:47.571465 141575 net.cpp:596] norm1 <- conv1
I1109 01:50:47.574060 141575 net.cpp:570] norm1 -> norm1
I1109 01:50:47.797952 141575 net.cpp:210] Setting up norm1
I1109 01:50:47.810763 141575 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:50:47.811151 141575 net.cpp:225] Memory required for data: 131300864
I1109 01:50:47.811465 141575 layer_factory.hpp:114] Creating layer pool1
I1109 01:50:47.906234 141575 net.cpp:160] Creating Layer pool1
I1109 01:50:47.906556 141575 net.cpp:596] pool1 <- norm1
I1109 01:50:47.921478 141575 net.cpp:570] pool1 -> pool1
I1109 01:50:48.227737 141575 net.cpp:210] Setting up pool1
I1109 01:50:48.230296 141575 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:50:48.230634 141575 net.cpp:225] Memory required for data: 140258816
I1109 01:50:48.230850 141575 layer_factory.hpp:114] Creating layer conv2
I1109 01:50:48.231245 141575 net.cpp:160] Creating Layer conv2
I1109 01:50:48.231485 141575 net.cpp:596] conv2 <- pool1
I1109 01:50:48.231814 141575 net.cpp:570] conv2 -> conv2
I1109 01:50:54.040050 141575 net.cpp:210] Setting up conv2
I1109 01:50:54.040410 141575 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:50:54.040907 141575 net.cpp:225] Memory required for data: 164146688
I1109 01:50:54.091478 141575 layer_factory.hpp:114] Creating layer relu2
I1109 01:50:54.091892 141575 net.cpp:160] Creating Layer relu2
I1109 01:50:54.092258 141575 net.cpp:596] relu2 <- conv2
I1109 01:50:54.092509 141575 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:50:54.093008 141575 net.cpp:210] Setting up relu2
I1109 01:50:54.093293 141575 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:50:54.093519 141575 net.cpp:225] Memory required for data: 188034560
I1109 01:50:54.093703 141575 layer_factory.hpp:114] Creating layer norm2
I1109 01:50:54.093950 141575 net.cpp:160] Creating Layer norm2
I1109 01:50:54.094151 141575 net.cpp:596] norm2 <- conv2
I1109 01:50:54.094374 141575 net.cpp:570] norm2 -> norm2
I1109 01:50:54.096537 141575 net.cpp:210] Setting up norm2
I1109 01:50:54.096932 141575 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:50:54.097183 141575 net.cpp:225] Memory required for data: 211922432
I1109 01:50:54.097404 141575 layer_factory.hpp:114] Creating layer pool2
I1109 01:50:54.098388 141575 net.cpp:160] Creating Layer pool2
I1109 01:50:54.098695 141575 net.cpp:596] pool2 <- norm2
I1109 01:50:54.098939 141575 net.cpp:570] pool2 -> pool2
I1109 01:50:54.099336 141575 net.cpp:210] Setting up pool2
I1109 01:50:54.099587 141575 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:50:54.099804 141575 net.cpp:225] Memory required for data: 217460224
I1109 01:50:54.100000 141575 layer_factory.hpp:114] Creating layer conv3
I1109 01:50:54.100327 141575 net.cpp:160] Creating Layer conv3
I1109 01:50:54.100579 141575 net.cpp:596] conv3 <- pool2
I1109 01:50:54.100880 141575 net.cpp:570] conv3 -> conv3
I1109 01:50:54.552628 141575 net.cpp:210] Setting up conv3
I1109 01:50:54.555088 141575 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:50:54.555436 141575 net.cpp:225] Memory required for data: 225766912
I1109 01:50:54.558554 141575 layer_factory.hpp:114] Creating layer relu3
I1109 01:50:54.558955 141575 net.cpp:160] Creating Layer relu3
I1109 01:50:54.559212 141575 net.cpp:596] relu3 <- conv3
I1109 01:50:54.559453 141575 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:50:54.563714 141575 net.cpp:210] Setting up relu3
I1109 01:50:54.564045 141575 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:50:54.564309 141575 net.cpp:225] Memory required for data: 234073600
I1109 01:50:54.564515 141575 layer_factory.hpp:114] Creating layer conv4
I1109 01:50:54.564939 141575 net.cpp:160] Creating Layer conv4
I1109 01:50:54.565244 141575 net.cpp:596] conv4 <- conv3
I1109 01:50:54.565513 141575 net.cpp:570] conv4 -> conv4
I1109 01:50:54.808032 141575 net.cpp:210] Setting up conv4
I1109 01:50:54.808416 141575 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:50:54.808898 141575 net.cpp:225] Memory required for data: 242380288
I1109 01:50:54.809248 141575 layer_factory.hpp:114] Creating layer relu4
I1109 01:50:54.809535 141575 net.cpp:160] Creating Layer relu4
I1109 01:50:54.809753 141575 net.cpp:596] relu4 <- conv4
I1109 01:50:54.809979 141575 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:50:54.822052 141575 net.cpp:210] Setting up relu4
I1109 01:50:54.822366 141575 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:50:54.822610 141575 net.cpp:225] Memory required for data: 250686976
I1109 01:50:54.822804 141575 layer_factory.hpp:114] Creating layer conv5
I1109 01:50:54.823166 141575 net.cpp:160] Creating Layer conv5
I1109 01:50:54.823411 141575 net.cpp:596] conv5 <- conv4
I1109 01:50:54.823654 141575 net.cpp:570] conv5 -> conv5
I1109 01:50:54.991513 141575 net.cpp:210] Setting up conv5
I1109 01:50:54.991931 141575 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:50:54.992343 141575 net.cpp:225] Memory required for data: 256224768
I1109 01:50:54.997104 141575 layer_factory.hpp:114] Creating layer relu5
I1109 01:50:54.997503 141575 net.cpp:160] Creating Layer relu5
I1109 01:50:54.997745 141575 net.cpp:596] relu5 <- conv5
I1109 01:50:54.997998 141575 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:50:54.998446 141575 net.cpp:210] Setting up relu5
I1109 01:50:54.998726 141575 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:50:54.998966 141575 net.cpp:225] Memory required for data: 261762560
I1109 01:50:54.999166 141575 layer_factory.hpp:114] Creating layer pool5
I1109 01:50:54.999423 141575 net.cpp:160] Creating Layer pool5
I1109 01:50:54.999673 141575 net.cpp:596] pool5 <- conv5
I1109 01:50:54.999910 141575 net.cpp:570] pool5 -> pool5
I1109 01:50:55.000396 141575 net.cpp:210] Setting up pool5
I1109 01:50:55.003314 141575 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:50:55.003574 141575 net.cpp:225] Memory required for data: 262942208
I1109 01:50:55.003767 141575 layer_factory.hpp:114] Creating layer fc6
I1109 01:50:55.058111 141575 net.cpp:160] Creating Layer fc6
I1109 01:50:55.058429 141575 net.cpp:596] fc6 <- pool5
I1109 01:50:55.058823 141575 net.cpp:570] fc6 -> fc6
I1109 01:50:59.155170 141575 net.cpp:210] Setting up fc6
I1109 01:50:59.155478 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:50:59.157570 141575 net.cpp:225] Memory required for data: 263466496
I1109 01:50:59.157882 141575 layer_factory.hpp:114] Creating layer relu6
I1109 01:50:59.160357 141575 net.cpp:160] Creating Layer relu6
I1109 01:50:59.160660 141575 net.cpp:596] relu6 <- fc6
I1109 01:50:59.160934 141575 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:50:59.161363 141575 net.cpp:210] Setting up relu6
I1109 01:50:59.161619 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:50:59.161839 141575 net.cpp:225] Memory required for data: 263990784
I1109 01:50:59.162021 141575 layer_factory.hpp:114] Creating layer drop6
I1109 01:50:59.182149 141575 net.cpp:160] Creating Layer drop6
I1109 01:50:59.182454 141575 net.cpp:596] drop6 <- fc6
I1109 01:50:59.182828 141575 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:50:59.286885 141575 net.cpp:210] Setting up drop6
I1109 01:50:59.287181 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:50:59.287528 141575 net.cpp:225] Memory required for data: 264515072
I1109 01:50:59.287767 141575 layer_factory.hpp:114] Creating layer fc7
I1109 01:50:59.288034 141575 net.cpp:160] Creating Layer fc7
I1109 01:50:59.288233 141575 net.cpp:596] fc7 <- fc6
I1109 01:50:59.288612 141575 net.cpp:570] fc7 -> fc7
I1109 01:51:01.002730 141575 net.cpp:210] Setting up fc7
I1109 01:51:01.003103 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:51:01.003584 141575 net.cpp:225] Memory required for data: 265039360
I1109 01:51:01.003964 141575 layer_factory.hpp:114] Creating layer relu7
I1109 01:51:01.004302 141575 net.cpp:160] Creating Layer relu7
I1109 01:51:01.004557 141575 net.cpp:596] relu7 <- fc7
I1109 01:51:01.004858 141575 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:51:01.005342 141575 net.cpp:210] Setting up relu7
I1109 01:51:01.005630 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:51:01.005882 141575 net.cpp:225] Memory required for data: 265563648
I1109 01:51:01.006085 141575 layer_factory.hpp:114] Creating layer drop7
I1109 01:51:01.006359 141575 net.cpp:160] Creating Layer drop7
I1109 01:51:01.006584 141575 net.cpp:596] drop7 <- fc7
I1109 01:51:01.006840 141575 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:51:01.007154 141575 net.cpp:210] Setting up drop7
I1109 01:51:01.007359 141575 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:51:01.007573 141575 net.cpp:225] Memory required for data: 266087936
I1109 01:51:01.007757 141575 layer_factory.hpp:114] Creating layer fc8
I1109 01:51:01.008010 141575 net.cpp:160] Creating Layer fc8
I1109 01:51:01.008206 141575 net.cpp:596] fc8 <- fc7
I1109 01:51:01.008429 141575 net.cpp:570] fc8 -> fc8
I1109 01:51:01.435166 141575 net.cpp:210] Setting up fc8
I1109 01:51:01.435523 141575 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:51:01.435919 141575 net.cpp:225] Memory required for data: 266215936
I1109 01:51:01.436254 141575 layer_factory.hpp:114] Creating layer loss
I1109 01:51:01.461125 141575 net.cpp:160] Creating Layer loss
I1109 01:51:01.461444 141575 net.cpp:596] loss <- fc8
I1109 01:51:01.462477 141575 net.cpp:596] loss <- label
I1109 01:51:01.490265 141575 net.cpp:570] loss -> loss
I1109 01:51:01.528348 141575 layer_factory.hpp:114] Creating layer loss
I1109 01:51:04.107774 141575 net.cpp:210] Setting up loss
I1109 01:51:04.159642 141575 net.cpp:217] Top shape: (1)
I1109 01:51:04.169185 141575 net.cpp:220]     with loss weight 1
I1109 01:51:04.298102 141575 net.cpp:225] Memory required for data: 266215940
I1109 01:51:04.344005 141575 net.cpp:287] loss needs backward computation.
I1109 01:51:04.431098 141575 net.cpp:287] fc8 needs backward computation.
I1109 01:51:04.438341 141575 net.cpp:287] drop7 needs backward computation.
I1109 01:51:04.449296 141575 net.cpp:287] relu7 needs backward computation.
I1109 01:51:04.449616 141575 net.cpp:287] fc7 needs backward computation.
I1109 01:51:04.451982 141575 net.cpp:287] drop6 needs backward computation.
I1109 01:51:04.452322 141575 net.cpp:287] relu6 needs backward computation.
I1109 01:51:04.452529 141575 net.cpp:287] fc6 needs backward computation.
I1109 01:51:04.453411 141575 net.cpp:287] pool5 needs backward computation.
I1109 01:51:04.454174 141575 net.cpp:287] relu5 needs backward computation.
I1109 01:51:04.454444 141575 net.cpp:287] conv5 needs backward computation.
I1109 01:51:04.454640 141575 net.cpp:287] relu4 needs backward computation.
I1109 01:51:04.454830 141575 net.cpp:287] conv4 needs backward computation.
I1109 01:51:04.455014 141575 net.cpp:287] relu3 needs backward computation.
I1109 01:51:04.455193 141575 net.cpp:287] conv3 needs backward computation.
I1109 01:51:04.467280 141575 net.cpp:287] pool2 needs backward computation.
I1109 01:51:04.467602 141575 net.cpp:287] norm2 needs backward computation.
I1109 01:51:04.467797 141575 net.cpp:287] relu2 needs backward computation.
I1109 01:51:04.467980 141575 net.cpp:287] conv2 needs backward computation.
I1109 01:51:04.468163 141575 net.cpp:287] pool1 needs backward computation.
I1109 01:51:04.468341 141575 net.cpp:287] norm1 needs backward computation.
I1109 01:51:04.468519 141575 net.cpp:287] relu1 needs backward computation.
I1109 01:51:04.468730 141575 net.cpp:287] conv1 needs backward computation.
I1109 01:51:04.480756 141575 net.cpp:289] data does not need backward computation.
I1109 01:51:04.505278 141575 net.cpp:331] This network produces output loss
I1109 01:51:04.576819 141575 net.cpp:345] Network initialization done.
I1109 01:51:04.745029 141575 caffe.cpp:452] Performing Forward
I1109 01:51:18.031358 141575 caffe.cpp:457] Initial loss: 6.93082
I1109 01:51:18.085120 141575 caffe.cpp:459] Performing Backward
I1109 01:51:22.826059 141575 caffe.cpp:468] *** Benchmark begins ***
I1109 01:51:22.837316 141575 caffe.cpp:469] Testing for 1 iterations.
I1109 01:51:22.980247 141575 caffe.cpp:485] Profiling Layer: pool1 backward
I1109 01:51:25.357473 141575 caffe.cpp:512] Iteration: 1 forward-backward time: 2374 ms.
I1109 01:51:25.514087 141575 caffe.cpp:519] Average time per layer: 
I1109 01:51:25.529285 141575 caffe.cpp:522]       data	forward: 550.034 ms.
I1109 01:51:25.604691 141575 caffe.cpp:526]       data	backward: 5.743 ms.
I1109 01:51:25.628933 141575 caffe.cpp:522]      conv1	forward: 128.496 ms.
I1109 01:51:25.633292 141575 caffe.cpp:526]      conv1	backward: 46.19 ms.
I1109 01:51:25.640815 141575 caffe.cpp:522]      relu1	forward: 26.987 ms.
I1109 01:51:25.646401 141575 caffe.cpp:526]      relu1	backward: 23.293 ms.
I1109 01:51:25.652582 141575 caffe.cpp:522]      norm1	forward: 18.103 ms.
I1109 01:51:25.660377 141575 caffe.cpp:526]      norm1	backward: 17.417 ms.
I1109 01:51:25.664608 141575 caffe.cpp:522]      pool1	forward: 19.134 ms.
I1109 01:51:25.670768 141575 caffe.cpp:526]      pool1	backward: 99.05 ms.
I1109 01:51:25.678849 141575 caffe.cpp:522]      conv2	forward: 63.342 ms.
I1109 01:51:25.688199 141575 caffe.cpp:526]      conv2	backward: 76.198 ms.
I1109 01:51:25.691952 141575 caffe.cpp:522]      relu2	forward: 9.731 ms.
I1109 01:51:25.703333 141575 caffe.cpp:526]      relu2	backward: 12.518 ms.
I1109 01:51:25.705788 141575 caffe.cpp:522]      norm2	forward: 9.614 ms.
I1109 01:51:25.706009 141575 caffe.cpp:526]      norm2	backward: 12.522 ms.
I1109 01:51:25.706214 141575 caffe.cpp:522]      pool2	forward: 15.616 ms.
I1109 01:51:25.706418 141575 caffe.cpp:526]      pool2	backward: 67.127 ms.
I1109 01:51:25.706621 141575 caffe.cpp:522]      conv3	forward: 34.674 ms.
I1109 01:51:25.706823 141575 caffe.cpp:526]      conv3	backward: 89.7 ms.
I1109 01:51:25.707026 141575 caffe.cpp:522]      relu3	forward: 23.006 ms.
I1109 01:51:25.707227 141575 caffe.cpp:526]      relu3	backward: 30.442 ms.
I1109 01:51:25.707429 141575 caffe.cpp:522]      conv4	forward: 38.352 ms.
I1109 01:51:25.707631 141575 caffe.cpp:526]      conv4	backward: 70.896 ms.
I1109 01:51:25.707837 141575 caffe.cpp:522]      relu4	forward: 15.442 ms.
I1109 01:51:25.708065 141575 caffe.cpp:526]      relu4	backward: 35.753 ms.
I1109 01:51:25.708276 141575 caffe.cpp:522]      conv5	forward: 36.268 ms.
I1109 01:51:25.708478 141575 caffe.cpp:526]      conv5	backward: 59.631 ms.
I1109 01:51:25.708680 141575 caffe.cpp:522]      relu5	forward: 15.302 ms.
I1109 01:51:25.708920 141575 caffe.cpp:526]      relu5	backward: 19.752 ms.
I1109 01:51:25.709122 141575 caffe.cpp:522]      pool5	forward: 13.867 ms.
I1109 01:51:25.709324 141575 caffe.cpp:526]      pool5	backward: 50.346 ms.
I1109 01:51:25.709527 141575 caffe.cpp:522]        fc6	forward: 44.553 ms.
I1109 01:51:25.709728 141575 caffe.cpp:526]        fc6	backward: 122.793 ms.
I1109 01:51:25.709931 141575 caffe.cpp:522]      relu6	forward: 17.304 ms.
I1109 01:51:25.710132 141575 caffe.cpp:526]      relu6	backward: 11.608 ms.
I1109 01:51:25.710335 141575 caffe.cpp:522]      drop6	forward: 40.263 ms.
I1109 01:51:25.710536 141575 caffe.cpp:526]      drop6	backward: 15.73 ms.
I1109 01:51:25.710737 141575 caffe.cpp:522]        fc7	forward: 17.827 ms.
I1109 01:51:25.710954 141575 caffe.cpp:526]        fc7	backward: 78.976 ms.
I1109 01:51:25.711169 141575 caffe.cpp:522]      relu7	forward: 12.256 ms.
I1109 01:51:25.711374 141575 caffe.cpp:526]      relu7	backward: 0.092 ms.
I1109 01:51:25.713966 141575 caffe.cpp:522]      drop7	forward: 6.528 ms.
I1109 01:51:25.714228 141575 caffe.cpp:526]      drop7	backward: 0.096 ms.
I1109 01:51:25.714540 141575 caffe.cpp:522]        fc8	forward: 1.69 ms.
I1109 01:51:25.714776 141575 caffe.cpp:526]        fc8	backward: 86.474 ms.
I1109 01:51:25.714972 141575 caffe.cpp:522]       loss	forward: 35.132 ms.
I1109 01:51:25.715162 141575 caffe.cpp:526]       loss	backward: 51.544 ms.
I1109 01:51:25.720479 141575 caffe.cpp:532] Average Forward pass: 1249.64 ms.
I1109 01:51:25.733971 141575 caffe.cpp:535] Average Backward pass: 1093.87 ms.
I1109 01:51:25.745095 141575 caffe.cpp:537] Average Forward-Backward: 2840 ms.
I1109 01:51:25.759985 141575 caffe.cpp:540] Total Time: 2840 ms.
I1109 01:51:25.772243 141575 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 139968
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2239488
--->Total double-precision FLOPs = 0
--->Total FLOPs = 2239488
mem-read-1 = 84793
mem-read-2 = 103
mem-read-4 = 770112
mem-read-8 = 1016989
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 559874
mem-write-1 = 152
mem-write-2 = 51
mem-write-4 = 23008
mem-write-8 = 104169
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 1166978
--->Total Bytes read = 47133359
--->Total Bytes written = 75612294
--->Total Bytes = 122745653
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer5_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=5 -prof_forward_direction=0
I1109 01:55:45.999624 141706 caffe.cpp:444] Use CPU.
I1109 01:56:02.796214 141706 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 01:56:02.851953 141706 cpu_info.cpp:455] Total number of sockets: 1
I1109 01:56:02.863829 141706 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 01:56:02.876330 141706 cpu_info.cpp:461] Total number of processors: 272
I1109 01:56:02.887523 141706 cpu_info.cpp:464] GPU is used: no
I1109 01:56:02.896471 141706 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 01:56:02.905385 141706 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 01:56:02.916766 141706 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 01:56:11.637894 141706 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 01:56:11.670449 141706 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 01:56:12.302198 141706 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 01:56:14.735340 141706 layer_factory.hpp:114] Creating layer data
I1109 01:56:14.881709 141706 net.cpp:160] Creating Layer data
I1109 01:56:14.930094 141706 net.cpp:570] data -> data
I1109 01:56:15.392884 141706 net.cpp:570] data -> label
I1109 01:56:22.450409 141706 net.cpp:210] Setting up data
I1109 01:56:22.529191 141706 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 01:56:22.633105 141706 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 01:56:22.640408 141706 net.cpp:225] Memory required for data: 19787264
I1109 01:56:22.707628 141706 layer_factory.hpp:114] Creating layer conv1
I1109 01:56:23.034663 141706 net.cpp:160] Creating Layer conv1
I1109 01:56:23.084391 141706 net.cpp:596] conv1 <- data
I1109 01:56:23.203379 141706 net.cpp:570] conv1 -> conv1
I1109 01:56:56.030565 141706 net.cpp:210] Setting up conv1
I1109 01:56:56.037438 141706 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:56:56.037830 141706 net.cpp:225] Memory required for data: 56958464
I1109 01:56:56.323196 141706 layer_factory.hpp:114] Creating layer relu1
I1109 01:56:56.443670 141706 net.cpp:160] Creating Layer relu1
I1109 01:56:56.448225 141706 net.cpp:596] relu1 <- conv1
I1109 01:56:56.480360 141706 net.cpp:557] relu1 -> conv1 (in-place)
I1109 01:56:56.669409 141706 net.cpp:210] Setting up relu1
I1109 01:56:56.671857 141706 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:56:56.672202 141706 net.cpp:225] Memory required for data: 94129664
I1109 01:56:56.672415 141706 layer_factory.hpp:114] Creating layer norm1
I1109 01:56:56.778916 141706 net.cpp:160] Creating Layer norm1
I1109 01:56:56.779233 141706 net.cpp:596] norm1 <- conv1
I1109 01:56:56.781828 141706 net.cpp:570] norm1 -> norm1
I1109 01:56:57.004974 141706 net.cpp:210] Setting up norm1
I1109 01:56:57.020016 141706 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 01:56:57.020396 141706 net.cpp:225] Memory required for data: 131300864
I1109 01:56:57.020704 141706 layer_factory.hpp:114] Creating layer pool1
I1109 01:56:57.114276 141706 net.cpp:160] Creating Layer pool1
I1109 01:56:57.114591 141706 net.cpp:596] pool1 <- norm1
I1109 01:56:57.129575 141706 net.cpp:570] pool1 -> pool1
I1109 01:56:57.442566 141706 net.cpp:210] Setting up pool1
I1109 01:56:57.445091 141706 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 01:56:57.445438 141706 net.cpp:225] Memory required for data: 140258816
I1109 01:56:57.445665 141706 layer_factory.hpp:114] Creating layer conv2
I1109 01:56:57.446035 141706 net.cpp:160] Creating Layer conv2
I1109 01:56:57.446260 141706 net.cpp:596] conv2 <- pool1
I1109 01:56:57.446506 141706 net.cpp:570] conv2 -> conv2
I1109 01:57:03.246069 141706 net.cpp:210] Setting up conv2
I1109 01:57:03.246389 141706 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:57:03.246829 141706 net.cpp:225] Memory required for data: 164146688
I1109 01:57:03.296484 141706 layer_factory.hpp:114] Creating layer relu2
I1109 01:57:03.296934 141706 net.cpp:160] Creating Layer relu2
I1109 01:57:03.297266 141706 net.cpp:596] relu2 <- conv2
I1109 01:57:03.297585 141706 net.cpp:557] relu2 -> conv2 (in-place)
I1109 01:57:03.298044 141706 net.cpp:210] Setting up relu2
I1109 01:57:03.298321 141706 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:57:03.298568 141706 net.cpp:225] Memory required for data: 188034560
I1109 01:57:03.298771 141706 layer_factory.hpp:114] Creating layer norm2
I1109 01:57:03.299024 141706 net.cpp:160] Creating Layer norm2
I1109 01:57:03.299228 141706 net.cpp:596] norm2 <- conv2
I1109 01:57:03.299470 141706 net.cpp:570] norm2 -> norm2
I1109 01:57:03.301612 141706 net.cpp:210] Setting up norm2
I1109 01:57:03.301931 141706 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 01:57:03.302168 141706 net.cpp:225] Memory required for data: 211922432
I1109 01:57:03.302359 141706 layer_factory.hpp:114] Creating layer pool2
I1109 01:57:03.303167 141706 net.cpp:160] Creating Layer pool2
I1109 01:57:03.303454 141706 net.cpp:596] pool2 <- norm2
I1109 01:57:03.303699 141706 net.cpp:570] pool2 -> pool2
I1109 01:57:03.304137 141706 net.cpp:210] Setting up pool2
I1109 01:57:03.304513 141706 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:57:03.304838 141706 net.cpp:225] Memory required for data: 217460224
I1109 01:57:03.305054 141706 layer_factory.hpp:114] Creating layer conv3
I1109 01:57:03.305393 141706 net.cpp:160] Creating Layer conv3
I1109 01:57:03.305618 141706 net.cpp:596] conv3 <- pool2
I1109 01:57:03.305858 141706 net.cpp:570] conv3 -> conv3
I1109 01:57:03.787977 141706 net.cpp:210] Setting up conv3
I1109 01:57:03.790417 141706 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:57:03.790776 141706 net.cpp:225] Memory required for data: 225766912
I1109 01:57:03.793934 141706 layer_factory.hpp:114] Creating layer relu3
I1109 01:57:03.794358 141706 net.cpp:160] Creating Layer relu3
I1109 01:57:03.794617 141706 net.cpp:596] relu3 <- conv3
I1109 01:57:03.794894 141706 net.cpp:557] relu3 -> conv3 (in-place)
I1109 01:57:03.798997 141706 net.cpp:210] Setting up relu3
I1109 01:57:03.799350 141706 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:57:03.799605 141706 net.cpp:225] Memory required for data: 234073600
I1109 01:57:03.799813 141706 layer_factory.hpp:114] Creating layer conv4
I1109 01:57:03.800184 141706 net.cpp:160] Creating Layer conv4
I1109 01:57:03.800446 141706 net.cpp:596] conv4 <- conv3
I1109 01:57:03.800703 141706 net.cpp:570] conv4 -> conv4
I1109 01:57:04.071640 141706 net.cpp:210] Setting up conv4
I1109 01:57:04.072033 141706 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:57:04.072443 141706 net.cpp:225] Memory required for data: 242380288
I1109 01:57:04.072959 141706 layer_factory.hpp:114] Creating layer relu4
I1109 01:57:04.073295 141706 net.cpp:160] Creating Layer relu4
I1109 01:57:04.073532 141706 net.cpp:596] relu4 <- conv4
I1109 01:57:04.073776 141706 net.cpp:557] relu4 -> conv4 (in-place)
I1109 01:57:04.085921 141706 net.cpp:210] Setting up relu4
I1109 01:57:04.086277 141706 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 01:57:04.086544 141706 net.cpp:225] Memory required for data: 250686976
I1109 01:57:04.086761 141706 layer_factory.hpp:114] Creating layer conv5
I1109 01:57:04.087172 141706 net.cpp:160] Creating Layer conv5
I1109 01:57:04.087425 141706 net.cpp:596] conv5 <- conv4
I1109 01:57:04.087678 141706 net.cpp:570] conv5 -> conv5
I1109 01:57:04.256052 141706 net.cpp:210] Setting up conv5
I1109 01:57:04.256453 141706 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:57:04.256981 141706 net.cpp:225] Memory required for data: 256224768
I1109 01:57:04.261687 141706 layer_factory.hpp:114] Creating layer relu5
I1109 01:57:04.262102 141706 net.cpp:160] Creating Layer relu5
I1109 01:57:04.262368 141706 net.cpp:596] relu5 <- conv5
I1109 01:57:04.262642 141706 net.cpp:557] relu5 -> conv5 (in-place)
I1109 01:57:04.263139 141706 net.cpp:210] Setting up relu5
I1109 01:57:04.263447 141706 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 01:57:04.263739 141706 net.cpp:225] Memory required for data: 261762560
I1109 01:57:04.263954 141706 layer_factory.hpp:114] Creating layer pool5
I1109 01:57:04.264217 141706 net.cpp:160] Creating Layer pool5
I1109 01:57:04.264441 141706 net.cpp:596] pool5 <- conv5
I1109 01:57:04.264669 141706 net.cpp:570] pool5 -> pool5
I1109 01:57:04.265125 141706 net.cpp:210] Setting up pool5
I1109 01:57:04.265391 141706 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 01:57:04.265621 141706 net.cpp:225] Memory required for data: 262942208
I1109 01:57:04.265810 141706 layer_factory.hpp:114] Creating layer fc6
I1109 01:57:04.320567 141706 net.cpp:160] Creating Layer fc6
I1109 01:57:04.320921 141706 net.cpp:596] fc6 <- pool5
I1109 01:57:04.321305 141706 net.cpp:570] fc6 -> fc6
I1109 01:57:08.409864 141706 net.cpp:210] Setting up fc6
I1109 01:57:08.410171 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:08.412221 141706 net.cpp:225] Memory required for data: 263466496
I1109 01:57:08.412534 141706 layer_factory.hpp:114] Creating layer relu6
I1109 01:57:08.415066 141706 net.cpp:160] Creating Layer relu6
I1109 01:57:08.415370 141706 net.cpp:596] relu6 <- fc6
I1109 01:57:08.415598 141706 net.cpp:557] relu6 -> fc6 (in-place)
I1109 01:57:08.416014 141706 net.cpp:210] Setting up relu6
I1109 01:57:08.416271 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:08.416498 141706 net.cpp:225] Memory required for data: 263990784
I1109 01:57:08.416685 141706 layer_factory.hpp:114] Creating layer drop6
I1109 01:57:08.436704 141706 net.cpp:160] Creating Layer drop6
I1109 01:57:08.437057 141706 net.cpp:596] drop6 <- fc6
I1109 01:57:08.437434 141706 net.cpp:557] drop6 -> fc6 (in-place)
I1109 01:57:08.541512 141706 net.cpp:210] Setting up drop6
I1109 01:57:08.541813 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:08.542153 141706 net.cpp:225] Memory required for data: 264515072
I1109 01:57:08.542403 141706 layer_factory.hpp:114] Creating layer fc7
I1109 01:57:08.542681 141706 net.cpp:160] Creating Layer fc7
I1109 01:57:08.542891 141706 net.cpp:596] fc7 <- fc6
I1109 01:57:08.543280 141706 net.cpp:570] fc7 -> fc7
I1109 01:57:10.255559 141706 net.cpp:210] Setting up fc7
I1109 01:57:10.255900 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:10.256265 141706 net.cpp:225] Memory required for data: 265039360
I1109 01:57:10.256597 141706 layer_factory.hpp:114] Creating layer relu7
I1109 01:57:10.256932 141706 net.cpp:160] Creating Layer relu7
I1109 01:57:10.257170 141706 net.cpp:596] relu7 <- fc7
I1109 01:57:10.257398 141706 net.cpp:557] relu7 -> fc7 (in-place)
I1109 01:57:10.257815 141706 net.cpp:210] Setting up relu7
I1109 01:57:10.258082 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:10.258306 141706 net.cpp:225] Memory required for data: 265563648
I1109 01:57:10.258497 141706 layer_factory.hpp:114] Creating layer drop7
I1109 01:57:10.258723 141706 net.cpp:160] Creating Layer drop7
I1109 01:57:10.258913 141706 net.cpp:596] drop7 <- fc7
I1109 01:57:10.259183 141706 net.cpp:557] drop7 -> fc7 (in-place)
I1109 01:57:10.259454 141706 net.cpp:210] Setting up drop7
I1109 01:57:10.259716 141706 net.cpp:217] Top shape: 32 4096 (131072)
I1109 01:57:10.259963 141706 net.cpp:225] Memory required for data: 266087936
I1109 01:57:10.260143 141706 layer_factory.hpp:114] Creating layer fc8
I1109 01:57:10.260385 141706 net.cpp:160] Creating Layer fc8
I1109 01:57:10.260573 141706 net.cpp:596] fc8 <- fc7
I1109 01:57:10.260831 141706 net.cpp:570] fc8 -> fc8
I1109 01:57:10.683053 141706 net.cpp:210] Setting up fc8
I1109 01:57:10.683403 141706 net.cpp:217] Top shape: 32 1000 (32000)
I1109 01:57:10.683796 141706 net.cpp:225] Memory required for data: 266215936
I1109 01:57:10.684098 141706 layer_factory.hpp:114] Creating layer loss
I1109 01:57:10.708375 141706 net.cpp:160] Creating Layer loss
I1109 01:57:10.708688 141706 net.cpp:596] loss <- fc8
I1109 01:57:10.709585 141706 net.cpp:596] loss <- label
I1109 01:57:10.736739 141706 net.cpp:570] loss -> loss
I1109 01:57:10.774482 141706 layer_factory.hpp:114] Creating layer loss
I1109 01:57:13.372575 141706 net.cpp:210] Setting up loss
I1109 01:57:13.415215 141706 net.cpp:217] Top shape: (1)
I1109 01:57:13.431269 141706 net.cpp:220]     with loss weight 1
I1109 01:57:13.557755 141706 net.cpp:225] Memory required for data: 266215940
I1109 01:57:13.608266 141706 net.cpp:287] loss needs backward computation.
I1109 01:57:13.706817 141706 net.cpp:287] fc8 needs backward computation.
I1109 01:57:13.717561 141706 net.cpp:287] drop7 needs backward computation.
I1109 01:57:13.730458 141706 net.cpp:287] relu7 needs backward computation.
I1109 01:57:13.730779 141706 net.cpp:287] fc7 needs backward computation.
I1109 01:57:13.733285 141706 net.cpp:287] drop6 needs backward computation.
I1109 01:57:13.733580 141706 net.cpp:287] relu6 needs backward computation.
I1109 01:57:13.733770 141706 net.cpp:287] fc6 needs backward computation.
I1109 01:57:13.734555 141706 net.cpp:287] pool5 needs backward computation.
I1109 01:57:13.735347 141706 net.cpp:287] relu5 needs backward computation.
I1109 01:57:13.735600 141706 net.cpp:287] conv5 needs backward computation.
I1109 01:57:13.735793 141706 net.cpp:287] relu4 needs backward computation.
I1109 01:57:13.735973 141706 net.cpp:287] conv4 needs backward computation.
I1109 01:57:13.736156 141706 net.cpp:287] relu3 needs backward computation.
I1109 01:57:13.736333 141706 net.cpp:287] conv3 needs backward computation.
I1109 01:57:13.748222 141706 net.cpp:287] pool2 needs backward computation.
I1109 01:57:13.748558 141706 net.cpp:287] norm2 needs backward computation.
I1109 01:57:13.748890 141706 net.cpp:287] relu2 needs backward computation.
I1109 01:57:13.749125 141706 net.cpp:287] conv2 needs backward computation.
I1109 01:57:13.749315 141706 net.cpp:287] pool1 needs backward computation.
I1109 01:57:13.749502 141706 net.cpp:287] norm1 needs backward computation.
I1109 01:57:13.749686 141706 net.cpp:287] relu1 needs backward computation.
I1109 01:57:13.749861 141706 net.cpp:287] conv1 needs backward computation.
I1109 01:57:13.762109 141706 net.cpp:289] data does not need backward computation.
I1109 01:57:13.786207 141706 net.cpp:331] This network produces output loss
I1109 01:57:13.858415 141706 net.cpp:345] Network initialization done.
I1109 01:57:14.030848 141706 caffe.cpp:452] Performing Forward
I1109 01:57:27.233069 141706 caffe.cpp:457] Initial loss: 6.80349
I1109 01:57:27.286761 141706 caffe.cpp:459] Performing Backward
I1109 01:57:32.189635 141706 caffe.cpp:468] *** Benchmark begins ***
I1109 01:57:32.200978 141706 caffe.cpp:469] Testing for 1 iterations.
I1109 01:57:32.343915 141706 caffe.cpp:485] Profiling Layer: conv2 backward
I1109 01:57:34.552505 141706 caffe.cpp:512] Iteration: 1 forward-backward time: 2208 ms.
I1109 01:57:34.716927 141706 caffe.cpp:519] Average time per layer: 
I1109 01:57:34.736234 141706 caffe.cpp:522]       data	forward: 547.708 ms.
I1109 01:57:34.806090 141706 caffe.cpp:526]       data	backward: 4.736 ms.
I1109 01:57:34.829998 141706 caffe.cpp:522]      conv1	forward: 132.624 ms.
I1109 01:57:34.834030 141706 caffe.cpp:526]      conv1	backward: 48.495 ms.
I1109 01:57:34.839643 141706 caffe.cpp:522]      relu1	forward: 13.791 ms.
I1109 01:57:34.851003 141706 caffe.cpp:526]      relu1	backward: 17.746 ms.
I1109 01:57:34.858806 141706 caffe.cpp:522]      norm1	forward: 23.374 ms.
I1109 01:57:34.868602 141706 caffe.cpp:526]      norm1	backward: 12.718 ms.
I1109 01:57:34.878468 141706 caffe.cpp:522]      pool1	forward: 18.938 ms.
I1109 01:57:34.887861 141706 caffe.cpp:526]      pool1	backward: 81.185 ms.
I1109 01:57:34.902740 141706 caffe.cpp:522]      conv2	forward: 55.529 ms.
I1109 01:57:34.903717 141706 caffe.cpp:526]      conv2	backward: 102.382 ms.
I1109 01:57:34.903929 141706 caffe.cpp:522]      relu2	forward: 0.533 ms.
I1109 01:57:34.904178 141706 caffe.cpp:526]      relu2	backward: 13.429 ms.
I1109 01:57:34.904393 141706 caffe.cpp:522]      norm2	forward: 3.357 ms.
I1109 01:57:34.904721 141706 caffe.cpp:526]      norm2	backward: 16.36 ms.
I1109 01:57:34.905041 141706 caffe.cpp:522]      pool2	forward: 1.22 ms.
I1109 01:57:34.905246 141706 caffe.cpp:526]      pool2	backward: 66.349 ms.
I1109 01:57:34.905452 141706 caffe.cpp:522]      conv3	forward: 9.754 ms.
I1109 01:57:34.906317 141706 caffe.cpp:526]      conv3	backward: 82.067 ms.
I1109 01:57:34.907006 141706 caffe.cpp:522]      relu3	forward: 0.235 ms.
I1109 01:57:34.907241 141706 caffe.cpp:526]      relu3	backward: 30.89 ms.
I1109 01:57:34.907591 141706 caffe.cpp:522]      conv4	forward: 7.561 ms.
I1109 01:57:34.907795 141706 caffe.cpp:526]      conv4	backward: 68.733 ms.
I1109 01:57:34.907995 141706 caffe.cpp:522]      relu4	forward: 0.243 ms.
I1109 01:57:34.908191 141706 caffe.cpp:526]      relu4	backward: 38.768 ms.
I1109 01:57:34.908385 141706 caffe.cpp:522]      conv5	forward: 5.208 ms.
I1109 01:57:34.908572 141706 caffe.cpp:526]      conv5	backward: 68.244 ms.
I1109 01:57:34.908762 141706 caffe.cpp:522]      relu5	forward: 0.194 ms.
I1109 01:57:34.908987 141706 caffe.cpp:526]      relu5	backward: 17.358 ms.
I1109 01:57:34.909178 141706 caffe.cpp:522]      pool5	forward: 0.286 ms.
I1109 01:57:34.909364 141706 caffe.cpp:526]      pool5	backward: 57.224 ms.
I1109 01:57:34.909554 141706 caffe.cpp:522]        fc6	forward: 16.392 ms.
I1109 01:57:34.909744 141706 caffe.cpp:526]        fc6	backward: 123.349 ms.
I1109 01:57:34.909976 141706 caffe.cpp:522]      relu6	forward: 0.815 ms.
I1109 01:57:34.910197 141706 caffe.cpp:526]      relu6	backward: 19.821 ms.
I1109 01:57:34.910488 141706 caffe.cpp:522]      drop6	forward: 1.462 ms.
I1109 01:57:34.910720 141706 caffe.cpp:526]      drop6	backward: 12.904 ms.
I1109 01:57:34.910914 141706 caffe.cpp:522]        fc7	forward: 4.459 ms.
I1109 01:57:34.911103 141706 caffe.cpp:526]        fc7	backward: 114.096 ms.
I1109 01:57:34.911293 141706 caffe.cpp:522]      relu7	forward: 0.14 ms.
I1109 01:57:34.911481 141706 caffe.cpp:526]      relu7	backward: 15.015 ms.
I1109 01:57:34.911671 141706 caffe.cpp:522]      drop7	forward: 0.308 ms.
I1109 01:57:34.911859 141706 caffe.cpp:526]      drop7	backward: 22.582 ms.
I1109 01:57:34.912047 141706 caffe.cpp:522]        fc8	forward: 1.951 ms.
I1109 01:57:34.912231 141706 caffe.cpp:526]        fc8	backward: 144.091 ms.
I1109 01:57:34.912422 141706 caffe.cpp:522]       loss	forward: 45.361 ms.
I1109 01:57:34.912612 141706 caffe.cpp:526]       loss	backward: 43.336 ms.
I1109 01:57:34.918272 141706 caffe.cpp:532] Average Forward pass: 946.413 ms.
I1109 01:57:34.931183 141706 caffe.cpp:535] Average Backward pass: 1231.95 ms.
I1109 01:57:34.941987 141706 caffe.cpp:537] Average Forward-Backward: 2674 ms.
I1109 01:57:34.956446 141706 caffe.cpp:540] Total Time: 2674 ms.
I1109 01:57:34.968564 141706 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 1636250112
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 26180001792
--->Total double-precision FLOPs = 0
--->Total FLOPs = 26180001792
mem-read-1 = 109237
mem-read-2 = 138
mem-read-4 = 819644224
mem-read-8 = 5123977
mem-read-16 = 0
mem-read-32 = 5220
mem-read-64 = 59251637
mem-write-1 = 202
mem-write-2 = 68
mem-write-4 = 11312
mem-write-8 = 3522847
mem-write-16 = 4
mem-write-32 = 4
mem-write-64 = 21981925
--->Total Bytes read = 7111950033
--->Total Bytes written = 1435071754
--->Total Bytes = 8547021787
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer6_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=6 -prof_forward_direction=0
I1109 02:02:08.639739 141869 caffe.cpp:444] Use CPU.
I1109 02:02:25.415827 141869 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:02:25.471563 141869 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:02:25.483273 141869 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:02:25.495713 141869 cpu_info.cpp:461] Total number of processors: 272
I1109 02:02:25.506919 141869 cpu_info.cpp:464] GPU is used: no
I1109 02:02:25.515802 141869 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:02:25.524616 141869 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:02:25.535516 141869 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:02:34.206055 141869 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:02:34.238358 141869 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:02:34.864235 141869 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:02:37.286381 141869 layer_factory.hpp:114] Creating layer data
I1109 02:02:37.434130 141869 net.cpp:160] Creating Layer data
I1109 02:02:37.482225 141869 net.cpp:570] data -> data
I1109 02:02:37.943375 141869 net.cpp:570] data -> label
I1109 02:02:44.921339 141869 net.cpp:210] Setting up data
I1109 02:02:45.000092 141869 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:02:45.107787 141869 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:02:45.114950 141869 net.cpp:225] Memory required for data: 19787264
I1109 02:02:45.181744 141869 layer_factory.hpp:114] Creating layer conv1
I1109 02:02:45.505127 141869 net.cpp:160] Creating Layer conv1
I1109 02:02:45.557775 141869 net.cpp:596] conv1 <- data
I1109 02:02:45.677376 141869 net.cpp:570] conv1 -> conv1
I1109 02:03:18.295533 141869 net.cpp:210] Setting up conv1
I1109 02:03:18.302745 141869 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:03:18.303119 141869 net.cpp:225] Memory required for data: 56958464
I1109 02:03:18.577460 141869 layer_factory.hpp:114] Creating layer relu1
I1109 02:03:18.696424 141869 net.cpp:160] Creating Layer relu1
I1109 02:03:18.701030 141869 net.cpp:596] relu1 <- conv1
I1109 02:03:18.733045 141869 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:03:18.922271 141869 net.cpp:210] Setting up relu1
I1109 02:03:18.924640 141869 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:03:18.925035 141869 net.cpp:225] Memory required for data: 94129664
I1109 02:03:18.925271 141869 layer_factory.hpp:114] Creating layer norm1
I1109 02:03:19.028566 141869 net.cpp:160] Creating Layer norm1
I1109 02:03:19.028919 141869 net.cpp:596] norm1 <- conv1
I1109 02:03:19.031414 141869 net.cpp:570] norm1 -> norm1
I1109 02:03:19.253964 141869 net.cpp:210] Setting up norm1
I1109 02:03:19.266623 141869 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:03:19.267007 141869 net.cpp:225] Memory required for data: 131300864
I1109 02:03:19.267339 141869 layer_factory.hpp:114] Creating layer pool1
I1109 02:03:19.359376 141869 net.cpp:160] Creating Layer pool1
I1109 02:03:19.359691 141869 net.cpp:596] pool1 <- norm1
I1109 02:03:19.374320 141869 net.cpp:570] pool1 -> pool1
I1109 02:03:19.676687 141869 net.cpp:210] Setting up pool1
I1109 02:03:19.679340 141869 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:03:19.679690 141869 net.cpp:225] Memory required for data: 140258816
I1109 02:03:19.679927 141869 layer_factory.hpp:114] Creating layer conv2
I1109 02:03:19.680356 141869 net.cpp:160] Creating Layer conv2
I1109 02:03:19.680625 141869 net.cpp:596] conv2 <- pool1
I1109 02:03:19.681038 141869 net.cpp:570] conv2 -> conv2
I1109 02:03:25.393579 141869 net.cpp:210] Setting up conv2
I1109 02:03:25.393898 141869 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:03:25.394304 141869 net.cpp:225] Memory required for data: 164146688
I1109 02:03:25.443984 141869 layer_factory.hpp:114] Creating layer relu2
I1109 02:03:25.444434 141869 net.cpp:160] Creating Layer relu2
I1109 02:03:25.444829 141869 net.cpp:596] relu2 <- conv2
I1109 02:03:25.445113 141869 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:03:25.445557 141869 net.cpp:210] Setting up relu2
I1109 02:03:25.445817 141869 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:03:25.446055 141869 net.cpp:225] Memory required for data: 188034560
I1109 02:03:25.446244 141869 layer_factory.hpp:114] Creating layer norm2
I1109 02:03:25.446492 141869 net.cpp:160] Creating Layer norm2
I1109 02:03:25.446693 141869 net.cpp:596] norm2 <- conv2
I1109 02:03:25.446919 141869 net.cpp:570] norm2 -> norm2
I1109 02:03:25.449043 141869 net.cpp:210] Setting up norm2
I1109 02:03:25.449362 141869 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:03:25.449596 141869 net.cpp:225] Memory required for data: 211922432
I1109 02:03:25.449785 141869 layer_factory.hpp:114] Creating layer pool2
I1109 02:03:25.450589 141869 net.cpp:160] Creating Layer pool2
I1109 02:03:25.450872 141869 net.cpp:596] pool2 <- norm2
I1109 02:03:25.451154 141869 net.cpp:570] pool2 -> pool2
I1109 02:03:25.451652 141869 net.cpp:210] Setting up pool2
I1109 02:03:25.451992 141869 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:03:25.452224 141869 net.cpp:225] Memory required for data: 217460224
I1109 02:03:25.452426 141869 layer_factory.hpp:114] Creating layer conv3
I1109 02:03:25.452769 141869 net.cpp:160] Creating Layer conv3
I1109 02:03:25.453057 141869 net.cpp:596] conv3 <- pool2
I1109 02:03:25.453308 141869 net.cpp:570] conv3 -> conv3
I1109 02:03:25.951359 141869 net.cpp:210] Setting up conv3
I1109 02:03:25.953799 141869 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:03:25.954164 141869 net.cpp:225] Memory required for data: 225766912
I1109 02:03:25.957245 141869 layer_factory.hpp:114] Creating layer relu3
I1109 02:03:25.957651 141869 net.cpp:160] Creating Layer relu3
I1109 02:03:25.957912 141869 net.cpp:596] relu3 <- conv3
I1109 02:03:25.958206 141869 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:03:25.962851 141869 net.cpp:210] Setting up relu3
I1109 02:03:25.963297 141869 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:03:25.963614 141869 net.cpp:225] Memory required for data: 234073600
I1109 02:03:25.963835 141869 layer_factory.hpp:114] Creating layer conv4
I1109 02:03:25.964220 141869 net.cpp:160] Creating Layer conv4
I1109 02:03:25.964484 141869 net.cpp:596] conv4 <- conv3
I1109 02:03:25.964745 141869 net.cpp:570] conv4 -> conv4
I1109 02:03:26.207787 141869 net.cpp:210] Setting up conv4
I1109 02:03:26.208196 141869 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:03:26.208613 141869 net.cpp:225] Memory required for data: 242380288
I1109 02:03:26.208981 141869 layer_factory.hpp:114] Creating layer relu4
I1109 02:03:26.209309 141869 net.cpp:160] Creating Layer relu4
I1109 02:03:26.209548 141869 net.cpp:596] relu4 <- conv4
I1109 02:03:26.209791 141869 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:03:26.221940 141869 net.cpp:210] Setting up relu4
I1109 02:03:26.222287 141869 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:03:26.222688 141869 net.cpp:225] Memory required for data: 250686976
I1109 02:03:26.222910 141869 layer_factory.hpp:114] Creating layer conv5
I1109 02:03:26.223285 141869 net.cpp:160] Creating Layer conv5
I1109 02:03:26.223536 141869 net.cpp:596] conv5 <- conv4
I1109 02:03:26.223788 141869 net.cpp:570] conv5 -> conv5
I1109 02:03:26.402910 141869 net.cpp:210] Setting up conv5
I1109 02:03:26.403280 141869 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:03:26.403646 141869 net.cpp:225] Memory required for data: 256224768
I1109 02:03:26.408229 141869 layer_factory.hpp:114] Creating layer relu5
I1109 02:03:26.408609 141869 net.cpp:160] Creating Layer relu5
I1109 02:03:26.408884 141869 net.cpp:596] relu5 <- conv5
I1109 02:03:26.409175 141869 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:03:26.409631 141869 net.cpp:210] Setting up relu5
I1109 02:03:26.409932 141869 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:03:26.410162 141869 net.cpp:225] Memory required for data: 261762560
I1109 02:03:26.410358 141869 layer_factory.hpp:114] Creating layer pool5
I1109 02:03:26.410606 141869 net.cpp:160] Creating Layer pool5
I1109 02:03:26.410809 141869 net.cpp:596] pool5 <- conv5
I1109 02:03:26.411023 141869 net.cpp:570] pool5 -> pool5
I1109 02:03:26.411407 141869 net.cpp:210] Setting up pool5
I1109 02:03:26.411645 141869 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:03:26.411859 141869 net.cpp:225] Memory required for data: 262942208
I1109 02:03:26.412036 141869 layer_factory.hpp:114] Creating layer fc6
I1109 02:03:26.465339 141869 net.cpp:160] Creating Layer fc6
I1109 02:03:26.465643 141869 net.cpp:596] fc6 <- pool5
I1109 02:03:26.466009 141869 net.cpp:570] fc6 -> fc6
I1109 02:03:30.555698 141869 net.cpp:210] Setting up fc6
I1109 02:03:30.556006 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:30.558078 141869 net.cpp:225] Memory required for data: 263466496
I1109 02:03:30.558385 141869 layer_factory.hpp:114] Creating layer relu6
I1109 02:03:30.560917 141869 net.cpp:160] Creating Layer relu6
I1109 02:03:30.561223 141869 net.cpp:596] relu6 <- fc6
I1109 02:03:30.561458 141869 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:03:30.561882 141869 net.cpp:210] Setting up relu6
I1109 02:03:30.562135 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:30.562361 141869 net.cpp:225] Memory required for data: 263990784
I1109 02:03:30.562549 141869 layer_factory.hpp:114] Creating layer drop6
I1109 02:03:30.582216 141869 net.cpp:160] Creating Layer drop6
I1109 02:03:30.582520 141869 net.cpp:596] drop6 <- fc6
I1109 02:03:30.582890 141869 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:03:30.686636 141869 net.cpp:210] Setting up drop6
I1109 02:03:30.686931 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:30.687275 141869 net.cpp:225] Memory required for data: 264515072
I1109 02:03:30.687527 141869 layer_factory.hpp:114] Creating layer fc7
I1109 02:03:30.687805 141869 net.cpp:160] Creating Layer fc7
I1109 02:03:30.688020 141869 net.cpp:596] fc7 <- fc6
I1109 02:03:30.688415 141869 net.cpp:570] fc7 -> fc7
I1109 02:03:32.400914 141869 net.cpp:210] Setting up fc7
I1109 02:03:32.401293 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:32.401787 141869 net.cpp:225] Memory required for data: 265039360
I1109 02:03:32.402158 141869 layer_factory.hpp:114] Creating layer relu7
I1109 02:03:32.402499 141869 net.cpp:160] Creating Layer relu7
I1109 02:03:32.402760 141869 net.cpp:596] relu7 <- fc7
I1109 02:03:32.403029 141869 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:03:32.403492 141869 net.cpp:210] Setting up relu7
I1109 02:03:32.403791 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:32.404042 141869 net.cpp:225] Memory required for data: 265563648
I1109 02:03:32.404286 141869 layer_factory.hpp:114] Creating layer drop7
I1109 02:03:32.404551 141869 net.cpp:160] Creating Layer drop7
I1109 02:03:32.404825 141869 net.cpp:596] drop7 <- fc7
I1109 02:03:32.405103 141869 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:03:32.405428 141869 net.cpp:210] Setting up drop7
I1109 02:03:32.405659 141869 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:03:32.405910 141869 net.cpp:225] Memory required for data: 266087936
I1109 02:03:32.406095 141869 layer_factory.hpp:114] Creating layer fc8
I1109 02:03:32.406350 141869 net.cpp:160] Creating Layer fc8
I1109 02:03:32.406559 141869 net.cpp:596] fc8 <- fc7
I1109 02:03:32.406787 141869 net.cpp:570] fc8 -> fc8
I1109 02:03:32.829028 141869 net.cpp:210] Setting up fc8
I1109 02:03:32.829388 141869 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:03:32.829797 141869 net.cpp:225] Memory required for data: 266215936
I1109 02:03:32.830104 141869 layer_factory.hpp:114] Creating layer loss
I1109 02:03:32.854686 141869 net.cpp:160] Creating Layer loss
I1109 02:03:32.855007 141869 net.cpp:596] loss <- fc8
I1109 02:03:32.856016 141869 net.cpp:596] loss <- label
I1109 02:03:32.883417 141869 net.cpp:570] loss -> loss
I1109 02:03:32.921540 141869 layer_factory.hpp:114] Creating layer loss
I1109 02:03:35.430244 141869 net.cpp:210] Setting up loss
I1109 02:03:35.482431 141869 net.cpp:217] Top shape: (1)
I1109 02:03:35.496161 141869 net.cpp:220]     with loss weight 1
I1109 02:03:35.625658 141869 net.cpp:225] Memory required for data: 266215940
I1109 02:03:35.672670 141869 net.cpp:287] loss needs backward computation.
I1109 02:03:35.768285 141869 net.cpp:287] fc8 needs backward computation.
I1109 02:03:35.775846 141869 net.cpp:287] drop7 needs backward computation.
I1109 02:03:35.786648 141869 net.cpp:287] relu7 needs backward computation.
I1109 02:03:35.786957 141869 net.cpp:287] fc7 needs backward computation.
I1109 02:03:35.789333 141869 net.cpp:287] drop6 needs backward computation.
I1109 02:03:35.789664 141869 net.cpp:287] relu6 needs backward computation.
I1109 02:03:35.789873 141869 net.cpp:287] fc6 needs backward computation.
I1109 02:03:35.790819 141869 net.cpp:287] pool5 needs backward computation.
I1109 02:03:35.791584 141869 net.cpp:287] relu5 needs backward computation.
I1109 02:03:35.791841 141869 net.cpp:287] conv5 needs backward computation.
I1109 02:03:35.792034 141869 net.cpp:287] relu4 needs backward computation.
I1109 02:03:35.792214 141869 net.cpp:287] conv4 needs backward computation.
I1109 02:03:35.792397 141869 net.cpp:287] relu3 needs backward computation.
I1109 02:03:35.792604 141869 net.cpp:287] conv3 needs backward computation.
I1109 02:03:35.804334 141869 net.cpp:287] pool2 needs backward computation.
I1109 02:03:35.804667 141869 net.cpp:287] norm2 needs backward computation.
I1109 02:03:35.805003 141869 net.cpp:287] relu2 needs backward computation.
I1109 02:03:35.805217 141869 net.cpp:287] conv2 needs backward computation.
I1109 02:03:35.805419 141869 net.cpp:287] pool1 needs backward computation.
I1109 02:03:35.805614 141869 net.cpp:287] norm1 needs backward computation.
I1109 02:03:35.805810 141869 net.cpp:287] relu1 needs backward computation.
I1109 02:03:35.806001 141869 net.cpp:287] conv1 needs backward computation.
I1109 02:03:35.818317 141869 net.cpp:289] data does not need backward computation.
I1109 02:03:35.842102 141869 net.cpp:331] This network produces output loss
I1109 02:03:35.917024 141869 net.cpp:345] Network initialization done.
I1109 02:03:36.079391 141869 caffe.cpp:452] Performing Forward
I1109 02:03:48.790941 141869 caffe.cpp:457] Initial loss: 6.97419
I1109 02:03:48.838402 141869 caffe.cpp:459] Performing Backward
I1109 02:03:53.732096 141869 caffe.cpp:468] *** Benchmark begins ***
I1109 02:03:53.739933 141869 caffe.cpp:469] Testing for 1 iterations.
I1109 02:03:53.891176 141869 caffe.cpp:485] Profiling Layer: relu2 backward
I1109 02:03:56.114576 141869 caffe.cpp:512] Iteration: 1 forward-backward time: 2218 ms.
I1109 02:03:56.267294 141869 caffe.cpp:519] Average time per layer: 
I1109 02:03:56.282770 141869 caffe.cpp:522]       data	forward: 545.921 ms.
I1109 02:03:56.356236 141869 caffe.cpp:526]       data	backward: 3.625 ms.
I1109 02:03:56.375773 141869 caffe.cpp:522]      conv1	forward: 124.854 ms.
I1109 02:03:56.376113 141869 caffe.cpp:526]      conv1	backward: 21.373 ms.
I1109 02:03:56.378398 141869 caffe.cpp:522]      relu1	forward: 18.278 ms.
I1109 02:03:56.378675 141869 caffe.cpp:526]      relu1	backward: 1.051 ms.
I1109 02:03:56.378897 141869 caffe.cpp:522]      norm1	forward: 18.818 ms.
I1109 02:03:56.379115 141869 caffe.cpp:526]      norm1	backward: 3.099 ms.
I1109 02:03:56.379326 141869 caffe.cpp:522]      pool1	forward: 20.94 ms.
I1109 02:03:56.379539 141869 caffe.cpp:526]      pool1	backward: 35.921 ms.
I1109 02:03:56.379751 141869 caffe.cpp:522]      conv2	forward: 63.685 ms.
I1109 02:03:56.379995 141869 caffe.cpp:526]      conv2	backward: 31.52 ms.
I1109 02:03:56.380271 141869 caffe.cpp:522]      relu2	forward: 14.09 ms.
I1109 02:03:56.381130 141869 caffe.cpp:526]      relu2	backward: 11.029 ms.
I1109 02:03:56.381372 141869 caffe.cpp:522]      norm2	forward: 12.208 ms.
I1109 02:03:56.381577 141869 caffe.cpp:526]      norm2	backward: 2.163 ms.
I1109 02:03:56.381770 141869 caffe.cpp:522]      pool2	forward: 19.668 ms.
I1109 02:03:56.381965 141869 caffe.cpp:526]      pool2	backward: 22.368 ms.
I1109 02:03:56.382159 141869 caffe.cpp:522]      conv3	forward: 27.008 ms.
I1109 02:03:56.382354 141869 caffe.cpp:526]      conv3	backward: 36.224 ms.
I1109 02:03:56.382545 141869 caffe.cpp:522]      relu3	forward: 19.309 ms.
I1109 02:03:56.382735 141869 caffe.cpp:526]      relu3	backward: 12.309 ms.
I1109 02:03:56.382966 141869 caffe.cpp:522]      conv4	forward: 30.15 ms.
I1109 02:03:56.383186 141869 caffe.cpp:526]      conv4	backward: 69.927 ms.
I1109 02:03:56.384115 141869 caffe.cpp:522]      relu4	forward: 16.495 ms.
I1109 02:03:56.384346 141869 caffe.cpp:526]      relu4	backward: 44.55 ms.
I1109 02:03:56.384544 141869 caffe.cpp:522]      conv5	forward: 35.981 ms.
I1109 02:03:56.384739 141869 caffe.cpp:526]      conv5	backward: 63.374 ms.
I1109 02:03:56.384984 141869 caffe.cpp:522]      relu5	forward: 19.478 ms.
I1109 02:03:56.385185 141869 caffe.cpp:526]      relu5	backward: 12.827 ms.
I1109 02:03:56.385378 141869 caffe.cpp:522]      pool5	forward: 21.621 ms.
I1109 02:03:56.385570 141869 caffe.cpp:526]      pool5	backward: 48.381 ms.
I1109 02:03:56.385793 141869 caffe.cpp:522]        fc6	forward: 40.703 ms.
I1109 02:03:56.385998 141869 caffe.cpp:526]        fc6	backward: 107.034 ms.
I1109 02:03:56.386301 141869 caffe.cpp:522]      relu6	forward: 19.206 ms.
I1109 02:03:56.386553 141869 caffe.cpp:526]      relu6	backward: 14.121 ms.
I1109 02:03:56.386785 141869 caffe.cpp:522]      drop6	forward: 33.959 ms.
I1109 02:03:56.386978 141869 caffe.cpp:526]      drop6	backward: 17.488 ms.
I1109 02:03:56.387171 141869 caffe.cpp:522]        fc7	forward: 16.207 ms.
I1109 02:03:56.387362 141869 caffe.cpp:526]        fc7	backward: 89.408 ms.
I1109 02:03:56.387552 141869 caffe.cpp:522]      relu7	forward: 17.231 ms.
I1109 02:03:56.387742 141869 caffe.cpp:526]      relu7	backward: 16.96 ms.
I1109 02:03:56.387933 141869 caffe.cpp:522]      drop7	forward: 23.574 ms.
I1109 02:03:56.388121 141869 caffe.cpp:526]      drop7	backward: 16.016 ms.
I1109 02:03:56.388312 141869 caffe.cpp:522]        fc8	forward: 19.165 ms.
I1109 02:03:56.388501 141869 caffe.cpp:526]        fc8	backward: 140.835 ms.
I1109 02:03:56.388692 141869 caffe.cpp:522]       loss	forward: 67.384 ms.
I1109 02:03:56.388958 141869 caffe.cpp:526]       loss	backward: 63.273 ms.
I1109 02:03:56.394505 141869 caffe.cpp:532] Average Forward pass: 1300.46 ms.
I1109 02:03:56.408664 141869 caffe.cpp:535] Average Backward pass: 893.718 ms.
I1109 02:03:56.419448 141869 caffe.cpp:537] Average Forward-Backward: 2614 ms.
I1109 02:03:56.433861 141869 caffe.cpp:540] Total Time: 2614 ms.
I1109 02:03:56.445860 141869 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 373248
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 746496
--->Total FLOPs = 746496
mem-read-1 = 361374
mem-read-2 = 34
mem-read-4 = 2894515
mem-read-8 = 3983225
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 746497
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 572
mem-write-8 = 364847
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 373249
--->Total Bytes read = 91581142
--->Total Bytes written = 26809116
--->Total Bytes = 118390258
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer7_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=7 -prof_forward_direction=0
I1109 02:07:47.875537 141990 caffe.cpp:444] Use CPU.
I1109 02:08:04.819535 141990 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:08:04.876009 141990 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:08:04.887519 141990 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:08:04.898753 141990 cpu_info.cpp:461] Total number of processors: 272
I1109 02:08:04.910192 141990 cpu_info.cpp:464] GPU is used: no
I1109 02:08:04.918846 141990 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:08:04.927413 141990 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:08:04.938475 141990 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:08:13.741753 141990 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:08:13.774891 141990 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:08:14.411010 141990 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:08:16.886390 141990 layer_factory.hpp:114] Creating layer data
I1109 02:08:17.033943 141990 net.cpp:160] Creating Layer data
I1109 02:08:17.082245 141990 net.cpp:570] data -> data
I1109 02:08:17.550375 141990 net.cpp:570] data -> label
I1109 02:08:24.648706 141990 net.cpp:210] Setting up data
I1109 02:08:24.728646 141990 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:08:24.832610 141990 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:08:24.839952 141990 net.cpp:225] Memory required for data: 19787264
I1109 02:08:24.907562 141990 layer_factory.hpp:114] Creating layer conv1
I1109 02:08:25.234233 141990 net.cpp:160] Creating Layer conv1
I1109 02:08:25.284124 141990 net.cpp:596] conv1 <- data
I1109 02:08:25.405484 141990 net.cpp:570] conv1 -> conv1
I1109 02:08:58.093659 141990 net.cpp:210] Setting up conv1
I1109 02:08:58.100010 141990 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:08:58.100389 141990 net.cpp:225] Memory required for data: 56958464
I1109 02:08:58.382355 141990 layer_factory.hpp:114] Creating layer relu1
I1109 02:08:58.501807 141990 net.cpp:160] Creating Layer relu1
I1109 02:08:58.506317 141990 net.cpp:596] relu1 <- conv1
I1109 02:08:58.538425 141990 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:08:58.728829 141990 net.cpp:210] Setting up relu1
I1109 02:08:58.731276 141990 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:08:58.731608 141990 net.cpp:225] Memory required for data: 94129664
I1109 02:08:58.731803 141990 layer_factory.hpp:114] Creating layer norm1
I1109 02:08:58.836020 141990 net.cpp:160] Creating Layer norm1
I1109 02:08:58.836328 141990 net.cpp:596] norm1 <- conv1
I1109 02:08:58.838898 141990 net.cpp:570] norm1 -> norm1
I1109 02:08:59.060969 141990 net.cpp:210] Setting up norm1
I1109 02:08:59.073904 141990 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:08:59.074292 141990 net.cpp:225] Memory required for data: 131300864
I1109 02:08:59.074606 141990 layer_factory.hpp:114] Creating layer pool1
I1109 02:08:59.168769 141990 net.cpp:160] Creating Layer pool1
I1109 02:08:59.169127 141990 net.cpp:596] pool1 <- norm1
I1109 02:08:59.183845 141990 net.cpp:570] pool1 -> pool1
I1109 02:08:59.486423 141990 net.cpp:210] Setting up pool1
I1109 02:08:59.489028 141990 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:08:59.489367 141990 net.cpp:225] Memory required for data: 140258816
I1109 02:08:59.489590 141990 layer_factory.hpp:114] Creating layer conv2
I1109 02:08:59.490000 141990 net.cpp:160] Creating Layer conv2
I1109 02:08:59.490244 141990 net.cpp:596] conv2 <- pool1
I1109 02:08:59.490512 141990 net.cpp:570] conv2 -> conv2
I1109 02:09:05.232383 141990 net.cpp:210] Setting up conv2
I1109 02:09:05.232717 141990 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:09:05.233211 141990 net.cpp:225] Memory required for data: 164146688
I1109 02:09:05.284356 141990 layer_factory.hpp:114] Creating layer relu2
I1109 02:09:05.284768 141990 net.cpp:160] Creating Layer relu2
I1109 02:09:05.285140 141990 net.cpp:596] relu2 <- conv2
I1109 02:09:05.285406 141990 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:09:05.285890 141990 net.cpp:210] Setting up relu2
I1109 02:09:05.286162 141990 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:09:05.286403 141990 net.cpp:225] Memory required for data: 188034560
I1109 02:09:05.286597 141990 layer_factory.hpp:114] Creating layer norm2
I1109 02:09:05.286864 141990 net.cpp:160] Creating Layer norm2
I1109 02:09:05.287050 141990 net.cpp:596] norm2 <- conv2
I1109 02:09:05.287271 141990 net.cpp:570] norm2 -> norm2
I1109 02:09:05.289551 141990 net.cpp:210] Setting up norm2
I1109 02:09:05.289858 141990 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:09:05.290088 141990 net.cpp:225] Memory required for data: 211922432
I1109 02:09:05.290274 141990 layer_factory.hpp:114] Creating layer pool2
I1109 02:09:05.290555 141990 net.cpp:160] Creating Layer pool2
I1109 02:09:05.290769 141990 net.cpp:596] pool2 <- norm2
I1109 02:09:05.291038 141990 net.cpp:570] pool2 -> pool2
I1109 02:09:05.291573 141990 net.cpp:210] Setting up pool2
I1109 02:09:05.291877 141990 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:09:05.292098 141990 net.cpp:225] Memory required for data: 217460224
I1109 02:09:05.292297 141990 layer_factory.hpp:114] Creating layer conv3
I1109 02:09:05.293225 141990 net.cpp:160] Creating Layer conv3
I1109 02:09:05.293516 141990 net.cpp:596] conv3 <- pool2
I1109 02:09:05.293766 141990 net.cpp:570] conv3 -> conv3
I1109 02:09:05.745928 141990 net.cpp:210] Setting up conv3
I1109 02:09:05.748551 141990 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:09:05.748985 141990 net.cpp:225] Memory required for data: 225766912
I1109 02:09:05.752164 141990 layer_factory.hpp:114] Creating layer relu3
I1109 02:09:05.752606 141990 net.cpp:160] Creating Layer relu3
I1109 02:09:05.752938 141990 net.cpp:596] relu3 <- conv3
I1109 02:09:05.753214 141990 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:09:05.757475 141990 net.cpp:210] Setting up relu3
I1109 02:09:05.757793 141990 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:09:05.758050 141990 net.cpp:225] Memory required for data: 234073600
I1109 02:09:05.758249 141990 layer_factory.hpp:114] Creating layer conv4
I1109 02:09:05.758620 141990 net.cpp:160] Creating Layer conv4
I1109 02:09:05.758911 141990 net.cpp:596] conv4 <- conv3
I1109 02:09:05.759174 141990 net.cpp:570] conv4 -> conv4
I1109 02:09:06.001862 141990 net.cpp:210] Setting up conv4
I1109 02:09:06.006391 141990 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:09:06.006827 141990 net.cpp:225] Memory required for data: 242380288
I1109 02:09:06.007134 141990 layer_factory.hpp:114] Creating layer relu4
I1109 02:09:06.007418 141990 net.cpp:160] Creating Layer relu4
I1109 02:09:06.007640 141990 net.cpp:596] relu4 <- conv4
I1109 02:09:06.007866 141990 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:09:06.020151 141990 net.cpp:210] Setting up relu4
I1109 02:09:06.020494 141990 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:09:06.020931 141990 net.cpp:225] Memory required for data: 250686976
I1109 02:09:06.021152 141990 layer_factory.hpp:114] Creating layer conv5
I1109 02:09:06.021517 141990 net.cpp:160] Creating Layer conv5
I1109 02:09:06.021756 141990 net.cpp:596] conv5 <- conv4
I1109 02:09:06.022001 141990 net.cpp:570] conv5 -> conv5
I1109 02:09:06.216336 141990 net.cpp:210] Setting up conv5
I1109 02:09:06.216717 141990 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:09:06.217185 141990 net.cpp:225] Memory required for data: 256224768
I1109 02:09:06.221911 141990 layer_factory.hpp:114] Creating layer relu5
I1109 02:09:06.222349 141990 net.cpp:160] Creating Layer relu5
I1109 02:09:06.222611 141990 net.cpp:596] relu5 <- conv5
I1109 02:09:06.222890 141990 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:09:06.223441 141990 net.cpp:210] Setting up relu5
I1109 02:09:06.223731 141990 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:09:06.223975 141990 net.cpp:225] Memory required for data: 261762560
I1109 02:09:06.224180 141990 layer_factory.hpp:114] Creating layer pool5
I1109 02:09:06.224436 141990 net.cpp:160] Creating Layer pool5
I1109 02:09:06.224647 141990 net.cpp:596] pool5 <- conv5
I1109 02:09:06.224921 141990 net.cpp:570] pool5 -> pool5
I1109 02:09:06.225389 141990 net.cpp:210] Setting up pool5
I1109 02:09:06.225654 141990 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:09:06.225911 141990 net.cpp:225] Memory required for data: 262942208
I1109 02:09:06.226099 141990 layer_factory.hpp:114] Creating layer fc6
I1109 02:09:06.280732 141990 net.cpp:160] Creating Layer fc6
I1109 02:09:06.281081 141990 net.cpp:596] fc6 <- pool5
I1109 02:09:06.281450 141990 net.cpp:570] fc6 -> fc6
I1109 02:09:10.366942 141990 net.cpp:210] Setting up fc6
I1109 02:09:10.367243 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:10.369329 141990 net.cpp:225] Memory required for data: 263466496
I1109 02:09:10.369637 141990 layer_factory.hpp:114] Creating layer relu6
I1109 02:09:10.372114 141990 net.cpp:160] Creating Layer relu6
I1109 02:09:10.372414 141990 net.cpp:596] relu6 <- fc6
I1109 02:09:10.372632 141990 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:09:10.373083 141990 net.cpp:210] Setting up relu6
I1109 02:09:10.373347 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:10.373569 141990 net.cpp:225] Memory required for data: 263990784
I1109 02:09:10.373754 141990 layer_factory.hpp:114] Creating layer drop6
I1109 02:09:10.393718 141990 net.cpp:160] Creating Layer drop6
I1109 02:09:10.394016 141990 net.cpp:596] drop6 <- fc6
I1109 02:09:10.394384 141990 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:09:10.498523 141990 net.cpp:210] Setting up drop6
I1109 02:09:10.498816 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:10.499156 141990 net.cpp:225] Memory required for data: 264515072
I1109 02:09:10.499403 141990 layer_factory.hpp:114] Creating layer fc7
I1109 02:09:10.499671 141990 net.cpp:160] Creating Layer fc7
I1109 02:09:10.499871 141990 net.cpp:596] fc7 <- fc6
I1109 02:09:10.500247 141990 net.cpp:570] fc7 -> fc7
I1109 02:09:12.210561 141990 net.cpp:210] Setting up fc7
I1109 02:09:12.210927 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:12.211374 141990 net.cpp:225] Memory required for data: 265039360
I1109 02:09:12.211704 141990 layer_factory.hpp:114] Creating layer relu7
I1109 02:09:12.212030 141990 net.cpp:160] Creating Layer relu7
I1109 02:09:12.212280 141990 net.cpp:596] relu7 <- fc7
I1109 02:09:12.212523 141990 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:09:12.213004 141990 net.cpp:210] Setting up relu7
I1109 02:09:12.213307 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:12.213554 141990 net.cpp:225] Memory required for data: 265563648
I1109 02:09:12.213755 141990 layer_factory.hpp:114] Creating layer drop7
I1109 02:09:12.213994 141990 net.cpp:160] Creating Layer drop7
I1109 02:09:12.214236 141990 net.cpp:596] drop7 <- fc7
I1109 02:09:12.214476 141990 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:09:12.214762 141990 net.cpp:210] Setting up drop7
I1109 02:09:12.215057 141990 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:09:12.215272 141990 net.cpp:225] Memory required for data: 266087936
I1109 02:09:12.215453 141990 layer_factory.hpp:114] Creating layer fc8
I1109 02:09:12.215721 141990 net.cpp:160] Creating Layer fc8
I1109 02:09:12.215929 141990 net.cpp:596] fc8 <- fc7
I1109 02:09:12.216161 141990 net.cpp:570] fc8 -> fc8
I1109 02:09:12.637686 141990 net.cpp:210] Setting up fc8
I1109 02:09:12.638041 141990 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:09:12.638427 141990 net.cpp:225] Memory required for data: 266215936
I1109 02:09:12.638757 141990 layer_factory.hpp:114] Creating layer loss
I1109 02:09:12.663478 141990 net.cpp:160] Creating Layer loss
I1109 02:09:12.663794 141990 net.cpp:596] loss <- fc8
I1109 02:09:12.664860 141990 net.cpp:596] loss <- label
I1109 02:09:12.692467 141990 net.cpp:570] loss -> loss
I1109 02:09:12.730665 141990 layer_factory.hpp:114] Creating layer loss
I1109 02:09:15.234788 141990 net.cpp:210] Setting up loss
I1109 02:09:15.285612 141990 net.cpp:217] Top shape: (1)
I1109 02:09:15.300935 141990 net.cpp:220]     with loss weight 1
I1109 02:09:15.443903 141990 net.cpp:225] Memory required for data: 266215940
I1109 02:09:15.491123 141990 net.cpp:287] loss needs backward computation.
I1109 02:09:15.588116 141990 net.cpp:287] fc8 needs backward computation.
I1109 02:09:15.600304 141990 net.cpp:287] drop7 needs backward computation.
I1109 02:09:15.611484 141990 net.cpp:287] relu7 needs backward computation.
I1109 02:09:15.611799 141990 net.cpp:287] fc7 needs backward computation.
I1109 02:09:15.614226 141990 net.cpp:287] drop6 needs backward computation.
I1109 02:09:15.614532 141990 net.cpp:287] relu6 needs backward computation.
I1109 02:09:15.614743 141990 net.cpp:287] fc6 needs backward computation.
I1109 02:09:15.615491 141990 net.cpp:287] pool5 needs backward computation.
I1109 02:09:15.616268 141990 net.cpp:287] relu5 needs backward computation.
I1109 02:09:15.616528 141990 net.cpp:287] conv5 needs backward computation.
I1109 02:09:15.616726 141990 net.cpp:287] relu4 needs backward computation.
I1109 02:09:15.616953 141990 net.cpp:287] conv4 needs backward computation.
I1109 02:09:15.617143 141990 net.cpp:287] relu3 needs backward computation.
I1109 02:09:15.617329 141990 net.cpp:287] conv3 needs backward computation.
I1109 02:09:15.631350 141990 net.cpp:287] pool2 needs backward computation.
I1109 02:09:15.631726 141990 net.cpp:287] norm2 needs backward computation.
I1109 02:09:15.632047 141990 net.cpp:287] relu2 needs backward computation.
I1109 02:09:15.632290 141990 net.cpp:287] conv2 needs backward computation.
I1109 02:09:15.632519 141990 net.cpp:287] pool1 needs backward computation.
I1109 02:09:15.632741 141990 net.cpp:287] norm1 needs backward computation.
I1109 02:09:15.633005 141990 net.cpp:287] relu1 needs backward computation.
I1109 02:09:15.633216 141990 net.cpp:287] conv1 needs backward computation.
I1109 02:09:15.645941 141990 net.cpp:289] data does not need backward computation.
I1109 02:09:15.671119 141990 net.cpp:331] This network produces output loss
I1109 02:09:15.745260 141990 net.cpp:345] Network initialization done.
I1109 02:09:15.921630 141990 caffe.cpp:452] Performing Forward
I1109 02:09:29.363302 141990 caffe.cpp:457] Initial loss: 6.90483
I1109 02:09:29.412044 141990 caffe.cpp:459] Performing Backward
I1109 02:09:34.292018 141990 caffe.cpp:468] *** Benchmark begins ***
I1109 02:09:34.303431 141990 caffe.cpp:469] Testing for 1 iterations.
I1109 02:09:34.447885 141990 caffe.cpp:485] Profiling Layer: norm2 backward
I1109 02:09:36.915484 141990 caffe.cpp:512] Iteration: 1 forward-backward time: 2461 ms.
I1109 02:09:37.075793 141990 caffe.cpp:519] Average time per layer: 
I1109 02:09:37.091493 141990 caffe.cpp:522]       data	forward: 547.256 ms.
I1109 02:09:37.158092 141990 caffe.cpp:526]       data	backward: 5.441 ms.
I1109 02:09:37.176133 141990 caffe.cpp:522]      conv1	forward: 128.788 ms.
I1109 02:09:37.178591 141990 caffe.cpp:526]      conv1	backward: 50.634 ms.
I1109 02:09:37.179333 141990 caffe.cpp:522]      relu1	forward: 17.066 ms.
I1109 02:09:37.180038 141990 caffe.cpp:526]      relu1	backward: 16.736 ms.
I1109 02:09:37.180341 141990 caffe.cpp:522]      norm1	forward: 13.719 ms.
I1109 02:09:37.180557 141990 caffe.cpp:526]      norm1	backward: 15.527 ms.
I1109 02:09:37.180763 141990 caffe.cpp:522]      pool1	forward: 19.61 ms.
I1109 02:09:37.181028 141990 caffe.cpp:526]      pool1	backward: 80.227 ms.
I1109 02:09:37.181810 141990 caffe.cpp:522]      conv2	forward: 61.851 ms.
I1109 02:09:37.182049 141990 caffe.cpp:526]      conv2	backward: 92.423 ms.
I1109 02:09:37.182257 141990 caffe.cpp:522]      relu2	forward: 12.9 ms.
I1109 02:09:37.182466 141990 caffe.cpp:526]      relu2	backward: 17.246 ms.
I1109 02:09:37.182682 141990 caffe.cpp:522]      norm2	forward: 16.438 ms.
I1109 02:09:37.182963 141990 caffe.cpp:526]      norm2	backward: 28.594 ms.
I1109 02:09:37.183182 141990 caffe.cpp:522]      pool2	forward: 11.743 ms.
I1109 02:09:37.183389 141990 caffe.cpp:526]      pool2	backward: 57.129 ms.
I1109 02:09:37.183593 141990 caffe.cpp:522]      conv3	forward: 39.102 ms.
I1109 02:09:37.183796 141990 caffe.cpp:526]      conv3	backward: 74.408 ms.
I1109 02:09:37.184000 141990 caffe.cpp:522]      relu3	forward: 15.724 ms.
I1109 02:09:37.184202 141990 caffe.cpp:526]      relu3	backward: 39.904 ms.
I1109 02:09:37.184413 141990 caffe.cpp:522]      conv4	forward: 30.439 ms.
I1109 02:09:37.184622 141990 caffe.cpp:526]      conv4	backward: 80.206 ms.
I1109 02:09:37.184857 141990 caffe.cpp:522]      relu4	forward: 11.59 ms.
I1109 02:09:37.185070 141990 caffe.cpp:526]      relu4	backward: 38.338 ms.
I1109 02:09:37.185277 141990 caffe.cpp:522]      conv5	forward: 32.213 ms.
I1109 02:09:37.185539 141990 caffe.cpp:526]      conv5	backward: 60.117 ms.
I1109 02:09:37.185773 141990 caffe.cpp:522]      relu5	forward: 12.421 ms.
I1109 02:09:37.185987 141990 caffe.cpp:526]      relu5	backward: 15.284 ms.
I1109 02:09:37.186190 141990 caffe.cpp:522]      pool5	forward: 16.199 ms.
I1109 02:09:37.186393 141990 caffe.cpp:526]      pool5	backward: 48.157 ms.
I1109 02:09:37.186596 141990 caffe.cpp:522]        fc6	forward: 38.785 ms.
I1109 02:09:37.186800 141990 caffe.cpp:526]        fc6	backward: 114.124 ms.
I1109 02:09:37.187007 141990 caffe.cpp:522]      relu6	forward: 13.22 ms.
I1109 02:09:37.187214 141990 caffe.cpp:526]      relu6	backward: 12.457 ms.
I1109 02:09:37.187420 141990 caffe.cpp:522]      drop6	forward: 42.801 ms.
I1109 02:09:37.187630 141990 caffe.cpp:526]      drop6	backward: 18.22 ms.
I1109 02:09:37.187834 141990 caffe.cpp:522]        fc7	forward: 14.044 ms.
I1109 02:09:37.188043 141990 caffe.cpp:526]        fc7	backward: 80.707 ms.
I1109 02:09:37.188297 141990 caffe.cpp:522]      relu7	forward: 16.128 ms.
I1109 02:09:37.188513 141990 caffe.cpp:526]      relu7	backward: 16.698 ms.
I1109 02:09:37.188724 141990 caffe.cpp:522]      drop7	forward: 33.321 ms.
I1109 02:09:37.188953 141990 caffe.cpp:526]      drop7	backward: 15.365 ms.
I1109 02:09:37.189155 141990 caffe.cpp:522]        fc8	forward: 12.211 ms.
I1109 02:09:37.189363 141990 caffe.cpp:526]        fc8	backward: 101.628 ms.
I1109 02:09:37.189570 141990 caffe.cpp:522]       loss	forward: 61.429 ms.
I1109 02:09:37.189774 141990 caffe.cpp:526]       loss	backward: 73.159 ms.
I1109 02:09:37.196966 141990 caffe.cpp:532] Average Forward pass: 1274.13 ms.
I1109 02:09:37.211271 141990 caffe.cpp:535] Average Backward pass: 1161.71 ms.
I1109 02:09:37.223282 141990 caffe.cpp:537] Average Forward-Backward: 2848 ms.
I1109 02:09:37.239431 141990 caffe.cpp:540] Total Time: 2848 ms.
I1109 02:09:37.252842 141990 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 3732512
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 59720192
--->Total double-precision FLOPs = 0
--->Total FLOPs = 59720192
mem-read-1 = 24496
mem-read-2 = 34
mem-read-4 = 794205
mem-read-8 = 348004
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 4105732
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 122741
mem-write-8 = 28506
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 1119745
--->Total Bytes read = 268752296
--->Total Bytes written = 72382808
--->Total Bytes = 341135104
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer8_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=8 -prof_forward_direction=0
I1109 02:13:14.585564 142108 caffe.cpp:444] Use CPU.
I1109 02:13:31.619233 142108 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:13:31.675446 142108 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:13:31.687577 142108 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:13:31.700148 142108 cpu_info.cpp:461] Total number of processors: 272
I1109 02:13:31.711448 142108 cpu_info.cpp:464] GPU is used: no
I1109 02:13:31.720468 142108 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:13:31.729444 142108 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:13:31.740428 142108 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:13:40.558876 142108 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:13:40.591922 142108 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:13:41.240190 142108 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:13:43.732182 142108 layer_factory.hpp:114] Creating layer data
I1109 02:13:43.881392 142108 net.cpp:160] Creating Layer data
I1109 02:13:43.930696 142108 net.cpp:570] data -> data
I1109 02:13:44.400313 142108 net.cpp:570] data -> label
I1109 02:13:51.501050 142108 net.cpp:210] Setting up data
I1109 02:13:51.583832 142108 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:13:51.692464 142108 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:13:51.699816 142108 net.cpp:225] Memory required for data: 19787264
I1109 02:13:51.767668 142108 layer_factory.hpp:114] Creating layer conv1
I1109 02:13:52.095767 142108 net.cpp:160] Creating Layer conv1
I1109 02:13:52.145781 142108 net.cpp:596] conv1 <- data
I1109 02:13:52.265705 142108 net.cpp:570] conv1 -> conv1
I1109 02:14:25.181531 142108 net.cpp:210] Setting up conv1
I1109 02:14:25.187870 142108 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:14:25.188247 142108 net.cpp:225] Memory required for data: 56958464
I1109 02:14:25.471148 142108 layer_factory.hpp:114] Creating layer relu1
I1109 02:14:25.591979 142108 net.cpp:160] Creating Layer relu1
I1109 02:14:25.596634 142108 net.cpp:596] relu1 <- conv1
I1109 02:14:25.629302 142108 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:14:25.820582 142108 net.cpp:210] Setting up relu1
I1109 02:14:25.823015 142108 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:14:25.823354 142108 net.cpp:225] Memory required for data: 94129664
I1109 02:14:25.823551 142108 layer_factory.hpp:114] Creating layer norm1
I1109 02:14:25.929631 142108 net.cpp:160] Creating Layer norm1
I1109 02:14:25.929960 142108 net.cpp:596] norm1 <- conv1
I1109 02:14:25.932497 142108 net.cpp:570] norm1 -> norm1
I1109 02:14:26.157507 142108 net.cpp:210] Setting up norm1
I1109 02:14:26.170342 142108 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:14:26.170714 142108 net.cpp:225] Memory required for data: 131300864
I1109 02:14:26.171016 142108 layer_factory.hpp:114] Creating layer pool1
I1109 02:14:26.264556 142108 net.cpp:160] Creating Layer pool1
I1109 02:14:26.264910 142108 net.cpp:596] pool1 <- norm1
I1109 02:14:26.279871 142108 net.cpp:570] pool1 -> pool1
I1109 02:14:26.587926 142108 net.cpp:210] Setting up pool1
I1109 02:14:26.590441 142108 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:14:26.590768 142108 net.cpp:225] Memory required for data: 140258816
I1109 02:14:26.591014 142108 layer_factory.hpp:114] Creating layer conv2
I1109 02:14:26.591377 142108 net.cpp:160] Creating Layer conv2
I1109 02:14:26.591670 142108 net.cpp:596] conv2 <- pool1
I1109 02:14:26.591929 142108 net.cpp:570] conv2 -> conv2
I1109 02:14:32.378137 142108 net.cpp:210] Setting up conv2
I1109 02:14:32.378478 142108 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:14:32.378885 142108 net.cpp:225] Memory required for data: 164146688
I1109 02:14:32.429159 142108 layer_factory.hpp:114] Creating layer relu2
I1109 02:14:32.429613 142108 net.cpp:160] Creating Layer relu2
I1109 02:14:32.429982 142108 net.cpp:596] relu2 <- conv2
I1109 02:14:32.430234 142108 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:14:32.430675 142108 net.cpp:210] Setting up relu2
I1109 02:14:32.430934 142108 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:14:32.431159 142108 net.cpp:225] Memory required for data: 188034560
I1109 02:14:32.431342 142108 layer_factory.hpp:114] Creating layer norm2
I1109 02:14:32.431579 142108 net.cpp:160] Creating Layer norm2
I1109 02:14:32.431771 142108 net.cpp:596] norm2 <- conv2
I1109 02:14:32.431998 142108 net.cpp:570] norm2 -> norm2
I1109 02:14:32.434159 142108 net.cpp:210] Setting up norm2
I1109 02:14:32.434470 142108 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:14:32.434698 142108 net.cpp:225] Memory required for data: 211922432
I1109 02:14:32.434885 142108 layer_factory.hpp:114] Creating layer pool2
I1109 02:14:32.435696 142108 net.cpp:160] Creating Layer pool2
I1109 02:14:32.435984 142108 net.cpp:596] pool2 <- norm2
I1109 02:14:32.436259 142108 net.cpp:570] pool2 -> pool2
I1109 02:14:32.436717 142108 net.cpp:210] Setting up pool2
I1109 02:14:32.437149 142108 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:14:32.437381 142108 net.cpp:225] Memory required for data: 217460224
I1109 02:14:32.437580 142108 layer_factory.hpp:114] Creating layer conv3
I1109 02:14:32.437921 142108 net.cpp:160] Creating Layer conv3
I1109 02:14:32.438144 142108 net.cpp:596] conv3 <- pool2
I1109 02:14:32.438382 142108 net.cpp:570] conv3 -> conv3
I1109 02:14:32.914197 142108 net.cpp:210] Setting up conv3
I1109 02:14:32.916599 142108 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:14:32.917016 142108 net.cpp:225] Memory required for data: 225766912
I1109 02:14:32.920012 142108 layer_factory.hpp:114] Creating layer relu3
I1109 02:14:32.920416 142108 net.cpp:160] Creating Layer relu3
I1109 02:14:32.920675 142108 net.cpp:596] relu3 <- conv3
I1109 02:14:32.921000 142108 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:14:32.925225 142108 net.cpp:210] Setting up relu3
I1109 02:14:32.925580 142108 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:14:32.925827 142108 net.cpp:225] Memory required for data: 234073600
I1109 02:14:32.926020 142108 layer_factory.hpp:114] Creating layer conv4
I1109 02:14:32.926381 142108 net.cpp:160] Creating Layer conv4
I1109 02:14:32.926642 142108 net.cpp:596] conv4 <- conv3
I1109 02:14:32.926887 142108 net.cpp:570] conv4 -> conv4
I1109 02:14:33.200404 142108 net.cpp:210] Setting up conv4
I1109 02:14:33.200856 142108 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:14:33.201266 142108 net.cpp:225] Memory required for data: 242380288
I1109 02:14:33.201606 142108 layer_factory.hpp:114] Creating layer relu4
I1109 02:14:33.201918 142108 net.cpp:160] Creating Layer relu4
I1109 02:14:33.202160 142108 net.cpp:596] relu4 <- conv4
I1109 02:14:33.202402 142108 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:14:33.214617 142108 net.cpp:210] Setting up relu4
I1109 02:14:33.215016 142108 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:14:33.215401 142108 net.cpp:225] Memory required for data: 250686976
I1109 02:14:33.215642 142108 layer_factory.hpp:114] Creating layer conv5
I1109 02:14:33.216007 142108 net.cpp:160] Creating Layer conv5
I1109 02:14:33.216253 142108 net.cpp:596] conv5 <- conv4
I1109 02:14:33.216500 142108 net.cpp:570] conv5 -> conv5
I1109 02:14:33.384588 142108 net.cpp:210] Setting up conv5
I1109 02:14:33.385021 142108 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:14:33.385471 142108 net.cpp:225] Memory required for data: 256224768
I1109 02:14:33.390156 142108 layer_factory.hpp:114] Creating layer relu5
I1109 02:14:33.390559 142108 net.cpp:160] Creating Layer relu5
I1109 02:14:33.390818 142108 net.cpp:596] relu5 <- conv5
I1109 02:14:33.391084 142108 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:14:33.391582 142108 net.cpp:210] Setting up relu5
I1109 02:14:33.391885 142108 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:14:33.392192 142108 net.cpp:225] Memory required for data: 261762560
I1109 02:14:33.392431 142108 layer_factory.hpp:114] Creating layer pool5
I1109 02:14:33.392693 142108 net.cpp:160] Creating Layer pool5
I1109 02:14:33.392971 142108 net.cpp:596] pool5 <- conv5
I1109 02:14:33.393206 142108 net.cpp:570] pool5 -> pool5
I1109 02:14:33.393612 142108 net.cpp:210] Setting up pool5
I1109 02:14:33.393867 142108 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:14:33.394088 142108 net.cpp:225] Memory required for data: 262942208
I1109 02:14:33.394271 142108 layer_factory.hpp:114] Creating layer fc6
I1109 02:14:33.449156 142108 net.cpp:160] Creating Layer fc6
I1109 02:14:33.449468 142108 net.cpp:596] fc6 <- pool5
I1109 02:14:33.449848 142108 net.cpp:570] fc6 -> fc6
I1109 02:14:37.540920 142108 net.cpp:210] Setting up fc6
I1109 02:14:37.541220 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:37.543287 142108 net.cpp:225] Memory required for data: 263466496
I1109 02:14:37.543598 142108 layer_factory.hpp:114] Creating layer relu6
I1109 02:14:37.546130 142108 net.cpp:160] Creating Layer relu6
I1109 02:14:37.546433 142108 net.cpp:596] relu6 <- fc6
I1109 02:14:37.546658 142108 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:14:37.547072 142108 net.cpp:210] Setting up relu6
I1109 02:14:37.547325 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:37.547545 142108 net.cpp:225] Memory required for data: 263990784
I1109 02:14:37.547730 142108 layer_factory.hpp:114] Creating layer drop6
I1109 02:14:37.567713 142108 net.cpp:160] Creating Layer drop6
I1109 02:14:37.568019 142108 net.cpp:596] drop6 <- fc6
I1109 02:14:37.568425 142108 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:14:37.672984 142108 net.cpp:210] Setting up drop6
I1109 02:14:37.673285 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:37.673678 142108 net.cpp:225] Memory required for data: 264515072
I1109 02:14:37.673918 142108 layer_factory.hpp:114] Creating layer fc7
I1109 02:14:37.674187 142108 net.cpp:160] Creating Layer fc7
I1109 02:14:37.674401 142108 net.cpp:596] fc7 <- fc6
I1109 02:14:37.674782 142108 net.cpp:570] fc7 -> fc7
I1109 02:14:39.385558 142108 net.cpp:210] Setting up fc7
I1109 02:14:39.385936 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:39.386366 142108 net.cpp:225] Memory required for data: 265039360
I1109 02:14:39.386726 142108 layer_factory.hpp:114] Creating layer relu7
I1109 02:14:39.387060 142108 net.cpp:160] Creating Layer relu7
I1109 02:14:39.387310 142108 net.cpp:596] relu7 <- fc7
I1109 02:14:39.387568 142108 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:14:39.388021 142108 net.cpp:210] Setting up relu7
I1109 02:14:39.388319 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:39.388563 142108 net.cpp:225] Memory required for data: 265563648
I1109 02:14:39.388763 142108 layer_factory.hpp:114] Creating layer drop7
I1109 02:14:39.389101 142108 net.cpp:160] Creating Layer drop7
I1109 02:14:39.389324 142108 net.cpp:596] drop7 <- fc7
I1109 02:14:39.389586 142108 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:14:39.389963 142108 net.cpp:210] Setting up drop7
I1109 02:14:39.390168 142108 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:14:39.390386 142108 net.cpp:225] Memory required for data: 266087936
I1109 02:14:39.390575 142108 layer_factory.hpp:114] Creating layer fc8
I1109 02:14:39.390831 142108 net.cpp:160] Creating Layer fc8
I1109 02:14:39.391033 142108 net.cpp:596] fc8 <- fc7
I1109 02:14:39.391261 142108 net.cpp:570] fc8 -> fc8
I1109 02:14:39.814786 142108 net.cpp:210] Setting up fc8
I1109 02:14:39.815157 142108 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:14:39.815577 142108 net.cpp:225] Memory required for data: 266215936
I1109 02:14:39.815925 142108 layer_factory.hpp:114] Creating layer loss
I1109 02:14:39.841356 142108 net.cpp:160] Creating Layer loss
I1109 02:14:39.841682 142108 net.cpp:596] loss <- fc8
I1109 02:14:39.842579 142108 net.cpp:596] loss <- label
I1109 02:14:39.870678 142108 net.cpp:570] loss -> loss
I1109 02:14:39.909948 142108 layer_factory.hpp:114] Creating layer loss
I1109 02:14:42.524461 142108 net.cpp:210] Setting up loss
I1109 02:14:42.575572 142108 net.cpp:217] Top shape: (1)
I1109 02:14:42.587945 142108 net.cpp:220]     with loss weight 1
I1109 02:14:42.727176 142108 net.cpp:225] Memory required for data: 266215940
I1109 02:14:42.767212 142108 net.cpp:287] loss needs backward computation.
I1109 02:14:42.856175 142108 net.cpp:287] fc8 needs backward computation.
I1109 02:14:42.863468 142108 net.cpp:287] drop7 needs backward computation.
I1109 02:14:42.874449 142108 net.cpp:287] relu7 needs backward computation.
I1109 02:14:42.874775 142108 net.cpp:287] fc7 needs backward computation.
I1109 02:14:42.877233 142108 net.cpp:287] drop6 needs backward computation.
I1109 02:14:42.877589 142108 net.cpp:287] relu6 needs backward computation.
I1109 02:14:42.877912 142108 net.cpp:287] fc6 needs backward computation.
I1109 02:14:42.878671 142108 net.cpp:287] pool5 needs backward computation.
I1109 02:14:42.879426 142108 net.cpp:287] relu5 needs backward computation.
I1109 02:14:42.879698 142108 net.cpp:287] conv5 needs backward computation.
I1109 02:14:42.879899 142108 net.cpp:287] relu4 needs backward computation.
I1109 02:14:42.880133 142108 net.cpp:287] conv4 needs backward computation.
I1109 02:14:42.880347 142108 net.cpp:287] relu3 needs backward computation.
I1109 02:14:42.880661 142108 net.cpp:287] conv3 needs backward computation.
I1109 02:14:42.893363 142108 net.cpp:287] pool2 needs backward computation.
I1109 02:14:42.893723 142108 net.cpp:287] norm2 needs backward computation.
I1109 02:14:42.894040 142108 net.cpp:287] relu2 needs backward computation.
I1109 02:14:42.894278 142108 net.cpp:287] conv2 needs backward computation.
I1109 02:14:42.894472 142108 net.cpp:287] pool1 needs backward computation.
I1109 02:14:42.894657 142108 net.cpp:287] norm1 needs backward computation.
I1109 02:14:42.894842 142108 net.cpp:287] relu1 needs backward computation.
I1109 02:14:42.895018 142108 net.cpp:287] conv1 needs backward computation.
I1109 02:14:42.907636 142108 net.cpp:289] data does not need backward computation.
I1109 02:14:42.932961 142108 net.cpp:331] This network produces output loss
I1109 02:14:43.006044 142108 net.cpp:345] Network initialization done.
I1109 02:14:43.177405 142108 caffe.cpp:452] Performing Forward
I1109 02:14:56.499531 142108 caffe.cpp:457] Initial loss: 6.89156
I1109 02:14:56.549530 142108 caffe.cpp:459] Performing Backward
I1109 02:15:01.709964 142108 caffe.cpp:468] *** Benchmark begins ***
I1109 02:15:01.724670 142108 caffe.cpp:469] Testing for 1 iterations.
I1109 02:15:01.872364 142108 caffe.cpp:485] Profiling Layer: pool2 backward
I1109 02:15:04.391513 142108 caffe.cpp:512] Iteration: 1 forward-backward time: 2510 ms.
I1109 02:15:04.553692 142108 caffe.cpp:519] Average time per layer: 
I1109 02:15:04.577647 142108 caffe.cpp:522]       data	forward: 566.159 ms.
I1109 02:15:04.644348 142108 caffe.cpp:526]       data	backward: 3.669 ms.
I1109 02:15:04.668572 142108 caffe.cpp:522]      conv1	forward: 130.14 ms.
I1109 02:15:04.674841 142108 caffe.cpp:526]      conv1	backward: 21.72 ms.
I1109 02:15:04.684973 142108 caffe.cpp:522]      relu1	forward: 18.312 ms.
I1109 02:15:04.690119 142108 caffe.cpp:526]      relu1	backward: 1.081 ms.
I1109 02:15:04.690505 142108 caffe.cpp:522]      norm1	forward: 16.583 ms.
I1109 02:15:04.700202 142108 caffe.cpp:526]      norm1	backward: 3.111 ms.
I1109 02:15:04.708128 142108 caffe.cpp:522]      pool1	forward: 19.126 ms.
I1109 02:15:04.714884 142108 caffe.cpp:526]      pool1	backward: 70.821 ms.
I1109 02:15:04.722805 142108 caffe.cpp:522]      conv2	forward: 64.983 ms.
I1109 02:15:04.730700 142108 caffe.cpp:526]      conv2	backward: 75.388 ms.
I1109 02:15:04.741876 142108 caffe.cpp:522]      relu2	forward: 14.984 ms.
I1109 02:15:04.748003 142108 caffe.cpp:526]      relu2	backward: 11.664 ms.
I1109 02:15:04.751811 142108 caffe.cpp:522]      norm2	forward: 12.283 ms.
I1109 02:15:04.752022 142108 caffe.cpp:526]      norm2	backward: 16.515 ms.
I1109 02:15:04.752215 142108 caffe.cpp:522]      pool2	forward: 16.34 ms.
I1109 02:15:04.752408 142108 caffe.cpp:526]      pool2	backward: 84.332 ms.
I1109 02:15:04.752600 142108 caffe.cpp:522]      conv3	forward: 34.145 ms.
I1109 02:15:04.752832 142108 caffe.cpp:526]      conv3	backward: 77.201 ms.
I1109 02:15:04.753027 142108 caffe.cpp:522]      relu3	forward: 18.412 ms.
I1109 02:15:04.753218 142108 caffe.cpp:526]      relu3	backward: 29.161 ms.
I1109 02:15:04.753448 142108 caffe.cpp:522]      conv4	forward: 36.802 ms.
I1109 02:15:04.753654 142108 caffe.cpp:526]      conv4	backward: 72.588 ms.
I1109 02:15:04.753963 142108 caffe.cpp:522]      relu4	forward: 23.81 ms.
I1109 02:15:04.754204 142108 caffe.cpp:526]      relu4	backward: 42.295 ms.
I1109 02:15:04.754396 142108 caffe.cpp:522]      conv5	forward: 45.299 ms.
I1109 02:15:04.754587 142108 caffe.cpp:526]      conv5	backward: 61.432 ms.
I1109 02:15:04.754778 142108 caffe.cpp:522]      relu5	forward: 21.228 ms.
I1109 02:15:04.754971 142108 caffe.cpp:526]      relu5	backward: 19.118 ms.
I1109 02:15:04.755162 142108 caffe.cpp:522]      pool5	forward: 18.906 ms.
I1109 02:15:04.755352 142108 caffe.cpp:526]      pool5	backward: 55.856 ms.
I1109 02:15:04.755543 142108 caffe.cpp:522]        fc6	forward: 38.528 ms.
I1109 02:15:04.755733 142108 caffe.cpp:526]        fc6	backward: 125.331 ms.
I1109 02:15:04.755926 142108 caffe.cpp:522]      relu6	forward: 19.355 ms.
I1109 02:15:04.756151 142108 caffe.cpp:526]      relu6	backward: 14.738 ms.
I1109 02:15:04.756356 142108 caffe.cpp:522]      drop6	forward: 32.253 ms.
I1109 02:15:04.756642 142108 caffe.cpp:526]      drop6	backward: 11.508 ms.
I1109 02:15:04.756882 142108 caffe.cpp:522]        fc7	forward: 16.418 ms.
I1109 02:15:04.757172 142108 caffe.cpp:526]        fc7	backward: 115.97 ms.
I1109 02:15:04.757365 142108 caffe.cpp:522]      relu7	forward: 15.11 ms.
I1109 02:15:04.757556 142108 caffe.cpp:526]      relu7	backward: 14.879 ms.
I1109 02:15:04.757746 142108 caffe.cpp:522]      drop7	forward: 28.955 ms.
I1109 02:15:04.757937 142108 caffe.cpp:526]      drop7	backward: 13.366 ms.
I1109 02:15:04.758128 142108 caffe.cpp:522]        fc8	forward: 18.104 ms.
I1109 02:15:04.758319 142108 caffe.cpp:526]        fc8	backward: 115.533 ms.
I1109 02:15:04.758512 142108 caffe.cpp:522]       loss	forward: 63.472 ms.
I1109 02:15:04.758702 142108 caffe.cpp:526]       loss	backward: 72.517 ms.
I1109 02:15:04.764223 142108 caffe.cpp:532] Average Forward pass: 1347.33 ms.
I1109 02:15:04.777050 142108 caffe.cpp:535] Average Backward pass: 1138.84 ms.
I1109 02:15:04.787775 142108 caffe.cpp:537] Average Forward-Backward: 2994 ms.
I1109 02:15:04.802554 142108 caffe.cpp:540] Total Time: 2994 ms.
I1109 02:15:04.814975 142108 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 86528
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 1384448
--->Total double-precision FLOPs = 0
--->Total FLOPs = 1384448
mem-read-1 = 79830
mem-read-2 = 103
mem-read-4 = 755694
mem-read-8 = 989438
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 346114
mem-write-1 = 152
mem-write-2 = 51
mem-write-4 = 28888
mem-write-8 = 105646
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 753666
--->Total Bytes read = 33169676
--->Total Bytes written = 49195662
--->Total Bytes = 82365338
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer9_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=9 -prof_forward_direction=0
I1109 02:19:20.059005 142265 caffe.cpp:444] Use CPU.
I1109 02:19:36.880475 142265 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:19:36.935925 142265 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:19:36.947546 142265 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:19:36.959986 142265 cpu_info.cpp:461] Total number of processors: 272
I1109 02:19:36.971186 142265 cpu_info.cpp:464] GPU is used: no
I1109 02:19:36.980096 142265 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:19:36.988899 142265 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:19:36.999701 142265 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:19:45.709358 142265 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:19:45.741739 142265 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:19:46.368957 142265 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:19:48.812290 142265 layer_factory.hpp:114] Creating layer data
I1109 02:19:48.958151 142265 net.cpp:160] Creating Layer data
I1109 02:19:49.005827 142265 net.cpp:570] data -> data
I1109 02:19:49.470319 142265 net.cpp:570] data -> label
I1109 02:19:56.477695 142265 net.cpp:210] Setting up data
I1109 02:19:56.560672 142265 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:19:56.665632 142265 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:19:56.672741 142265 net.cpp:225] Memory required for data: 19787264
I1109 02:19:56.739815 142265 layer_factory.hpp:114] Creating layer conv1
I1109 02:19:57.064322 142265 net.cpp:160] Creating Layer conv1
I1109 02:19:57.114547 142265 net.cpp:596] conv1 <- data
I1109 02:19:57.234287 142265 net.cpp:570] conv1 -> conv1
I1109 02:20:29.923877 142265 net.cpp:210] Setting up conv1
I1109 02:20:29.930254 142265 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:20:29.930644 142265 net.cpp:225] Memory required for data: 56958464
I1109 02:20:30.211568 142265 layer_factory.hpp:114] Creating layer relu1
I1109 02:20:30.330811 142265 net.cpp:160] Creating Layer relu1
I1109 02:20:30.335433 142265 net.cpp:596] relu1 <- conv1
I1109 02:20:30.367965 142265 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:20:30.556473 142265 net.cpp:210] Setting up relu1
I1109 02:20:30.558956 142265 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:20:30.559331 142265 net.cpp:225] Memory required for data: 94129664
I1109 02:20:30.559535 142265 layer_factory.hpp:114] Creating layer norm1
I1109 02:20:30.664062 142265 net.cpp:160] Creating Layer norm1
I1109 02:20:30.664374 142265 net.cpp:596] norm1 <- conv1
I1109 02:20:30.666909 142265 net.cpp:570] norm1 -> norm1
I1109 02:20:30.890202 142265 net.cpp:210] Setting up norm1
I1109 02:20:30.902988 142265 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:20:30.903369 142265 net.cpp:225] Memory required for data: 131300864
I1109 02:20:30.903673 142265 layer_factory.hpp:114] Creating layer pool1
I1109 02:20:30.996615 142265 net.cpp:160] Creating Layer pool1
I1109 02:20:30.996973 142265 net.cpp:596] pool1 <- norm1
I1109 02:20:31.011636 142265 net.cpp:570] pool1 -> pool1
I1109 02:20:31.310384 142265 net.cpp:210] Setting up pool1
I1109 02:20:31.312911 142265 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:20:31.313235 142265 net.cpp:225] Memory required for data: 140258816
I1109 02:20:31.313485 142265 layer_factory.hpp:114] Creating layer conv2
I1109 02:20:31.313860 142265 net.cpp:160] Creating Layer conv2
I1109 02:20:31.314116 142265 net.cpp:596] conv2 <- pool1
I1109 02:20:31.314347 142265 net.cpp:570] conv2 -> conv2
I1109 02:20:37.060024 142265 net.cpp:210] Setting up conv2
I1109 02:20:37.060340 142265 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:20:37.060704 142265 net.cpp:225] Memory required for data: 164146688
I1109 02:20:37.112051 142265 layer_factory.hpp:114] Creating layer relu2
I1109 02:20:37.112437 142265 net.cpp:160] Creating Layer relu2
I1109 02:20:37.112767 142265 net.cpp:596] relu2 <- conv2
I1109 02:20:37.113106 142265 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:20:37.113548 142265 net.cpp:210] Setting up relu2
I1109 02:20:37.113800 142265 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:20:37.114032 142265 net.cpp:225] Memory required for data: 188034560
I1109 02:20:37.114222 142265 layer_factory.hpp:114] Creating layer norm2
I1109 02:20:37.114464 142265 net.cpp:160] Creating Layer norm2
I1109 02:20:37.114662 142265 net.cpp:596] norm2 <- conv2
I1109 02:20:37.114892 142265 net.cpp:570] norm2 -> norm2
I1109 02:20:37.117115 142265 net.cpp:210] Setting up norm2
I1109 02:20:37.117425 142265 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:20:37.117663 142265 net.cpp:225] Memory required for data: 211922432
I1109 02:20:37.117856 142265 layer_factory.hpp:114] Creating layer pool2
I1109 02:20:37.118855 142265 net.cpp:160] Creating Layer pool2
I1109 02:20:37.119153 142265 net.cpp:596] pool2 <- norm2
I1109 02:20:37.119395 142265 net.cpp:570] pool2 -> pool2
I1109 02:20:37.119793 142265 net.cpp:210] Setting up pool2
I1109 02:20:37.120039 142265 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:20:37.120261 142265 net.cpp:225] Memory required for data: 217460224
I1109 02:20:37.120461 142265 layer_factory.hpp:114] Creating layer conv3
I1109 02:20:37.120836 142265 net.cpp:160] Creating Layer conv3
I1109 02:20:37.121116 142265 net.cpp:596] conv3 <- pool2
I1109 02:20:37.121479 142265 net.cpp:570] conv3 -> conv3
I1109 02:20:37.600294 142265 net.cpp:210] Setting up conv3
I1109 02:20:37.602843 142265 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:20:37.603235 142265 net.cpp:225] Memory required for data: 225766912
I1109 02:20:37.606446 142265 layer_factory.hpp:114] Creating layer relu3
I1109 02:20:37.606909 142265 net.cpp:160] Creating Layer relu3
I1109 02:20:37.607192 142265 net.cpp:596] relu3 <- conv3
I1109 02:20:37.607542 142265 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:20:37.611665 142265 net.cpp:210] Setting up relu3
I1109 02:20:37.612009 142265 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:20:37.612277 142265 net.cpp:225] Memory required for data: 234073600
I1109 02:20:37.612490 142265 layer_factory.hpp:114] Creating layer conv4
I1109 02:20:37.612977 142265 net.cpp:160] Creating Layer conv4
I1109 02:20:37.613272 142265 net.cpp:596] conv4 <- conv3
I1109 02:20:37.613543 142265 net.cpp:570] conv4 -> conv4
I1109 02:20:37.855633 142265 net.cpp:210] Setting up conv4
I1109 02:20:37.856017 142265 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:20:37.856406 142265 net.cpp:225] Memory required for data: 242380288
I1109 02:20:37.856755 142265 layer_factory.hpp:114] Creating layer relu4
I1109 02:20:37.857110 142265 net.cpp:160] Creating Layer relu4
I1109 02:20:37.857349 142265 net.cpp:596] relu4 <- conv4
I1109 02:20:37.857592 142265 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:20:37.870545 142265 net.cpp:210] Setting up relu4
I1109 02:20:37.870909 142265 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:20:37.871322 142265 net.cpp:225] Memory required for data: 250686976
I1109 02:20:37.871594 142265 layer_factory.hpp:114] Creating layer conv5
I1109 02:20:37.871995 142265 net.cpp:160] Creating Layer conv5
I1109 02:20:37.872267 142265 net.cpp:596] conv5 <- conv4
I1109 02:20:37.872544 142265 net.cpp:570] conv5 -> conv5
I1109 02:20:38.070611 142265 net.cpp:210] Setting up conv5
I1109 02:20:38.071004 142265 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:20:38.071451 142265 net.cpp:225] Memory required for data: 256224768
I1109 02:20:38.076212 142265 layer_factory.hpp:114] Creating layer relu5
I1109 02:20:38.076619 142265 net.cpp:160] Creating Layer relu5
I1109 02:20:38.076979 142265 net.cpp:596] relu5 <- conv5
I1109 02:20:38.077282 142265 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:20:38.077858 142265 net.cpp:210] Setting up relu5
I1109 02:20:38.078150 142265 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:20:38.078403 142265 net.cpp:225] Memory required for data: 261762560
I1109 02:20:38.078614 142265 layer_factory.hpp:114] Creating layer pool5
I1109 02:20:38.078884 142265 net.cpp:160] Creating Layer pool5
I1109 02:20:38.079099 142265 net.cpp:596] pool5 <- conv5
I1109 02:20:38.079324 142265 net.cpp:570] pool5 -> pool5
I1109 02:20:38.079759 142265 net.cpp:210] Setting up pool5
I1109 02:20:38.080031 142265 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:20:38.080270 142265 net.cpp:225] Memory required for data: 262942208
I1109 02:20:38.080490 142265 layer_factory.hpp:114] Creating layer fc6
I1109 02:20:38.135365 142265 net.cpp:160] Creating Layer fc6
I1109 02:20:38.135674 142265 net.cpp:596] fc6 <- pool5
I1109 02:20:38.136049 142265 net.cpp:570] fc6 -> fc6
I1109 02:20:42.223762 142265 net.cpp:210] Setting up fc6
I1109 02:20:42.224066 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:42.226116 142265 net.cpp:225] Memory required for data: 263466496
I1109 02:20:42.226426 142265 layer_factory.hpp:114] Creating layer relu6
I1109 02:20:42.228998 142265 net.cpp:160] Creating Layer relu6
I1109 02:20:42.229300 142265 net.cpp:596] relu6 <- fc6
I1109 02:20:42.229531 142265 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:20:42.229954 142265 net.cpp:210] Setting up relu6
I1109 02:20:42.230204 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:42.230425 142265 net.cpp:225] Memory required for data: 263990784
I1109 02:20:42.230610 142265 layer_factory.hpp:114] Creating layer drop6
I1109 02:20:42.250973 142265 net.cpp:160] Creating Layer drop6
I1109 02:20:42.251287 142265 net.cpp:596] drop6 <- fc6
I1109 02:20:42.251636 142265 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:20:42.354743 142265 net.cpp:210] Setting up drop6
I1109 02:20:42.355037 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:42.355372 142265 net.cpp:225] Memory required for data: 264515072
I1109 02:20:42.355613 142265 layer_factory.hpp:114] Creating layer fc7
I1109 02:20:42.355882 142265 net.cpp:160] Creating Layer fc7
I1109 02:20:42.356088 142265 net.cpp:596] fc7 <- fc6
I1109 02:20:42.356475 142265 net.cpp:570] fc7 -> fc7
I1109 02:20:44.070781 142265 net.cpp:210] Setting up fc7
I1109 02:20:44.071137 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:44.071537 142265 net.cpp:225] Memory required for data: 265039360
I1109 02:20:44.071889 142265 layer_factory.hpp:114] Creating layer relu7
I1109 02:20:44.072213 142265 net.cpp:160] Creating Layer relu7
I1109 02:20:44.072456 142265 net.cpp:596] relu7 <- fc7
I1109 02:20:44.072710 142265 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:20:44.073351 142265 net.cpp:210] Setting up relu7
I1109 02:20:44.073632 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:44.073878 142265 net.cpp:225] Memory required for data: 265563648
I1109 02:20:44.074076 142265 layer_factory.hpp:114] Creating layer drop7
I1109 02:20:44.074316 142265 net.cpp:160] Creating Layer drop7
I1109 02:20:44.074570 142265 net.cpp:596] drop7 <- fc7
I1109 02:20:44.074836 142265 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:20:44.075152 142265 net.cpp:210] Setting up drop7
I1109 02:20:44.075358 142265 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:20:44.075580 142265 net.cpp:225] Memory required for data: 266087936
I1109 02:20:44.075767 142265 layer_factory.hpp:114] Creating layer fc8
I1109 02:20:44.076020 142265 net.cpp:160] Creating Layer fc8
I1109 02:20:44.076220 142265 net.cpp:596] fc8 <- fc7
I1109 02:20:44.076447 142265 net.cpp:570] fc8 -> fc8
I1109 02:20:44.499480 142265 net.cpp:210] Setting up fc8
I1109 02:20:44.499831 142265 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:20:44.500213 142265 net.cpp:225] Memory required for data: 266215936
I1109 02:20:44.500551 142265 layer_factory.hpp:114] Creating layer loss
I1109 02:20:44.525221 142265 net.cpp:160] Creating Layer loss
I1109 02:20:44.525532 142265 net.cpp:596] loss <- fc8
I1109 02:20:44.526554 142265 net.cpp:596] loss <- label
I1109 02:20:44.553783 142265 net.cpp:570] loss -> loss
I1109 02:20:44.591850 142265 layer_factory.hpp:114] Creating layer loss
I1109 02:20:47.148818 142265 net.cpp:210] Setting up loss
I1109 02:20:47.201870 142265 net.cpp:217] Top shape: (1)
I1109 02:20:47.215031 142265 net.cpp:220]     with loss weight 1
I1109 02:20:47.345232 142265 net.cpp:225] Memory required for data: 266215940
I1109 02:20:47.394702 142265 net.cpp:287] loss needs backward computation.
I1109 02:20:47.483731 142265 net.cpp:287] fc8 needs backward computation.
I1109 02:20:47.491014 142265 net.cpp:287] drop7 needs backward computation.
I1109 02:20:47.502092 142265 net.cpp:287] relu7 needs backward computation.
I1109 02:20:47.502404 142265 net.cpp:287] fc7 needs backward computation.
I1109 02:20:47.504825 142265 net.cpp:287] drop6 needs backward computation.
I1109 02:20:47.505177 142265 net.cpp:287] relu6 needs backward computation.
I1109 02:20:47.505473 142265 net.cpp:287] fc6 needs backward computation.
I1109 02:20:47.506238 142265 net.cpp:287] pool5 needs backward computation.
I1109 02:20:47.506965 142265 net.cpp:287] relu5 needs backward computation.
I1109 02:20:47.507215 142265 net.cpp:287] conv5 needs backward computation.
I1109 02:20:47.507410 142265 net.cpp:287] relu4 needs backward computation.
I1109 02:20:47.507591 142265 net.cpp:287] conv4 needs backward computation.
I1109 02:20:47.507772 142265 net.cpp:287] relu3 needs backward computation.
I1109 02:20:47.507987 142265 net.cpp:287] conv3 needs backward computation.
I1109 02:20:47.520161 142265 net.cpp:287] pool2 needs backward computation.
I1109 02:20:47.520500 142265 net.cpp:287] norm2 needs backward computation.
I1109 02:20:47.520859 142265 net.cpp:287] relu2 needs backward computation.
I1109 02:20:47.521080 142265 net.cpp:287] conv2 needs backward computation.
I1109 02:20:47.521273 142265 net.cpp:287] pool1 needs backward computation.
I1109 02:20:47.521464 142265 net.cpp:287] norm1 needs backward computation.
I1109 02:20:47.521651 142265 net.cpp:287] relu1 needs backward computation.
I1109 02:20:47.521831 142265 net.cpp:287] conv1 needs backward computation.
I1109 02:20:47.534857 142265 net.cpp:289] data does not need backward computation.
I1109 02:20:47.560032 142265 net.cpp:331] This network produces output loss
I1109 02:20:47.632333 142265 net.cpp:345] Network initialization done.
I1109 02:20:47.800417 142265 caffe.cpp:452] Performing Forward
I1109 02:21:00.763466 142265 caffe.cpp:457] Initial loss: 6.81891
I1109 02:21:00.808914 142265 caffe.cpp:459] Performing Backward
I1109 02:21:05.417377 142265 caffe.cpp:468] *** Benchmark begins ***
I1109 02:21:05.430336 142265 caffe.cpp:469] Testing for 1 iterations.
I1109 02:21:05.573379 142265 caffe.cpp:485] Profiling Layer: conv3 backward
I1109 02:21:08.277592 142265 caffe.cpp:512] Iteration: 1 forward-backward time: 2699 ms.
I1109 02:21:08.433975 142265 caffe.cpp:519] Average time per layer: 
I1109 02:21:08.451422 142265 caffe.cpp:522]       data	forward: 547.49 ms.
I1109 02:21:08.526674 142265 caffe.cpp:526]       data	backward: 4.916 ms.
I1109 02:21:08.554069 142265 caffe.cpp:522]      conv1	forward: 128.088 ms.
I1109 02:21:08.563447 142265 caffe.cpp:526]      conv1	backward: 40.062 ms.
I1109 02:21:08.569474 142265 caffe.cpp:522]      relu1	forward: 18.741 ms.
I1109 02:21:08.575597 142265 caffe.cpp:526]      relu1	backward: 13.007 ms.
I1109 02:21:08.587285 142265 caffe.cpp:522]      norm1	forward: 20.131 ms.
I1109 02:21:08.591241 142265 caffe.cpp:526]      norm1	backward: 14.069 ms.
I1109 02:21:08.597615 142265 caffe.cpp:522]      pool1	forward: 15.906 ms.
I1109 02:21:08.606487 142265 caffe.cpp:526]      pool1	backward: 85.916 ms.
I1109 02:21:08.612743 142265 caffe.cpp:522]      conv2	forward: 68.043 ms.
I1109 02:21:08.619815 142265 caffe.cpp:526]      conv2	backward: 70.196 ms.
I1109 02:21:08.627640 142265 caffe.cpp:522]      relu2	forward: 13.232 ms.
I1109 02:21:08.633729 142265 caffe.cpp:526]      relu2	backward: 15.28 ms.
I1109 02:21:08.637048 142265 caffe.cpp:522]      norm2	forward: 15.534 ms.
I1109 02:21:08.639739 142265 caffe.cpp:526]      norm2	backward: 20.077 ms.
I1109 02:21:08.641129 142265 caffe.cpp:522]      pool2	forward: 14.26 ms.
I1109 02:21:08.642137 142265 caffe.cpp:526]      pool2	backward: 66.025 ms.
I1109 02:21:08.642382 142265 caffe.cpp:522]      conv3	forward: 28.827 ms.
I1109 02:21:08.642590 142265 caffe.cpp:526]      conv3	backward: 96.669 ms.
I1109 02:21:08.642882 142265 caffe.cpp:522]      relu3	forward: 11.011 ms.
I1109 02:21:08.643183 142265 caffe.cpp:526]      relu3	backward: 31.004 ms.
I1109 02:21:08.643376 142265 caffe.cpp:522]      conv4	forward: 30.972 ms.
I1109 02:21:08.643566 142265 caffe.cpp:526]      conv4	backward: 72.882 ms.
I1109 02:21:08.643756 142265 caffe.cpp:522]      relu4	forward: 20.155 ms.
I1109 02:21:08.643946 142265 caffe.cpp:526]      relu4	backward: 39.66 ms.
I1109 02:21:08.644135 142265 caffe.cpp:522]      conv5	forward: 39.6 ms.
I1109 02:21:08.644325 142265 caffe.cpp:526]      conv5	backward: 61.181 ms.
I1109 02:21:08.644515 142265 caffe.cpp:522]      relu5	forward: 14.786 ms.
I1109 02:21:08.644704 142265 caffe.cpp:526]      relu5	backward: 13.492 ms.
I1109 02:21:08.644932 142265 caffe.cpp:522]      pool5	forward: 21.237 ms.
I1109 02:21:08.645123 142265 caffe.cpp:526]      pool5	backward: 9.178 ms.
I1109 02:21:08.646075 142265 caffe.cpp:522]        fc6	forward: 35.862 ms.
I1109 02:21:08.646404 142265 caffe.cpp:526]        fc6	backward: 155.346 ms.
I1109 02:21:08.646704 142265 caffe.cpp:522]      relu6	forward: 22.794 ms.
I1109 02:21:08.646898 142265 caffe.cpp:526]      relu6	backward: 0.085 ms.
I1109 02:21:08.649539 142265 caffe.cpp:522]      drop6	forward: 33.449 ms.
I1109 02:21:08.649796 142265 caffe.cpp:526]      drop6	backward: 0.088 ms.
I1109 02:21:08.650005 142265 caffe.cpp:522]        fc7	forward: 15.311 ms.
I1109 02:21:08.650208 142265 caffe.cpp:526]        fc7	backward: 152.92 ms.
I1109 02:21:08.650406 142265 caffe.cpp:522]      relu7	forward: 22.237 ms.
I1109 02:21:08.650599 142265 caffe.cpp:526]      relu7	backward: 21.661 ms.
I1109 02:21:08.650791 142265 caffe.cpp:522]      drop7	forward: 25.943 ms.
I1109 02:21:08.650984 142265 caffe.cpp:526]      drop7	backward: 14.869 ms.
I1109 02:21:08.651173 142265 caffe.cpp:522]        fc8	forward: 19.982 ms.
I1109 02:21:08.651363 142265 caffe.cpp:526]        fc8	backward: 308.163 ms.
I1109 02:21:08.651553 142265 caffe.cpp:522]       loss	forward: 64.208 ms.
I1109 02:21:08.651782 142265 caffe.cpp:526]       loss	backward: 54.391 ms.
I1109 02:21:08.657347 142265 caffe.cpp:532] Average Forward pass: 1302.69 ms.
I1109 02:21:08.670147 142265 caffe.cpp:535] Average Backward pass: 1369.85 ms.
I1109 02:21:08.680897 142265 caffe.cpp:537] Average Forward-Backward: 3184 ms.
I1109 02:21:08.695427 142265 caffe.cpp:540] Total Time: 3184 ms.
I1109 02:21:08.707660 142265 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 1076755200
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 17228083200
--->Total double-precision FLOPs = 0
--->Total FLOPs = 17228083200
mem-read-1 = 97095
mem-read-2 = 138
mem-read-4 = 540841842
mem-read-8 = 10377017
mem-read-16 = 0
mem-read-32 = 6692
mem-read-64 = 73852725
mem-write-1 = 202
mem-write-2 = 68
mem-write-4 = 26828
mem-write-8 = 8348459
mem-write-16 = 4
mem-write-32 = 4
mem-write-64 = 28560941
--->Total Bytes read = 6973269419
--->Total Bytes written = 1894795738
--->Total Bytes = 8868065157
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer10_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=10 -prof_forward_direction=0
I1109 02:25:27.059479 142393 caffe.cpp:444] Use CPU.
I1109 02:25:44.073959 142393 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:25:44.130607 142393 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:25:44.143213 142393 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:25:44.156352 142393 cpu_info.cpp:461] Total number of processors: 272
I1109 02:25:44.168056 142393 cpu_info.cpp:464] GPU is used: no
I1109 02:25:44.177536 142393 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:25:44.186555 142393 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:25:44.197734 142393 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:25:53.043496 142393 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:25:53.076721 142393 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:25:53.715101 142393 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:25:56.161857 142393 layer_factory.hpp:114] Creating layer data
I1109 02:25:56.314004 142393 net.cpp:160] Creating Layer data
I1109 02:25:56.362170 142393 net.cpp:570] data -> data
I1109 02:25:56.830744 142393 net.cpp:570] data -> label
I1109 02:26:03.899111 142393 net.cpp:210] Setting up data
I1109 02:26:03.978605 142393 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:26:04.082988 142393 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:26:04.090312 142393 net.cpp:225] Memory required for data: 19787264
I1109 02:26:04.158175 142393 layer_factory.hpp:114] Creating layer conv1
I1109 02:26:04.485739 142393 net.cpp:160] Creating Layer conv1
I1109 02:26:04.535751 142393 net.cpp:596] conv1 <- data
I1109 02:26:04.655040 142393 net.cpp:570] conv1 -> conv1
I1109 02:26:37.474081 142393 net.cpp:210] Setting up conv1
I1109 02:26:37.481066 142393 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:26:37.481436 142393 net.cpp:225] Memory required for data: 56958464
I1109 02:26:37.764843 142393 layer_factory.hpp:114] Creating layer relu1
I1109 02:26:37.884732 142393 net.cpp:160] Creating Layer relu1
I1109 02:26:37.890225 142393 net.cpp:596] relu1 <- conv1
I1109 02:26:37.922770 142393 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:26:38.111568 142393 net.cpp:210] Setting up relu1
I1109 02:26:38.114002 142393 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:26:38.114349 142393 net.cpp:225] Memory required for data: 94129664
I1109 02:26:38.114553 142393 layer_factory.hpp:114] Creating layer norm1
I1109 02:26:38.221372 142393 net.cpp:160] Creating Layer norm1
I1109 02:26:38.221690 142393 net.cpp:596] norm1 <- conv1
I1109 02:26:38.224191 142393 net.cpp:570] norm1 -> norm1
I1109 02:26:38.449558 142393 net.cpp:210] Setting up norm1
I1109 02:26:38.462800 142393 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:26:38.463199 142393 net.cpp:225] Memory required for data: 131300864
I1109 02:26:38.463533 142393 layer_factory.hpp:114] Creating layer pool1
I1109 02:26:38.557976 142393 net.cpp:160] Creating Layer pool1
I1109 02:26:38.558295 142393 net.cpp:596] pool1 <- norm1
I1109 02:26:38.573225 142393 net.cpp:570] pool1 -> pool1
I1109 02:26:38.872726 142393 net.cpp:210] Setting up pool1
I1109 02:26:38.875200 142393 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:26:38.875522 142393 net.cpp:225] Memory required for data: 140258816
I1109 02:26:38.875737 142393 layer_factory.hpp:114] Creating layer conv2
I1109 02:26:38.876135 142393 net.cpp:160] Creating Layer conv2
I1109 02:26:38.876363 142393 net.cpp:596] conv2 <- pool1
I1109 02:26:38.876664 142393 net.cpp:570] conv2 -> conv2
I1109 02:26:44.627799 142393 net.cpp:210] Setting up conv2
I1109 02:26:44.628144 142393 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:26:44.628556 142393 net.cpp:225] Memory required for data: 164146688
I1109 02:26:44.678817 142393 layer_factory.hpp:114] Creating layer relu2
I1109 02:26:44.679237 142393 net.cpp:160] Creating Layer relu2
I1109 02:26:44.679597 142393 net.cpp:596] relu2 <- conv2
I1109 02:26:44.679850 142393 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:26:44.680291 142393 net.cpp:210] Setting up relu2
I1109 02:26:44.680557 142393 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:26:44.680830 142393 net.cpp:225] Memory required for data: 188034560
I1109 02:26:44.681035 142393 layer_factory.hpp:114] Creating layer norm2
I1109 02:26:44.681278 142393 net.cpp:160] Creating Layer norm2
I1109 02:26:44.681475 142393 net.cpp:596] norm2 <- conv2
I1109 02:26:44.681700 142393 net.cpp:570] norm2 -> norm2
I1109 02:26:44.683796 142393 net.cpp:210] Setting up norm2
I1109 02:26:44.684105 142393 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:26:44.684337 142393 net.cpp:225] Memory required for data: 211922432
I1109 02:26:44.684525 142393 layer_factory.hpp:114] Creating layer pool2
I1109 02:26:44.685379 142393 net.cpp:160] Creating Layer pool2
I1109 02:26:44.685709 142393 net.cpp:596] pool2 <- norm2
I1109 02:26:44.686079 142393 net.cpp:570] pool2 -> pool2
I1109 02:26:44.686579 142393 net.cpp:210] Setting up pool2
I1109 02:26:44.686818 142393 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:26:44.687043 142393 net.cpp:225] Memory required for data: 217460224
I1109 02:26:44.687242 142393 layer_factory.hpp:114] Creating layer conv3
I1109 02:26:44.687571 142393 net.cpp:160] Creating Layer conv3
I1109 02:26:44.687785 142393 net.cpp:596] conv3 <- pool2
I1109 02:26:44.688022 142393 net.cpp:570] conv3 -> conv3
I1109 02:26:45.165637 142393 net.cpp:210] Setting up conv3
I1109 02:26:45.167990 142393 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:26:45.168344 142393 net.cpp:225] Memory required for data: 225766912
I1109 02:26:45.171488 142393 layer_factory.hpp:114] Creating layer relu3
I1109 02:26:45.171893 142393 net.cpp:160] Creating Layer relu3
I1109 02:26:45.172145 142393 net.cpp:596] relu3 <- conv3
I1109 02:26:45.172394 142393 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:26:45.176513 142393 net.cpp:210] Setting up relu3
I1109 02:26:45.176918 142393 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:26:45.177278 142393 net.cpp:225] Memory required for data: 234073600
I1109 02:26:45.177507 142393 layer_factory.hpp:114] Creating layer conv4
I1109 02:26:45.177896 142393 net.cpp:160] Creating Layer conv4
I1109 02:26:45.178166 142393 net.cpp:596] conv4 <- conv3
I1109 02:26:45.178431 142393 net.cpp:570] conv4 -> conv4
I1109 02:26:45.419347 142393 net.cpp:210] Setting up conv4
I1109 02:26:45.419734 142393 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:26:45.420130 142393 net.cpp:225] Memory required for data: 242380288
I1109 02:26:45.420469 142393 layer_factory.hpp:114] Creating layer relu4
I1109 02:26:45.420764 142393 net.cpp:160] Creating Layer relu4
I1109 02:26:45.421051 142393 net.cpp:596] relu4 <- conv4
I1109 02:26:45.421291 142393 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:26:45.433603 142393 net.cpp:210] Setting up relu4
I1109 02:26:45.433939 142393 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:26:45.434200 142393 net.cpp:225] Memory required for data: 250686976
I1109 02:26:45.434402 142393 layer_factory.hpp:114] Creating layer conv5
I1109 02:26:45.434782 142393 net.cpp:160] Creating Layer conv5
I1109 02:26:45.435031 142393 net.cpp:596] conv5 <- conv4
I1109 02:26:45.435302 142393 net.cpp:570] conv5 -> conv5
I1109 02:26:45.604077 142393 net.cpp:210] Setting up conv5
I1109 02:26:45.604466 142393 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:26:45.604919 142393 net.cpp:225] Memory required for data: 256224768
I1109 02:26:45.609688 142393 layer_factory.hpp:114] Creating layer relu5
I1109 02:26:45.610091 142393 net.cpp:160] Creating Layer relu5
I1109 02:26:45.610342 142393 net.cpp:596] relu5 <- conv5
I1109 02:26:45.610610 142393 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:26:45.611078 142393 net.cpp:210] Setting up relu5
I1109 02:26:45.611366 142393 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:26:45.611613 142393 net.cpp:225] Memory required for data: 261762560
I1109 02:26:45.611860 142393 layer_factory.hpp:114] Creating layer pool5
I1109 02:26:45.612141 142393 net.cpp:160] Creating Layer pool5
I1109 02:26:45.612370 142393 net.cpp:596] pool5 <- conv5
I1109 02:26:45.612658 142393 net.cpp:570] pool5 -> pool5
I1109 02:26:45.613157 142393 net.cpp:210] Setting up pool5
I1109 02:26:45.613425 142393 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:26:45.613658 142393 net.cpp:225] Memory required for data: 262942208
I1109 02:26:45.613845 142393 layer_factory.hpp:114] Creating layer fc6
I1109 02:26:45.669688 142393 net.cpp:160] Creating Layer fc6
I1109 02:26:45.670006 142393 net.cpp:596] fc6 <- pool5
I1109 02:26:45.670408 142393 net.cpp:570] fc6 -> fc6
I1109 02:26:49.787952 142393 net.cpp:210] Setting up fc6
I1109 02:26:49.788259 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:49.790382 142393 net.cpp:225] Memory required for data: 263466496
I1109 02:26:49.790729 142393 layer_factory.hpp:114] Creating layer relu6
I1109 02:26:49.793655 142393 net.cpp:160] Creating Layer relu6
I1109 02:26:49.793999 142393 net.cpp:596] relu6 <- fc6
I1109 02:26:49.794282 142393 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:26:49.794761 142393 net.cpp:210] Setting up relu6
I1109 02:26:49.795054 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:49.795325 142393 net.cpp:225] Memory required for data: 263990784
I1109 02:26:49.795539 142393 layer_factory.hpp:114] Creating layer drop6
I1109 02:26:49.816767 142393 net.cpp:160] Creating Layer drop6
I1109 02:26:49.817157 142393 net.cpp:596] drop6 <- fc6
I1109 02:26:49.817561 142393 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:26:49.922716 142393 net.cpp:210] Setting up drop6
I1109 02:26:49.923017 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:49.923357 142393 net.cpp:225] Memory required for data: 264515072
I1109 02:26:49.923607 142393 layer_factory.hpp:114] Creating layer fc7
I1109 02:26:49.923876 142393 net.cpp:160] Creating Layer fc7
I1109 02:26:49.924084 142393 net.cpp:596] fc7 <- fc6
I1109 02:26:49.924464 142393 net.cpp:570] fc7 -> fc7
I1109 02:26:51.636008 142393 net.cpp:210] Setting up fc7
I1109 02:26:51.636361 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:51.636764 142393 net.cpp:225] Memory required for data: 265039360
I1109 02:26:51.637181 142393 layer_factory.hpp:114] Creating layer relu7
I1109 02:26:51.637502 142393 net.cpp:160] Creating Layer relu7
I1109 02:26:51.637739 142393 net.cpp:596] relu7 <- fc7
I1109 02:26:51.637986 142393 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:26:51.638432 142393 net.cpp:210] Setting up relu7
I1109 02:26:51.638706 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:51.638947 142393 net.cpp:225] Memory required for data: 265563648
I1109 02:26:51.639140 142393 layer_factory.hpp:114] Creating layer drop7
I1109 02:26:51.639374 142393 net.cpp:160] Creating Layer drop7
I1109 02:26:51.639575 142393 net.cpp:596] drop7 <- fc7
I1109 02:26:51.639853 142393 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:26:51.640139 142393 net.cpp:210] Setting up drop7
I1109 02:26:51.640410 142393 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:26:51.640658 142393 net.cpp:225] Memory required for data: 266087936
I1109 02:26:51.640892 142393 layer_factory.hpp:114] Creating layer fc8
I1109 02:26:51.641154 142393 net.cpp:160] Creating Layer fc8
I1109 02:26:51.641350 142393 net.cpp:596] fc8 <- fc7
I1109 02:26:51.641576 142393 net.cpp:570] fc8 -> fc8
I1109 02:26:52.065295 142393 net.cpp:210] Setting up fc8
I1109 02:26:52.065647 142393 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:26:52.066052 142393 net.cpp:225] Memory required for data: 266215936
I1109 02:26:52.066443 142393 layer_factory.hpp:114] Creating layer loss
I1109 02:26:52.091040 142393 net.cpp:160] Creating Layer loss
I1109 02:26:52.091362 142393 net.cpp:596] loss <- fc8
I1109 02:26:52.092254 142393 net.cpp:596] loss <- label
I1109 02:26:52.119736 142393 net.cpp:570] loss -> loss
I1109 02:26:52.157479 142393 layer_factory.hpp:114] Creating layer loss
I1109 02:26:54.691558 142393 net.cpp:210] Setting up loss
I1109 02:26:54.741782 142393 net.cpp:217] Top shape: (1)
I1109 02:26:54.753937 142393 net.cpp:220]     with loss weight 1
I1109 02:26:54.892732 142393 net.cpp:225] Memory required for data: 266215940
I1109 02:26:54.934389 142393 net.cpp:287] loss needs backward computation.
I1109 02:26:55.020999 142393 net.cpp:287] fc8 needs backward computation.
I1109 02:26:55.028175 142393 net.cpp:287] drop7 needs backward computation.
I1109 02:26:55.039450 142393 net.cpp:287] relu7 needs backward computation.
I1109 02:26:55.039777 142393 net.cpp:287] fc7 needs backward computation.
I1109 02:26:55.042253 142393 net.cpp:287] drop6 needs backward computation.
I1109 02:26:55.042594 142393 net.cpp:287] relu6 needs backward computation.
I1109 02:26:55.042805 142393 net.cpp:287] fc6 needs backward computation.
I1109 02:26:55.043721 142393 net.cpp:287] pool5 needs backward computation.
I1109 02:26:55.044495 142393 net.cpp:287] relu5 needs backward computation.
I1109 02:26:55.044812 142393 net.cpp:287] conv5 needs backward computation.
I1109 02:26:55.045029 142393 net.cpp:287] relu4 needs backward computation.
I1109 02:26:55.045225 142393 net.cpp:287] conv4 needs backward computation.
I1109 02:26:55.045414 142393 net.cpp:287] relu3 needs backward computation.
I1109 02:26:55.045594 142393 net.cpp:287] conv3 needs backward computation.
I1109 02:26:55.057693 142393 net.cpp:287] pool2 needs backward computation.
I1109 02:26:55.058053 142393 net.cpp:287] norm2 needs backward computation.
I1109 02:26:55.058367 142393 net.cpp:287] relu2 needs backward computation.
I1109 02:26:55.058600 142393 net.cpp:287] conv2 needs backward computation.
I1109 02:26:55.058794 142393 net.cpp:287] pool1 needs backward computation.
I1109 02:26:55.058977 142393 net.cpp:287] norm1 needs backward computation.
I1109 02:26:55.059160 142393 net.cpp:287] relu1 needs backward computation.
I1109 02:26:55.059337 142393 net.cpp:287] conv1 needs backward computation.
I1109 02:26:55.071699 142393 net.cpp:289] data does not need backward computation.
I1109 02:26:55.096894 142393 net.cpp:331] This network produces output loss
I1109 02:26:55.169172 142393 net.cpp:345] Network initialization done.
I1109 02:26:55.337465 142393 caffe.cpp:452] Performing Forward
I1109 02:27:08.300894 142393 caffe.cpp:457] Initial loss: 6.96281
I1109 02:27:08.357228 142393 caffe.cpp:459] Performing Backward
I1109 02:27:13.138837 142393 caffe.cpp:468] *** Benchmark begins ***
I1109 02:27:13.151602 142393 caffe.cpp:469] Testing for 1 iterations.
I1109 02:27:13.297978 142393 caffe.cpp:485] Profiling Layer: relu3 backward
I1109 02:27:15.523892 142393 caffe.cpp:512] Iteration: 1 forward-backward time: 2223 ms.
I1109 02:27:15.681287 142393 caffe.cpp:519] Average time per layer: 
I1109 02:27:15.700673 142393 caffe.cpp:522]       data	forward: 552.254 ms.
I1109 02:27:15.772405 142393 caffe.cpp:526]       data	backward: 5.115 ms.
I1109 02:27:15.794178 142393 caffe.cpp:522]      conv1	forward: 137.175 ms.
I1109 02:27:15.797297 142393 caffe.cpp:526]      conv1	backward: 47.921 ms.
I1109 02:27:15.803732 142393 caffe.cpp:522]      relu1	forward: 13.966 ms.
I1109 02:27:15.813804 142393 caffe.cpp:526]      relu1	backward: 22.305 ms.
I1109 02:27:15.819862 142393 caffe.cpp:522]      norm1	forward: 21.153 ms.
I1109 02:27:15.825966 142393 caffe.cpp:526]      norm1	backward: 13.538 ms.
I1109 02:27:15.830348 142393 caffe.cpp:522]      pool1	forward: 25.25 ms.
I1109 02:27:15.836882 142393 caffe.cpp:526]      pool1	backward: 77.166 ms.
I1109 02:27:15.843839 142393 caffe.cpp:522]      conv2	forward: 62.634 ms.
I1109 02:27:15.849364 142393 caffe.cpp:526]      conv2	backward: 85.139 ms.
I1109 02:27:15.862200 142393 caffe.cpp:522]      relu2	forward: 18.224 ms.
I1109 02:27:15.869947 142393 caffe.cpp:526]      relu2	backward: 23.232 ms.
I1109 02:27:15.874927 142393 caffe.cpp:522]      norm2	forward: 12.689 ms.
I1109 02:27:15.876145 142393 caffe.cpp:526]      norm2	backward: 16.531 ms.
I1109 02:27:15.876354 142393 caffe.cpp:522]      pool2	forward: 14.893 ms.
I1109 02:27:15.876546 142393 caffe.cpp:526]      pool2	backward: 80.574 ms.
I1109 02:27:15.876821 142393 caffe.cpp:522]      conv3	forward: 32.155 ms.
I1109 02:27:15.877074 142393 caffe.cpp:526]      conv3	backward: 86.674 ms.
I1109 02:27:15.877400 142393 caffe.cpp:522]      relu3	forward: 13.214 ms.
I1109 02:27:15.877627 142393 caffe.cpp:526]      relu3	backward: 46.085 ms.
I1109 02:27:15.877820 142393 caffe.cpp:522]      conv4	forward: 30.659 ms.
I1109 02:27:15.878011 142393 caffe.cpp:526]      conv4	backward: 73.551 ms.
I1109 02:27:15.878203 142393 caffe.cpp:522]      relu4	forward: 10.11 ms.
I1109 02:27:15.880733 142393 caffe.cpp:526]      relu4	backward: 27.89 ms.
I1109 02:27:15.881029 142393 caffe.cpp:522]      conv5	forward: 28.248 ms.
I1109 02:27:15.881229 142393 caffe.cpp:526]      conv5	backward: 71.356 ms.
I1109 02:27:15.881427 142393 caffe.cpp:522]      relu5	forward: 13.417 ms.
I1109 02:27:15.881619 142393 caffe.cpp:526]      relu5	backward: 18.063 ms.
I1109 02:27:15.881809 142393 caffe.cpp:522]      pool5	forward: 10.366 ms.
I1109 02:27:15.881999 142393 caffe.cpp:526]      pool5	backward: 59.804 ms.
I1109 02:27:15.882189 142393 caffe.cpp:522]        fc6	forward: 47.185 ms.
I1109 02:27:15.882378 142393 caffe.cpp:526]        fc6	backward: 29.895 ms.
I1109 02:27:15.882567 142393 caffe.cpp:522]      relu6	forward: 15.674 ms.
I1109 02:27:15.882756 142393 caffe.cpp:526]      relu6	backward: 0.087 ms.
I1109 02:27:15.885447 142393 caffe.cpp:522]      drop6	forward: 33.083 ms.
I1109 02:27:15.885699 142393 caffe.cpp:526]      drop6	backward: 0.088 ms.
I1109 02:27:15.885895 142393 caffe.cpp:522]        fc7	forward: 14.235 ms.
I1109 02:27:15.886090 142393 caffe.cpp:526]        fc7	backward: 21.586 ms.
I1109 02:27:15.886283 142393 caffe.cpp:522]      relu7	forward: 14.972 ms.
I1109 02:27:15.886476 142393 caffe.cpp:526]      relu7	backward: 0.087 ms.
I1109 02:27:15.886665 142393 caffe.cpp:522]      drop7	forward: 31.123 ms.
I1109 02:27:15.886896 142393 caffe.cpp:526]      drop7	backward: 0.094 ms.
I1109 02:27:15.887138 142393 caffe.cpp:522]        fc8	forward: 19.191 ms.
I1109 02:27:15.887410 142393 caffe.cpp:526]        fc8	backward: 67.511 ms.
I1109 02:27:15.887646 142393 caffe.cpp:522]       loss	forward: 44.613 ms.
I1109 02:27:15.887840 142393 caffe.cpp:526]       loss	backward: 38.775 ms.
I1109 02:27:15.893862 142393 caffe.cpp:532] Average Forward pass: 1272.7 ms.
I1109 02:27:15.907218 142393 caffe.cpp:535] Average Backward pass: 922.758 ms.
I1109 02:27:15.917886 142393 caffe.cpp:537] Average Forward-Backward: 2696 ms.
I1109 02:27:15.932462 142393 caffe.cpp:540] Total Time: 2696 ms.
I1109 02:27:15.944648 142393 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 129792
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 259584
--->Total FLOPs = 259584
mem-read-1 = 47508
mem-read-2 = 68
mem-read-4 = 381719
mem-read-8 = 660048
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 389378
mem-write-1 = 100
mem-write-2 = 34
mem-write-4 = 1097
mem-write-8 = 60783
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 259586
--->Total Bytes read = 31775160
--->Total Bytes written = 17104388
--->Total Bytes = 48879548
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer11_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=11 -prof_forward_direction=0
I1109 02:30:57.255174 142520 caffe.cpp:444] Use CPU.
I1109 02:31:14.226837 142520 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:31:14.283488 142520 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:31:14.295440 142520 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:31:14.308020 142520 cpu_info.cpp:461] Total number of processors: 272
I1109 02:31:14.319188 142520 cpu_info.cpp:464] GPU is used: no
I1109 02:31:14.328225 142520 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:31:14.337116 142520 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:31:14.348192 142520 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:31:23.100009 142520 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:31:23.132992 142520 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:31:23.774179 142520 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:31:26.221583 142520 layer_factory.hpp:114] Creating layer data
I1109 02:31:26.368870 142520 net.cpp:160] Creating Layer data
I1109 02:31:26.417146 142520 net.cpp:570] data -> data
I1109 02:31:26.888234 142520 net.cpp:570] data -> label
I1109 02:31:33.919522 142520 net.cpp:210] Setting up data
I1109 02:31:33.998320 142520 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:31:34.101564 142520 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:31:34.108762 142520 net.cpp:225] Memory required for data: 19787264
I1109 02:31:34.179285 142520 layer_factory.hpp:114] Creating layer conv1
I1109 02:31:34.506788 142520 net.cpp:160] Creating Layer conv1
I1109 02:31:34.556565 142520 net.cpp:596] conv1 <- data
I1109 02:31:34.675701 142520 net.cpp:570] conv1 -> conv1
I1109 02:32:07.303203 142520 net.cpp:210] Setting up conv1
I1109 02:32:07.310106 142520 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:32:07.310462 142520 net.cpp:225] Memory required for data: 56958464
I1109 02:32:07.592056 142520 layer_factory.hpp:114] Creating layer relu1
I1109 02:32:07.712335 142520 net.cpp:160] Creating Layer relu1
I1109 02:32:07.717087 142520 net.cpp:596] relu1 <- conv1
I1109 02:32:07.749172 142520 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:32:07.938323 142520 net.cpp:210] Setting up relu1
I1109 02:32:07.940697 142520 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:32:07.941092 142520 net.cpp:225] Memory required for data: 94129664
I1109 02:32:07.941298 142520 layer_factory.hpp:114] Creating layer norm1
I1109 02:32:08.045825 142520 net.cpp:160] Creating Layer norm1
I1109 02:32:08.046134 142520 net.cpp:596] norm1 <- conv1
I1109 02:32:08.048631 142520 net.cpp:570] norm1 -> norm1
I1109 02:32:08.270900 142520 net.cpp:210] Setting up norm1
I1109 02:32:08.285037 142520 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:32:08.285421 142520 net.cpp:225] Memory required for data: 131300864
I1109 02:32:08.285763 142520 layer_factory.hpp:114] Creating layer pool1
I1109 02:32:08.379242 142520 net.cpp:160] Creating Layer pool1
I1109 02:32:08.379555 142520 net.cpp:596] pool1 <- norm1
I1109 02:32:08.394331 142520 net.cpp:570] pool1 -> pool1
I1109 02:32:08.694160 142520 net.cpp:210] Setting up pool1
I1109 02:32:08.696599 142520 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:32:08.696977 142520 net.cpp:225] Memory required for data: 140258816
I1109 02:32:08.697227 142520 layer_factory.hpp:114] Creating layer conv2
I1109 02:32:08.697600 142520 net.cpp:160] Creating Layer conv2
I1109 02:32:08.697857 142520 net.cpp:596] conv2 <- pool1
I1109 02:32:08.698094 142520 net.cpp:570] conv2 -> conv2
I1109 02:32:14.421008 142520 net.cpp:210] Setting up conv2
I1109 02:32:14.421339 142520 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:32:14.421711 142520 net.cpp:225] Memory required for data: 164146688
I1109 02:32:14.471982 142520 layer_factory.hpp:114] Creating layer relu2
I1109 02:32:14.472395 142520 net.cpp:160] Creating Layer relu2
I1109 02:32:14.472744 142520 net.cpp:596] relu2 <- conv2
I1109 02:32:14.473042 142520 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:32:14.473516 142520 net.cpp:210] Setting up relu2
I1109 02:32:14.473774 142520 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:32:14.474001 142520 net.cpp:225] Memory required for data: 188034560
I1109 02:32:14.474185 142520 layer_factory.hpp:114] Creating layer norm2
I1109 02:32:14.474423 142520 net.cpp:160] Creating Layer norm2
I1109 02:32:14.474618 142520 net.cpp:596] norm2 <- conv2
I1109 02:32:14.474843 142520 net.cpp:570] norm2 -> norm2
I1109 02:32:14.477118 142520 net.cpp:210] Setting up norm2
I1109 02:32:14.477427 142520 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:32:14.477653 142520 net.cpp:225] Memory required for data: 211922432
I1109 02:32:14.477838 142520 layer_factory.hpp:114] Creating layer pool2
I1109 02:32:14.478772 142520 net.cpp:160] Creating Layer pool2
I1109 02:32:14.479112 142520 net.cpp:596] pool2 <- norm2
I1109 02:32:14.479357 142520 net.cpp:570] pool2 -> pool2
I1109 02:32:14.479755 142520 net.cpp:210] Setting up pool2
I1109 02:32:14.479990 142520 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:32:14.480207 142520 net.cpp:225] Memory required for data: 217460224
I1109 02:32:14.480401 142520 layer_factory.hpp:114] Creating layer conv3
I1109 02:32:14.480722 142520 net.cpp:160] Creating Layer conv3
I1109 02:32:14.480998 142520 net.cpp:596] conv3 <- pool2
I1109 02:32:14.481243 142520 net.cpp:570] conv3 -> conv3
I1109 02:32:14.962874 142520 net.cpp:210] Setting up conv3
I1109 02:32:14.965334 142520 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:32:14.965688 142520 net.cpp:225] Memory required for data: 225766912
I1109 02:32:14.968734 142520 layer_factory.hpp:114] Creating layer relu3
I1109 02:32:14.969229 142520 net.cpp:160] Creating Layer relu3
I1109 02:32:14.969497 142520 net.cpp:596] relu3 <- conv3
I1109 02:32:14.969781 142520 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:32:14.973923 142520 net.cpp:210] Setting up relu3
I1109 02:32:14.974231 142520 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:32:14.974534 142520 net.cpp:225] Memory required for data: 234073600
I1109 02:32:14.974751 142520 layer_factory.hpp:114] Creating layer conv4
I1109 02:32:14.975158 142520 net.cpp:160] Creating Layer conv4
I1109 02:32:14.975419 142520 net.cpp:596] conv4 <- conv3
I1109 02:32:14.975674 142520 net.cpp:570] conv4 -> conv4
I1109 02:32:15.222991 142520 net.cpp:210] Setting up conv4
I1109 02:32:15.223376 142520 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:32:15.223822 142520 net.cpp:225] Memory required for data: 242380288
I1109 02:32:15.224174 142520 layer_factory.hpp:114] Creating layer relu4
I1109 02:32:15.224467 142520 net.cpp:160] Creating Layer relu4
I1109 02:32:15.224694 142520 net.cpp:596] relu4 <- conv4
I1109 02:32:15.224994 142520 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:32:15.237622 142520 net.cpp:210] Setting up relu4
I1109 02:32:15.237967 142520 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:32:15.238363 142520 net.cpp:225] Memory required for data: 250686976
I1109 02:32:15.238579 142520 layer_factory.hpp:114] Creating layer conv5
I1109 02:32:15.238940 142520 net.cpp:160] Creating Layer conv5
I1109 02:32:15.239181 142520 net.cpp:596] conv5 <- conv4
I1109 02:32:15.239425 142520 net.cpp:570] conv5 -> conv5
I1109 02:32:15.407970 142520 net.cpp:210] Setting up conv5
I1109 02:32:15.408360 142520 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:32:15.408828 142520 net.cpp:225] Memory required for data: 256224768
I1109 02:32:15.413554 142520 layer_factory.hpp:114] Creating layer relu5
I1109 02:32:15.413970 142520 net.cpp:160] Creating Layer relu5
I1109 02:32:15.414240 142520 net.cpp:596] relu5 <- conv5
I1109 02:32:15.414526 142520 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:32:15.415074 142520 net.cpp:210] Setting up relu5
I1109 02:32:15.415390 142520 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:32:15.415644 142520 net.cpp:225] Memory required for data: 261762560
I1109 02:32:15.415854 142520 layer_factory.hpp:114] Creating layer pool5
I1109 02:32:15.416113 142520 net.cpp:160] Creating Layer pool5
I1109 02:32:15.416330 142520 net.cpp:596] pool5 <- conv5
I1109 02:32:15.416553 142520 net.cpp:570] pool5 -> pool5
I1109 02:32:15.416997 142520 net.cpp:210] Setting up pool5
I1109 02:32:15.417271 142520 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:32:15.417541 142520 net.cpp:225] Memory required for data: 262942208
I1109 02:32:15.417742 142520 layer_factory.hpp:114] Creating layer fc6
I1109 02:32:15.472762 142520 net.cpp:160] Creating Layer fc6
I1109 02:32:15.473230 142520 net.cpp:596] fc6 <- pool5
I1109 02:32:15.473788 142520 net.cpp:570] fc6 -> fc6
I1109 02:32:19.586675 142520 net.cpp:210] Setting up fc6
I1109 02:32:19.586977 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:19.589100 142520 net.cpp:225] Memory required for data: 263466496
I1109 02:32:19.589413 142520 layer_factory.hpp:114] Creating layer relu6
I1109 02:32:19.591897 142520 net.cpp:160] Creating Layer relu6
I1109 02:32:19.592190 142520 net.cpp:596] relu6 <- fc6
I1109 02:32:19.592422 142520 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:32:19.592890 142520 net.cpp:210] Setting up relu6
I1109 02:32:19.593160 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:19.593421 142520 net.cpp:225] Memory required for data: 263990784
I1109 02:32:19.593618 142520 layer_factory.hpp:114] Creating layer drop6
I1109 02:32:19.613579 142520 net.cpp:160] Creating Layer drop6
I1109 02:32:19.613883 142520 net.cpp:596] drop6 <- fc6
I1109 02:32:19.614253 142520 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:32:19.717360 142520 net.cpp:210] Setting up drop6
I1109 02:32:19.717654 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:19.718055 142520 net.cpp:225] Memory required for data: 264515072
I1109 02:32:19.718299 142520 layer_factory.hpp:114] Creating layer fc7
I1109 02:32:19.718569 142520 net.cpp:160] Creating Layer fc7
I1109 02:32:19.718777 142520 net.cpp:596] fc7 <- fc6
I1109 02:32:19.719166 142520 net.cpp:570] fc7 -> fc7
I1109 02:32:21.430397 142520 net.cpp:210] Setting up fc7
I1109 02:32:21.430730 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:21.431143 142520 net.cpp:225] Memory required for data: 265039360
I1109 02:32:21.431481 142520 layer_factory.hpp:114] Creating layer relu7
I1109 02:32:21.431771 142520 net.cpp:160] Creating Layer relu7
I1109 02:32:21.431988 142520 net.cpp:596] relu7 <- fc7
I1109 02:32:21.432214 142520 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:32:21.432636 142520 net.cpp:210] Setting up relu7
I1109 02:32:21.432950 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:21.433177 142520 net.cpp:225] Memory required for data: 265563648
I1109 02:32:21.433362 142520 layer_factory.hpp:114] Creating layer drop7
I1109 02:32:21.433583 142520 net.cpp:160] Creating Layer drop7
I1109 02:32:21.433774 142520 net.cpp:596] drop7 <- fc7
I1109 02:32:21.434003 142520 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:32:21.434309 142520 net.cpp:210] Setting up drop7
I1109 02:32:21.434520 142520 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:32:21.434765 142520 net.cpp:225] Memory required for data: 266087936
I1109 02:32:21.434942 142520 layer_factory.hpp:114] Creating layer fc8
I1109 02:32:21.435185 142520 net.cpp:160] Creating Layer fc8
I1109 02:32:21.435377 142520 net.cpp:596] fc8 <- fc7
I1109 02:32:21.435597 142520 net.cpp:570] fc8 -> fc8
I1109 02:32:21.859313 142520 net.cpp:210] Setting up fc8
I1109 02:32:21.859679 142520 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:32:21.860119 142520 net.cpp:225] Memory required for data: 266215936
I1109 02:32:21.860450 142520 layer_factory.hpp:114] Creating layer loss
I1109 02:32:21.885275 142520 net.cpp:160] Creating Layer loss
I1109 02:32:21.885591 142520 net.cpp:596] loss <- fc8
I1109 02:32:21.886569 142520 net.cpp:596] loss <- label
I1109 02:32:21.914867 142520 net.cpp:570] loss -> loss
I1109 02:32:21.953085 142520 layer_factory.hpp:114] Creating layer loss
I1109 02:32:24.490931 142520 net.cpp:210] Setting up loss
I1109 02:32:24.537223 142520 net.cpp:217] Top shape: (1)
I1109 02:32:24.552464 142520 net.cpp:220]     with loss weight 1
I1109 02:32:24.683848 142520 net.cpp:225] Memory required for data: 266215940
I1109 02:32:24.723430 142520 net.cpp:287] loss needs backward computation.
I1109 02:32:24.809707 142520 net.cpp:287] fc8 needs backward computation.
I1109 02:32:24.816927 142520 net.cpp:287] drop7 needs backward computation.
I1109 02:32:24.827770 142520 net.cpp:287] relu7 needs backward computation.
I1109 02:32:24.828097 142520 net.cpp:287] fc7 needs backward computation.
I1109 02:32:24.830529 142520 net.cpp:287] drop6 needs backward computation.
I1109 02:32:24.830867 142520 net.cpp:287] relu6 needs backward computation.
I1109 02:32:24.831077 142520 net.cpp:287] fc6 needs backward computation.
I1109 02:32:24.831915 142520 net.cpp:287] pool5 needs backward computation.
I1109 02:32:24.832664 142520 net.cpp:287] relu5 needs backward computation.
I1109 02:32:24.832978 142520 net.cpp:287] conv5 needs backward computation.
I1109 02:32:24.833181 142520 net.cpp:287] relu4 needs backward computation.
I1109 02:32:24.833375 142520 net.cpp:287] conv4 needs backward computation.
I1109 02:32:24.833565 142520 net.cpp:287] relu3 needs backward computation.
I1109 02:32:24.833751 142520 net.cpp:287] conv3 needs backward computation.
I1109 02:32:24.845801 142520 net.cpp:287] pool2 needs backward computation.
I1109 02:32:24.846153 142520 net.cpp:287] norm2 needs backward computation.
I1109 02:32:24.846467 142520 net.cpp:287] relu2 needs backward computation.
I1109 02:32:24.846704 142520 net.cpp:287] conv2 needs backward computation.
I1109 02:32:24.846899 142520 net.cpp:287] pool1 needs backward computation.
I1109 02:32:24.847084 142520 net.cpp:287] norm1 needs backward computation.
I1109 02:32:24.847267 142520 net.cpp:287] relu1 needs backward computation.
I1109 02:32:24.847445 142520 net.cpp:287] conv1 needs backward computation.
I1109 02:32:24.859875 142520 net.cpp:289] data does not need backward computation.
I1109 02:32:24.884251 142520 net.cpp:331] This network produces output loss
I1109 02:32:24.955328 142520 net.cpp:345] Network initialization done.
I1109 02:32:25.122306 142520 caffe.cpp:452] Performing Forward
I1109 02:32:38.067579 142520 caffe.cpp:457] Initial loss: 6.89597
I1109 02:32:38.118628 142520 caffe.cpp:459] Performing Backward
I1109 02:32:42.953541 142520 caffe.cpp:468] *** Benchmark begins ***
I1109 02:32:42.966717 142520 caffe.cpp:469] Testing for 1 iterations.
I1109 02:32:43.112486 142520 caffe.cpp:485] Profiling Layer: conv4 backward
I1109 02:32:45.357275 142520 caffe.cpp:512] Iteration: 1 forward-backward time: 2239 ms.
I1109 02:32:45.512742 142520 caffe.cpp:519] Average time per layer: 
I1109 02:32:45.526089 142520 caffe.cpp:522]       data	forward: 550.802 ms.
I1109 02:32:45.596058 142520 caffe.cpp:526]       data	backward: 4.801 ms.
I1109 02:32:45.618430 142520 caffe.cpp:522]      conv1	forward: 135.458 ms.
I1109 02:32:45.626351 142520 caffe.cpp:526]      conv1	backward: 49.138 ms.
I1109 02:32:45.631693 142520 caffe.cpp:522]      relu1	forward: 12.739 ms.
I1109 02:32:45.634079 142520 caffe.cpp:526]      relu1	backward: 15.526 ms.
I1109 02:32:45.640146 142520 caffe.cpp:522]      norm1	forward: 16.536 ms.
I1109 02:32:45.650260 142520 caffe.cpp:526]      norm1	backward: 14.825 ms.
I1109 02:32:45.658035 142520 caffe.cpp:522]      pool1	forward: 17.625 ms.
I1109 02:32:45.666292 142520 caffe.cpp:526]      pool1	backward: 77.729 ms.
I1109 02:32:45.680208 142520 caffe.cpp:522]      conv2	forward: 62.983 ms.
I1109 02:32:45.686660 142520 caffe.cpp:526]      conv2	backward: 31.596 ms.
I1109 02:32:45.694805 142520 caffe.cpp:522]      relu2	forward: 16.027 ms.
I1109 02:32:45.705210 142520 caffe.cpp:526]      relu2	backward: 0.711 ms.
I1109 02:32:45.706310 142520 caffe.cpp:522]      norm2	forward: 13.23 ms.
I1109 02:32:45.706743 142520 caffe.cpp:526]      norm2	backward: 2.28 ms.
I1109 02:32:45.707484 142520 caffe.cpp:522]      pool2	forward: 11.33 ms.
I1109 02:32:45.707696 142520 caffe.cpp:526]      pool2	backward: 23.688 ms.
I1109 02:32:45.707890 142520 caffe.cpp:522]      conv3	forward: 31.754 ms.
I1109 02:32:45.708081 142520 caffe.cpp:526]      conv3	backward: 36.498 ms.
I1109 02:32:45.708304 142520 caffe.cpp:522]      relu3	forward: 17.393 ms.
I1109 02:32:45.708508 142520 caffe.cpp:526]      relu3	backward: 0.715 ms.
I1109 02:32:45.708748 142520 caffe.cpp:522]      conv4	forward: 29.343 ms.
I1109 02:32:45.709091 142520 caffe.cpp:526]      conv4	backward: 38.621 ms.
I1109 02:32:45.709290 142520 caffe.cpp:522]      relu4	forward: 21.982 ms.
I1109 02:32:45.709481 142520 caffe.cpp:526]      relu4	backward: 7.267 ms.
I1109 02:32:45.709668 142520 caffe.cpp:522]      conv5	forward: 22.443 ms.
I1109 02:32:45.709859 142520 caffe.cpp:526]      conv5	backward: 21.782 ms.
I1109 02:32:45.710049 142520 caffe.cpp:522]      relu5	forward: 13.511 ms.
I1109 02:32:45.710239 142520 caffe.cpp:526]      relu5	backward: 0.234 ms.
I1109 02:32:45.710427 142520 caffe.cpp:522]      pool5	forward: 11.564 ms.
I1109 02:32:45.710618 142520 caffe.cpp:526]      pool5	backward: 9.182 ms.
I1109 02:32:45.711477 142520 caffe.cpp:522]        fc6	forward: 41.406 ms.
I1109 02:32:45.711836 142520 caffe.cpp:526]        fc6	backward: 186.625 ms.
I1109 02:32:45.712085 142520 caffe.cpp:522]      relu6	forward: 11.645 ms.
I1109 02:32:45.712280 142520 caffe.cpp:526]      relu6	backward: 12.416 ms.
I1109 02:32:45.712472 142520 caffe.cpp:522]      drop6	forward: 31.29 ms.
I1109 02:32:45.712662 142520 caffe.cpp:526]      drop6	backward: 11.13 ms.
I1109 02:32:45.712890 142520 caffe.cpp:522]        fc7	forward: 12.672 ms.
I1109 02:32:45.713083 142520 caffe.cpp:526]        fc7	backward: 141.904 ms.
I1109 02:32:45.713274 142520 caffe.cpp:522]      relu7	forward: 19.234 ms.
I1109 02:32:45.713464 142520 caffe.cpp:526]      relu7	backward: 13.309 ms.
I1109 02:32:45.713654 142520 caffe.cpp:522]      drop7	forward: 31.949 ms.
I1109 02:32:45.713845 142520 caffe.cpp:526]      drop7	backward: 16.775 ms.
I1109 02:32:45.714035 142520 caffe.cpp:522]        fc8	forward: 12.968 ms.
I1109 02:32:45.714224 142520 caffe.cpp:526]        fc8	backward: 153.872 ms.
I1109 02:32:45.714460 142520 caffe.cpp:522]       loss	forward: 65.048 ms.
I1109 02:32:45.714682 142520 caffe.cpp:526]       loss	backward: 66.468 ms.
I1109 02:32:45.720136 142520 caffe.cpp:532] Average Forward pass: 1266.5 ms.
I1109 02:32:45.732962 142520 caffe.cpp:535] Average Backward pass: 945.938 ms.
I1109 02:32:45.743784 142520 caffe.cpp:537] Average Forward-Backward: 2709 ms.
I1109 02:32:45.758278 142520 caffe.cpp:540] Total Time: 2709 ms.
I1109 02:32:45.770299 142520 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 807598848
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 12921581568
--->Total double-precision FLOPs = 0
--->Total FLOPs = 12921581568
mem-read-1 = 394636
mem-read-2 = 138
mem-read-4 = 408290075
mem-read-8 = 11475199
mem-read-16 = 0
mem-read-32 = 10020
mem-read-64 = 55431989
mem-write-1 = 202
mem-write-2 = 68
mem-write-4 = 25880
mem-write-8 = 6615289
mem-write-16 = 4
mem-write-32 = 4
mem-write-64 = 21575469
--->Total Bytes read = 5273324740
--->Total Bytes written = 1433856378
--->Total Bytes = 6707181118
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer12_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=12 -prof_forward_direction=0
I1109 02:37:03.441779 142675 caffe.cpp:444] Use CPU.
I1109 02:37:20.268466 142675 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:37:20.324357 142675 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:37:20.336194 142675 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:37:20.348675 142675 cpu_info.cpp:461] Total number of processors: 272
I1109 02:37:20.359781 142675 cpu_info.cpp:464] GPU is used: no
I1109 02:37:20.368918 142675 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:37:20.377727 142675 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:37:20.388691 142675 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:37:29.099704 142675 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:37:29.132484 142675 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:37:29.767886 142675 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:37:32.213984 142675 layer_factory.hpp:114] Creating layer data
I1109 02:37:32.360199 142675 net.cpp:160] Creating Layer data
I1109 02:37:32.408028 142675 net.cpp:570] data -> data
I1109 02:37:32.877365 142675 net.cpp:570] data -> label
I1109 02:37:39.930080 142675 net.cpp:210] Setting up data
I1109 02:37:40.010402 142675 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:37:40.114182 142675 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:37:40.121314 142675 net.cpp:225] Memory required for data: 19787264
I1109 02:37:40.188289 142675 layer_factory.hpp:114] Creating layer conv1
I1109 02:37:40.513216 142675 net.cpp:160] Creating Layer conv1
I1109 02:37:40.562949 142675 net.cpp:596] conv1 <- data
I1109 02:37:40.682709 142675 net.cpp:570] conv1 -> conv1
I1109 02:38:13.548372 142675 net.cpp:210] Setting up conv1
I1109 02:38:13.555276 142675 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:38:13.555676 142675 net.cpp:225] Memory required for data: 56958464
I1109 02:38:13.835160 142675 layer_factory.hpp:114] Creating layer relu1
I1109 02:38:13.955415 142675 net.cpp:160] Creating Layer relu1
I1109 02:38:13.959998 142675 net.cpp:596] relu1 <- conv1
I1109 02:38:13.991794 142675 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:38:14.181673 142675 net.cpp:210] Setting up relu1
I1109 02:38:14.184093 142675 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:38:14.184432 142675 net.cpp:225] Memory required for data: 94129664
I1109 02:38:14.184638 142675 layer_factory.hpp:114] Creating layer norm1
I1109 02:38:14.288547 142675 net.cpp:160] Creating Layer norm1
I1109 02:38:14.288899 142675 net.cpp:596] norm1 <- conv1
I1109 02:38:14.291458 142675 net.cpp:570] norm1 -> norm1
I1109 02:38:14.513528 142675 net.cpp:210] Setting up norm1
I1109 02:38:14.526206 142675 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:38:14.526587 142675 net.cpp:225] Memory required for data: 131300864
I1109 02:38:14.526917 142675 layer_factory.hpp:114] Creating layer pool1
I1109 02:38:14.619796 142675 net.cpp:160] Creating Layer pool1
I1109 02:38:14.620113 142675 net.cpp:596] pool1 <- norm1
I1109 02:38:14.634820 142675 net.cpp:570] pool1 -> pool1
I1109 02:38:14.934612 142675 net.cpp:210] Setting up pool1
I1109 02:38:14.937125 142675 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:38:14.937456 142675 net.cpp:225] Memory required for data: 140258816
I1109 02:38:14.937674 142675 layer_factory.hpp:114] Creating layer conv2
I1109 02:38:14.938073 142675 net.cpp:160] Creating Layer conv2
I1109 02:38:14.938308 142675 net.cpp:596] conv2 <- pool1
I1109 02:38:14.938565 142675 net.cpp:570] conv2 -> conv2
I1109 02:38:20.686707 142675 net.cpp:210] Setting up conv2
I1109 02:38:20.687018 142675 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:38:20.687386 142675 net.cpp:225] Memory required for data: 164146688
I1109 02:38:20.737503 142675 layer_factory.hpp:114] Creating layer relu2
I1109 02:38:20.737890 142675 net.cpp:160] Creating Layer relu2
I1109 02:38:20.738221 142675 net.cpp:596] relu2 <- conv2
I1109 02:38:20.738504 142675 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:38:20.738930 142675 net.cpp:210] Setting up relu2
I1109 02:38:20.739187 142675 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:38:20.739418 142675 net.cpp:225] Memory required for data: 188034560
I1109 02:38:20.739603 142675 layer_factory.hpp:114] Creating layer norm2
I1109 02:38:20.739840 142675 net.cpp:160] Creating Layer norm2
I1109 02:38:20.740028 142675 net.cpp:596] norm2 <- conv2
I1109 02:38:20.740248 142675 net.cpp:570] norm2 -> norm2
I1109 02:38:20.742429 142675 net.cpp:210] Setting up norm2
I1109 02:38:20.742739 142675 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:38:20.742967 142675 net.cpp:225] Memory required for data: 211922432
I1109 02:38:20.743154 142675 layer_factory.hpp:114] Creating layer pool2
I1109 02:38:20.743958 142675 net.cpp:160] Creating Layer pool2
I1109 02:38:20.744243 142675 net.cpp:596] pool2 <- norm2
I1109 02:38:20.744519 142675 net.cpp:570] pool2 -> pool2
I1109 02:38:20.745054 142675 net.cpp:210] Setting up pool2
I1109 02:38:20.745370 142675 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:38:20.745610 142675 net.cpp:225] Memory required for data: 217460224
I1109 02:38:20.745826 142675 layer_factory.hpp:114] Creating layer conv3
I1109 02:38:20.746181 142675 net.cpp:160] Creating Layer conv3
I1109 02:38:20.746417 142675 net.cpp:596] conv3 <- pool2
I1109 02:38:20.746668 142675 net.cpp:570] conv3 -> conv3
I1109 02:38:21.199260 142675 net.cpp:210] Setting up conv3
I1109 02:38:21.201800 142675 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:38:21.202157 142675 net.cpp:225] Memory required for data: 225766912
I1109 02:38:21.205437 142675 layer_factory.hpp:114] Creating layer relu3
I1109 02:38:21.205852 142675 net.cpp:160] Creating Layer relu3
I1109 02:38:21.206107 142675 net.cpp:596] relu3 <- conv3
I1109 02:38:21.206348 142675 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:38:21.210541 142675 net.cpp:210] Setting up relu3
I1109 02:38:21.210930 142675 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:38:21.211196 142675 net.cpp:225] Memory required for data: 234073600
I1109 02:38:21.211427 142675 layer_factory.hpp:114] Creating layer conv4
I1109 02:38:21.211788 142675 net.cpp:160] Creating Layer conv4
I1109 02:38:21.212049 142675 net.cpp:596] conv4 <- conv3
I1109 02:38:21.212293 142675 net.cpp:570] conv4 -> conv4
I1109 02:38:21.480989 142675 net.cpp:210] Setting up conv4
I1109 02:38:21.481374 142675 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:38:21.481791 142675 net.cpp:225] Memory required for data: 242380288
I1109 02:38:21.482117 142675 layer_factory.hpp:114] Creating layer relu4
I1109 02:38:21.482414 142675 net.cpp:160] Creating Layer relu4
I1109 02:38:21.482640 142675 net.cpp:596] relu4 <- conv4
I1109 02:38:21.482874 142675 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:38:21.495015 142675 net.cpp:210] Setting up relu4
I1109 02:38:21.495328 142675 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:38:21.495574 142675 net.cpp:225] Memory required for data: 250686976
I1109 02:38:21.495770 142675 layer_factory.hpp:114] Creating layer conv5
I1109 02:38:21.496129 142675 net.cpp:160] Creating Layer conv5
I1109 02:38:21.496368 142675 net.cpp:596] conv5 <- conv4
I1109 02:38:21.496603 142675 net.cpp:570] conv5 -> conv5
I1109 02:38:21.665256 142675 net.cpp:210] Setting up conv5
I1109 02:38:21.665657 142675 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:38:21.666105 142675 net.cpp:225] Memory required for data: 256224768
I1109 02:38:21.670711 142675 layer_factory.hpp:114] Creating layer relu5
I1109 02:38:21.671113 142675 net.cpp:160] Creating Layer relu5
I1109 02:38:21.671366 142675 net.cpp:596] relu5 <- conv5
I1109 02:38:21.671627 142675 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:38:21.672078 142675 net.cpp:210] Setting up relu5
I1109 02:38:21.672412 142675 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:38:21.672674 142675 net.cpp:225] Memory required for data: 261762560
I1109 02:38:21.673002 142675 layer_factory.hpp:114] Creating layer pool5
I1109 02:38:21.673300 142675 net.cpp:160] Creating Layer pool5
I1109 02:38:21.673509 142675 net.cpp:596] pool5 <- conv5
I1109 02:38:21.673725 142675 net.cpp:570] pool5 -> pool5
I1109 02:38:21.674123 142675 net.cpp:210] Setting up pool5
I1109 02:38:21.674386 142675 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:38:21.674613 142675 net.cpp:225] Memory required for data: 262942208
I1109 02:38:21.674799 142675 layer_factory.hpp:114] Creating layer fc6
I1109 02:38:21.729511 142675 net.cpp:160] Creating Layer fc6
I1109 02:38:21.729822 142675 net.cpp:596] fc6 <- pool5
I1109 02:38:21.730187 142675 net.cpp:570] fc6 -> fc6
I1109 02:38:25.820093 142675 net.cpp:210] Setting up fc6
I1109 02:38:25.820426 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:25.822612 142675 net.cpp:225] Memory required for data: 263466496
I1109 02:38:25.822957 142675 layer_factory.hpp:114] Creating layer relu6
I1109 02:38:25.825584 142675 net.cpp:160] Creating Layer relu6
I1109 02:38:25.825902 142675 net.cpp:596] relu6 <- fc6
I1109 02:38:25.826146 142675 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:38:25.826583 142675 net.cpp:210] Setting up relu6
I1109 02:38:25.826865 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:25.827100 142675 net.cpp:225] Memory required for data: 263990784
I1109 02:38:25.827293 142675 layer_factory.hpp:114] Creating layer drop6
I1109 02:38:25.847790 142675 net.cpp:160] Creating Layer drop6
I1109 02:38:25.848104 142675 net.cpp:596] drop6 <- fc6
I1109 02:38:25.848551 142675 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:38:25.955025 142675 net.cpp:210] Setting up drop6
I1109 02:38:25.955322 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:25.955667 142675 net.cpp:225] Memory required for data: 264515072
I1109 02:38:25.955916 142675 layer_factory.hpp:114] Creating layer fc7
I1109 02:38:25.956187 142675 net.cpp:160] Creating Layer fc7
I1109 02:38:25.956393 142675 net.cpp:596] fc7 <- fc6
I1109 02:38:25.956815 142675 net.cpp:570] fc7 -> fc7
I1109 02:38:27.672158 142675 net.cpp:210] Setting up fc7
I1109 02:38:27.672511 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:27.672955 142675 net.cpp:225] Memory required for data: 265039360
I1109 02:38:27.673379 142675 layer_factory.hpp:114] Creating layer relu7
I1109 02:38:27.673717 142675 net.cpp:160] Creating Layer relu7
I1109 02:38:27.673967 142675 net.cpp:596] relu7 <- fc7
I1109 02:38:27.674221 142675 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:38:27.674661 142675 net.cpp:210] Setting up relu7
I1109 02:38:27.674943 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:27.675189 142675 net.cpp:225] Memory required for data: 265563648
I1109 02:38:27.675387 142675 layer_factory.hpp:114] Creating layer drop7
I1109 02:38:27.675622 142675 net.cpp:160] Creating Layer drop7
I1109 02:38:27.675860 142675 net.cpp:596] drop7 <- fc7
I1109 02:38:27.676108 142675 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:38:27.676388 142675 net.cpp:210] Setting up drop7
I1109 02:38:27.676663 142675 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:38:27.676960 142675 net.cpp:225] Memory required for data: 266087936
I1109 02:38:27.677153 142675 layer_factory.hpp:114] Creating layer fc8
I1109 02:38:27.677408 142675 net.cpp:160] Creating Layer fc8
I1109 02:38:27.677605 142675 net.cpp:596] fc8 <- fc7
I1109 02:38:27.677829 142675 net.cpp:570] fc8 -> fc8
I1109 02:38:28.099921 142675 net.cpp:210] Setting up fc8
I1109 02:38:28.100272 142675 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:38:28.100643 142675 net.cpp:225] Memory required for data: 266215936
I1109 02:38:28.101022 142675 layer_factory.hpp:114] Creating layer loss
I1109 02:38:28.125499 142675 net.cpp:160] Creating Layer loss
I1109 02:38:28.125809 142675 net.cpp:596] loss <- fc8
I1109 02:38:28.126701 142675 net.cpp:596] loss <- label
I1109 02:38:28.153957 142675 net.cpp:570] loss -> loss
I1109 02:38:28.191546 142675 layer_factory.hpp:114] Creating layer loss
I1109 02:38:30.689038 142675 net.cpp:210] Setting up loss
I1109 02:38:30.734030 142675 net.cpp:217] Top shape: (1)
I1109 02:38:30.747771 142675 net.cpp:220]     with loss weight 1
I1109 02:38:30.880102 142675 net.cpp:225] Memory required for data: 266215940
I1109 02:38:30.933151 142675 net.cpp:287] loss needs backward computation.
I1109 02:38:31.030231 142675 net.cpp:287] fc8 needs backward computation.
I1109 02:38:31.037384 142675 net.cpp:287] drop7 needs backward computation.
I1109 02:38:31.048491 142675 net.cpp:287] relu7 needs backward computation.
I1109 02:38:31.048849 142675 net.cpp:287] fc7 needs backward computation.
I1109 02:38:31.051259 142675 net.cpp:287] drop6 needs backward computation.
I1109 02:38:31.051554 142675 net.cpp:287] relu6 needs backward computation.
I1109 02:38:31.051775 142675 net.cpp:287] fc6 needs backward computation.
I1109 02:38:31.052611 142675 net.cpp:287] pool5 needs backward computation.
I1109 02:38:31.053541 142675 net.cpp:287] relu5 needs backward computation.
I1109 02:38:31.053802 142675 net.cpp:287] conv5 needs backward computation.
I1109 02:38:31.053992 142675 net.cpp:287] relu4 needs backward computation.
I1109 02:38:31.054169 142675 net.cpp:287] conv4 needs backward computation.
I1109 02:38:31.054347 142675 net.cpp:287] relu3 needs backward computation.
I1109 02:38:31.054522 142675 net.cpp:287] conv3 needs backward computation.
I1109 02:38:31.066493 142675 net.cpp:287] pool2 needs backward computation.
I1109 02:38:31.066824 142675 net.cpp:287] norm2 needs backward computation.
I1109 02:38:31.067118 142675 net.cpp:287] relu2 needs backward computation.
I1109 02:38:31.067350 142675 net.cpp:287] conv2 needs backward computation.
I1109 02:38:31.067533 142675 net.cpp:287] pool1 needs backward computation.
I1109 02:38:31.067713 142675 net.cpp:287] norm1 needs backward computation.
I1109 02:38:31.067891 142675 net.cpp:287] relu1 needs backward computation.
I1109 02:38:31.068065 142675 net.cpp:287] conv1 needs backward computation.
I1109 02:38:31.080271 142675 net.cpp:289] data does not need backward computation.
I1109 02:38:31.104293 142675 net.cpp:331] This network produces output loss
I1109 02:38:31.178086 142675 net.cpp:345] Network initialization done.
I1109 02:38:31.348527 142675 caffe.cpp:452] Performing Forward
I1109 02:38:44.489521 142675 caffe.cpp:457] Initial loss: 6.8946
I1109 02:38:44.541004 142675 caffe.cpp:459] Performing Backward
I1109 02:38:49.783493 142675 caffe.cpp:468] *** Benchmark begins ***
I1109 02:38:49.795506 142675 caffe.cpp:469] Testing for 1 iterations.
I1109 02:38:49.941648 142675 caffe.cpp:485] Profiling Layer: relu4 backward
I1109 02:38:52.153674 142675 caffe.cpp:512] Iteration: 1 forward-backward time: 2207 ms.
I1109 02:38:52.311645 142675 caffe.cpp:519] Average time per layer: 
I1109 02:38:52.326889 142675 caffe.cpp:522]       data	forward: 546.871 ms.
I1109 02:38:52.392340 142675 caffe.cpp:526]       data	backward: 5.764 ms.
I1109 02:38:52.414629 142675 caffe.cpp:522]      conv1	forward: 136.807 ms.
I1109 02:38:52.422447 142675 caffe.cpp:526]      conv1	backward: 45.883 ms.
I1109 02:38:52.432473 142675 caffe.cpp:522]      relu1	forward: 15.686 ms.
I1109 02:38:52.437592 142675 caffe.cpp:526]      relu1	backward: 15.762 ms.
I1109 02:38:52.439440 142675 caffe.cpp:522]      norm1	forward: 21.556 ms.
I1109 02:38:52.452622 142675 caffe.cpp:526]      norm1	backward: 12.539 ms.
I1109 02:38:52.462579 142675 caffe.cpp:522]      pool1	forward: 20.161 ms.
I1109 02:38:52.470700 142675 caffe.cpp:526]      pool1	backward: 83.486 ms.
I1109 02:38:52.479228 142675 caffe.cpp:522]      conv2	forward: 46.423 ms.
I1109 02:38:52.485469 142675 caffe.cpp:526]      conv2	backward: 81.2 ms.
I1109 02:38:52.502686 142675 caffe.cpp:522]      relu2	forward: 0.525 ms.
I1109 02:38:52.509613 142675 caffe.cpp:526]      relu2	backward: 16.31 ms.
I1109 02:38:52.518415 142675 caffe.cpp:522]      norm2	forward: 3.308 ms.
I1109 02:38:52.520014 142675 caffe.cpp:526]      norm2	backward: 27.355 ms.
I1109 02:38:52.520246 142675 caffe.cpp:522]      pool2	forward: 1.176 ms.
I1109 02:38:52.520450 142675 caffe.cpp:526]      pool2	backward: 64.681 ms.
I1109 02:38:52.520656 142675 caffe.cpp:522]      conv3	forward: 9.763 ms.
I1109 02:38:52.521564 142675 caffe.cpp:526]      conv3	backward: 80.718 ms.
I1109 02:38:52.521842 142675 caffe.cpp:522]      relu3	forward: 0.291 ms.
I1109 02:38:52.522053 142675 caffe.cpp:526]      relu3	backward: 31.825 ms.
I1109 02:38:52.522261 142675 caffe.cpp:522]      conv4	forward: 7.515 ms.
I1109 02:38:52.522460 142675 caffe.cpp:526]      conv4	backward: 77.302 ms.
I1109 02:38:52.522668 142675 caffe.cpp:522]      relu4	forward: 0.244 ms.
I1109 02:38:52.522869 142675 caffe.cpp:526]      relu4	backward: 53.059 ms.
I1109 02:38:52.523594 142675 caffe.cpp:522]      conv5	forward: 5.273 ms.
I1109 02:38:52.523823 142675 caffe.cpp:526]      conv5	backward: 85.978 ms.
I1109 02:38:52.524037 142675 caffe.cpp:522]      relu5	forward: 0.195 ms.
I1109 02:38:52.524242 142675 caffe.cpp:526]      relu5	backward: 17.265 ms.
I1109 02:38:52.524449 142675 caffe.cpp:522]      pool5	forward: 0.293 ms.
I1109 02:38:52.524649 142675 caffe.cpp:526]      pool5	backward: 55.033 ms.
I1109 02:38:52.524899 142675 caffe.cpp:522]        fc6	forward: 19.029 ms.
I1109 02:38:52.525152 142675 caffe.cpp:526]        fc6	backward: 125.669 ms.
I1109 02:38:52.525385 142675 caffe.cpp:522]      relu6	forward: 0.797 ms.
I1109 02:38:52.525589 142675 caffe.cpp:526]      relu6	backward: 16.931 ms.
I1109 02:38:52.525797 142675 caffe.cpp:522]      drop6	forward: 1.461 ms.
I1109 02:38:52.525996 142675 caffe.cpp:526]      drop6	backward: 21.299 ms.
I1109 02:38:52.526202 142675 caffe.cpp:522]        fc7	forward: 4.379 ms.
I1109 02:38:52.526401 142675 caffe.cpp:526]        fc7	backward: 107.27 ms.
I1109 02:38:52.526607 142675 caffe.cpp:522]      relu7	forward: 0.128 ms.
I1109 02:38:52.526808 142675 caffe.cpp:526]      relu7	backward: 18.649 ms.
I1109 02:38:52.527011 142675 caffe.cpp:522]      drop7	forward: 0.304 ms.
I1109 02:38:52.527210 142675 caffe.cpp:526]      drop7	backward: 12.054 ms.
I1109 02:38:52.527413 142675 caffe.cpp:522]        fc8	forward: 1.892 ms.
I1109 02:38:52.527611 142675 caffe.cpp:526]        fc8	backward: 131.586 ms.
I1109 02:38:52.527817 142675 caffe.cpp:522]       loss	forward: 42.654 ms.
I1109 02:38:52.528048 142675 caffe.cpp:526]       loss	backward: 37.757 ms.
I1109 02:38:52.533532 142675 caffe.cpp:532] Average Forward pass: 942.382 ms.
I1109 02:38:52.546602 142675 caffe.cpp:535] Average Backward pass: 1235.29 ms.
I1109 02:38:52.557327 142675 caffe.cpp:537] Average Forward-Backward: 2694 ms.
I1109 02:38:52.571825 142675 caffe.cpp:540] Total Time: 2694 ms.
I1109 02:38:52.583864 142675 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 129792
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 259584
--->Total FLOPs = 259584
mem-read-1 = 48532
mem-read-2 = 68
mem-read-4 = 389995
mem-read-8 = 671410
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 389378
mem-write-1 = 100
mem-write-2 = 34
mem-write-4 = 1135
mem-write-8 = 61853
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 259586
--->Total Bytes read = 31900184
--->Total Bytes written = 17113100
--->Total Bytes = 49013284

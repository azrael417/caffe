total layers 26
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer13_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=13 -prof_forward_direction=0
I1109 02:42:57.757378 143881 caffe.cpp:444] Use CPU.
I1109 02:43:14.652081 143881 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:43:14.707662 143881 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:43:14.719414 143881 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:43:14.731869 143881 cpu_info.cpp:461] Total number of processors: 272
I1109 02:43:14.743005 143881 cpu_info.cpp:464] GPU is used: no
I1109 02:43:14.752007 143881 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:43:14.760939 143881 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:43:14.771896 143881 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:43:23.489483 143881 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:43:23.522305 143881 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:43:24.155782 143881 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:43:26.591646 143881 layer_factory.hpp:114] Creating layer data
I1109 02:43:26.738373 143881 net.cpp:160] Creating Layer data
I1109 02:43:26.786365 143881 net.cpp:570] data -> data
I1109 02:43:27.251669 143881 net.cpp:570] data -> label
I1109 02:43:34.261968 143881 net.cpp:210] Setting up data
I1109 02:43:34.340036 143881 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:43:34.443110 143881 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:43:34.450117 143881 net.cpp:225] Memory required for data: 19787264
I1109 02:43:34.516980 143881 layer_factory.hpp:114] Creating layer conv1
I1109 02:43:34.840914 143881 net.cpp:160] Creating Layer conv1
I1109 02:43:34.890384 143881 net.cpp:596] conv1 <- data
I1109 02:43:35.011310 143881 net.cpp:570] conv1 -> conv1
I1109 02:44:07.709583 143881 net.cpp:210] Setting up conv1
I1109 02:44:07.716955 143881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:44:07.717366 143881 net.cpp:225] Memory required for data: 56958464
I1109 02:44:07.998349 143881 layer_factory.hpp:114] Creating layer relu1
I1109 02:44:08.117338 143881 net.cpp:160] Creating Layer relu1
I1109 02:44:08.121819 143881 net.cpp:596] relu1 <- conv1
I1109 02:44:08.153368 143881 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:44:08.340492 143881 net.cpp:210] Setting up relu1
I1109 02:44:08.342834 143881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:44:08.343166 143881 net.cpp:225] Memory required for data: 94129664
I1109 02:44:08.343359 143881 layer_factory.hpp:114] Creating layer norm1
I1109 02:44:08.446151 143881 net.cpp:160] Creating Layer norm1
I1109 02:44:08.446480 143881 net.cpp:596] norm1 <- conv1
I1109 02:44:08.448863 143881 net.cpp:570] norm1 -> norm1
I1109 02:44:08.666726 143881 net.cpp:210] Setting up norm1
I1109 02:44:08.679116 143881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:44:08.679507 143881 net.cpp:225] Memory required for data: 131300864
I1109 02:44:08.679723 143881 layer_factory.hpp:114] Creating layer pool1
I1109 02:44:08.770297 143881 net.cpp:160] Creating Layer pool1
I1109 02:44:08.770611 143881 net.cpp:596] pool1 <- norm1
I1109 02:44:08.785121 143881 net.cpp:570] pool1 -> pool1
I1109 02:44:09.081861 143881 net.cpp:210] Setting up pool1
I1109 02:44:09.084323 143881 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:44:09.084645 143881 net.cpp:225] Memory required for data: 140258816
I1109 02:44:09.084930 143881 layer_factory.hpp:114] Creating layer conv2
I1109 02:44:09.085311 143881 net.cpp:160] Creating Layer conv2
I1109 02:44:09.085539 143881 net.cpp:596] conv2 <- pool1
I1109 02:44:09.085803 143881 net.cpp:570] conv2 -> conv2
I1109 02:44:14.851256 143881 net.cpp:210] Setting up conv2
I1109 02:44:14.851575 143881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:44:14.851990 143881 net.cpp:225] Memory required for data: 164146688
I1109 02:44:14.905838 143881 layer_factory.hpp:114] Creating layer relu2
I1109 02:44:14.906277 143881 net.cpp:160] Creating Layer relu2
I1109 02:44:14.906635 143881 net.cpp:596] relu2 <- conv2
I1109 02:44:14.906929 143881 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:44:14.907409 143881 net.cpp:210] Setting up relu2
I1109 02:44:14.907691 143881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:44:14.907915 143881 net.cpp:225] Memory required for data: 188034560
I1109 02:44:14.908102 143881 layer_factory.hpp:114] Creating layer norm2
I1109 02:44:14.908341 143881 net.cpp:160] Creating Layer norm2
I1109 02:44:14.908542 143881 net.cpp:596] norm2 <- conv2
I1109 02:44:14.908856 143881 net.cpp:570] norm2 -> norm2
I1109 02:44:14.910928 143881 net.cpp:210] Setting up norm2
I1109 02:44:14.911232 143881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:44:14.911460 143881 net.cpp:225] Memory required for data: 211922432
I1109 02:44:14.911644 143881 layer_factory.hpp:114] Creating layer pool2
I1109 02:44:14.912510 143881 net.cpp:160] Creating Layer pool2
I1109 02:44:14.912840 143881 net.cpp:596] pool2 <- norm2
I1109 02:44:14.913172 143881 net.cpp:570] pool2 -> pool2
I1109 02:44:14.913698 143881 net.cpp:210] Setting up pool2
I1109 02:44:14.913962 143881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:44:14.914196 143881 net.cpp:225] Memory required for data: 217460224
I1109 02:44:14.914407 143881 layer_factory.hpp:114] Creating layer conv3
I1109 02:44:14.914752 143881 net.cpp:160] Creating Layer conv3
I1109 02:44:14.914986 143881 net.cpp:596] conv3 <- pool2
I1109 02:44:14.915241 143881 net.cpp:570] conv3 -> conv3
I1109 02:44:15.379905 143881 net.cpp:210] Setting up conv3
I1109 02:44:15.382392 143881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:44:15.382757 143881 net.cpp:225] Memory required for data: 225766912
I1109 02:44:15.385923 143881 layer_factory.hpp:114] Creating layer relu3
I1109 02:44:15.386340 143881 net.cpp:160] Creating Layer relu3
I1109 02:44:15.386606 143881 net.cpp:596] relu3 <- conv3
I1109 02:44:15.386864 143881 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:44:15.391018 143881 net.cpp:210] Setting up relu3
I1109 02:44:15.391341 143881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:44:15.391603 143881 net.cpp:225] Memory required for data: 234073600
I1109 02:44:15.391808 143881 layer_factory.hpp:114] Creating layer conv4
I1109 02:44:15.392180 143881 net.cpp:160] Creating Layer conv4
I1109 02:44:15.392449 143881 net.cpp:596] conv4 <- conv3
I1109 02:44:15.392709 143881 net.cpp:570] conv4 -> conv4
I1109 02:44:15.648246 143881 net.cpp:210] Setting up conv4
I1109 02:44:15.648648 143881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:44:15.649085 143881 net.cpp:225] Memory required for data: 242380288
I1109 02:44:15.649423 143881 layer_factory.hpp:114] Creating layer relu4
I1109 02:44:15.649739 143881 net.cpp:160] Creating Layer relu4
I1109 02:44:15.649989 143881 net.cpp:596] relu4 <- conv4
I1109 02:44:15.650245 143881 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:44:15.662642 143881 net.cpp:210] Setting up relu4
I1109 02:44:15.662971 143881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:44:15.663238 143881 net.cpp:225] Memory required for data: 250686976
I1109 02:44:15.663447 143881 layer_factory.hpp:114] Creating layer conv5
I1109 02:44:15.663828 143881 net.cpp:160] Creating Layer conv5
I1109 02:44:15.664090 143881 net.cpp:596] conv5 <- conv4
I1109 02:44:15.664346 143881 net.cpp:570] conv5 -> conv5
I1109 02:44:15.839979 143881 net.cpp:210] Setting up conv5
I1109 02:44:15.840389 143881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:44:15.840816 143881 net.cpp:225] Memory required for data: 256224768
I1109 02:44:15.845572 143881 layer_factory.hpp:114] Creating layer relu5
I1109 02:44:15.845989 143881 net.cpp:160] Creating Layer relu5
I1109 02:44:15.846256 143881 net.cpp:596] relu5 <- conv5
I1109 02:44:15.846536 143881 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:44:15.847019 143881 net.cpp:210] Setting up relu5
I1109 02:44:15.847319 143881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:44:15.847575 143881 net.cpp:225] Memory required for data: 261762560
I1109 02:44:15.847791 143881 layer_factory.hpp:114] Creating layer pool5
I1109 02:44:15.848067 143881 net.cpp:160] Creating Layer pool5
I1109 02:44:15.848292 143881 net.cpp:596] pool5 <- conv5
I1109 02:44:15.848532 143881 net.cpp:570] pool5 -> pool5
I1109 02:44:15.848995 143881 net.cpp:210] Setting up pool5
I1109 02:44:15.849287 143881 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:44:15.849525 143881 net.cpp:225] Memory required for data: 262942208
I1109 02:44:15.849721 143881 layer_factory.hpp:114] Creating layer fc6
I1109 02:44:15.907095 143881 net.cpp:160] Creating Layer fc6
I1109 02:44:15.907423 143881 net.cpp:596] fc6 <- pool5
I1109 02:44:15.907773 143881 net.cpp:570] fc6 -> fc6
I1109 02:44:20.077261 143881 net.cpp:210] Setting up fc6
I1109 02:44:20.077563 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:20.079587 143881 net.cpp:225] Memory required for data: 263466496
I1109 02:44:20.079891 143881 layer_factory.hpp:114] Creating layer relu6
I1109 02:44:20.082454 143881 net.cpp:160] Creating Layer relu6
I1109 02:44:20.082749 143881 net.cpp:596] relu6 <- fc6
I1109 02:44:20.082976 143881 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:44:20.083389 143881 net.cpp:210] Setting up relu6
I1109 02:44:20.083631 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:20.083850 143881 net.cpp:225] Memory required for data: 263990784
I1109 02:44:20.084034 143881 layer_factory.hpp:114] Creating layer drop6
I1109 02:44:20.104215 143881 net.cpp:160] Creating Layer drop6
I1109 02:44:20.104533 143881 net.cpp:596] drop6 <- fc6
I1109 02:44:20.104913 143881 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:44:20.207561 143881 net.cpp:210] Setting up drop6
I1109 02:44:20.207857 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:20.208189 143881 net.cpp:225] Memory required for data: 264515072
I1109 02:44:20.208431 143881 layer_factory.hpp:114] Creating layer fc7
I1109 02:44:20.208703 143881 net.cpp:160] Creating Layer fc7
I1109 02:44:20.208958 143881 net.cpp:596] fc7 <- fc6
I1109 02:44:20.209337 143881 net.cpp:570] fc7 -> fc7
I1109 02:44:21.921633 143881 net.cpp:210] Setting up fc7
I1109 02:44:21.922003 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:21.922497 143881 net.cpp:225] Memory required for data: 265039360
I1109 02:44:21.922865 143881 layer_factory.hpp:114] Creating layer relu7
I1109 02:44:21.923198 143881 net.cpp:160] Creating Layer relu7
I1109 02:44:21.923454 143881 net.cpp:596] relu7 <- fc7
I1109 02:44:21.923714 143881 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:44:21.924170 143881 net.cpp:210] Setting up relu7
I1109 02:44:21.924458 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:21.924710 143881 net.cpp:225] Memory required for data: 265563648
I1109 02:44:21.925007 143881 layer_factory.hpp:114] Creating layer drop7
I1109 02:44:21.925267 143881 net.cpp:160] Creating Layer drop7
I1109 02:44:21.925493 143881 net.cpp:596] drop7 <- fc7
I1109 02:44:21.925751 143881 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:44:21.926126 143881 net.cpp:210] Setting up drop7
I1109 02:44:21.926332 143881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:44:21.926550 143881 net.cpp:225] Memory required for data: 266087936
I1109 02:44:21.926731 143881 layer_factory.hpp:114] Creating layer fc8
I1109 02:44:21.926981 143881 net.cpp:160] Creating Layer fc8
I1109 02:44:21.927186 143881 net.cpp:596] fc8 <- fc7
I1109 02:44:21.927415 143881 net.cpp:570] fc8 -> fc8
I1109 02:44:22.349445 143881 net.cpp:210] Setting up fc8
I1109 02:44:22.349795 143881 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:44:22.350220 143881 net.cpp:225] Memory required for data: 266215936
I1109 02:44:22.350524 143881 layer_factory.hpp:114] Creating layer loss
I1109 02:44:22.375324 143881 net.cpp:160] Creating Layer loss
I1109 02:44:22.375638 143881 net.cpp:596] loss <- fc8
I1109 02:44:22.376631 143881 net.cpp:596] loss <- label
I1109 02:44:22.404163 143881 net.cpp:570] loss -> loss
I1109 02:44:22.442214 143881 layer_factory.hpp:114] Creating layer loss
I1109 02:44:24.995385 143881 net.cpp:210] Setting up loss
I1109 02:44:25.043977 143881 net.cpp:217] Top shape: (1)
I1109 02:44:25.053553 143881 net.cpp:220]     with loss weight 1
I1109 02:44:25.184263 143881 net.cpp:225] Memory required for data: 266215940
I1109 02:44:25.228459 143881 net.cpp:287] loss needs backward computation.
I1109 02:44:25.315738 143881 net.cpp:287] fc8 needs backward computation.
I1109 02:44:25.324354 143881 net.cpp:287] drop7 needs backward computation.
I1109 02:44:25.335374 143881 net.cpp:287] relu7 needs backward computation.
I1109 02:44:25.335692 143881 net.cpp:287] fc7 needs backward computation.
I1109 02:44:25.338165 143881 net.cpp:287] drop6 needs backward computation.
I1109 02:44:25.338467 143881 net.cpp:287] relu6 needs backward computation.
I1109 02:44:25.338697 143881 net.cpp:287] fc6 needs backward computation.
I1109 02:44:25.339515 143881 net.cpp:287] pool5 needs backward computation.
I1109 02:44:25.340255 143881 net.cpp:287] relu5 needs backward computation.
I1109 02:44:25.340526 143881 net.cpp:287] conv5 needs backward computation.
I1109 02:44:25.340720 143881 net.cpp:287] relu4 needs backward computation.
I1109 02:44:25.340955 143881 net.cpp:287] conv4 needs backward computation.
I1109 02:44:25.341138 143881 net.cpp:287] relu3 needs backward computation.
I1109 02:44:25.341317 143881 net.cpp:287] conv3 needs backward computation.
I1109 02:44:25.353406 143881 net.cpp:287] pool2 needs backward computation.
I1109 02:44:25.353756 143881 net.cpp:287] norm2 needs backward computation.
I1109 02:44:25.354058 143881 net.cpp:287] relu2 needs backward computation.
I1109 02:44:25.354290 143881 net.cpp:287] conv2 needs backward computation.
I1109 02:44:25.354480 143881 net.cpp:287] pool1 needs backward computation.
I1109 02:44:25.354660 143881 net.cpp:287] norm1 needs backward computation.
I1109 02:44:25.354836 143881 net.cpp:287] relu1 needs backward computation.
I1109 02:44:25.355010 143881 net.cpp:287] conv1 needs backward computation.
I1109 02:44:25.367444 143881 net.cpp:289] data does not need backward computation.
I1109 02:44:25.392498 143881 net.cpp:331] This network produces output loss
I1109 02:44:25.464393 143881 net.cpp:345] Network initialization done.
I1109 02:44:25.631609 143881 caffe.cpp:452] Performing Forward
I1109 02:44:38.849406 143881 caffe.cpp:457] Initial loss: 6.80558
I1109 02:44:38.904867 143881 caffe.cpp:459] Performing Backward
I1109 02:44:43.719578 143881 caffe.cpp:468] *** Benchmark begins ***
I1109 02:44:43.732960 143881 caffe.cpp:469] Testing for 1 iterations.
I1109 02:44:43.877077 143881 caffe.cpp:485] Profiling Layer: conv5 backward
I1109 02:44:46.443166 143881 caffe.cpp:512] Iteration: 1 forward-backward time: 2561 ms.
I1109 02:44:46.604096 143881 caffe.cpp:519] Average time per layer: 
I1109 02:44:46.622942 143881 caffe.cpp:522]       data	forward: 550.903 ms.
I1109 02:44:46.698457 143881 caffe.cpp:526]       data	backward: 4.84 ms.
I1109 02:44:46.723103 143881 caffe.cpp:522]      conv1	forward: 130.797 ms.
I1109 02:44:46.735057 143881 caffe.cpp:526]      conv1	backward: 37.538 ms.
I1109 02:44:46.742703 143881 caffe.cpp:522]      relu1	forward: 21.357 ms.
I1109 02:44:46.750866 143881 caffe.cpp:526]      relu1	backward: 22.397 ms.
I1109 02:44:46.758625 143881 caffe.cpp:522]      norm1	forward: 16.55 ms.
I1109 02:44:46.762733 143881 caffe.cpp:526]      norm1	backward: 10.999 ms.
I1109 02:44:46.778378 143881 caffe.cpp:522]      pool1	forward: 17.109 ms.
I1109 02:44:46.788991 143881 caffe.cpp:526]      pool1	backward: 84.084 ms.
I1109 02:44:46.795522 143881 caffe.cpp:522]      conv2	forward: 68.362 ms.
I1109 02:44:46.796007 143881 caffe.cpp:526]      conv2	backward: 75.348 ms.
I1109 02:44:46.796237 143881 caffe.cpp:522]      relu2	forward: 17.962 ms.
I1109 02:44:46.796429 143881 caffe.cpp:526]      relu2	backward: 24.564 ms.
I1109 02:44:46.796622 143881 caffe.cpp:522]      norm2	forward: 14.695 ms.
I1109 02:44:46.796887 143881 caffe.cpp:526]      norm2	backward: 13.876 ms.
I1109 02:44:46.797094 143881 caffe.cpp:522]      pool2	forward: 16.126 ms.
I1109 02:44:46.797298 143881 caffe.cpp:526]      pool2	backward: 67.035 ms.
I1109 02:44:46.797502 143881 caffe.cpp:522]      conv3	forward: 33.975 ms.
I1109 02:44:46.797706 143881 caffe.cpp:526]      conv3	backward: 85.381 ms.
I1109 02:44:46.797910 143881 caffe.cpp:522]      relu3	forward: 11.648 ms.
I1109 02:44:46.798112 143881 caffe.cpp:526]      relu3	backward: 34.68 ms.
I1109 02:44:46.798316 143881 caffe.cpp:522]      conv4	forward: 37.875 ms.
I1109 02:44:46.798518 143881 caffe.cpp:526]      conv4	backward: 65.18 ms.
I1109 02:44:46.798722 143881 caffe.cpp:522]      relu4	forward: 14.383 ms.
I1109 02:44:46.798925 143881 caffe.cpp:526]      relu4	backward: 31.829 ms.
I1109 02:44:46.799127 143881 caffe.cpp:522]      conv5	forward: 15.464 ms.
I1109 02:44:46.799335 143881 caffe.cpp:526]      conv5	backward: 87.27 ms.
I1109 02:44:46.799561 143881 caffe.cpp:522]      relu5	forward: 0.198 ms.
I1109 02:44:46.799785 143881 caffe.cpp:526]      relu5	backward: 15.706 ms.
I1109 02:44:46.799991 143881 caffe.cpp:522]      pool5	forward: 0.281 ms.
I1109 02:44:46.800192 143881 caffe.cpp:526]      pool5	backward: 61.384 ms.
I1109 02:44:46.800395 143881 caffe.cpp:522]        fc6	forward: 16.423 ms.
I1109 02:44:46.800598 143881 caffe.cpp:526]        fc6	backward: 252.3 ms.
I1109 02:44:46.800829 143881 caffe.cpp:522]      relu6	forward: 0.806 ms.
I1109 02:44:46.801033 143881 caffe.cpp:526]      relu6	backward: 14.74 ms.
I1109 02:44:46.801236 143881 caffe.cpp:522]      drop6	forward: 1.412 ms.
I1109 02:44:46.801434 143881 caffe.cpp:526]      drop6	backward: 16.308 ms.
I1109 02:44:46.801638 143881 caffe.cpp:522]        fc7	forward: 4.537 ms.
I1109 02:44:46.801836 143881 caffe.cpp:526]        fc7	backward: 157.36 ms.
I1109 02:44:46.802039 143881 caffe.cpp:522]      relu7	forward: 0.124 ms.
I1109 02:44:46.802933 143881 caffe.cpp:526]      relu7	backward: 15.652 ms.
I1109 02:44:46.803212 143881 caffe.cpp:522]      drop7	forward: 0.308 ms.
I1109 02:44:46.803405 143881 caffe.cpp:526]      drop7	backward: 16.706 ms.
I1109 02:44:46.803596 143881 caffe.cpp:522]        fc8	forward: 1.878 ms.
I1109 02:44:46.803781 143881 caffe.cpp:526]        fc8	backward: 190.886 ms.
I1109 02:44:46.803973 143881 caffe.cpp:522]       loss	forward: 38.932 ms.
I1109 02:44:46.804163 143881 caffe.cpp:526]       loss	backward: 47.6 ms.
I1109 02:44:46.809864 143881 caffe.cpp:532] Average Forward pass: 1089.49 ms.
I1109 02:44:46.823174 143881 caffe.cpp:535] Average Backward pass: 1443.68 ms.
I1109 02:44:46.834136 143881 caffe.cpp:537] Average Forward-Backward: 3032 ms.
I1109 02:44:46.849225 143881 caffe.cpp:540] Total Time: 3032 ms.
I1109 02:44:46.861487 143881 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 538399232
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 8614387712
--->Total double-precision FLOPs = 0
--->Total FLOPs = 8614387712
mem-read-1 = 107309
mem-read-2 = 138
mem-read-4 = 271001161
mem-read-8 = 6032446
mem-read-16 = 0
mem-read-32 = 10020
mem-read-64 = 36961333
mem-write-1 = 202
mem-write-2 = 68
mem-write-4 = 21676
mem-write-8 = 4276574
mem-write-16 = 4
mem-write-32 = 4
mem-write-64 = 14486821
--->Total Bytes read = 3498217749
--->Total Bytes written = 961456370
--->Total Bytes = 4459674119
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer14_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=14 -prof_forward_direction=0
I1109 02:49:16.945276 144052 caffe.cpp:444] Use CPU.
I1109 02:49:33.939175 144052 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:49:33.995438 144052 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:49:34.007424 144052 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:49:34.022826 144052 cpu_info.cpp:461] Total number of processors: 272
I1109 02:49:34.034044 144052 cpu_info.cpp:464] GPU is used: no
I1109 02:49:34.043141 144052 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:49:34.052096 144052 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:49:34.063097 144052 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:49:42.854343 144052 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:49:42.886942 144052 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:49:43.516588 144052 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:49:45.953474 144052 layer_factory.hpp:114] Creating layer data
I1109 02:49:46.100155 144052 net.cpp:160] Creating Layer data
I1109 02:49:46.147840 144052 net.cpp:570] data -> data
I1109 02:49:46.611330 144052 net.cpp:570] data -> label
I1109 02:49:53.651404 144052 net.cpp:210] Setting up data
I1109 02:49:53.730842 144052 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:49:53.834863 144052 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:49:53.841709 144052 net.cpp:225] Memory required for data: 19787264
I1109 02:49:53.910918 144052 layer_factory.hpp:114] Creating layer conv1
I1109 02:49:54.238461 144052 net.cpp:160] Creating Layer conv1
I1109 02:49:54.289247 144052 net.cpp:596] conv1 <- data
I1109 02:49:54.409255 144052 net.cpp:570] conv1 -> conv1
I1109 02:50:26.842164 144052 net.cpp:210] Setting up conv1
I1109 02:50:26.849292 144052 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:50:26.849695 144052 net.cpp:225] Memory required for data: 56958464
I1109 02:50:27.141158 144052 layer_factory.hpp:114] Creating layer relu1
I1109 02:50:27.261540 144052 net.cpp:160] Creating Layer relu1
I1109 02:50:27.266067 144052 net.cpp:596] relu1 <- conv1
I1109 02:50:27.298102 144052 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:50:27.486907 144052 net.cpp:210] Setting up relu1
I1109 02:50:27.489388 144052 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:50:27.489730 144052 net.cpp:225] Memory required for data: 94129664
I1109 02:50:27.489944 144052 layer_factory.hpp:114] Creating layer norm1
I1109 02:50:27.599870 144052 net.cpp:160] Creating Layer norm1
I1109 02:50:27.600196 144052 net.cpp:596] norm1 <- conv1
I1109 02:50:27.602792 144052 net.cpp:570] norm1 -> norm1
I1109 02:50:27.826696 144052 net.cpp:210] Setting up norm1
I1109 02:50:27.839447 144052 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:50:27.839834 144052 net.cpp:225] Memory required for data: 131300864
I1109 02:50:27.840170 144052 layer_factory.hpp:114] Creating layer pool1
I1109 02:50:27.934614 144052 net.cpp:160] Creating Layer pool1
I1109 02:50:27.934933 144052 net.cpp:596] pool1 <- norm1
I1109 02:50:27.949764 144052 net.cpp:570] pool1 -> pool1
I1109 02:50:28.251389 144052 net.cpp:210] Setting up pool1
I1109 02:50:28.253860 144052 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:50:28.254190 144052 net.cpp:225] Memory required for data: 140258816
I1109 02:50:28.254415 144052 layer_factory.hpp:114] Creating layer conv2
I1109 02:50:28.254819 144052 net.cpp:160] Creating Layer conv2
I1109 02:50:28.255061 144052 net.cpp:596] conv2 <- pool1
I1109 02:50:28.255321 144052 net.cpp:570] conv2 -> conv2
I1109 02:50:34.035656 144052 net.cpp:210] Setting up conv2
I1109 02:50:34.036005 144052 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:50:34.036407 144052 net.cpp:225] Memory required for data: 164146688
I1109 02:50:34.086846 144052 layer_factory.hpp:114] Creating layer relu2
I1109 02:50:34.087267 144052 net.cpp:160] Creating Layer relu2
I1109 02:50:34.087627 144052 net.cpp:596] relu2 <- conv2
I1109 02:50:34.087890 144052 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:50:34.088358 144052 net.cpp:210] Setting up relu2
I1109 02:50:34.088634 144052 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:50:34.088933 144052 net.cpp:225] Memory required for data: 188034560
I1109 02:50:34.089136 144052 layer_factory.hpp:114] Creating layer norm2
I1109 02:50:34.089395 144052 net.cpp:160] Creating Layer norm2
I1109 02:50:34.089596 144052 net.cpp:596] norm2 <- conv2
I1109 02:50:34.089831 144052 net.cpp:570] norm2 -> norm2
I1109 02:50:34.092027 144052 net.cpp:210] Setting up norm2
I1109 02:50:34.092336 144052 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:50:34.092581 144052 net.cpp:225] Memory required for data: 211922432
I1109 02:50:34.092818 144052 layer_factory.hpp:114] Creating layer pool2
I1109 02:50:34.093658 144052 net.cpp:160] Creating Layer pool2
I1109 02:50:34.094061 144052 net.cpp:596] pool2 <- norm2
I1109 02:50:34.094391 144052 net.cpp:570] pool2 -> pool2
I1109 02:50:34.094801 144052 net.cpp:210] Setting up pool2
I1109 02:50:34.095049 144052 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:50:34.095281 144052 net.cpp:225] Memory required for data: 217460224
I1109 02:50:34.095491 144052 layer_factory.hpp:114] Creating layer conv3
I1109 02:50:34.095830 144052 net.cpp:160] Creating Layer conv3
I1109 02:50:34.096051 144052 net.cpp:596] conv3 <- pool2
I1109 02:50:34.096303 144052 net.cpp:570] conv3 -> conv3
I1109 02:50:34.574600 144052 net.cpp:210] Setting up conv3
I1109 02:50:34.577033 144052 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:50:34.577389 144052 net.cpp:225] Memory required for data: 225766912
I1109 02:50:34.580432 144052 layer_factory.hpp:114] Creating layer relu3
I1109 02:50:34.580883 144052 net.cpp:160] Creating Layer relu3
I1109 02:50:34.581166 144052 net.cpp:596] relu3 <- conv3
I1109 02:50:34.581420 144052 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:50:34.585427 144052 net.cpp:210] Setting up relu3
I1109 02:50:34.585763 144052 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:50:34.586073 144052 net.cpp:225] Memory required for data: 234073600
I1109 02:50:34.586285 144052 layer_factory.hpp:114] Creating layer conv4
I1109 02:50:34.586664 144052 net.cpp:160] Creating Layer conv4
I1109 02:50:34.586925 144052 net.cpp:596] conv4 <- conv3
I1109 02:50:34.587183 144052 net.cpp:570] conv4 -> conv4
I1109 02:50:34.831720 144052 net.cpp:210] Setting up conv4
I1109 02:50:34.832118 144052 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:50:34.832556 144052 net.cpp:225] Memory required for data: 242380288
I1109 02:50:34.832924 144052 layer_factory.hpp:114] Creating layer relu4
I1109 02:50:34.833264 144052 net.cpp:160] Creating Layer relu4
I1109 02:50:34.833506 144052 net.cpp:596] relu4 <- conv4
I1109 02:50:34.833760 144052 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:50:34.846101 144052 net.cpp:210] Setting up relu4
I1109 02:50:34.846451 144052 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:50:34.846861 144052 net.cpp:225] Memory required for data: 250686976
I1109 02:50:34.847087 144052 layer_factory.hpp:114] Creating layer conv5
I1109 02:50:34.847470 144052 net.cpp:160] Creating Layer conv5
I1109 02:50:34.847721 144052 net.cpp:596] conv5 <- conv4
I1109 02:50:34.847986 144052 net.cpp:570] conv5 -> conv5
I1109 02:50:35.017179 144052 net.cpp:210] Setting up conv5
I1109 02:50:35.017571 144052 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:50:35.018019 144052 net.cpp:225] Memory required for data: 256224768
I1109 02:50:35.022552 144052 layer_factory.hpp:114] Creating layer relu5
I1109 02:50:35.022964 144052 net.cpp:160] Creating Layer relu5
I1109 02:50:35.023224 144052 net.cpp:596] relu5 <- conv5
I1109 02:50:35.023504 144052 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:50:35.024025 144052 net.cpp:210] Setting up relu5
I1109 02:50:35.024370 144052 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:50:35.024701 144052 net.cpp:225] Memory required for data: 261762560
I1109 02:50:35.024989 144052 layer_factory.hpp:114] Creating layer pool5
I1109 02:50:35.025274 144052 net.cpp:160] Creating Layer pool5
I1109 02:50:35.025506 144052 net.cpp:596] pool5 <- conv5
I1109 02:50:35.025749 144052 net.cpp:570] pool5 -> pool5
I1109 02:50:35.026162 144052 net.cpp:210] Setting up pool5
I1109 02:50:35.026428 144052 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:50:35.026670 144052 net.cpp:225] Memory required for data: 262942208
I1109 02:50:35.026867 144052 layer_factory.hpp:114] Creating layer fc6
I1109 02:50:35.083179 144052 net.cpp:160] Creating Layer fc6
I1109 02:50:35.083494 144052 net.cpp:596] fc6 <- pool5
I1109 02:50:35.083870 144052 net.cpp:570] fc6 -> fc6
I1109 02:50:39.194689 144052 net.cpp:210] Setting up fc6
I1109 02:50:39.195026 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:39.197268 144052 net.cpp:225] Memory required for data: 263466496
I1109 02:50:39.197630 144052 layer_factory.hpp:114] Creating layer relu6
I1109 02:50:39.200206 144052 net.cpp:160] Creating Layer relu6
I1109 02:50:39.200513 144052 net.cpp:596] relu6 <- fc6
I1109 02:50:39.200763 144052 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:50:39.201268 144052 net.cpp:210] Setting up relu6
I1109 02:50:39.201551 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:39.201799 144052 net.cpp:225] Memory required for data: 263990784
I1109 02:50:39.202003 144052 layer_factory.hpp:114] Creating layer drop6
I1109 02:50:39.221892 144052 net.cpp:160] Creating Layer drop6
I1109 02:50:39.222285 144052 net.cpp:596] drop6 <- fc6
I1109 02:50:39.222672 144052 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:50:39.326109 144052 net.cpp:210] Setting up drop6
I1109 02:50:39.326409 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:39.326755 144052 net.cpp:225] Memory required for data: 264515072
I1109 02:50:39.327004 144052 layer_factory.hpp:114] Creating layer fc7
I1109 02:50:39.327282 144052 net.cpp:160] Creating Layer fc7
I1109 02:50:39.327497 144052 net.cpp:596] fc7 <- fc6
I1109 02:50:39.327891 144052 net.cpp:570] fc7 -> fc7
I1109 02:50:41.050710 144052 net.cpp:210] Setting up fc7
I1109 02:50:41.051079 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:41.051524 144052 net.cpp:225] Memory required for data: 265039360
I1109 02:50:41.051862 144052 layer_factory.hpp:114] Creating layer relu7
I1109 02:50:41.052202 144052 net.cpp:160] Creating Layer relu7
I1109 02:50:41.052458 144052 net.cpp:596] relu7 <- fc7
I1109 02:50:41.052729 144052 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:50:41.053254 144052 net.cpp:210] Setting up relu7
I1109 02:50:41.053580 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:41.053854 144052 net.cpp:225] Memory required for data: 265563648
I1109 02:50:41.054083 144052 layer_factory.hpp:114] Creating layer drop7
I1109 02:50:41.054378 144052 net.cpp:160] Creating Layer drop7
I1109 02:50:41.054597 144052 net.cpp:596] drop7 <- fc7
I1109 02:50:41.054858 144052 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:50:41.055150 144052 net.cpp:210] Setting up drop7
I1109 02:50:41.055366 144052 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:50:41.055599 144052 net.cpp:225] Memory required for data: 266087936
I1109 02:50:41.055799 144052 layer_factory.hpp:114] Creating layer fc8
I1109 02:50:41.056063 144052 net.cpp:160] Creating Layer fc8
I1109 02:50:41.056274 144052 net.cpp:596] fc8 <- fc7
I1109 02:50:41.056556 144052 net.cpp:570] fc8 -> fc8
I1109 02:50:41.480820 144052 net.cpp:210] Setting up fc8
I1109 02:50:41.481186 144052 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:50:41.481637 144052 net.cpp:225] Memory required for data: 266215936
I1109 02:50:41.481979 144052 layer_factory.hpp:114] Creating layer loss
I1109 02:50:41.506523 144052 net.cpp:160] Creating Layer loss
I1109 02:50:41.506845 144052 net.cpp:596] loss <- fc8
I1109 02:50:41.507776 144052 net.cpp:596] loss <- label
I1109 02:50:41.535018 144052 net.cpp:570] loss -> loss
I1109 02:50:41.572562 144052 layer_factory.hpp:114] Creating layer loss
I1109 02:50:44.153174 144052 net.cpp:210] Setting up loss
I1109 02:50:44.203707 144052 net.cpp:217] Top shape: (1)
I1109 02:50:44.213260 144052 net.cpp:220]     with loss weight 1
I1109 02:50:44.344295 144052 net.cpp:225] Memory required for data: 266215940
I1109 02:50:44.387565 144052 net.cpp:287] loss needs backward computation.
I1109 02:50:44.482172 144052 net.cpp:287] fc8 needs backward computation.
I1109 02:50:44.490178 144052 net.cpp:287] drop7 needs backward computation.
I1109 02:50:44.501088 144052 net.cpp:287] relu7 needs backward computation.
I1109 02:50:44.501413 144052 net.cpp:287] fc7 needs backward computation.
I1109 02:50:44.503809 144052 net.cpp:287] drop6 needs backward computation.
I1109 02:50:44.504112 144052 net.cpp:287] relu6 needs backward computation.
I1109 02:50:44.504345 144052 net.cpp:287] fc6 needs backward computation.
I1109 02:50:44.505182 144052 net.cpp:287] pool5 needs backward computation.
I1109 02:50:44.506008 144052 net.cpp:287] relu5 needs backward computation.
I1109 02:50:44.506304 144052 net.cpp:287] conv5 needs backward computation.
I1109 02:50:44.506523 144052 net.cpp:287] relu4 needs backward computation.
I1109 02:50:44.506768 144052 net.cpp:287] conv4 needs backward computation.
I1109 02:50:44.506969 144052 net.cpp:287] relu3 needs backward computation.
I1109 02:50:44.507164 144052 net.cpp:287] conv3 needs backward computation.
I1109 02:50:44.519109 144052 net.cpp:287] pool2 needs backward computation.
I1109 02:50:44.519469 144052 net.cpp:287] norm2 needs backward computation.
I1109 02:50:44.519784 144052 net.cpp:287] relu2 needs backward computation.
I1109 02:50:44.520031 144052 net.cpp:287] conv2 needs backward computation.
I1109 02:50:44.520234 144052 net.cpp:287] pool1 needs backward computation.
I1109 02:50:44.520427 144052 net.cpp:287] norm1 needs backward computation.
I1109 02:50:44.520622 144052 net.cpp:287] relu1 needs backward computation.
I1109 02:50:44.520843 144052 net.cpp:287] conv1 needs backward computation.
I1109 02:50:44.533037 144052 net.cpp:289] data does not need backward computation.
I1109 02:50:44.557762 144052 net.cpp:331] This network produces output loss
I1109 02:50:44.630589 144052 net.cpp:345] Network initialization done.
I1109 02:50:44.797650 144052 caffe.cpp:452] Performing Forward
I1109 02:50:57.976191 144052 caffe.cpp:457] Initial loss: 6.87819
I1109 02:50:58.031901 144052 caffe.cpp:459] Performing Backward
I1109 02:51:02.720968 144052 caffe.cpp:468] *** Benchmark begins ***
I1109 02:51:02.736289 144052 caffe.cpp:469] Testing for 1 iterations.
I1109 02:51:02.880100 144052 caffe.cpp:485] Profiling Layer: relu5 backward
I1109 02:51:05.138368 144052 caffe.cpp:512] Iteration: 1 forward-backward time: 2252 ms.
I1109 02:51:05.295516 144052 caffe.cpp:519] Average time per layer: 
I1109 02:51:05.310478 144052 caffe.cpp:522]       data	forward: 548.662 ms.
I1109 02:51:05.382484 144052 caffe.cpp:526]       data	backward: 5.712 ms.
I1109 02:51:05.406138 144052 caffe.cpp:522]      conv1	forward: 128.638 ms.
I1109 02:51:05.412962 144052 caffe.cpp:526]      conv1	backward: 36.521 ms.
I1109 02:51:05.421571 144052 caffe.cpp:522]      relu1	forward: 20.038 ms.
I1109 02:51:05.436288 144052 caffe.cpp:526]      relu1	backward: 21.177 ms.
I1109 02:51:05.451910 144052 caffe.cpp:522]      norm1	forward: 19.821 ms.
I1109 02:51:05.462698 144052 caffe.cpp:526]      norm1	backward: 21.011 ms.
I1109 02:51:05.470393 144052 caffe.cpp:522]      pool1	forward: 25.721 ms.
I1109 02:51:05.479545 144052 caffe.cpp:526]      pool1	backward: 89.005 ms.
I1109 02:51:05.495537 144052 caffe.cpp:522]      conv2	forward: 62.053 ms.
I1109 02:51:05.503484 144052 caffe.cpp:526]      conv2	backward: 39.122 ms.
I1109 02:51:05.508455 144052 caffe.cpp:522]      relu2	forward: 19.909 ms.
I1109 02:51:05.508754 144052 caffe.cpp:526]      relu2	backward: 0.753 ms.
I1109 02:51:05.509004 144052 caffe.cpp:522]      norm2	forward: 22.113 ms.
I1109 02:51:05.509244 144052 caffe.cpp:526]      norm2	backward: 2.113 ms.
I1109 02:51:05.509485 144052 caffe.cpp:522]      pool2	forward: 13.764 ms.
I1109 02:51:05.509758 144052 caffe.cpp:526]      pool2	backward: 22.323 ms.
I1109 02:51:05.509995 144052 caffe.cpp:522]      conv3	forward: 40.192 ms.
I1109 02:51:05.510196 144052 caffe.cpp:526]      conv3	backward: 36.452 ms.
I1109 02:51:05.510396 144052 caffe.cpp:522]      relu3	forward: 16.837 ms.
I1109 02:51:05.510594 144052 caffe.cpp:526]      relu3	backward: 0.609 ms.
I1109 02:51:05.510787 144052 caffe.cpp:522]      conv4	forward: 32.522 ms.
I1109 02:51:05.510979 144052 caffe.cpp:526]      conv4	backward: 27.888 ms.
I1109 02:51:05.511173 144052 caffe.cpp:522]      relu4	forward: 13.173 ms.
I1109 02:51:05.511363 144052 caffe.cpp:526]      relu4	backward: 7.603 ms.
I1109 02:51:05.511548 144052 caffe.cpp:522]      conv5	forward: 29.378 ms.
I1109 02:51:05.511739 144052 caffe.cpp:526]      conv5	backward: 18.884 ms.
I1109 02:51:05.511929 144052 caffe.cpp:522]      relu5	forward: 15.568 ms.
I1109 02:51:05.512120 144052 caffe.cpp:526]      relu5	backward: 11.135 ms.
I1109 02:51:05.512349 144052 caffe.cpp:522]      pool5	forward: 13.262 ms.
I1109 02:51:05.512568 144052 caffe.cpp:526]      pool5	backward: 9.41 ms.
I1109 02:51:05.513592 144052 caffe.cpp:522]        fc6	forward: 35.225 ms.
I1109 02:51:05.513829 144052 caffe.cpp:526]        fc6	backward: 31.32 ms.
I1109 02:51:05.514031 144052 caffe.cpp:522]      relu6	forward: 15.7 ms.
I1109 02:51:05.514232 144052 caffe.cpp:526]      relu6	backward: 0.41 ms.
I1109 02:51:05.514430 144052 caffe.cpp:522]      drop6	forward: 43.73 ms.
I1109 02:51:05.514627 144052 caffe.cpp:526]      drop6	backward: 11.066 ms.
I1109 02:51:05.514825 144052 caffe.cpp:522]        fc7	forward: 15.864 ms.
I1109 02:51:05.515020 144052 caffe.cpp:526]        fc7	backward: 231.483 ms.
I1109 02:51:05.515216 144052 caffe.cpp:522]      relu7	forward: 11.816 ms.
I1109 02:51:05.515440 144052 caffe.cpp:526]      relu7	backward: 21.671 ms.
I1109 02:51:05.515645 144052 caffe.cpp:522]      drop7	forward: 30.696 ms.
I1109 02:51:05.515902 144052 caffe.cpp:526]      drop7	backward: 17.118 ms.
I1109 02:51:05.516180 144052 caffe.cpp:522]        fc8	forward: 18.145 ms.
I1109 02:51:05.516417 144052 caffe.cpp:526]        fc8	backward: 188.047 ms.
I1109 02:51:05.518703 144052 caffe.cpp:522]       loss	forward: 55.984 ms.
I1109 02:51:05.519001 144052 caffe.cpp:526]       loss	backward: 57.234 ms.
I1109 02:51:05.524569 144052 caffe.cpp:532] Average Forward pass: 1309.01 ms.
I1109 02:51:05.537554 144052 caffe.cpp:535] Average Backward pass: 916.813 ms.
I1109 02:51:05.548107 144052 caffe.cpp:537] Average Forward-Backward: 2746 ms.
I1109 02:51:05.562542 144052 caffe.cpp:540] Total Time: 2746 ms.
I1109 02:51:05.574594 144052 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 86528
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 173056
--->Total FLOPs = 173056
mem-read-1 = 395874
mem-read-2 = 34
mem-read-4 = 3170701
mem-read-8 = 4363036
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 173057
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 542
mem-write-8 = 399458
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 86529
--->Total Bytes read = 59058714
--->Total Bytes written = 8735804
--->Total Bytes = 67794518
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer15_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=15 -prof_forward_direction=0
I1109 02:54:38.384865 144172 caffe.cpp:444] Use CPU.
I1109 02:54:55.404243 144172 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 02:54:55.461091 144172 cpu_info.cpp:455] Total number of sockets: 1
I1109 02:54:55.472749 144172 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 02:54:55.485417 144172 cpu_info.cpp:461] Total number of processors: 272
I1109 02:54:55.496672 144172 cpu_info.cpp:464] GPU is used: no
I1109 02:54:55.505935 144172 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 02:54:55.514864 144172 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 02:54:55.526198 144172 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 02:55:04.393177 144172 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 02:55:04.426403 144172 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 02:55:05.062794 144172 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 02:55:07.542866 144172 layer_factory.hpp:114] Creating layer data
I1109 02:55:07.692936 144172 net.cpp:160] Creating Layer data
I1109 02:55:07.741307 144172 net.cpp:570] data -> data
I1109 02:55:08.214570 144172 net.cpp:570] data -> label
I1109 02:55:15.275282 144172 net.cpp:210] Setting up data
I1109 02:55:15.403390 144172 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 02:55:15.507336 144172 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 02:55:15.514647 144172 net.cpp:225] Memory required for data: 19787264
I1109 02:55:15.584380 144172 layer_factory.hpp:114] Creating layer conv1
I1109 02:55:15.912866 144172 net.cpp:160] Creating Layer conv1
I1109 02:55:15.962640 144172 net.cpp:596] conv1 <- data
I1109 02:55:16.083647 144172 net.cpp:570] conv1 -> conv1
I1109 02:55:48.648488 144172 net.cpp:210] Setting up conv1
I1109 02:55:48.655459 144172 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:55:48.655864 144172 net.cpp:225] Memory required for data: 56958464
I1109 02:55:48.937630 144172 layer_factory.hpp:114] Creating layer relu1
I1109 02:55:49.058584 144172 net.cpp:160] Creating Layer relu1
I1109 02:55:49.063161 144172 net.cpp:596] relu1 <- conv1
I1109 02:55:49.095896 144172 net.cpp:557] relu1 -> conv1 (in-place)
I1109 02:55:49.286625 144172 net.cpp:210] Setting up relu1
I1109 02:55:49.289055 144172 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:55:49.289397 144172 net.cpp:225] Memory required for data: 94129664
I1109 02:55:49.289600 144172 layer_factory.hpp:114] Creating layer norm1
I1109 02:55:49.394099 144172 net.cpp:160] Creating Layer norm1
I1109 02:55:49.394412 144172 net.cpp:596] norm1 <- conv1
I1109 02:55:49.396937 144172 net.cpp:570] norm1 -> norm1
I1109 02:55:49.618911 144172 net.cpp:210] Setting up norm1
I1109 02:55:49.631654 144172 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 02:55:49.632036 144172 net.cpp:225] Memory required for data: 131300864
I1109 02:55:49.632341 144172 layer_factory.hpp:114] Creating layer pool1
I1109 02:55:49.725487 144172 net.cpp:160] Creating Layer pool1
I1109 02:55:49.725803 144172 net.cpp:596] pool1 <- norm1
I1109 02:55:49.740636 144172 net.cpp:570] pool1 -> pool1
I1109 02:55:50.043198 144172 net.cpp:210] Setting up pool1
I1109 02:55:50.045703 144172 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 02:55:50.046035 144172 net.cpp:225] Memory required for data: 140258816
I1109 02:55:50.046254 144172 layer_factory.hpp:114] Creating layer conv2
I1109 02:55:50.046651 144172 net.cpp:160] Creating Layer conv2
I1109 02:55:50.046892 144172 net.cpp:596] conv2 <- pool1
I1109 02:55:50.047202 144172 net.cpp:570] conv2 -> conv2
I1109 02:55:55.800225 144172 net.cpp:210] Setting up conv2
I1109 02:55:55.800567 144172 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:55:55.801021 144172 net.cpp:225] Memory required for data: 164146688
I1109 02:55:55.851749 144172 layer_factory.hpp:114] Creating layer relu2
I1109 02:55:55.852243 144172 net.cpp:160] Creating Layer relu2
I1109 02:55:55.852607 144172 net.cpp:596] relu2 <- conv2
I1109 02:55:55.852898 144172 net.cpp:557] relu2 -> conv2 (in-place)
I1109 02:55:55.853358 144172 net.cpp:210] Setting up relu2
I1109 02:55:55.853621 144172 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:55:55.853850 144172 net.cpp:225] Memory required for data: 188034560
I1109 02:55:55.854037 144172 layer_factory.hpp:114] Creating layer norm2
I1109 02:55:55.854280 144172 net.cpp:160] Creating Layer norm2
I1109 02:55:55.854477 144172 net.cpp:596] norm2 <- conv2
I1109 02:55:55.854707 144172 net.cpp:570] norm2 -> norm2
I1109 02:55:55.856835 144172 net.cpp:210] Setting up norm2
I1109 02:55:55.857156 144172 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 02:55:55.857390 144172 net.cpp:225] Memory required for data: 211922432
I1109 02:55:55.857578 144172 layer_factory.hpp:114] Creating layer pool2
I1109 02:55:55.858423 144172 net.cpp:160] Creating Layer pool2
I1109 02:55:55.858731 144172 net.cpp:596] pool2 <- norm2
I1109 02:55:55.859127 144172 net.cpp:570] pool2 -> pool2
I1109 02:55:55.859586 144172 net.cpp:210] Setting up pool2
I1109 02:55:55.859828 144172 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:55:55.860051 144172 net.cpp:225] Memory required for data: 217460224
I1109 02:55:55.860249 144172 layer_factory.hpp:114] Creating layer conv3
I1109 02:55:55.860576 144172 net.cpp:160] Creating Layer conv3
I1109 02:55:55.860827 144172 net.cpp:596] conv3 <- pool2
I1109 02:55:55.861090 144172 net.cpp:570] conv3 -> conv3
I1109 02:55:56.362634 144172 net.cpp:210] Setting up conv3
I1109 02:55:56.365030 144172 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:55:56.365381 144172 net.cpp:225] Memory required for data: 225766912
I1109 02:55:56.368517 144172 layer_factory.hpp:114] Creating layer relu3
I1109 02:55:56.368973 144172 net.cpp:160] Creating Layer relu3
I1109 02:55:56.369246 144172 net.cpp:596] relu3 <- conv3
I1109 02:55:56.369500 144172 net.cpp:557] relu3 -> conv3 (in-place)
I1109 02:55:56.373903 144172 net.cpp:210] Setting up relu3
I1109 02:55:56.374217 144172 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:55:56.374471 144172 net.cpp:225] Memory required for data: 234073600
I1109 02:55:56.374671 144172 layer_factory.hpp:114] Creating layer conv4
I1109 02:55:56.375036 144172 net.cpp:160] Creating Layer conv4
I1109 02:55:56.375293 144172 net.cpp:596] conv4 <- conv3
I1109 02:55:56.375540 144172 net.cpp:570] conv4 -> conv4
I1109 02:55:56.618139 144172 net.cpp:210] Setting up conv4
I1109 02:55:56.618527 144172 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:55:56.618922 144172 net.cpp:225] Memory required for data: 242380288
I1109 02:55:56.619266 144172 layer_factory.hpp:114] Creating layer relu4
I1109 02:55:56.619557 144172 net.cpp:160] Creating Layer relu4
I1109 02:55:56.619786 144172 net.cpp:596] relu4 <- conv4
I1109 02:55:56.620018 144172 net.cpp:557] relu4 -> conv4 (in-place)
I1109 02:55:56.632117 144172 net.cpp:210] Setting up relu4
I1109 02:55:56.632463 144172 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 02:55:56.632886 144172 net.cpp:225] Memory required for data: 250686976
I1109 02:55:56.633178 144172 layer_factory.hpp:114] Creating layer conv5
I1109 02:55:56.633572 144172 net.cpp:160] Creating Layer conv5
I1109 02:55:56.633812 144172 net.cpp:596] conv5 <- conv4
I1109 02:55:56.634059 144172 net.cpp:570] conv5 -> conv5
I1109 02:55:56.802003 144172 net.cpp:210] Setting up conv5
I1109 02:55:56.802393 144172 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:55:56.802805 144172 net.cpp:225] Memory required for data: 256224768
I1109 02:55:56.807468 144172 layer_factory.hpp:114] Creating layer relu5
I1109 02:55:56.807871 144172 net.cpp:160] Creating Layer relu5
I1109 02:55:56.808123 144172 net.cpp:596] relu5 <- conv5
I1109 02:55:56.808389 144172 net.cpp:557] relu5 -> conv5 (in-place)
I1109 02:55:56.808934 144172 net.cpp:210] Setting up relu5
I1109 02:55:56.809255 144172 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 02:55:56.809551 144172 net.cpp:225] Memory required for data: 261762560
I1109 02:55:56.809762 144172 layer_factory.hpp:114] Creating layer pool5
I1109 02:55:56.810031 144172 net.cpp:160] Creating Layer pool5
I1109 02:55:56.810247 144172 net.cpp:596] pool5 <- conv5
I1109 02:55:56.810477 144172 net.cpp:570] pool5 -> pool5
I1109 02:55:56.810880 144172 net.cpp:210] Setting up pool5
I1109 02:55:56.811147 144172 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 02:55:56.811372 144172 net.cpp:225] Memory required for data: 262942208
I1109 02:55:56.811560 144172 layer_factory.hpp:114] Creating layer fc6
I1109 02:55:56.866071 144172 net.cpp:160] Creating Layer fc6
I1109 02:55:56.866384 144172 net.cpp:596] fc6 <- pool5
I1109 02:55:56.866760 144172 net.cpp:570] fc6 -> fc6
I1109 02:56:00.963475 144172 net.cpp:210] Setting up fc6
I1109 02:56:00.963834 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:00.965962 144172 net.cpp:225] Memory required for data: 263466496
I1109 02:56:00.966271 144172 layer_factory.hpp:114] Creating layer relu6
I1109 02:56:00.968672 144172 net.cpp:160] Creating Layer relu6
I1109 02:56:00.969025 144172 net.cpp:596] relu6 <- fc6
I1109 02:56:00.969271 144172 net.cpp:557] relu6 -> fc6 (in-place)
I1109 02:56:00.969787 144172 net.cpp:210] Setting up relu6
I1109 02:56:00.970041 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:00.970266 144172 net.cpp:225] Memory required for data: 263990784
I1109 02:56:00.970451 144172 layer_factory.hpp:114] Creating layer drop6
I1109 02:56:00.990835 144172 net.cpp:160] Creating Layer drop6
I1109 02:56:00.991152 144172 net.cpp:596] drop6 <- fc6
I1109 02:56:00.991504 144172 net.cpp:557] drop6 -> fc6 (in-place)
I1109 02:56:01.095827 144172 net.cpp:210] Setting up drop6
I1109 02:56:01.096127 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:01.096494 144172 net.cpp:225] Memory required for data: 264515072
I1109 02:56:01.096705 144172 layer_factory.hpp:114] Creating layer fc7
I1109 02:56:01.097021 144172 net.cpp:160] Creating Layer fc7
I1109 02:56:01.097234 144172 net.cpp:596] fc7 <- fc6
I1109 02:56:01.097622 144172 net.cpp:570] fc7 -> fc7
I1109 02:56:02.811031 144172 net.cpp:210] Setting up fc7
I1109 02:56:02.811403 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:02.811851 144172 net.cpp:225] Memory required for data: 265039360
I1109 02:56:02.812191 144172 layer_factory.hpp:114] Creating layer relu7
I1109 02:56:02.812531 144172 net.cpp:160] Creating Layer relu7
I1109 02:56:02.812829 144172 net.cpp:596] relu7 <- fc7
I1109 02:56:02.813118 144172 net.cpp:557] relu7 -> fc7 (in-place)
I1109 02:56:02.813583 144172 net.cpp:210] Setting up relu7
I1109 02:56:02.813886 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:02.814184 144172 net.cpp:225] Memory required for data: 265563648
I1109 02:56:02.814410 144172 layer_factory.hpp:114] Creating layer drop7
I1109 02:56:02.814668 144172 net.cpp:160] Creating Layer drop7
I1109 02:56:02.814911 144172 net.cpp:596] drop7 <- fc7
I1109 02:56:02.815165 144172 net.cpp:557] drop7 -> fc7 (in-place)
I1109 02:56:02.815444 144172 net.cpp:210] Setting up drop7
I1109 02:56:02.815656 144172 net.cpp:217] Top shape: 32 4096 (131072)
I1109 02:56:02.815879 144172 net.cpp:225] Memory required for data: 266087936
I1109 02:56:02.816067 144172 layer_factory.hpp:114] Creating layer fc8
I1109 02:56:02.816326 144172 net.cpp:160] Creating Layer fc8
I1109 02:56:02.816529 144172 net.cpp:596] fc8 <- fc7
I1109 02:56:02.816761 144172 net.cpp:570] fc8 -> fc8
I1109 02:56:03.240010 144172 net.cpp:210] Setting up fc8
I1109 02:56:03.240360 144172 net.cpp:217] Top shape: 32 1000 (32000)
I1109 02:56:03.240746 144172 net.cpp:225] Memory required for data: 266215936
I1109 02:56:03.241129 144172 layer_factory.hpp:114] Creating layer loss
I1109 02:56:03.265877 144172 net.cpp:160] Creating Layer loss
I1109 02:56:03.266197 144172 net.cpp:596] loss <- fc8
I1109 02:56:03.267215 144172 net.cpp:596] loss <- label
I1109 02:56:03.295030 144172 net.cpp:570] loss -> loss
I1109 02:56:03.333191 144172 layer_factory.hpp:114] Creating layer loss
I1109 02:56:05.904129 144172 net.cpp:210] Setting up loss
I1109 02:56:05.955176 144172 net.cpp:217] Top shape: (1)
I1109 02:56:05.966620 144172 net.cpp:220]     with loss weight 1
I1109 02:56:06.097831 144172 net.cpp:225] Memory required for data: 266215940
I1109 02:56:06.137825 144172 net.cpp:287] loss needs backward computation.
I1109 02:56:06.224565 144172 net.cpp:287] fc8 needs backward computation.
I1109 02:56:06.231837 144172 net.cpp:287] drop7 needs backward computation.
I1109 02:56:06.242823 144172 net.cpp:287] relu7 needs backward computation.
I1109 02:56:06.243146 144172 net.cpp:287] fc7 needs backward computation.
I1109 02:56:06.245612 144172 net.cpp:287] drop6 needs backward computation.
I1109 02:56:06.245954 144172 net.cpp:287] relu6 needs backward computation.
I1109 02:56:06.246178 144172 net.cpp:287] fc6 needs backward computation.
I1109 02:56:06.247009 144172 net.cpp:287] pool5 needs backward computation.
I1109 02:56:06.247761 144172 net.cpp:287] relu5 needs backward computation.
I1109 02:56:06.248034 144172 net.cpp:287] conv5 needs backward computation.
I1109 02:56:06.248239 144172 net.cpp:287] relu4 needs backward computation.
I1109 02:56:06.248435 144172 net.cpp:287] conv4 needs backward computation.
I1109 02:56:06.248622 144172 net.cpp:287] relu3 needs backward computation.
I1109 02:56:06.248888 144172 net.cpp:287] conv3 needs backward computation.
I1109 02:56:06.260995 144172 net.cpp:287] pool2 needs backward computation.
I1109 02:56:06.261343 144172 net.cpp:287] norm2 needs backward computation.
I1109 02:56:06.261683 144172 net.cpp:287] relu2 needs backward computation.
I1109 02:56:06.261893 144172 net.cpp:287] conv2 needs backward computation.
I1109 02:56:06.262086 144172 net.cpp:287] pool1 needs backward computation.
I1109 02:56:06.262269 144172 net.cpp:287] norm1 needs backward computation.
I1109 02:56:06.262451 144172 net.cpp:287] relu1 needs backward computation.
I1109 02:56:06.262630 144172 net.cpp:287] conv1 needs backward computation.
I1109 02:56:06.275002 144172 net.cpp:289] data does not need backward computation.
I1109 02:56:06.299684 144172 net.cpp:331] This network produces output loss
I1109 02:56:06.374672 144172 net.cpp:345] Network initialization done.
I1109 02:56:06.542485 144172 caffe.cpp:452] Performing Forward
I1109 02:56:19.383066 144172 caffe.cpp:457] Initial loss: 6.97301
I1109 02:56:19.440307 144172 caffe.cpp:459] Performing Backward
I1109 02:56:24.484709 144172 caffe.cpp:468] *** Benchmark begins ***
I1109 02:56:24.495714 144172 caffe.cpp:469] Testing for 1 iterations.
I1109 02:56:24.644623 144172 caffe.cpp:485] Profiling Layer: pool5 backward
I1109 02:56:26.765943 144172 caffe.cpp:512] Iteration: 1 forward-backward time: 2115 ms.
I1109 02:56:26.920330 144172 caffe.cpp:519] Average time per layer: 
I1109 02:56:26.941932 144172 caffe.cpp:522]       data	forward: 549.293 ms.
I1109 02:56:27.021453 144172 caffe.cpp:526]       data	backward: 5.307 ms.
I1109 02:56:27.043715 144172 caffe.cpp:522]      conv1	forward: 132.94 ms.
I1109 02:56:27.051774 144172 caffe.cpp:526]      conv1	backward: 49.305 ms.
I1109 02:56:27.061807 144172 caffe.cpp:522]      relu1	forward: 27.768 ms.
I1109 02:56:27.067586 144172 caffe.cpp:526]      relu1	backward: 19.157 ms.
I1109 02:56:27.075785 144172 caffe.cpp:522]      norm1	forward: 15.933 ms.
I1109 02:56:27.081581 144172 caffe.cpp:526]      norm1	backward: 10.469 ms.
I1109 02:56:27.087817 144172 caffe.cpp:522]      pool1	forward: 24.819 ms.
I1109 02:56:27.091946 144172 caffe.cpp:526]      pool1	backward: 78.432 ms.
I1109 02:56:27.096451 144172 caffe.cpp:522]      conv2	forward: 62.683 ms.
I1109 02:56:27.104322 144172 caffe.cpp:526]      conv2	backward: 83.641 ms.
I1109 02:56:27.111387 144172 caffe.cpp:522]      relu2	forward: 17.314 ms.
I1109 02:56:27.115329 144172 caffe.cpp:526]      relu2	backward: 15.757 ms.
I1109 02:56:27.121681 144172 caffe.cpp:522]      norm2	forward: 10.361 ms.
I1109 02:56:27.128160 144172 caffe.cpp:526]      norm2	backward: 17.929 ms.
I1109 02:56:27.128459 144172 caffe.cpp:522]      pool2	forward: 14.713 ms.
I1109 02:56:27.128655 144172 caffe.cpp:526]      pool2	backward: 53.465 ms.
I1109 02:56:27.128888 144172 caffe.cpp:522]      conv3	forward: 41.449 ms.
I1109 02:56:27.129081 144172 caffe.cpp:526]      conv3	backward: 86 ms.
I1109 02:56:27.129271 144172 caffe.cpp:522]      relu3	forward: 13.373 ms.
I1109 02:56:27.129462 144172 caffe.cpp:526]      relu3	backward: 32.297 ms.
I1109 02:56:27.129652 144172 caffe.cpp:522]      conv4	forward: 31.308 ms.
I1109 02:56:27.129842 144172 caffe.cpp:526]      conv4	backward: 36.274 ms.
I1109 02:56:27.130033 144172 caffe.cpp:522]      relu4	forward: 22.44 ms.
I1109 02:56:27.130223 144172 caffe.cpp:526]      relu4	backward: 7.451 ms.
I1109 02:56:27.130409 144172 caffe.cpp:522]      conv5	forward: 31.81 ms.
I1109 02:56:27.130599 144172 caffe.cpp:526]      conv5	backward: 19.135 ms.
I1109 02:56:27.130790 144172 caffe.cpp:522]      relu5	forward: 17.979 ms.
I1109 02:56:27.130980 144172 caffe.cpp:526]      relu5	backward: 0.25 ms.
I1109 02:56:27.131170 144172 caffe.cpp:522]      pool5	forward: 18.38 ms.
I1109 02:56:27.131359 144172 caffe.cpp:526]      pool5	backward: 19.84 ms.
I1109 02:56:27.131549 144172 caffe.cpp:522]        fc6	forward: 43.042 ms.
I1109 02:56:27.131741 144172 caffe.cpp:526]        fc6	backward: 28.201 ms.
I1109 02:56:27.131930 144172 caffe.cpp:522]      relu6	forward: 14.383 ms.
I1109 02:56:27.132122 144172 caffe.cpp:526]      relu6	backward: 0.082 ms.
I1109 02:56:27.134521 144172 caffe.cpp:522]      drop6	forward: 29.315 ms.
I1109 02:56:27.134770 144172 caffe.cpp:526]      drop6	backward: 0.087 ms.
I1109 02:56:27.134973 144172 caffe.cpp:522]        fc7	forward: 17.257 ms.
I1109 02:56:27.135169 144172 caffe.cpp:526]        fc7	backward: 25.676 ms.
I1109 02:56:27.135365 144172 caffe.cpp:522]      relu7	forward: 12.615 ms.
I1109 02:56:27.135557 144172 caffe.cpp:526]      relu7	backward: 0.083 ms.
I1109 02:56:27.135748 144172 caffe.cpp:522]      drop7	forward: 23.416 ms.
I1109 02:56:27.135939 144172 caffe.cpp:526]      drop7	backward: 0.09 ms.
I1109 02:56:27.136128 144172 caffe.cpp:522]        fc8	forward: 20.597 ms.
I1109 02:56:27.136319 144172 caffe.cpp:526]        fc8	backward: 84.615 ms.
I1109 02:56:27.136510 144172 caffe.cpp:522]       loss	forward: 76.108 ms.
I1109 02:56:27.136701 144172 caffe.cpp:526]       loss	backward: 78.97 ms.
I1109 02:56:27.141676 144172 caffe.cpp:532] Average Forward pass: 1326.13 ms.
I1109 02:56:27.155555 144172 caffe.cpp:535] Average Backward pass: 762.751 ms.
I1109 02:56:27.166497 144172 caffe.cpp:537] Average Forward-Backward: 2599 ms.
I1109 02:56:27.181274 144172 caffe.cpp:540] Total Time: 2599 ms.
I1109 02:56:27.193460 144172 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 18432
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 294912
--->Total double-precision FLOPs = 0
--->Total FLOPs = 294912
mem-read-1 = 417354
mem-read-2 = 104
mem-read-4 = 3397483
mem-read-8 = 5620003
mem-read-16 = 0
mem-read-32 = 98306
mem-read-64 = 202786
mem-write-1 = 154
mem-write-2 = 51
mem-write-4 = 309407
mem-write-8 = 611771
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 158210
--->Total Bytes read = 75091614
--->Total Bytes written = 16257556
--->Total Bytes = 91349170
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer16_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=16 -prof_forward_direction=0
I1109 03:00:22.502769 144290 caffe.cpp:444] Use CPU.
I1109 03:00:39.316923 144290 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:00:39.372577 144290 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:00:39.384609 144290 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:00:39.397181 144290 cpu_info.cpp:461] Total number of processors: 272
I1109 03:00:39.408500 144290 cpu_info.cpp:464] GPU is used: no
I1109 03:00:39.417632 144290 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:00:39.426563 144290 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:00:39.437551 144290 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:00:48.188498 144290 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:00:48.219691 144290 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:00:48.853377 144290 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:00:51.301725 144290 layer_factory.hpp:114] Creating layer data
I1109 03:00:51.448971 144290 net.cpp:160] Creating Layer data
I1109 03:00:51.496834 144290 net.cpp:570] data -> data
I1109 03:00:51.964977 144290 net.cpp:570] data -> label
I1109 03:00:58.998251 144290 net.cpp:210] Setting up data
I1109 03:00:59.077414 144290 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:00:59.181534 144290 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:00:59.188817 144290 net.cpp:225] Memory required for data: 19787264
I1109 03:00:59.255980 144290 layer_factory.hpp:114] Creating layer conv1
I1109 03:00:59.587045 144290 net.cpp:160] Creating Layer conv1
I1109 03:00:59.637835 144290 net.cpp:596] conv1 <- data
I1109 03:00:59.757448 144290 net.cpp:570] conv1 -> conv1
I1109 03:01:32.452304 144290 net.cpp:210] Setting up conv1
I1109 03:01:32.459484 144290 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:01:32.459841 144290 net.cpp:225] Memory required for data: 56958464
I1109 03:01:32.739552 144290 layer_factory.hpp:114] Creating layer relu1
I1109 03:01:32.859926 144290 net.cpp:160] Creating Layer relu1
I1109 03:01:32.864548 144290 net.cpp:596] relu1 <- conv1
I1109 03:01:32.896744 144290 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:01:33.086446 144290 net.cpp:210] Setting up relu1
I1109 03:01:33.088953 144290 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:01:33.089299 144290 net.cpp:225] Memory required for data: 94129664
I1109 03:01:33.089541 144290 layer_factory.hpp:114] Creating layer norm1
I1109 03:01:33.193688 144290 net.cpp:160] Creating Layer norm1
I1109 03:01:33.194006 144290 net.cpp:596] norm1 <- conv1
I1109 03:01:33.196569 144290 net.cpp:570] norm1 -> norm1
I1109 03:01:33.418234 144290 net.cpp:210] Setting up norm1
I1109 03:01:33.431138 144290 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:01:33.431522 144290 net.cpp:225] Memory required for data: 131300864
I1109 03:01:33.431833 144290 layer_factory.hpp:114] Creating layer pool1
I1109 03:01:33.528465 144290 net.cpp:160] Creating Layer pool1
I1109 03:01:33.528856 144290 net.cpp:596] pool1 <- norm1
I1109 03:01:33.543895 144290 net.cpp:570] pool1 -> pool1
I1109 03:01:33.843276 144290 net.cpp:210] Setting up pool1
I1109 03:01:33.845790 144290 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:01:33.846125 144290 net.cpp:225] Memory required for data: 140258816
I1109 03:01:33.846350 144290 layer_factory.hpp:114] Creating layer conv2
I1109 03:01:33.846755 144290 net.cpp:160] Creating Layer conv2
I1109 03:01:33.846997 144290 net.cpp:596] conv2 <- pool1
I1109 03:01:33.847277 144290 net.cpp:570] conv2 -> conv2
I1109 03:01:39.608764 144290 net.cpp:210] Setting up conv2
I1109 03:01:39.609138 144290 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:01:39.609547 144290 net.cpp:225] Memory required for data: 164146688
I1109 03:01:39.661161 144290 layer_factory.hpp:114] Creating layer relu2
I1109 03:01:39.661563 144290 net.cpp:160] Creating Layer relu2
I1109 03:01:39.661941 144290 net.cpp:596] relu2 <- conv2
I1109 03:01:39.662212 144290 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:01:39.662668 144290 net.cpp:210] Setting up relu2
I1109 03:01:39.662942 144290 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:01:39.663183 144290 net.cpp:225] Memory required for data: 188034560
I1109 03:01:39.663378 144290 layer_factory.hpp:114] Creating layer norm2
I1109 03:01:39.663631 144290 net.cpp:160] Creating Layer norm2
I1109 03:01:39.663835 144290 net.cpp:596] norm2 <- conv2
I1109 03:01:39.664063 144290 net.cpp:570] norm2 -> norm2
I1109 03:01:39.666154 144290 net.cpp:210] Setting up norm2
I1109 03:01:39.666486 144290 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:01:39.666764 144290 net.cpp:225] Memory required for data: 211922432
I1109 03:01:39.666954 144290 layer_factory.hpp:114] Creating layer pool2
I1109 03:01:39.667805 144290 net.cpp:160] Creating Layer pool2
I1109 03:01:39.668112 144290 net.cpp:596] pool2 <- norm2
I1109 03:01:39.668516 144290 net.cpp:570] pool2 -> pool2
I1109 03:01:39.669025 144290 net.cpp:210] Setting up pool2
I1109 03:01:39.669281 144290 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:01:39.669512 144290 net.cpp:225] Memory required for data: 217460224
I1109 03:01:39.669715 144290 layer_factory.hpp:114] Creating layer conv3
I1109 03:01:39.670054 144290 net.cpp:160] Creating Layer conv3
I1109 03:01:39.670279 144290 net.cpp:596] conv3 <- pool2
I1109 03:01:39.670523 144290 net.cpp:570] conv3 -> conv3
I1109 03:01:40.131139 144290 net.cpp:210] Setting up conv3
I1109 03:01:40.133630 144290 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:01:40.133991 144290 net.cpp:225] Memory required for data: 225766912
I1109 03:01:40.137202 144290 layer_factory.hpp:114] Creating layer relu3
I1109 03:01:40.137619 144290 net.cpp:160] Creating Layer relu3
I1109 03:01:40.137879 144290 net.cpp:596] relu3 <- conv3
I1109 03:01:40.138161 144290 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:01:40.142374 144290 net.cpp:210] Setting up relu3
I1109 03:01:40.142693 144290 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:01:40.142949 144290 net.cpp:225] Memory required for data: 234073600
I1109 03:01:40.143149 144290 layer_factory.hpp:114] Creating layer conv4
I1109 03:01:40.143515 144290 net.cpp:160] Creating Layer conv4
I1109 03:01:40.143772 144290 net.cpp:596] conv4 <- conv3
I1109 03:01:40.144028 144290 net.cpp:570] conv4 -> conv4
I1109 03:01:40.412714 144290 net.cpp:210] Setting up conv4
I1109 03:01:40.413144 144290 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:01:40.413550 144290 net.cpp:225] Memory required for data: 242380288
I1109 03:01:40.413902 144290 layer_factory.hpp:114] Creating layer relu4
I1109 03:01:40.414201 144290 net.cpp:160] Creating Layer relu4
I1109 03:01:40.414438 144290 net.cpp:596] relu4 <- conv4
I1109 03:01:40.414680 144290 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:01:40.427160 144290 net.cpp:210] Setting up relu4
I1109 03:01:40.427525 144290 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:01:40.427881 144290 net.cpp:225] Memory required for data: 250686976
I1109 03:01:40.428134 144290 layer_factory.hpp:114] Creating layer conv5
I1109 03:01:40.428503 144290 net.cpp:160] Creating Layer conv5
I1109 03:01:40.428752 144290 net.cpp:596] conv5 <- conv4
I1109 03:01:40.429067 144290 net.cpp:570] conv5 -> conv5
I1109 03:01:40.597914 144290 net.cpp:210] Setting up conv5
I1109 03:01:40.598315 144290 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:01:40.598770 144290 net.cpp:225] Memory required for data: 256224768
I1109 03:01:40.603461 144290 layer_factory.hpp:114] Creating layer relu5
I1109 03:01:40.603868 144290 net.cpp:160] Creating Layer relu5
I1109 03:01:40.604135 144290 net.cpp:596] relu5 <- conv5
I1109 03:01:40.604418 144290 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:01:40.604974 144290 net.cpp:210] Setting up relu5
I1109 03:01:40.605298 144290 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:01:40.605657 144290 net.cpp:225] Memory required for data: 261762560
I1109 03:01:40.605875 144290 layer_factory.hpp:114] Creating layer pool5
I1109 03:01:40.606144 144290 net.cpp:160] Creating Layer pool5
I1109 03:01:40.606374 144290 net.cpp:596] pool5 <- conv5
I1109 03:01:40.606604 144290 net.cpp:570] pool5 -> pool5
I1109 03:01:40.607005 144290 net.cpp:210] Setting up pool5
I1109 03:01:40.607266 144290 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:01:40.607497 144290 net.cpp:225] Memory required for data: 262942208
I1109 03:01:40.607686 144290 layer_factory.hpp:114] Creating layer fc6
I1109 03:01:40.662917 144290 net.cpp:160] Creating Layer fc6
I1109 03:01:40.663230 144290 net.cpp:596] fc6 <- pool5
I1109 03:01:40.663633 144290 net.cpp:570] fc6 -> fc6
I1109 03:01:44.758280 144290 net.cpp:210] Setting up fc6
I1109 03:01:44.758587 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:44.760614 144290 net.cpp:225] Memory required for data: 263466496
I1109 03:01:44.760982 144290 layer_factory.hpp:114] Creating layer relu6
I1109 03:01:44.763492 144290 net.cpp:160] Creating Layer relu6
I1109 03:01:44.763792 144290 net.cpp:596] relu6 <- fc6
I1109 03:01:44.764024 144290 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:01:44.764453 144290 net.cpp:210] Setting up relu6
I1109 03:01:44.764710 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:44.764998 144290 net.cpp:225] Memory required for data: 263990784
I1109 03:01:44.765195 144290 layer_factory.hpp:114] Creating layer drop6
I1109 03:01:44.785430 144290 net.cpp:160] Creating Layer drop6
I1109 03:01:44.785738 144290 net.cpp:596] drop6 <- fc6
I1109 03:01:44.786137 144290 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:01:44.890697 144290 net.cpp:210] Setting up drop6
I1109 03:01:44.891003 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:44.891350 144290 net.cpp:225] Memory required for data: 264515072
I1109 03:01:44.891602 144290 layer_factory.hpp:114] Creating layer fc7
I1109 03:01:44.891881 144290 net.cpp:160] Creating Layer fc7
I1109 03:01:44.892102 144290 net.cpp:596] fc7 <- fc6
I1109 03:01:44.892503 144290 net.cpp:570] fc7 -> fc7
I1109 03:01:46.606578 144290 net.cpp:210] Setting up fc7
I1109 03:01:46.606923 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:46.607302 144290 net.cpp:225] Memory required for data: 265039360
I1109 03:01:46.607651 144290 layer_factory.hpp:114] Creating layer relu7
I1109 03:01:46.607964 144290 net.cpp:160] Creating Layer relu7
I1109 03:01:46.608199 144290 net.cpp:596] relu7 <- fc7
I1109 03:01:46.608446 144290 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:01:46.608932 144290 net.cpp:210] Setting up relu7
I1109 03:01:46.609227 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:46.609468 144290 net.cpp:225] Memory required for data: 265563648
I1109 03:01:46.609670 144290 layer_factory.hpp:114] Creating layer drop7
I1109 03:01:46.609906 144290 net.cpp:160] Creating Layer drop7
I1109 03:01:46.610152 144290 net.cpp:596] drop7 <- fc7
I1109 03:01:46.610405 144290 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:01:46.610692 144290 net.cpp:210] Setting up drop7
I1109 03:01:46.610929 144290 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:01:46.611147 144290 net.cpp:225] Memory required for data: 266087936
I1109 03:01:46.611332 144290 layer_factory.hpp:114] Creating layer fc8
I1109 03:01:46.611584 144290 net.cpp:160] Creating Layer fc8
I1109 03:01:46.611780 144290 net.cpp:596] fc8 <- fc7
I1109 03:01:46.612005 144290 net.cpp:570] fc8 -> fc8
I1109 03:01:47.035086 144290 net.cpp:210] Setting up fc8
I1109 03:01:47.035467 144290 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:01:47.035892 144290 net.cpp:225] Memory required for data: 266215936
I1109 03:01:47.036257 144290 layer_factory.hpp:114] Creating layer loss
I1109 03:01:47.061362 144290 net.cpp:160] Creating Layer loss
I1109 03:01:47.061736 144290 net.cpp:596] loss <- fc8
I1109 03:01:47.062794 144290 net.cpp:596] loss <- label
I1109 03:01:47.090327 144290 net.cpp:570] loss -> loss
I1109 03:01:47.128103 144290 layer_factory.hpp:114] Creating layer loss
I1109 03:01:49.671699 144290 net.cpp:210] Setting up loss
I1109 03:01:49.715323 144290 net.cpp:217] Top shape: (1)
I1109 03:01:49.733422 144290 net.cpp:220]     with loss weight 1
I1109 03:01:49.863550 144290 net.cpp:225] Memory required for data: 266215940
I1109 03:01:49.913738 144290 net.cpp:287] loss needs backward computation.
I1109 03:01:50.009930 144290 net.cpp:287] fc8 needs backward computation.
I1109 03:01:50.019384 144290 net.cpp:287] drop7 needs backward computation.
I1109 03:01:50.030403 144290 net.cpp:287] relu7 needs backward computation.
I1109 03:01:50.030712 144290 net.cpp:287] fc7 needs backward computation.
I1109 03:01:50.033228 144290 net.cpp:287] drop6 needs backward computation.
I1109 03:01:50.033560 144290 net.cpp:287] relu6 needs backward computation.
I1109 03:01:50.033764 144290 net.cpp:287] fc6 needs backward computation.
I1109 03:01:50.034592 144290 net.cpp:287] pool5 needs backward computation.
I1109 03:01:50.035346 144290 net.cpp:287] relu5 needs backward computation.
I1109 03:01:50.035603 144290 net.cpp:287] conv5 needs backward computation.
I1109 03:01:50.035799 144290 net.cpp:287] relu4 needs backward computation.
I1109 03:01:50.035980 144290 net.cpp:287] conv4 needs backward computation.
I1109 03:01:50.036166 144290 net.cpp:287] relu3 needs backward computation.
I1109 03:01:50.036348 144290 net.cpp:287] conv3 needs backward computation.
I1109 03:01:50.048611 144290 net.cpp:287] pool2 needs backward computation.
I1109 03:01:50.048988 144290 net.cpp:287] norm2 needs backward computation.
I1109 03:01:50.049326 144290 net.cpp:287] relu2 needs backward computation.
I1109 03:01:50.049530 144290 net.cpp:287] conv2 needs backward computation.
I1109 03:01:50.049721 144290 net.cpp:287] pool1 needs backward computation.
I1109 03:01:50.049904 144290 net.cpp:287] norm1 needs backward computation.
I1109 03:01:50.050092 144290 net.cpp:287] relu1 needs backward computation.
I1109 03:01:50.050271 144290 net.cpp:287] conv1 needs backward computation.
I1109 03:01:50.062852 144290 net.cpp:289] data does not need backward computation.
I1109 03:01:50.087015 144290 net.cpp:331] This network produces output loss
I1109 03:01:50.160704 144290 net.cpp:345] Network initialization done.
I1109 03:01:50.326108 144290 caffe.cpp:452] Performing Forward
I1109 03:02:03.551740 144290 caffe.cpp:457] Initial loss: 6.99479
I1109 03:02:03.597899 144290 caffe.cpp:459] Performing Backward
I1109 03:02:08.378672 144290 caffe.cpp:468] *** Benchmark begins ***
I1109 03:02:08.391319 144290 caffe.cpp:469] Testing for 1 iterations.
I1109 03:02:08.536427 144290 caffe.cpp:485] Profiling Layer: fc6 backward
I1109 03:02:10.921944 144290 caffe.cpp:512] Iteration: 1 forward-backward time: 2381 ms.
I1109 03:02:11.083434 144290 caffe.cpp:519] Average time per layer: 
I1109 03:02:11.100414 144290 caffe.cpp:522]       data	forward: 542.894 ms.
I1109 03:02:11.171015 144290 caffe.cpp:526]       data	backward: 4.978 ms.
I1109 03:02:11.197763 144290 caffe.cpp:522]      conv1	forward: 122.222 ms.
I1109 03:02:11.209666 144290 caffe.cpp:526]      conv1	backward: 52.163 ms.
I1109 03:02:11.214233 144290 caffe.cpp:522]      relu1	forward: 23.775 ms.
I1109 03:02:11.221961 144290 caffe.cpp:526]      relu1	backward: 17.674 ms.
I1109 03:02:11.230217 144290 caffe.cpp:522]      norm1	forward: 16.095 ms.
I1109 03:02:11.240643 144290 caffe.cpp:526]      norm1	backward: 24.136 ms.
I1109 03:02:11.251850 144290 caffe.cpp:522]      pool1	forward: 22.038 ms.
I1109 03:02:11.254196 144290 caffe.cpp:526]      pool1	backward: 78.892 ms.
I1109 03:02:11.254988 144290 caffe.cpp:522]      conv2	forward: 70.956 ms.
I1109 03:02:11.255213 144290 caffe.cpp:526]      conv2	backward: 85.459 ms.
I1109 03:02:11.255411 144290 caffe.cpp:522]      relu2	forward: 13.756 ms.
I1109 03:02:11.257220 144290 caffe.cpp:526]      relu2	backward: 18.144 ms.
I1109 03:02:11.257525 144290 caffe.cpp:522]      norm2	forward: 13.467 ms.
I1109 03:02:11.257762 144290 caffe.cpp:526]      norm2	backward: 16.873 ms.
I1109 03:02:11.257992 144290 caffe.cpp:522]      pool2	forward: 14.642 ms.
I1109 03:02:11.258220 144290 caffe.cpp:526]      pool2	backward: 62.423 ms.
I1109 03:02:11.258456 144290 caffe.cpp:522]      conv3	forward: 35.848 ms.
I1109 03:02:11.258684 144290 caffe.cpp:526]      conv3	backward: 78.912 ms.
I1109 03:02:11.258940 144290 caffe.cpp:522]      relu3	forward: 13.007 ms.
I1109 03:02:11.259214 144290 caffe.cpp:526]      relu3	backward: 65.592 ms.
I1109 03:02:11.259613 144290 caffe.cpp:522]      conv4	forward: 32.891 ms.
I1109 03:02:11.259858 144290 caffe.cpp:526]      conv4	backward: 79.084 ms.
I1109 03:02:11.260079 144290 caffe.cpp:522]      relu4	forward: 9.334 ms.
I1109 03:02:11.260965 144290 caffe.cpp:526]      relu4	backward: 40.698 ms.
I1109 03:02:11.261229 144290 caffe.cpp:522]      conv5	forward: 25.933 ms.
I1109 03:02:11.261451 144290 caffe.cpp:526]      conv5	backward: 66.112 ms.
I1109 03:02:11.261667 144290 caffe.cpp:522]      relu5	forward: 8.955 ms.
I1109 03:02:11.261876 144290 caffe.cpp:526]      relu5	backward: 14.248 ms.
I1109 03:02:11.262089 144290 caffe.cpp:522]      pool5	forward: 0.812 ms.
I1109 03:02:11.262337 144290 caffe.cpp:526]      pool5	backward: 51.387 ms.
I1109 03:02:11.262629 144290 caffe.cpp:522]        fc6	forward: 18.709 ms.
I1109 03:02:11.262943 144290 caffe.cpp:526]        fc6	backward: 121.649 ms.
I1109 03:02:11.263234 144290 caffe.cpp:522]      relu6	forward: 0.88 ms.
I1109 03:02:11.263478 144290 caffe.cpp:526]      relu6	backward: 13.283 ms.
I1109 03:02:11.263684 144290 caffe.cpp:522]      drop6	forward: 1.504 ms.
I1109 03:02:11.263887 144290 caffe.cpp:526]      drop6	backward: 22.945 ms.
I1109 03:02:11.264091 144290 caffe.cpp:522]        fc7	forward: 4.547 ms.
I1109 03:02:11.264288 144290 caffe.cpp:526]        fc7	backward: 139.963 ms.
I1109 03:02:11.264492 144290 caffe.cpp:522]      relu7	forward: 0.13 ms.
I1109 03:02:11.264688 144290 caffe.cpp:526]      relu7	backward: 14.997 ms.
I1109 03:02:11.264931 144290 caffe.cpp:522]      drop7	forward: 0.299 ms.
I1109 03:02:11.265131 144290 caffe.cpp:526]      drop7	backward: 16.636 ms.
I1109 03:02:11.265362 144290 caffe.cpp:522]        fc8	forward: 1.955 ms.
I1109 03:02:11.265566 144290 caffe.cpp:526]        fc8	backward: 124.444 ms.
I1109 03:02:11.265830 144290 caffe.cpp:522]       loss	forward: 37.083 ms.
I1109 03:02:11.266098 144290 caffe.cpp:526]       loss	backward: 43.784 ms.
I1109 03:02:11.271459 144290 caffe.cpp:532] Average Forward pass: 1086.78 ms.
I1109 03:02:11.284592 144290 caffe.cpp:535] Average Backward pass: 1266.26 ms.
I1109 03:02:11.295651 144290 caffe.cpp:537] Average Forward-Backward: 2836 ms.
I1109 03:02:11.310480 144290 caffe.cpp:540] Total Time: 2836 ms.
I1109 03:02:11.322942 144290 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 7763
elements_fp_single_4 = 4608
elements_fp_single_8 = 5064448
elements_fp_single_16 = 304587264
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 4913938003
--->Total double-precision FLOPs = 0
--->Total FLOPs = 4913938003
mem-read-1 = 66364
mem-read-2 = 143
mem-read-4 = 151867562
mem-read-8 = 1617105
mem-read-16 = 465620
mem-read-32 = 4802048
mem-read-64 = 37011936
mem-write-1 = 169
mem-write-2 = 51
mem-write-4 = 3805
mem-write-8 = 380476
mem-write-16 = 71892
mem-write-32 = 4998912
mem-write-64 = 2631968
--->Total Bytes read = 3150353098
--->Total Bytes written = 332620707
--->Total Bytes = 3482973805
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer17_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=17 -prof_forward_direction=0
I1109 03:08:36.030560 144463 caffe.cpp:444] Use CPU.
I1109 03:08:52.896834 144463 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:08:52.952639 144463 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:08:52.964507 144463 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:08:52.975409 144463 cpu_info.cpp:461] Total number of processors: 272
I1109 03:08:52.986624 144463 cpu_info.cpp:464] GPU is used: no
I1109 03:08:52.995647 144463 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:08:53.006315 144463 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:08:53.020548 144463 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:09:01.729950 144463 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:09:01.762565 144463 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:09:02.393585 144463 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:09:04.835809 144463 layer_factory.hpp:114] Creating layer data
I1109 03:09:04.983981 144463 net.cpp:160] Creating Layer data
I1109 03:09:05.032243 144463 net.cpp:570] data -> data
I1109 03:09:05.493329 144463 net.cpp:570] data -> label
I1109 03:09:12.485991 144463 net.cpp:210] Setting up data
I1109 03:09:12.565683 144463 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:09:12.669304 144463 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:09:12.676527 144463 net.cpp:225] Memory required for data: 19787264
I1109 03:09:12.743638 144463 layer_factory.hpp:114] Creating layer conv1
I1109 03:09:13.071110 144463 net.cpp:160] Creating Layer conv1
I1109 03:09:13.121006 144463 net.cpp:596] conv1 <- data
I1109 03:09:13.239537 144463 net.cpp:570] conv1 -> conv1
I1109 03:09:46.153260 144463 net.cpp:210] Setting up conv1
I1109 03:09:46.159574 144463 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:09:46.159951 144463 net.cpp:225] Memory required for data: 56958464
I1109 03:09:46.440542 144463 layer_factory.hpp:114] Creating layer relu1
I1109 03:09:46.562456 144463 net.cpp:160] Creating Layer relu1
I1109 03:09:46.567450 144463 net.cpp:596] relu1 <- conv1
I1109 03:09:46.601171 144463 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:09:46.791234 144463 net.cpp:210] Setting up relu1
I1109 03:09:46.793661 144463 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:09:46.793998 144463 net.cpp:225] Memory required for data: 94129664
I1109 03:09:46.794231 144463 layer_factory.hpp:114] Creating layer norm1
I1109 03:09:46.898448 144463 net.cpp:160] Creating Layer norm1
I1109 03:09:46.898762 144463 net.cpp:596] norm1 <- conv1
I1109 03:09:46.901327 144463 net.cpp:570] norm1 -> norm1
I1109 03:09:47.124492 144463 net.cpp:210] Setting up norm1
I1109 03:09:47.137328 144463 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:09:47.137701 144463 net.cpp:225] Memory required for data: 131300864
I1109 03:09:47.138000 144463 layer_factory.hpp:114] Creating layer pool1
I1109 03:09:47.231073 144463 net.cpp:160] Creating Layer pool1
I1109 03:09:47.231386 144463 net.cpp:596] pool1 <- norm1
I1109 03:09:47.245542 144463 net.cpp:570] pool1 -> pool1
I1109 03:09:47.560480 144463 net.cpp:210] Setting up pool1
I1109 03:09:47.563056 144463 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:09:47.563377 144463 net.cpp:225] Memory required for data: 140258816
I1109 03:09:47.563623 144463 layer_factory.hpp:114] Creating layer conv2
I1109 03:09:47.563990 144463 net.cpp:160] Creating Layer conv2
I1109 03:09:47.564239 144463 net.cpp:596] conv2 <- pool1
I1109 03:09:47.564468 144463 net.cpp:570] conv2 -> conv2
I1109 03:09:53.305521 144463 net.cpp:210] Setting up conv2
I1109 03:09:53.305871 144463 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:09:53.306259 144463 net.cpp:225] Memory required for data: 164146688
I1109 03:09:53.357367 144463 layer_factory.hpp:114] Creating layer relu2
I1109 03:09:53.357784 144463 net.cpp:160] Creating Layer relu2
I1109 03:09:53.358139 144463 net.cpp:596] relu2 <- conv2
I1109 03:09:53.358384 144463 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:09:53.358860 144463 net.cpp:210] Setting up relu2
I1109 03:09:53.359125 144463 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:09:53.359357 144463 net.cpp:225] Memory required for data: 188034560
I1109 03:09:53.359549 144463 layer_factory.hpp:114] Creating layer norm2
I1109 03:09:53.359786 144463 net.cpp:160] Creating Layer norm2
I1109 03:09:53.359979 144463 net.cpp:596] norm2 <- conv2
I1109 03:09:53.360239 144463 net.cpp:570] norm2 -> norm2
I1109 03:09:53.362385 144463 net.cpp:210] Setting up norm2
I1109 03:09:53.362689 144463 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:09:53.362915 144463 net.cpp:225] Memory required for data: 211922432
I1109 03:09:53.363131 144463 layer_factory.hpp:114] Creating layer pool2
I1109 03:09:53.364054 144463 net.cpp:160] Creating Layer pool2
I1109 03:09:53.364341 144463 net.cpp:596] pool2 <- norm2
I1109 03:09:53.364580 144463 net.cpp:570] pool2 -> pool2
I1109 03:09:53.365013 144463 net.cpp:210] Setting up pool2
I1109 03:09:53.365268 144463 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:09:53.365487 144463 net.cpp:225] Memory required for data: 217460224
I1109 03:09:53.365680 144463 layer_factory.hpp:114] Creating layer conv3
I1109 03:09:53.366051 144463 net.cpp:160] Creating Layer conv3
I1109 03:09:53.366392 144463 net.cpp:596] conv3 <- pool2
I1109 03:09:53.366714 144463 net.cpp:570] conv3 -> conv3
I1109 03:09:53.846577 144463 net.cpp:210] Setting up conv3
I1109 03:09:53.849006 144463 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:09:53.849356 144463 net.cpp:225] Memory required for data: 225766912
I1109 03:09:53.852509 144463 layer_factory.hpp:114] Creating layer relu3
I1109 03:09:53.852959 144463 net.cpp:160] Creating Layer relu3
I1109 03:09:53.853250 144463 net.cpp:596] relu3 <- conv3
I1109 03:09:53.853490 144463 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:09:53.857714 144463 net.cpp:210] Setting up relu3
I1109 03:09:53.858037 144463 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:09:53.858295 144463 net.cpp:225] Memory required for data: 234073600
I1109 03:09:53.858520 144463 layer_factory.hpp:114] Creating layer conv4
I1109 03:09:53.858873 144463 net.cpp:160] Creating Layer conv4
I1109 03:09:53.859118 144463 net.cpp:596] conv4 <- conv3
I1109 03:09:53.859364 144463 net.cpp:570] conv4 -> conv4
I1109 03:09:54.102324 144463 net.cpp:210] Setting up conv4
I1109 03:09:54.102700 144463 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:09:54.103086 144463 net.cpp:225] Memory required for data: 242380288
I1109 03:09:54.103420 144463 layer_factory.hpp:114] Creating layer relu4
I1109 03:09:54.103704 144463 net.cpp:160] Creating Layer relu4
I1109 03:09:54.103924 144463 net.cpp:596] relu4 <- conv4
I1109 03:09:54.104153 144463 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:09:54.116374 144463 net.cpp:210] Setting up relu4
I1109 03:09:54.116717 144463 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:09:54.117136 144463 net.cpp:225] Memory required for data: 250686976
I1109 03:09:54.117358 144463 layer_factory.hpp:114] Creating layer conv5
I1109 03:09:54.117743 144463 net.cpp:160] Creating Layer conv5
I1109 03:09:54.117995 144463 net.cpp:596] conv5 <- conv4
I1109 03:09:54.118252 144463 net.cpp:570] conv5 -> conv5
I1109 03:09:54.288190 144463 net.cpp:210] Setting up conv5
I1109 03:09:54.288569 144463 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:09:54.289011 144463 net.cpp:225] Memory required for data: 256224768
I1109 03:09:54.293630 144463 layer_factory.hpp:114] Creating layer relu5
I1109 03:09:54.294025 144463 net.cpp:160] Creating Layer relu5
I1109 03:09:54.294306 144463 net.cpp:596] relu5 <- conv5
I1109 03:09:54.294581 144463 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:09:54.295112 144463 net.cpp:210] Setting up relu5
I1109 03:09:54.295426 144463 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:09:54.295667 144463 net.cpp:225] Memory required for data: 261762560
I1109 03:09:54.295873 144463 layer_factory.hpp:114] Creating layer pool5
I1109 03:09:54.296125 144463 net.cpp:160] Creating Layer pool5
I1109 03:09:54.296336 144463 net.cpp:596] pool5 <- conv5
I1109 03:09:54.296558 144463 net.cpp:570] pool5 -> pool5
I1109 03:09:54.296989 144463 net.cpp:210] Setting up pool5
I1109 03:09:54.297312 144463 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:09:54.297554 144463 net.cpp:225] Memory required for data: 262942208
I1109 03:09:54.297773 144463 layer_factory.hpp:114] Creating layer fc6
I1109 03:09:54.352143 144463 net.cpp:160] Creating Layer fc6
I1109 03:09:54.352448 144463 net.cpp:596] fc6 <- pool5
I1109 03:09:54.352885 144463 net.cpp:570] fc6 -> fc6
I1109 03:09:58.465699 144463 net.cpp:210] Setting up fc6
I1109 03:09:58.466001 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:09:58.468001 144463 net.cpp:225] Memory required for data: 263466496
I1109 03:09:58.468302 144463 layer_factory.hpp:114] Creating layer relu6
I1109 03:09:58.470870 144463 net.cpp:160] Creating Layer relu6
I1109 03:09:58.471163 144463 net.cpp:596] relu6 <- fc6
I1109 03:09:58.471387 144463 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:09:58.471804 144463 net.cpp:210] Setting up relu6
I1109 03:09:58.472057 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:09:58.472318 144463 net.cpp:225] Memory required for data: 263990784
I1109 03:09:58.472517 144463 layer_factory.hpp:114] Creating layer drop6
I1109 03:09:58.492416 144463 net.cpp:160] Creating Layer drop6
I1109 03:09:58.492717 144463 net.cpp:596] drop6 <- fc6
I1109 03:09:58.493130 144463 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:09:58.596438 144463 net.cpp:210] Setting up drop6
I1109 03:09:58.596736 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:09:58.597118 144463 net.cpp:225] Memory required for data: 264515072
I1109 03:09:58.597342 144463 layer_factory.hpp:114] Creating layer fc7
I1109 03:09:58.597625 144463 net.cpp:160] Creating Layer fc7
I1109 03:09:58.597847 144463 net.cpp:596] fc7 <- fc6
I1109 03:09:58.598249 144463 net.cpp:570] fc7 -> fc7
I1109 03:10:00.321347 144463 net.cpp:210] Setting up fc7
I1109 03:10:00.321715 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:10:00.322197 144463 net.cpp:225] Memory required for data: 265039360
I1109 03:10:00.322563 144463 layer_factory.hpp:114] Creating layer relu7
I1109 03:10:00.322898 144463 net.cpp:160] Creating Layer relu7
I1109 03:10:00.323153 144463 net.cpp:596] relu7 <- fc7
I1109 03:10:00.323410 144463 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:10:00.323863 144463 net.cpp:210] Setting up relu7
I1109 03:10:00.324148 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:10:00.324393 144463 net.cpp:225] Memory required for data: 265563648
I1109 03:10:00.324587 144463 layer_factory.hpp:114] Creating layer drop7
I1109 03:10:00.324892 144463 net.cpp:160] Creating Layer drop7
I1109 03:10:00.325137 144463 net.cpp:596] drop7 <- fc7
I1109 03:10:00.325397 144463 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:10:00.325778 144463 net.cpp:210] Setting up drop7
I1109 03:10:00.325984 144463 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:10:00.326200 144463 net.cpp:225] Memory required for data: 266087936
I1109 03:10:00.326382 144463 layer_factory.hpp:114] Creating layer fc8
I1109 03:10:00.326632 144463 net.cpp:160] Creating Layer fc8
I1109 03:10:00.326836 144463 net.cpp:596] fc8 <- fc7
I1109 03:10:00.327062 144463 net.cpp:570] fc8 -> fc8
I1109 03:10:00.751638 144463 net.cpp:210] Setting up fc8
I1109 03:10:00.751989 144463 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:10:00.752384 144463 net.cpp:225] Memory required for data: 266215936
I1109 03:10:00.752820 144463 layer_factory.hpp:114] Creating layer loss
I1109 03:10:00.777694 144463 net.cpp:160] Creating Layer loss
I1109 03:10:00.778007 144463 net.cpp:596] loss <- fc8
I1109 03:10:00.778986 144463 net.cpp:596] loss <- label
I1109 03:10:00.808769 144463 net.cpp:570] loss -> loss
I1109 03:10:00.847638 144463 layer_factory.hpp:114] Creating layer loss
I1109 03:10:03.495218 144463 net.cpp:210] Setting up loss
I1109 03:10:03.544626 144463 net.cpp:217] Top shape: (1)
I1109 03:10:03.556514 144463 net.cpp:220]     with loss weight 1
I1109 03:10:03.694245 144463 net.cpp:225] Memory required for data: 266215940
I1109 03:10:03.734855 144463 net.cpp:287] loss needs backward computation.
I1109 03:10:03.822216 144463 net.cpp:287] fc8 needs backward computation.
I1109 03:10:03.829470 144463 net.cpp:287] drop7 needs backward computation.
I1109 03:10:03.840442 144463 net.cpp:287] relu7 needs backward computation.
I1109 03:10:03.840764 144463 net.cpp:287] fc7 needs backward computation.
I1109 03:10:03.843317 144463 net.cpp:287] drop6 needs backward computation.
I1109 03:10:03.843675 144463 net.cpp:287] relu6 needs backward computation.
I1109 03:10:03.843909 144463 net.cpp:287] fc6 needs backward computation.
I1109 03:10:03.844615 144463 net.cpp:287] pool5 needs backward computation.
I1109 03:10:03.845443 144463 net.cpp:287] relu5 needs backward computation.
I1109 03:10:03.845743 144463 net.cpp:287] conv5 needs backward computation.
I1109 03:10:03.845957 144463 net.cpp:287] relu4 needs backward computation.
I1109 03:10:03.846251 144463 net.cpp:287] conv4 needs backward computation.
I1109 03:10:03.846500 144463 net.cpp:287] relu3 needs backward computation.
I1109 03:10:03.846720 144463 net.cpp:287] conv3 needs backward computation.
I1109 03:10:03.859176 144463 net.cpp:287] pool2 needs backward computation.
I1109 03:10:03.859525 144463 net.cpp:287] norm2 needs backward computation.
I1109 03:10:03.859835 144463 net.cpp:287] relu2 needs backward computation.
I1109 03:10:03.860070 144463 net.cpp:287] conv2 needs backward computation.
I1109 03:10:03.860260 144463 net.cpp:287] pool1 needs backward computation.
I1109 03:10:03.860441 144463 net.cpp:287] norm1 needs backward computation.
I1109 03:10:03.860621 144463 net.cpp:287] relu1 needs backward computation.
I1109 03:10:03.860828 144463 net.cpp:287] conv1 needs backward computation.
I1109 03:10:03.873313 144463 net.cpp:289] data does not need backward computation.
I1109 03:10:03.899058 144463 net.cpp:331] This network produces output loss
I1109 03:10:03.970859 144463 net.cpp:345] Network initialization done.
I1109 03:10:04.139102 144463 caffe.cpp:452] Performing Forward
I1109 03:10:17.283175 144463 caffe.cpp:457] Initial loss: 7.00373
I1109 03:10:17.333971 144463 caffe.cpp:459] Performing Backward
I1109 03:10:22.116125 144463 caffe.cpp:468] *** Benchmark begins ***
I1109 03:10:22.129698 144463 caffe.cpp:469] Testing for 1 iterations.
I1109 03:10:22.275539 144463 caffe.cpp:485] Profiling Layer: relu6 backward
I1109 03:10:24.872897 144463 caffe.cpp:512] Iteration: 1 forward-backward time: 2595 ms.
I1109 03:10:25.028981 144463 caffe.cpp:519] Average time per layer: 
I1109 03:10:25.047870 144463 caffe.cpp:522]       data	forward: 550.464 ms.
I1109 03:10:25.118580 144463 caffe.cpp:526]       data	backward: 5.556 ms.
I1109 03:10:25.146998 144463 caffe.cpp:522]      conv1	forward: 134.048 ms.
I1109 03:10:25.151942 144463 caffe.cpp:526]      conv1	backward: 43.297 ms.
I1109 03:10:25.158570 144463 caffe.cpp:522]      relu1	forward: 17.182 ms.
I1109 03:10:25.166170 144463 caffe.cpp:526]      relu1	backward: 12.999 ms.
I1109 03:10:25.172339 144463 caffe.cpp:522]      norm1	forward: 18.827 ms.
I1109 03:10:25.180754 144463 caffe.cpp:526]      norm1	backward: 17.623 ms.
I1109 03:10:25.190242 144463 caffe.cpp:522]      pool1	forward: 22.414 ms.
I1109 03:10:25.201570 144463 caffe.cpp:526]      pool1	backward: 76.194 ms.
I1109 03:10:25.206370 144463 caffe.cpp:522]      conv2	forward: 64.675 ms.
I1109 03:10:25.215577 144463 caffe.cpp:526]      conv2	backward: 75.529 ms.
I1109 03:10:25.220145 144463 caffe.cpp:522]      relu2	forward: 16.392 ms.
I1109 03:10:25.223054 144463 caffe.cpp:526]      relu2	backward: 19.751 ms.
I1109 03:10:25.223282 144463 caffe.cpp:522]      norm2	forward: 15.004 ms.
I1109 03:10:25.223489 144463 caffe.cpp:526]      norm2	backward: 9.16 ms.
I1109 03:10:25.224318 144463 caffe.cpp:522]      pool2	forward: 11.65 ms.
I1109 03:10:25.224550 144463 caffe.cpp:526]      pool2	backward: 82.785 ms.
I1109 03:10:25.224756 144463 caffe.cpp:522]      conv3	forward: 33.152 ms.
I1109 03:10:25.225015 144463 caffe.cpp:526]      conv3	backward: 77.38 ms.
I1109 03:10:25.225224 144463 caffe.cpp:522]      relu3	forward: 11.678 ms.
I1109 03:10:25.225462 144463 caffe.cpp:526]      relu3	backward: 24.971 ms.
I1109 03:10:25.225677 144463 caffe.cpp:522]      conv4	forward: 38.102 ms.
I1109 03:10:25.225879 144463 caffe.cpp:526]      conv4	backward: 69.469 ms.
I1109 03:10:25.226083 144463 caffe.cpp:522]      relu4	forward: 13.202 ms.
I1109 03:10:25.226284 144463 caffe.cpp:526]      relu4	backward: 43.721 ms.
I1109 03:10:25.226487 144463 caffe.cpp:522]      conv5	forward: 34.585 ms.
I1109 03:10:25.226689 144463 caffe.cpp:526]      conv5	backward: 72.941 ms.
I1109 03:10:25.226892 144463 caffe.cpp:522]      relu5	forward: 16.086 ms.
I1109 03:10:25.227095 144463 caffe.cpp:526]      relu5	backward: 22.061 ms.
I1109 03:10:25.227298 144463 caffe.cpp:522]      pool5	forward: 17.476 ms.
I1109 03:10:25.227499 144463 caffe.cpp:526]      pool5	backward: 54.785 ms.
I1109 03:10:25.227702 144463 caffe.cpp:522]        fc6	forward: 47.588 ms.
I1109 03:10:25.227929 144463 caffe.cpp:526]        fc6	backward: 178.314 ms.
I1109 03:10:25.230510 144463 caffe.cpp:522]      relu6	forward: 15.668 ms.
I1109 03:10:25.230801 144463 caffe.cpp:526]      relu6	backward: 30.904 ms.
I1109 03:10:25.230998 144463 caffe.cpp:522]      drop6	forward: 30.618 ms.
I1109 03:10:25.231190 144463 caffe.cpp:526]      drop6	backward: 6.564 ms.
I1109 03:10:25.231377 144463 caffe.cpp:522]        fc7	forward: 13.322 ms.
I1109 03:10:25.231569 144463 caffe.cpp:526]        fc7	backward: 31.472 ms.
I1109 03:10:25.231758 144463 caffe.cpp:522]      relu7	forward: 16.574 ms.
I1109 03:10:25.231948 144463 caffe.cpp:526]      relu7	backward: 0.086 ms.
I1109 03:10:25.234630 144463 caffe.cpp:522]      drop7	forward: 26.368 ms.
I1109 03:10:25.234908 144463 caffe.cpp:526]      drop7	backward: 0.092 ms.
I1109 03:10:25.235141 144463 caffe.cpp:522]        fc8	forward: 18.724 ms.
I1109 03:10:25.235350 144463 caffe.cpp:526]        fc8	backward: 252.2 ms.
I1109 03:10:25.235669 144463 caffe.cpp:522]       loss	forward: 51.116 ms.
I1109 03:10:25.235946 144463 caffe.cpp:526]       loss	backward: 59.933 ms.
I1109 03:10:25.241636 144463 caffe.cpp:532] Average Forward pass: 1290.18 ms.
I1109 03:10:25.254838 144463 caffe.cpp:535] Average Backward pass: 1276.53 ms.
I1109 03:10:25.265697 144463 caffe.cpp:537] Average Forward-Backward: 3066 ms.
I1109 03:10:25.280308 144463 caffe.cpp:540] Total Time: 3066 ms.
I1109 03:10:25.292455 144463 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 8192
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 16384
--->Total FLOPs = 16384
mem-read-1 = 25937
mem-read-2 = 37
mem-read-4 = 208338
mem-read-8 = 289370
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 16385
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 572
mem-write-8 = 28086
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 8193
--->Total Bytes read = 4222995
--->Total Bytes written = 751450
--->Total Bytes = 4974445
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer18_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=18 -prof_forward_direction=0
I1109 03:14:04.084122 144581 caffe.cpp:444] Use CPU.
I1109 03:14:21.004227 144581 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:14:21.063742 144581 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:14:21.075625 144581 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:14:21.088093 144581 cpu_info.cpp:461] Total number of processors: 272
I1109 03:14:21.099210 144581 cpu_info.cpp:464] GPU is used: no
I1109 03:14:21.108333 144581 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:14:21.117219 144581 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:14:21.128131 144581 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:14:29.839851 144581 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:14:29.872262 144581 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:14:30.501627 144581 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:14:32.941654 144581 layer_factory.hpp:114] Creating layer data
I1109 03:14:33.087769 144581 net.cpp:160] Creating Layer data
I1109 03:14:33.135494 144581 net.cpp:570] data -> data
I1109 03:14:33.595055 144581 net.cpp:570] data -> label
I1109 03:14:40.600122 144581 net.cpp:210] Setting up data
I1109 03:14:40.678738 144581 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:14:40.784673 144581 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:14:40.792402 144581 net.cpp:225] Memory required for data: 19787264
I1109 03:14:40.861258 144581 layer_factory.hpp:114] Creating layer conv1
I1109 03:14:41.191707 144581 net.cpp:160] Creating Layer conv1
I1109 03:14:41.241616 144581 net.cpp:596] conv1 <- data
I1109 03:14:41.360249 144581 net.cpp:570] conv1 -> conv1
I1109 03:15:14.062727 144581 net.cpp:210] Setting up conv1
I1109 03:15:14.069875 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:14.070231 144581 net.cpp:225] Memory required for data: 56958464
I1109 03:15:14.355648 144581 layer_factory.hpp:114] Creating layer relu1
I1109 03:15:14.477143 144581 net.cpp:160] Creating Layer relu1
I1109 03:15:14.481747 144581 net.cpp:596] relu1 <- conv1
I1109 03:15:14.515318 144581 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:15:14.705950 144581 net.cpp:210] Setting up relu1
I1109 03:15:14.708364 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:14.708714 144581 net.cpp:225] Memory required for data: 94129664
I1109 03:15:14.709010 144581 layer_factory.hpp:114] Creating layer norm1
I1109 03:15:14.814208 144581 net.cpp:160] Creating Layer norm1
I1109 03:15:14.814529 144581 net.cpp:596] norm1 <- conv1
I1109 03:15:14.817121 144581 net.cpp:570] norm1 -> norm1
I1109 03:15:15.040161 144581 net.cpp:210] Setting up norm1
I1109 03:15:15.053037 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:15.053426 144581 net.cpp:225] Memory required for data: 131300864
I1109 03:15:15.053735 144581 layer_factory.hpp:114] Creating layer pool1
I1109 03:15:15.149006 144581 net.cpp:160] Creating Layer pool1
I1109 03:15:15.149328 144581 net.cpp:596] pool1 <- norm1
I1109 03:15:15.164095 144581 net.cpp:570] pool1 -> pool1
I1109 03:15:15.465466 144581 net.cpp:210] Setting up pool1
I1109 03:15:15.467936 144581 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:15:15.468272 144581 net.cpp:225] Memory required for data: 140258816
I1109 03:15:15.468536 144581 layer_factory.hpp:114] Creating layer conv2
I1109 03:15:15.468977 144581 net.cpp:160] Creating Layer conv2
I1109 03:15:15.469216 144581 net.cpp:596] conv2 <- pool1
I1109 03:15:15.469460 144581 net.cpp:570] conv2 -> conv2
I1109 03:15:21.276048 144581 net.cpp:210] Setting up conv2
I1109 03:15:21.276376 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.276768 144581 net.cpp:225] Memory required for data: 164146688
I1109 03:15:21.327150 144581 layer_factory.hpp:114] Creating layer relu2
I1109 03:15:21.327558 144581 net.cpp:160] Creating Layer relu2
I1109 03:15:21.327924 144581 net.cpp:596] relu2 <- conv2
I1109 03:15:21.328197 144581 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:15:21.328644 144581 net.cpp:210] Setting up relu2
I1109 03:15:21.328964 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.329210 144581 net.cpp:225] Memory required for data: 188034560
I1109 03:15:21.329404 144581 layer_factory.hpp:114] Creating layer norm2
I1109 03:15:21.329653 144581 net.cpp:160] Creating Layer norm2
I1109 03:15:21.329854 144581 net.cpp:596] norm2 <- conv2
I1109 03:15:21.330119 144581 net.cpp:570] norm2 -> norm2
I1109 03:15:21.332142 144581 net.cpp:210] Setting up norm2
I1109 03:15:21.332458 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.332700 144581 net.cpp:225] Memory required for data: 211922432
I1109 03:15:21.332975 144581 layer_factory.hpp:114] Creating layer pool2
I1109 03:15:21.333947 144581 net.cpp:160] Creating Layer pool2
I1109 03:15:21.334246 144581 net.cpp:596] pool2 <- norm2
I1109 03:15:21.334499 144581 net.cpp:570] pool2 -> pool2
I1109 03:15:21.334908 144581 net.cpp:210] Setting up pool2
I1109 03:15:21.335162 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:21.335389 144581 net.cpp:225] Memory required for data: 217460224
I1109 03:15:21.335633 144581 layer_factory.hpp:114] Creating layer conv3
I1109 03:15:21.336079 144581 net.cpp:160] Creating Layer conv3
I1109 03:15:21.336403 144581 net.cpp:596] conv3 <- pool2
I1109 03:15:21.336671 144581 net.cpp:570] conv3 -> conv3
I1109 03:15:21.817616 144581 net.cpp:210] Setting up conv3
I1109 03:15:21.820060 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:21.820446 144581 net.cpp:225] Memory required for data: 225766912
I1109 03:15:21.823689 144581 layer_factory.hpp:114] Creating layer relu3
I1109 03:15:21.824156 144581 net.cpp:160] Creating Layer relu3
I1109 03:15:21.824422 144581 net.cpp:596] relu3 <- conv3
I1109 03:15:21.824683 144581 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:15:21.828848 144581 net.cpp:210] Setting up relu3
I1109 03:15:21.829203 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:21.829604 144581 net.cpp:225] Memory required for data: 234073600
I1109 03:15:21.829846 144581 layer_factory.hpp:114] Creating layer conv4
I1109 03:15:21.830211 144581 net.cpp:160] Creating Layer conv4
I1109 03:15:21.830477 144581 net.cpp:596] conv4 <- conv3
I1109 03:15:21.830737 144581 net.cpp:570] conv4 -> conv4
I1109 03:15:22.073447 144581 net.cpp:210] Setting up conv4
I1109 03:15:22.073849 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:22.074249 144581 net.cpp:225] Memory required for data: 242380288
I1109 03:15:22.074604 144581 layer_factory.hpp:114] Creating layer relu4
I1109 03:15:22.074910 144581 net.cpp:160] Creating Layer relu4
I1109 03:15:22.075150 144581 net.cpp:596] relu4 <- conv4
I1109 03:15:22.075400 144581 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:15:22.087805 144581 net.cpp:210] Setting up relu4
I1109 03:15:22.088160 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:22.088543 144581 net.cpp:225] Memory required for data: 250686976
I1109 03:15:22.088830 144581 layer_factory.hpp:114] Creating layer conv5
I1109 03:15:22.089231 144581 net.cpp:160] Creating Layer conv5
I1109 03:15:22.089486 144581 net.cpp:596] conv5 <- conv4
I1109 03:15:22.089745 144581 net.cpp:570] conv5 -> conv5
I1109 03:15:22.259388 144581 net.cpp:210] Setting up conv5
I1109 03:15:22.259801 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:22.260256 144581 net.cpp:225] Memory required for data: 256224768
I1109 03:15:22.265054 144581 layer_factory.hpp:114] Creating layer relu5
I1109 03:15:22.265481 144581 net.cpp:160] Creating Layer relu5
I1109 03:15:22.265782 144581 net.cpp:596] relu5 <- conv5
I1109 03:15:22.266064 144581 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:15:22.266538 144581 net.cpp:210] Setting up relu5
I1109 03:15:22.266834 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:22.267094 144581 net.cpp:225] Memory required for data: 261762560
I1109 03:15:22.267344 144581 layer_factory.hpp:114] Creating layer pool5
I1109 03:15:22.267627 144581 net.cpp:160] Creating Layer pool5
I1109 03:15:22.267868 144581 net.cpp:596] pool5 <- conv5
I1109 03:15:22.268136 144581 net.cpp:570] pool5 -> pool5
I1109 03:15:22.268546 144581 net.cpp:210] Setting up pool5
I1109 03:15:22.268851 144581 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:15:22.269109 144581 net.cpp:225] Memory required for data: 262942208
I1109 03:15:22.269302 144581 layer_factory.hpp:114] Creating layer fc6
I1109 03:15:22.324019 144581 net.cpp:160] Creating Layer fc6
I1109 03:15:22.324338 144581 net.cpp:596] fc6 <- pool5
I1109 03:15:22.324717 144581 net.cpp:570] fc6 -> fc6
I1109 03:15:26.415623 144581 net.cpp:210] Setting up fc6
I1109 03:15:26.415938 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.418057 144581 net.cpp:225] Memory required for data: 263466496
I1109 03:15:26.418380 144581 layer_factory.hpp:114] Creating layer relu6
I1109 03:15:26.420892 144581 net.cpp:160] Creating Layer relu6
I1109 03:15:26.421201 144581 net.cpp:596] relu6 <- fc6
I1109 03:15:26.421439 144581 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:15:26.421866 144581 net.cpp:210] Setting up relu6
I1109 03:15:26.422158 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.422401 144581 net.cpp:225] Memory required for data: 263990784
I1109 03:15:26.422611 144581 layer_factory.hpp:114] Creating layer drop6
I1109 03:15:26.442781 144581 net.cpp:160] Creating Layer drop6
I1109 03:15:26.443097 144581 net.cpp:596] drop6 <- fc6
I1109 03:15:26.443503 144581 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:15:26.547603 144581 net.cpp:210] Setting up drop6
I1109 03:15:26.547911 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.548259 144581 net.cpp:225] Memory required for data: 264515072
I1109 03:15:26.548511 144581 layer_factory.hpp:114] Creating layer fc7
I1109 03:15:26.548828 144581 net.cpp:160] Creating Layer fc7
I1109 03:15:26.549067 144581 net.cpp:596] fc7 <- fc6
I1109 03:15:26.549469 144581 net.cpp:570] fc7 -> fc7
I1109 03:15:28.261710 144581 net.cpp:210] Setting up fc7
I1109 03:15:28.262084 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.262529 144581 net.cpp:225] Memory required for data: 265039360
I1109 03:15:28.262866 144581 layer_factory.hpp:114] Creating layer relu7
I1109 03:15:28.263205 144581 net.cpp:160] Creating Layer relu7
I1109 03:15:28.263458 144581 net.cpp:596] relu7 <- fc7
I1109 03:15:28.263726 144581 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:15:28.264189 144581 net.cpp:210] Setting up relu7
I1109 03:15:28.264478 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.264731 144581 net.cpp:225] Memory required for data: 265563648
I1109 03:15:28.265034 144581 layer_factory.hpp:114] Creating layer drop7
I1109 03:15:28.265300 144581 net.cpp:160] Creating Layer drop7
I1109 03:15:28.265527 144581 net.cpp:596] drop7 <- fc7
I1109 03:15:28.265823 144581 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:15:28.266103 144581 net.cpp:210] Setting up drop7
I1109 03:15:28.266314 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.266536 144581 net.cpp:225] Memory required for data: 266087936
I1109 03:15:28.266726 144581 layer_factory.hpp:114] Creating layer fc8
I1109 03:15:28.266983 144581 net.cpp:160] Creating Layer fc8
I1109 03:15:28.267184 144581 net.cpp:596] fc8 <- fc7
I1109 03:15:28.267413 144581 net.cpp:570] fc8 -> fc8
I1109 03:15:28.691860 144581 net.cpp:210] Setting up fc8
I1109 03:15:28.692224 144581 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:15:28.692641 144581 net.cpp:225] Memory required for data: 266215936
I1109 03:15:28.693003 144581 layer_factory.hpp:114] Creating layer loss
I1109 03:15:28.717963 144581 net.cpp:160] Creating Layer loss
I1109 03:15:28.718291 144581 net.cpp:596] loss <- fc8
I1109 03:15:28.719297 144581 net.cpp:596] loss <- label
I1109 03:15:28.747107 144581 net.cpp:570] loss -> loss
I1109 03:15:28.785631 144581 layer_factory.hpp:114] Creating layer loss
I1109 03:15:31.272161 144581 net.cpp:210] Setting up loss
I1109 03:15:31.317008 144581 net.cpp:217] Top shape: (1)
I1109 03:15:31.331240 144581 net.cpp:220]     with loss weight 1
I1109 03:15:31.461827 144581 net.cpp:225] Memory required for data: 266215940
I1109 03:15:31.512262 144581 net.cpp:287] loss needs backward computation.
I1109 03:15:31.610437 144581 net.cpp:287] fc8 needs backward computation.
I1109 03:15:31.622076 144581 net.cpp:287] drop7 needs backward computation.
I1109 03:15:31.632908 144581 net.cpp:287] relu7 needs backward computation.
I1109 03:15:31.633218 144581 net.cpp:287] fc7 needs backward computation.
I1109 03:15:31.635547 144581 net.cpp:287] drop6 needs backward computation.
I1109 03:15:31.635888 144581 net.cpp:287] relu6 needs backward computation.
I1109 03:15:31.636193 144581 net.cpp:287] fc6 needs backward computation.
I1109 03:15:31.636963 144581 net.cpp:287] pool5 needs backward computation.
I1109 03:15:31.637696 144581 net.cpp:287] relu5 needs backward computation.
I1109 03:15:31.637949 144581 net.cpp:287] conv5 needs backward computation.
I1109 03:15:31.638139 144581 net.cpp:287] relu4 needs backward computation.
I1109 03:15:31.638316 144581 net.cpp:287] conv4 needs backward computation.
I1109 03:15:31.638536 144581 net.cpp:287] relu3 needs backward computation.
I1109 03:15:31.638731 144581 net.cpp:287] conv3 needs backward computation.
I1109 03:15:31.651257 144581 net.cpp:287] pool2 needs backward computation.
I1109 03:15:31.651594 144581 net.cpp:287] norm2 needs backward computation.
I1109 03:15:31.651895 144581 net.cpp:287] relu2 needs backward computation.
I1109 03:15:31.652127 144581 net.cpp:287] conv2 needs backward computation.
I1109 03:15:31.652315 144581 net.cpp:287] pool1 needs backward computation.
I1109 03:15:31.652500 144581 net.cpp:287] norm1 needs backward computation.
I1109 03:15:31.652683 144581 net.cpp:287] relu1 needs backward computation.
I1109 03:15:31.652905 144581 net.cpp:287] conv1 needs backward computation.
I1109 03:15:31.665381 144581 net.cpp:289] data does not need backward computation.
I1109 03:15:31.689586 144581 net.cpp:331] This network produces output loss
I1109 03:15:31.763322 144581 net.cpp:345] Network initialization done.
I1109 03:15:31.931301 144581 caffe.cpp:452] Performing Forward
I1109 03:15:45.224436 144581 caffe.cpp:457] Initial loss: 6.90134
I1109 03:15:45.279042 144581 caffe.cpp:459] Performing Backward
I1109 03:15:50.090430 144581 caffe.cpp:468] *** Benchmark begins ***
I1109 03:15:50.102063 144581 caffe.cpp:469] Testing for 1 iterations.
I1109 03:15:50.249383 144581 caffe.cpp:485] Profiling Layer: drop6 backward
I1109 03:15:52.421960 144581 caffe.cpp:512] Iteration: 1 forward-backward time: 2165 ms.
I1109 03:15:52.581023 144581 caffe.cpp:519] Average time per layer: 
I1109 03:15:52.600108 144581 caffe.cpp:522]       data	forward: 546.999 ms.
I1109 03:15:52.673866 144581 caffe.cpp:526]       data	backward: 5.247 ms.
I1109 03:15:52.697134 144581 caffe.cpp:522]      conv1	forward: 123.725 ms.
I1109 03:15:52.714140 144581 caffe.cpp:526]      conv1	backward: 41.744 ms.
I1109 03:15:52.721014 144581 caffe.cpp:522]      relu1	forward: 25.406 ms.
I1109 03:15:52.729439 144581 caffe.cpp:526]      relu1	backward: 15.369 ms.
I1109 03:15:52.742593 144581 caffe.cpp:522]      norm1	forward: 16.396 ms.
I1109 03:15:52.749006 144581 caffe.cpp:526]      norm1	backward: 15.137 ms.
I1109 03:15:52.757910 144581 caffe.cpp:522]      pool1	forward: 27.193 ms.
I1109 03:15:52.761970 144581 caffe.cpp:526]      pool1	backward: 68.123 ms.
I1109 03:15:52.766660 144581 caffe.cpp:522]      conv2	forward: 61.741 ms.
I1109 03:15:52.769222 144581 caffe.cpp:526]      conv2	backward: 75.727 ms.
I1109 03:15:52.781787 144581 caffe.cpp:522]      relu2	forward: 11.522 ms.
I1109 03:15:52.785727 144581 caffe.cpp:526]      relu2	backward: 18.036 ms.
I1109 03:15:52.787376 144581 caffe.cpp:522]      norm2	forward: 12.794 ms.
I1109 03:15:52.787585 144581 caffe.cpp:526]      norm2	backward: 17.428 ms.
I1109 03:15:52.787780 144581 caffe.cpp:522]      pool2	forward: 13.854 ms.
I1109 03:15:52.788007 144581 caffe.cpp:526]      pool2	backward: 56.419 ms.
I1109 03:15:52.788210 144581 caffe.cpp:522]      conv3	forward: 32.112 ms.
I1109 03:15:52.788499 144581 caffe.cpp:526]      conv3	backward: 88.098 ms.
I1109 03:15:52.788754 144581 caffe.cpp:522]      relu3	forward: 12.181 ms.
I1109 03:15:52.788995 144581 caffe.cpp:526]      relu3	backward: 23.283 ms.
I1109 03:15:52.789189 144581 caffe.cpp:522]      conv4	forward: 35.451 ms.
I1109 03:15:52.789382 144581 caffe.cpp:526]      conv4	backward: 77.82 ms.
I1109 03:15:52.789575 144581 caffe.cpp:522]      relu4	forward: 20.514 ms.
I1109 03:15:52.789767 144581 caffe.cpp:526]      relu4	backward: 43.933 ms.
I1109 03:15:52.789958 144581 caffe.cpp:522]      conv5	forward: 24.782 ms.
I1109 03:15:52.790148 144581 caffe.cpp:526]      conv5	backward: 66.974 ms.
I1109 03:15:52.790339 144581 caffe.cpp:522]      relu5	forward: 0.203 ms.
I1109 03:15:52.790562 144581 caffe.cpp:526]      relu5	backward: 10.174 ms.
I1109 03:15:52.793202 144581 caffe.cpp:522]      pool5	forward: 0.328 ms.
I1109 03:15:52.793560 144581 caffe.cpp:526]      pool5	backward: 54.84 ms.
I1109 03:15:52.793833 144581 caffe.cpp:522]        fc6	forward: 16.882 ms.
I1109 03:15:52.794075 144581 caffe.cpp:526]        fc6	backward: 120.944 ms.
I1109 03:15:52.794275 144581 caffe.cpp:522]      relu6	forward: 0.812 ms.
I1109 03:15:52.794466 144581 caffe.cpp:526]      relu6	backward: 17.794 ms.
I1109 03:15:52.794659 144581 caffe.cpp:522]      drop6	forward: 1.545 ms.
I1109 03:15:52.794847 144581 caffe.cpp:526]      drop6	backward: 30.746 ms.
I1109 03:15:52.795038 144581 caffe.cpp:522]        fc7	forward: 4.653 ms.
I1109 03:15:52.795225 144581 caffe.cpp:526]        fc7	backward: 81.488 ms.
I1109 03:15:52.795418 144581 caffe.cpp:522]      relu7	forward: 0.125 ms.
I1109 03:15:52.795605 144581 caffe.cpp:526]      relu7	backward: 0.091 ms.
I1109 03:15:52.798229 144581 caffe.cpp:522]      drop7	forward: 0.298 ms.
I1109 03:15:52.798501 144581 caffe.cpp:526]      drop7	backward: 0.092 ms.
I1109 03:15:52.798831 144581 caffe.cpp:522]        fc8	forward: 1.928 ms.
I1109 03:15:52.799087 144581 caffe.cpp:526]        fc8	backward: 75.153 ms.
I1109 03:15:52.799294 144581 caffe.cpp:522]       loss	forward: 33.758 ms.
I1109 03:15:52.799491 144581 caffe.cpp:526]       loss	backward: 39.701 ms.
I1109 03:15:52.805058 144581 caffe.cpp:532] Average Forward pass: 1079.78 ms.
I1109 03:15:52.819470 144581 caffe.cpp:535] Average Backward pass: 1054.3 ms.
I1109 03:15:52.830391 144581 caffe.cpp:537] Average Forward-Backward: 2657 ms.
I1109 03:15:52.845538 144581 caffe.cpp:540] Total Time: 2657 ms.
I1109 03:15:52.857942 144581 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 16384
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 262144
--->Total double-precision FLOPs = 0
--->Total FLOPs = 262144
mem-read-1 = 27985
mem-read-2 = 37
mem-read-4 = 224941
mem-read-8 = 311478
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 16384
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 749
mem-write-8 = 30021
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 8192
--->Total Bytes read = 4468223
--->Total Bytes written = 767542
--->Total Bytes = 5235765
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer19_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=19 -prof_forward_direction=0
I1109 03:19:20.286106 144743 caffe.cpp:444] Use CPU.
I1109 03:19:37.096258 144743 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:19:37.152024 144743 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:19:37.163873 144743 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:19:37.176451 144743 cpu_info.cpp:461] Total number of processors: 272
I1109 03:19:37.187644 144743 cpu_info.cpp:464] GPU is used: no
I1109 03:19:37.196660 144743 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:19:37.205466 144743 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:19:37.216608 144743 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:19:45.952239 144743 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:19:45.984994 144743 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:19:46.613996 144743 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:19:49.059994 144743 layer_factory.hpp:114] Creating layer data
I1109 03:19:49.209563 144743 net.cpp:160] Creating Layer data
I1109 03:19:49.258191 144743 net.cpp:570] data -> data
I1109 03:19:49.721678 144743 net.cpp:570] data -> label
I1109 03:19:56.742799 144743 net.cpp:210] Setting up data
I1109 03:19:56.822649 144743 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:19:56.927377 144743 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:19:56.934571 144743 net.cpp:225] Memory required for data: 19787264
I1109 03:19:57.002116 144743 layer_factory.hpp:114] Creating layer conv1
I1109 03:19:57.335938 144743 net.cpp:160] Creating Layer conv1
I1109 03:19:57.386548 144743 net.cpp:596] conv1 <- data
I1109 03:19:57.506227 144743 net.cpp:570] conv1 -> conv1
I1109 03:20:30.210557 144743 net.cpp:210] Setting up conv1
I1109 03:20:30.216878 144743 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:20:30.217260 144743 net.cpp:225] Memory required for data: 56958464
I1109 03:20:30.495723 144743 layer_factory.hpp:114] Creating layer relu1
I1109 03:20:30.616695 144743 net.cpp:160] Creating Layer relu1
I1109 03:20:30.621390 144743 net.cpp:596] relu1 <- conv1
I1109 03:20:30.654727 144743 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:20:30.842578 144743 net.cpp:210] Setting up relu1
I1109 03:20:30.845059 144743 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:20:30.845410 144743 net.cpp:225] Memory required for data: 94129664
I1109 03:20:30.845619 144743 layer_factory.hpp:114] Creating layer norm1
I1109 03:20:30.949838 144743 net.cpp:160] Creating Layer norm1
I1109 03:20:30.950162 144743 net.cpp:596] norm1 <- conv1
I1109 03:20:30.952828 144743 net.cpp:570] norm1 -> norm1
I1109 03:20:31.174656 144743 net.cpp:210] Setting up norm1
I1109 03:20:31.187371 144743 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:20:31.187757 144743 net.cpp:225] Memory required for data: 131300864
I1109 03:20:31.188091 144743 layer_factory.hpp:114] Creating layer pool1
I1109 03:20:31.280825 144743 net.cpp:160] Creating Layer pool1
I1109 03:20:31.281146 144743 net.cpp:596] pool1 <- norm1
I1109 03:20:31.295872 144743 net.cpp:570] pool1 -> pool1
I1109 03:20:31.598933 144743 net.cpp:210] Setting up pool1
I1109 03:20:31.601460 144743 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:20:31.601836 144743 net.cpp:225] Memory required for data: 140258816
I1109 03:20:31.602068 144743 layer_factory.hpp:114] Creating layer conv2
I1109 03:20:31.602525 144743 net.cpp:160] Creating Layer conv2
I1109 03:20:31.602754 144743 net.cpp:596] conv2 <- pool1
I1109 03:20:31.602991 144743 net.cpp:570] conv2 -> conv2
I1109 03:20:37.345774 144743 net.cpp:210] Setting up conv2
I1109 03:20:37.346096 144743 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:20:37.346487 144743 net.cpp:225] Memory required for data: 164146688
I1109 03:20:37.397337 144743 layer_factory.hpp:114] Creating layer relu2
I1109 03:20:37.397745 144743 net.cpp:160] Creating Layer relu2
I1109 03:20:37.398123 144743 net.cpp:596] relu2 <- conv2
I1109 03:20:37.398406 144743 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:20:37.398869 144743 net.cpp:210] Setting up relu2
I1109 03:20:37.399142 144743 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:20:37.399392 144743 net.cpp:225] Memory required for data: 188034560
I1109 03:20:37.399595 144743 layer_factory.hpp:114] Creating layer norm2
I1109 03:20:37.399844 144743 net.cpp:160] Creating Layer norm2
I1109 03:20:37.400049 144743 net.cpp:596] norm2 <- conv2
I1109 03:20:37.400316 144743 net.cpp:570] norm2 -> norm2
I1109 03:20:37.402423 144743 net.cpp:210] Setting up norm2
I1109 03:20:37.402751 144743 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:20:37.403003 144743 net.cpp:225] Memory required for data: 211922432
I1109 03:20:37.403201 144743 layer_factory.hpp:114] Creating layer pool2
I1109 03:20:37.404091 144743 net.cpp:160] Creating Layer pool2
I1109 03:20:37.404399 144743 net.cpp:596] pool2 <- norm2
I1109 03:20:37.404661 144743 net.cpp:570] pool2 -> pool2
I1109 03:20:37.405138 144743 net.cpp:210] Setting up pool2
I1109 03:20:37.405416 144743 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:20:37.405710 144743 net.cpp:225] Memory required for data: 217460224
I1109 03:20:37.405949 144743 layer_factory.hpp:114] Creating layer conv3
I1109 03:20:37.406376 144743 net.cpp:160] Creating Layer conv3
I1109 03:20:37.406750 144743 net.cpp:596] conv3 <- pool2
I1109 03:20:37.407055 144743 net.cpp:570] conv3 -> conv3
I1109 03:20:37.860918 144743 net.cpp:210] Setting up conv3
I1109 03:20:37.863327 144743 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:20:37.863688 144743 net.cpp:225] Memory required for data: 225766912
I1109 03:20:37.866817 144743 layer_factory.hpp:114] Creating layer relu3
I1109 03:20:37.867280 144743 net.cpp:160] Creating Layer relu3
I1109 03:20:37.867547 144743 net.cpp:596] relu3 <- conv3
I1109 03:20:37.867861 144743 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:20:37.872124 144743 net.cpp:210] Setting up relu3
I1109 03:20:37.872442 144743 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:20:37.872740 144743 net.cpp:225] Memory required for data: 234073600
I1109 03:20:37.873011 144743 layer_factory.hpp:114] Creating layer conv4
I1109 03:20:37.873457 144743 net.cpp:160] Creating Layer conv4
I1109 03:20:37.873745 144743 net.cpp:596] conv4 <- conv3
I1109 03:20:37.873996 144743 net.cpp:570] conv4 -> conv4
I1109 03:20:38.116273 144743 net.cpp:210] Setting up conv4
I1109 03:20:38.116665 144743 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:20:38.117108 144743 net.cpp:225] Memory required for data: 242380288
I1109 03:20:38.117447 144743 layer_factory.hpp:114] Creating layer relu4
I1109 03:20:38.117766 144743 net.cpp:160] Creating Layer relu4
I1109 03:20:38.118016 144743 net.cpp:596] relu4 <- conv4
I1109 03:20:38.118270 144743 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:20:38.130563 144743 net.cpp:210] Setting up relu4
I1109 03:20:38.130914 144743 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:20:38.131332 144743 net.cpp:225] Memory required for data: 250686976
I1109 03:20:38.131559 144743 layer_factory.hpp:114] Creating layer conv5
I1109 03:20:38.131933 144743 net.cpp:160] Creating Layer conv5
I1109 03:20:38.132187 144743 net.cpp:596] conv5 <- conv4
I1109 03:20:38.132448 144743 net.cpp:570] conv5 -> conv5
I1109 03:20:38.327566 144743 net.cpp:210] Setting up conv5
I1109 03:20:38.327966 144743 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:20:38.328429 144743 net.cpp:225] Memory required for data: 256224768
I1109 03:20:38.333340 144743 layer_factory.hpp:114] Creating layer relu5
I1109 03:20:38.333768 144743 net.cpp:160] Creating Layer relu5
I1109 03:20:38.334131 144743 net.cpp:596] relu5 <- conv5
I1109 03:20:38.334419 144743 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:20:38.334890 144743 net.cpp:210] Setting up relu5
I1109 03:20:38.335191 144743 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:20:38.335456 144743 net.cpp:225] Memory required for data: 261762560
I1109 03:20:38.335675 144743 layer_factory.hpp:114] Creating layer pool5
I1109 03:20:38.335985 144743 net.cpp:160] Creating Layer pool5
I1109 03:20:38.336228 144743 net.cpp:596] pool5 <- conv5
I1109 03:20:38.336496 144743 net.cpp:570] pool5 -> pool5
I1109 03:20:38.336949 144743 net.cpp:210] Setting up pool5
I1109 03:20:38.337229 144743 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:20:38.337465 144743 net.cpp:225] Memory required for data: 262942208
I1109 03:20:38.337649 144743 layer_factory.hpp:114] Creating layer fc6
I1109 03:20:38.392570 144743 net.cpp:160] Creating Layer fc6
I1109 03:20:38.392923 144743 net.cpp:596] fc6 <- pool5
I1109 03:20:38.393308 144743 net.cpp:570] fc6 -> fc6
I1109 03:20:42.481976 144743 net.cpp:210] Setting up fc6
I1109 03:20:42.482286 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:42.484357 144743 net.cpp:225] Memory required for data: 263466496
I1109 03:20:42.484676 144743 layer_factory.hpp:114] Creating layer relu6
I1109 03:20:42.487259 144743 net.cpp:160] Creating Layer relu6
I1109 03:20:42.487563 144743 net.cpp:596] relu6 <- fc6
I1109 03:20:42.487800 144743 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:20:42.488225 144743 net.cpp:210] Setting up relu6
I1109 03:20:42.488515 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:42.488757 144743 net.cpp:225] Memory required for data: 263990784
I1109 03:20:42.489002 144743 layer_factory.hpp:114] Creating layer drop6
I1109 03:20:42.509171 144743 net.cpp:160] Creating Layer drop6
I1109 03:20:42.509474 144743 net.cpp:596] drop6 <- fc6
I1109 03:20:42.509848 144743 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:20:42.612927 144743 net.cpp:210] Setting up drop6
I1109 03:20:42.613225 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:42.613571 144743 net.cpp:225] Memory required for data: 264515072
I1109 03:20:42.613819 144743 layer_factory.hpp:114] Creating layer fc7
I1109 03:20:42.614089 144743 net.cpp:160] Creating Layer fc7
I1109 03:20:42.614302 144743 net.cpp:596] fc7 <- fc6
I1109 03:20:42.614696 144743 net.cpp:570] fc7 -> fc7
I1109 03:20:44.327220 144743 net.cpp:210] Setting up fc7
I1109 03:20:44.327580 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:44.327989 144743 net.cpp:225] Memory required for data: 265039360
I1109 03:20:44.328337 144743 layer_factory.hpp:114] Creating layer relu7
I1109 03:20:44.328656 144743 net.cpp:160] Creating Layer relu7
I1109 03:20:44.328961 144743 net.cpp:596] relu7 <- fc7
I1109 03:20:44.329226 144743 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:20:44.329668 144743 net.cpp:210] Setting up relu7
I1109 03:20:44.329949 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:44.330224 144743 net.cpp:225] Memory required for data: 265563648
I1109 03:20:44.330431 144743 layer_factory.hpp:114] Creating layer drop7
I1109 03:20:44.330678 144743 net.cpp:160] Creating Layer drop7
I1109 03:20:44.330893 144743 net.cpp:596] drop7 <- fc7
I1109 03:20:44.331156 144743 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:20:44.331421 144743 net.cpp:210] Setting up drop7
I1109 03:20:44.331624 144743 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:20:44.331838 144743 net.cpp:225] Memory required for data: 266087936
I1109 03:20:44.332018 144743 layer_factory.hpp:114] Creating layer fc8
I1109 03:20:44.332264 144743 net.cpp:160] Creating Layer fc8
I1109 03:20:44.332465 144743 net.cpp:596] fc8 <- fc7
I1109 03:20:44.332693 144743 net.cpp:570] fc8 -> fc8
I1109 03:20:44.754277 144743 net.cpp:210] Setting up fc8
I1109 03:20:44.754632 144743 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:20:44.755022 144743 net.cpp:225] Memory required for data: 266215936
I1109 03:20:44.755354 144743 layer_factory.hpp:114] Creating layer loss
I1109 03:20:44.779933 144743 net.cpp:160] Creating Layer loss
I1109 03:20:44.780253 144743 net.cpp:596] loss <- fc8
I1109 03:20:44.781204 144743 net.cpp:596] loss <- label
I1109 03:20:44.808743 144743 net.cpp:570] loss -> loss
I1109 03:20:44.846601 144743 layer_factory.hpp:114] Creating layer loss
I1109 03:20:47.369226 144743 net.cpp:210] Setting up loss
I1109 03:20:47.411772 144743 net.cpp:217] Top shape: (1)
I1109 03:20:47.422281 144743 net.cpp:220]     with loss weight 1
I1109 03:20:47.565063 144743 net.cpp:225] Memory required for data: 266215940
I1109 03:20:47.611795 144743 net.cpp:287] loss needs backward computation.
I1109 03:20:47.710481 144743 net.cpp:287] fc8 needs backward computation.
I1109 03:20:47.718381 144743 net.cpp:287] drop7 needs backward computation.
I1109 03:20:47.729153 144743 net.cpp:287] relu7 needs backward computation.
I1109 03:20:47.729460 144743 net.cpp:287] fc7 needs backward computation.
I1109 03:20:47.731865 144743 net.cpp:287] drop6 needs backward computation.
I1109 03:20:47.732156 144743 net.cpp:287] relu6 needs backward computation.
I1109 03:20:47.732342 144743 net.cpp:287] fc6 needs backward computation.
I1109 03:20:47.733073 144743 net.cpp:287] pool5 needs backward computation.
I1109 03:20:47.733887 144743 net.cpp:287] relu5 needs backward computation.
I1109 03:20:47.734158 144743 net.cpp:287] conv5 needs backward computation.
I1109 03:20:47.734360 144743 net.cpp:287] relu4 needs backward computation.
I1109 03:20:47.734549 144743 net.cpp:287] conv4 needs backward computation.
I1109 03:20:47.734740 144743 net.cpp:287] relu3 needs backward computation.
I1109 03:20:47.734947 144743 net.cpp:287] conv3 needs backward computation.
I1109 03:20:47.746804 144743 net.cpp:287] pool2 needs backward computation.
I1109 03:20:47.747143 144743 net.cpp:287] norm2 needs backward computation.
I1109 03:20:47.747440 144743 net.cpp:287] relu2 needs backward computation.
I1109 03:20:47.747676 144743 net.cpp:287] conv2 needs backward computation.
I1109 03:20:47.747865 144743 net.cpp:287] pool1 needs backward computation.
I1109 03:20:47.748049 144743 net.cpp:287] norm1 needs backward computation.
I1109 03:20:47.748229 144743 net.cpp:287] relu1 needs backward computation.
I1109 03:20:47.748406 144743 net.cpp:287] conv1 needs backward computation.
I1109 03:20:47.760849 144743 net.cpp:289] data does not need backward computation.
I1109 03:20:47.785045 144743 net.cpp:331] This network produces output loss
I1109 03:20:47.858706 144743 net.cpp:345] Network initialization done.
I1109 03:20:48.028118 144743 caffe.cpp:452] Performing Forward
I1109 03:21:00.920903 144743 caffe.cpp:457] Initial loss: 6.89213
I1109 03:21:00.976167 144743 caffe.cpp:459] Performing Backward
I1109 03:21:05.859061 144743 caffe.cpp:468] *** Benchmark begins ***
I1109 03:21:05.874209 144743 caffe.cpp:469] Testing for 1 iterations.
I1109 03:21:06.018784 144743 caffe.cpp:485] Profiling Layer: fc7 backward
I1109 03:21:08.073355 144743 caffe.cpp:512] Iteration: 1 forward-backward time: 2053 ms.
I1109 03:21:08.232614 144743 caffe.cpp:519] Average time per layer: 
I1109 03:21:08.248076 144743 caffe.cpp:522]       data	forward: 549.317 ms.
I1109 03:21:08.318249 144743 caffe.cpp:526]       data	backward: 5.363 ms.
I1109 03:21:08.337805 144743 caffe.cpp:522]      conv1	forward: 127.472 ms.
I1109 03:21:08.341058 144743 caffe.cpp:526]      conv1	backward: 45.321 ms.
I1109 03:21:08.341913 144743 caffe.cpp:522]      relu1	forward: 14.806 ms.
I1109 03:21:08.342154 144743 caffe.cpp:526]      relu1	backward: 24.395 ms.
I1109 03:21:08.342355 144743 caffe.cpp:522]      norm1	forward: 20.896 ms.
I1109 03:21:08.342550 144743 caffe.cpp:526]      norm1	backward: 14.705 ms.
I1109 03:21:08.342744 144743 caffe.cpp:522]      pool1	forward: 22.604 ms.
I1109 03:21:08.342936 144743 caffe.cpp:526]      pool1	backward: 75.435 ms.
I1109 03:21:08.343605 144743 caffe.cpp:522]      conv2	forward: 62.506 ms.
I1109 03:21:08.343849 144743 caffe.cpp:526]      conv2	backward: 46.697 ms.
I1109 03:21:08.344187 144743 caffe.cpp:522]      relu2	forward: 16.373 ms.
I1109 03:21:08.344399 144743 caffe.cpp:526]      relu2	backward: 0.715 ms.
I1109 03:21:08.344594 144743 caffe.cpp:522]      norm2	forward: 14.402 ms.
I1109 03:21:08.344822 144743 caffe.cpp:526]      norm2	backward: 2.031 ms.
I1109 03:21:08.345016 144743 caffe.cpp:522]      pool2	forward: 20.098 ms.
I1109 03:21:08.345700 144743 caffe.cpp:526]      pool2	backward: 24.854 ms.
I1109 03:21:08.345924 144743 caffe.cpp:522]      conv3	forward: 39.016 ms.
I1109 03:21:08.346156 144743 caffe.cpp:526]      conv3	backward: 36.749 ms.
I1109 03:21:08.346364 144743 caffe.cpp:522]      relu3	forward: 18.956 ms.
I1109 03:21:08.346662 144743 caffe.cpp:526]      relu3	backward: 0.684 ms.
I1109 03:21:08.346917 144743 caffe.cpp:522]      conv4	forward: 39.443 ms.
I1109 03:21:08.347115 144743 caffe.cpp:526]      conv4	backward: 27.947 ms.
I1109 03:21:08.347307 144743 caffe.cpp:522]      relu4	forward: 13.704 ms.
I1109 03:21:08.347501 144743 caffe.cpp:526]      relu4	backward: 7.328 ms.
I1109 03:21:08.347687 144743 caffe.cpp:522]      conv5	forward: 31.002 ms.
I1109 03:21:08.347877 144743 caffe.cpp:526]      conv5	backward: 18.976 ms.
I1109 03:21:08.348067 144743 caffe.cpp:522]      relu5	forward: 21.774 ms.
I1109 03:21:08.348258 144743 caffe.cpp:526]      relu5	backward: 0.251 ms.
I1109 03:21:08.348444 144743 caffe.cpp:522]      pool5	forward: 15.003 ms.
I1109 03:21:08.348634 144743 caffe.cpp:526]      pool5	backward: 9.194 ms.
I1109 03:21:08.349616 144743 caffe.cpp:522]        fc6	forward: 40.429 ms.
I1109 03:21:08.349859 144743 caffe.cpp:526]        fc6	backward: 55.269 ms.
I1109 03:21:08.350056 144743 caffe.cpp:522]      relu6	forward: 20.2 ms.
I1109 03:21:08.350250 144743 caffe.cpp:526]      relu6	backward: 0.095 ms.
I1109 03:21:08.352872 144743 caffe.cpp:522]      drop6	forward: 38.705 ms.
I1109 03:21:08.353143 144743 caffe.cpp:526]      drop6	backward: 0.11 ms.
I1109 03:21:08.353843 144743 caffe.cpp:522]        fc7	forward: 15.291 ms.
I1109 03:21:08.354076 144743 caffe.cpp:526]        fc7	backward: 89.412 ms.
I1109 03:21:08.354311 144743 caffe.cpp:522]      relu7	forward: 20.122 ms.
I1109 03:21:08.354521 144743 caffe.cpp:526]      relu7	backward: 14.076 ms.
I1109 03:21:08.354826 144743 caffe.cpp:522]      drop7	forward: 22.343 ms.
I1109 03:21:08.355098 144743 caffe.cpp:526]      drop7	backward: 20.06 ms.
I1109 03:21:08.355298 144743 caffe.cpp:522]        fc8	forward: 20.391 ms.
I1109 03:21:08.355492 144743 caffe.cpp:526]        fc8	backward: 109.735 ms.
I1109 03:21:08.355686 144743 caffe.cpp:522]       loss	forward: 59.503 ms.
I1109 03:21:08.355876 144743 caffe.cpp:526]       loss	backward: 66.706 ms.
I1109 03:21:08.361446 144743 caffe.cpp:532] Average Forward pass: 1317.94 ms.
I1109 03:21:08.374615 144743 caffe.cpp:535] Average Backward pass: 704.962 ms.
I1109 03:21:08.385293 144743 caffe.cpp:537] Average Forward-Backward: 2442 ms.
I1109 03:21:08.399772 144743 caffe.cpp:540] Total Time: 2442 ms.
I1109 03:21:08.411905 144743 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3603
elements_fp_single_4 = 4608
elements_fp_single_8 = 2422528
elements_fp_single_16 = 135381504
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2185506323
--->Total double-precision FLOPs = 0
--->Total FLOPs = 2185506323
mem-read-1 = 474628
mem-read-2 = 143
mem-read-4 = 71242479
mem-read-8 = 5821652
mem-read-16 = 465620
mem-read-32 = 2160128
mem-read-64 = 16659616
mem-write-1 = 169
mem-write-2 = 51
mem-write-4 = 3804
mem-write-8 = 632330
mem-write-16 = 71892
mem-write-32 = 2356992
mem-write-64 = 1171488
--->Total Bytes read = 1474807486
--->Total Bytes written = 156623375
--->Total Bytes = 1631430861
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer20_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=20 -prof_forward_direction=0
I1109 03:27:34.539726 144881 caffe.cpp:444] Use CPU.
I1109 03:27:51.436434 144881 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:27:51.492121 144881 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:27:51.503773 144881 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:27:51.516252 144881 cpu_info.cpp:461] Total number of processors: 272
I1109 03:27:51.527462 144881 cpu_info.cpp:464] GPU is used: no
I1109 03:27:51.537464 144881 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:27:51.547122 144881 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:27:51.558715 144881 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:28:00.349259 144881 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:28:00.382097 144881 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:28:01.011497 144881 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:28:03.452901 144881 layer_factory.hpp:114] Creating layer data
I1109 03:28:03.604413 144881 net.cpp:160] Creating Layer data
I1109 03:28:03.652830 144881 net.cpp:570] data -> data
I1109 03:28:04.119251 144881 net.cpp:570] data -> label
I1109 03:28:11.156235 144881 net.cpp:210] Setting up data
I1109 03:28:11.236340 144881 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:28:11.339606 144881 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:28:11.346896 144881 net.cpp:225] Memory required for data: 19787264
I1109 03:28:11.414185 144881 layer_factory.hpp:114] Creating layer conv1
I1109 03:28:11.744374 144881 net.cpp:160] Creating Layer conv1
I1109 03:28:11.794193 144881 net.cpp:596] conv1 <- data
I1109 03:28:11.914216 144881 net.cpp:570] conv1 -> conv1
I1109 03:28:44.499079 144881 net.cpp:210] Setting up conv1
I1109 03:28:44.505520 144881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:28:44.505903 144881 net.cpp:225] Memory required for data: 56958464
I1109 03:28:44.785181 144881 layer_factory.hpp:114] Creating layer relu1
I1109 03:28:44.906395 144881 net.cpp:160] Creating Layer relu1
I1109 03:28:44.911130 144881 net.cpp:596] relu1 <- conv1
I1109 03:28:44.943897 144881 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:28:45.132133 144881 net.cpp:210] Setting up relu1
I1109 03:28:45.134589 144881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:28:45.134965 144881 net.cpp:225] Memory required for data: 94129664
I1109 03:28:45.135177 144881 layer_factory.hpp:114] Creating layer norm1
I1109 03:28:45.239378 144881 net.cpp:160] Creating Layer norm1
I1109 03:28:45.239692 144881 net.cpp:596] norm1 <- conv1
I1109 03:28:45.242269 144881 net.cpp:570] norm1 -> norm1
I1109 03:28:45.463958 144881 net.cpp:210] Setting up norm1
I1109 03:28:45.476670 144881 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:28:45.477092 144881 net.cpp:225] Memory required for data: 131300864
I1109 03:28:45.477390 144881 layer_factory.hpp:114] Creating layer pool1
I1109 03:28:45.570169 144881 net.cpp:160] Creating Layer pool1
I1109 03:28:45.570487 144881 net.cpp:596] pool1 <- norm1
I1109 03:28:45.585281 144881 net.cpp:570] pool1 -> pool1
I1109 03:28:45.886119 144881 net.cpp:210] Setting up pool1
I1109 03:28:45.888557 144881 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:28:45.889574 144881 net.cpp:225] Memory required for data: 140258816
I1109 03:28:45.889848 144881 layer_factory.hpp:114] Creating layer conv2
I1109 03:28:45.890210 144881 net.cpp:160] Creating Layer conv2
I1109 03:28:45.890437 144881 net.cpp:596] conv2 <- pool1
I1109 03:28:45.890673 144881 net.cpp:570] conv2 -> conv2
I1109 03:28:51.629567 144881 net.cpp:210] Setting up conv2
I1109 03:28:51.629884 144881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:28:51.630302 144881 net.cpp:225] Memory required for data: 164146688
I1109 03:28:51.683339 144881 layer_factory.hpp:114] Creating layer relu2
I1109 03:28:51.683769 144881 net.cpp:160] Creating Layer relu2
I1109 03:28:51.684131 144881 net.cpp:596] relu2 <- conv2
I1109 03:28:51.684391 144881 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:28:51.684906 144881 net.cpp:210] Setting up relu2
I1109 03:28:51.685190 144881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:28:51.685428 144881 net.cpp:225] Memory required for data: 188034560
I1109 03:28:51.685617 144881 layer_factory.hpp:114] Creating layer norm2
I1109 03:28:51.685863 144881 net.cpp:160] Creating Layer norm2
I1109 03:28:51.686095 144881 net.cpp:596] norm2 <- conv2
I1109 03:28:51.686336 144881 net.cpp:570] norm2 -> norm2
I1109 03:28:51.688438 144881 net.cpp:210] Setting up norm2
I1109 03:28:51.688745 144881 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:28:51.689035 144881 net.cpp:225] Memory required for data: 211922432
I1109 03:28:51.689225 144881 layer_factory.hpp:114] Creating layer pool2
I1109 03:28:51.690232 144881 net.cpp:160] Creating Layer pool2
I1109 03:28:51.690524 144881 net.cpp:596] pool2 <- norm2
I1109 03:28:51.690764 144881 net.cpp:570] pool2 -> pool2
I1109 03:28:51.691164 144881 net.cpp:210] Setting up pool2
I1109 03:28:51.691404 144881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:28:51.691627 144881 net.cpp:225] Memory required for data: 217460224
I1109 03:28:51.691823 144881 layer_factory.hpp:114] Creating layer conv3
I1109 03:28:51.692198 144881 net.cpp:160] Creating Layer conv3
I1109 03:28:51.692569 144881 net.cpp:596] conv3 <- pool2
I1109 03:28:51.692931 144881 net.cpp:570] conv3 -> conv3
I1109 03:28:52.171483 144881 net.cpp:210] Setting up conv3
I1109 03:28:52.173955 144881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:28:52.174314 144881 net.cpp:225] Memory required for data: 225766912
I1109 03:28:52.177446 144881 layer_factory.hpp:114] Creating layer relu3
I1109 03:28:52.177893 144881 net.cpp:160] Creating Layer relu3
I1109 03:28:52.178189 144881 net.cpp:596] relu3 <- conv3
I1109 03:28:52.178434 144881 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:28:52.182507 144881 net.cpp:210] Setting up relu3
I1109 03:28:52.182821 144881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:28:52.183075 144881 net.cpp:225] Memory required for data: 234073600
I1109 03:28:52.183306 144881 layer_factory.hpp:114] Creating layer conv4
I1109 03:28:52.183688 144881 net.cpp:160] Creating Layer conv4
I1109 03:28:52.183987 144881 net.cpp:596] conv4 <- conv3
I1109 03:28:52.184242 144881 net.cpp:570] conv4 -> conv4
I1109 03:28:52.452867 144881 net.cpp:210] Setting up conv4
I1109 03:28:52.453250 144881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:28:52.453694 144881 net.cpp:225] Memory required for data: 242380288
I1109 03:28:52.454036 144881 layer_factory.hpp:114] Creating layer relu4
I1109 03:28:52.454329 144881 net.cpp:160] Creating Layer relu4
I1109 03:28:52.454552 144881 net.cpp:596] relu4 <- conv4
I1109 03:28:52.454785 144881 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:28:52.467123 144881 net.cpp:210] Setting up relu4
I1109 03:28:52.467463 144881 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:28:52.467844 144881 net.cpp:225] Memory required for data: 250686976
I1109 03:28:52.468091 144881 layer_factory.hpp:114] Creating layer conv5
I1109 03:28:52.468449 144881 net.cpp:160] Creating Layer conv5
I1109 03:28:52.468691 144881 net.cpp:596] conv5 <- conv4
I1109 03:28:52.468988 144881 net.cpp:570] conv5 -> conv5
I1109 03:28:52.637284 144881 net.cpp:210] Setting up conv5
I1109 03:28:52.637677 144881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:28:52.638100 144881 net.cpp:225] Memory required for data: 256224768
I1109 03:28:52.642747 144881 layer_factory.hpp:114] Creating layer relu5
I1109 03:28:52.643149 144881 net.cpp:160] Creating Layer relu5
I1109 03:28:52.643401 144881 net.cpp:596] relu5 <- conv5
I1109 03:28:52.643666 144881 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:28:52.644125 144881 net.cpp:210] Setting up relu5
I1109 03:28:52.644415 144881 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:28:52.644661 144881 net.cpp:225] Memory required for data: 261762560
I1109 03:28:52.644915 144881 layer_factory.hpp:114] Creating layer pool5
I1109 03:28:52.645191 144881 net.cpp:160] Creating Layer pool5
I1109 03:28:52.645406 144881 net.cpp:596] pool5 <- conv5
I1109 03:28:52.645628 144881 net.cpp:570] pool5 -> pool5
I1109 03:28:52.646020 144881 net.cpp:210] Setting up pool5
I1109 03:28:52.646270 144881 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:28:52.646488 144881 net.cpp:225] Memory required for data: 262942208
I1109 03:28:52.646667 144881 layer_factory.hpp:114] Creating layer fc6
I1109 03:28:52.701212 144881 net.cpp:160] Creating Layer fc6
I1109 03:28:52.701524 144881 net.cpp:596] fc6 <- pool5
I1109 03:28:52.701946 144881 net.cpp:570] fc6 -> fc6
I1109 03:28:56.789912 144881 net.cpp:210] Setting up fc6
I1109 03:28:56.790215 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:56.792250 144881 net.cpp:225] Memory required for data: 263466496
I1109 03:28:56.792557 144881 layer_factory.hpp:114] Creating layer relu6
I1109 03:28:56.795054 144881 net.cpp:160] Creating Layer relu6
I1109 03:28:56.795343 144881 net.cpp:596] relu6 <- fc6
I1109 03:28:56.795567 144881 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:28:56.795989 144881 net.cpp:210] Setting up relu6
I1109 03:28:56.796249 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:56.796507 144881 net.cpp:225] Memory required for data: 263990784
I1109 03:28:56.796701 144881 layer_factory.hpp:114] Creating layer drop6
I1109 03:28:56.816823 144881 net.cpp:160] Creating Layer drop6
I1109 03:28:56.817131 144881 net.cpp:596] drop6 <- fc6
I1109 03:28:56.817503 144881 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:28:56.920754 144881 net.cpp:210] Setting up drop6
I1109 03:28:56.921099 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:56.921468 144881 net.cpp:225] Memory required for data: 264515072
I1109 03:28:56.921670 144881 layer_factory.hpp:114] Creating layer fc7
I1109 03:28:56.921937 144881 net.cpp:160] Creating Layer fc7
I1109 03:28:56.922149 144881 net.cpp:596] fc7 <- fc6
I1109 03:28:56.922535 144881 net.cpp:570] fc7 -> fc7
I1109 03:28:58.635546 144881 net.cpp:210] Setting up fc7
I1109 03:28:58.635892 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:58.636268 144881 net.cpp:225] Memory required for data: 265039360
I1109 03:28:58.636613 144881 layer_factory.hpp:114] Creating layer relu7
I1109 03:28:58.636970 144881 net.cpp:160] Creating Layer relu7
I1109 03:28:58.637219 144881 net.cpp:596] relu7 <- fc7
I1109 03:28:58.637466 144881 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:28:58.637905 144881 net.cpp:210] Setting up relu7
I1109 03:28:58.638180 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:58.638458 144881 net.cpp:225] Memory required for data: 265563648
I1109 03:28:58.638669 144881 layer_factory.hpp:114] Creating layer drop7
I1109 03:28:58.638926 144881 net.cpp:160] Creating Layer drop7
I1109 03:28:58.639197 144881 net.cpp:596] drop7 <- fc7
I1109 03:28:58.639472 144881 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:28:58.639739 144881 net.cpp:210] Setting up drop7
I1109 03:28:58.639943 144881 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:28:58.640159 144881 net.cpp:225] Memory required for data: 266087936
I1109 03:28:58.640344 144881 layer_factory.hpp:114] Creating layer fc8
I1109 03:28:58.640595 144881 net.cpp:160] Creating Layer fc8
I1109 03:28:58.640832 144881 net.cpp:596] fc8 <- fc7
I1109 03:28:58.641072 144881 net.cpp:570] fc8 -> fc8
I1109 03:28:59.062435 144881 net.cpp:210] Setting up fc8
I1109 03:28:59.062785 144881 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:28:59.063150 144881 net.cpp:225] Memory required for data: 266215936
I1109 03:28:59.063483 144881 layer_factory.hpp:114] Creating layer loss
I1109 03:28:59.088143 144881 net.cpp:160] Creating Layer loss
I1109 03:28:59.088460 144881 net.cpp:596] loss <- fc8
I1109 03:28:59.089501 144881 net.cpp:596] loss <- label
I1109 03:28:59.116859 144881 net.cpp:570] loss -> loss
I1109 03:28:59.154628 144881 layer_factory.hpp:114] Creating layer loss
I1109 03:29:01.720705 144881 net.cpp:210] Setting up loss
I1109 03:29:01.770252 144881 net.cpp:217] Top shape: (1)
I1109 03:29:01.787358 144881 net.cpp:220]     with loss weight 1
I1109 03:29:01.922313 144881 net.cpp:225] Memory required for data: 266215940
I1109 03:29:01.962576 144881 net.cpp:287] loss needs backward computation.
I1109 03:29:02.053524 144881 net.cpp:287] fc8 needs backward computation.
I1109 03:29:02.061663 144881 net.cpp:287] drop7 needs backward computation.
I1109 03:29:02.073873 144881 net.cpp:287] relu7 needs backward computation.
I1109 03:29:02.074224 144881 net.cpp:287] fc7 needs backward computation.
I1109 03:29:02.076838 144881 net.cpp:287] drop6 needs backward computation.
I1109 03:29:02.077426 144881 net.cpp:287] relu6 needs backward computation.
I1109 03:29:02.077805 144881 net.cpp:287] fc6 needs backward computation.
I1109 03:29:02.078819 144881 net.cpp:287] pool5 needs backward computation.
I1109 03:29:02.079740 144881 net.cpp:287] relu5 needs backward computation.
I1109 03:29:02.080121 144881 net.cpp:287] conv5 needs backward computation.
I1109 03:29:02.080531 144881 net.cpp:287] relu4 needs backward computation.
I1109 03:29:02.080945 144881 net.cpp:287] conv4 needs backward computation.
I1109 03:29:02.081192 144881 net.cpp:287] relu3 needs backward computation.
I1109 03:29:02.081416 144881 net.cpp:287] conv3 needs backward computation.
I1109 03:29:02.094388 144881 net.cpp:287] pool2 needs backward computation.
I1109 03:29:02.094755 144881 net.cpp:287] norm2 needs backward computation.
I1109 03:29:02.095104 144881 net.cpp:287] relu2 needs backward computation.
I1109 03:29:02.095361 144881 net.cpp:287] conv2 needs backward computation.
I1109 03:29:02.095569 144881 net.cpp:287] pool1 needs backward computation.
I1109 03:29:02.095763 144881 net.cpp:287] norm1 needs backward computation.
I1109 03:29:02.095950 144881 net.cpp:287] relu1 needs backward computation.
I1109 03:29:02.096129 144881 net.cpp:287] conv1 needs backward computation.
I1109 03:29:02.109014 144881 net.cpp:289] data does not need backward computation.
I1109 03:29:02.134414 144881 net.cpp:331] This network produces output loss
I1109 03:29:02.205440 144881 net.cpp:345] Network initialization done.
I1109 03:29:02.373265 144881 caffe.cpp:452] Performing Forward
I1109 03:29:15.269232 144881 caffe.cpp:457] Initial loss: 6.89544
I1109 03:29:15.322060 144881 caffe.cpp:459] Performing Backward
I1109 03:29:20.149788 144881 caffe.cpp:468] *** Benchmark begins ***
I1109 03:29:20.165249 144881 caffe.cpp:469] Testing for 1 iterations.
I1109 03:29:20.311383 144881 caffe.cpp:485] Profiling Layer: relu7 backward
I1109 03:29:22.500908 144881 caffe.cpp:512] Iteration: 1 forward-backward time: 2182 ms.
I1109 03:29:22.657636 144881 caffe.cpp:519] Average time per layer: 
I1109 03:29:22.673125 144881 caffe.cpp:522]       data	forward: 549.863 ms.
I1109 03:29:22.750947 144881 caffe.cpp:526]       data	backward: 4.981 ms.
I1109 03:29:22.776031 144881 caffe.cpp:522]      conv1	forward: 126.42 ms.
I1109 03:29:22.784696 144881 caffe.cpp:526]      conv1	backward: 49.172 ms.
I1109 03:29:22.792755 144881 caffe.cpp:522]      relu1	forward: 21.246 ms.
I1109 03:29:22.804673 144881 caffe.cpp:526]      relu1	backward: 12.538 ms.
I1109 03:29:22.812271 144881 caffe.cpp:522]      norm1	forward: 19.597 ms.
I1109 03:29:22.816766 144881 caffe.cpp:526]      norm1	backward: 10.07 ms.
I1109 03:29:22.825214 144881 caffe.cpp:522]      pool1	forward: 19.308 ms.
I1109 03:29:22.829030 144881 caffe.cpp:526]      pool1	backward: 40.017 ms.
I1109 03:29:22.837680 144881 caffe.cpp:522]      conv2	forward: 63.172 ms.
I1109 03:29:22.843682 144881 caffe.cpp:526]      conv2	backward: 31.575 ms.
I1109 03:29:22.850020 144881 caffe.cpp:522]      relu2	forward: 17.386 ms.
I1109 03:29:22.855487 144881 caffe.cpp:526]      relu2	backward: 0.714 ms.
I1109 03:29:22.863865 144881 caffe.cpp:522]      norm2	forward: 15.407 ms.
I1109 03:29:22.868259 144881 caffe.cpp:526]      norm2	backward: 2.111 ms.
I1109 03:29:22.868944 144881 caffe.cpp:522]      pool2	forward: 18.864 ms.
I1109 03:29:22.869151 144881 caffe.cpp:526]      pool2	backward: 22.329 ms.
I1109 03:29:22.869344 144881 caffe.cpp:522]      conv3	forward: 38.675 ms.
I1109 03:29:22.869535 144881 caffe.cpp:526]      conv3	backward: 36.377 ms.
I1109 03:29:22.869725 144881 caffe.cpp:522]      relu3	forward: 11.205 ms.
I1109 03:29:22.869916 144881 caffe.cpp:526]      relu3	backward: 0.581 ms.
I1109 03:29:22.870105 144881 caffe.cpp:522]      conv4	forward: 28.678 ms.
I1109 03:29:22.870296 144881 caffe.cpp:526]      conv4	backward: 28.014 ms.
I1109 03:29:22.870528 144881 caffe.cpp:522]      relu4	forward: 14.646 ms.
I1109 03:29:22.870744 144881 caffe.cpp:526]      relu4	backward: 7.302 ms.
I1109 03:29:22.870968 144881 caffe.cpp:522]      conv5	forward: 32.184 ms.
I1109 03:29:22.871230 144881 caffe.cpp:526]      conv5	backward: 18.933 ms.
I1109 03:29:22.871450 144881 caffe.cpp:522]      relu5	forward: 14.97 ms.
I1109 03:29:22.871642 144881 caffe.cpp:526]      relu5	backward: 0.24 ms.
I1109 03:29:22.871830 144881 caffe.cpp:522]      pool5	forward: 16.765 ms.
I1109 03:29:22.872020 144881 caffe.cpp:526]      pool5	backward: 9.094 ms.
I1109 03:29:22.872860 144881 caffe.cpp:522]        fc6	forward: 41.123 ms.
I1109 03:29:22.873127 144881 caffe.cpp:526]        fc6	backward: 28.106 ms.
I1109 03:29:22.873333 144881 caffe.cpp:522]      relu6	forward: 18.745 ms.
I1109 03:29:22.873621 144881 caffe.cpp:526]      relu6	backward: 2.548 ms.
I1109 03:29:22.873867 144881 caffe.cpp:522]      drop6	forward: 31.671 ms.
I1109 03:29:22.874061 144881 caffe.cpp:526]      drop6	backward: 19.048 ms.
I1109 03:29:22.874251 144881 caffe.cpp:522]        fc7	forward: 11.576 ms.
I1109 03:29:22.874442 144881 caffe.cpp:526]        fc7	backward: 169.375 ms.
I1109 03:29:22.874634 144881 caffe.cpp:522]      relu7	forward: 18.636 ms.
I1109 03:29:22.874825 144881 caffe.cpp:526]      relu7	backward: 29.676 ms.
I1109 03:29:22.875013 144881 caffe.cpp:522]      drop7	forward: 26.43 ms.
I1109 03:29:22.875203 144881 caffe.cpp:526]      drop7	backward: 16.901 ms.
I1109 03:29:22.875393 144881 caffe.cpp:522]        fc8	forward: 12.379 ms.
I1109 03:29:22.875583 144881 caffe.cpp:526]        fc8	backward: 234.918 ms.
I1109 03:29:22.875814 144881 caffe.cpp:522]       loss	forward: 58.661 ms.
I1109 03:29:22.876026 144881 caffe.cpp:526]       loss	backward: 85.676 ms.
I1109 03:29:22.882351 144881 caffe.cpp:532] Average Forward pass: 1284.34 ms.
I1109 03:29:22.895107 144881 caffe.cpp:535] Average Backward pass: 870.749 ms.
I1109 03:29:22.906014 144881 caffe.cpp:537] Average Forward-Backward: 2672 ms.
I1109 03:29:22.920544 144881 caffe.cpp:540] Total Time: 2672 ms.
I1109 03:29:22.932729 144881 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 8192
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 16384
--->Total FLOPs = 16384
mem-read-1 = 26961
mem-read-2 = 37
mem-read-4 = 216587
mem-read-8 = 300711
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 16385
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 598
mem-write-8 = 29150
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 8193
--->Total Bytes read = 4347743
--->Total Bytes written = 760066
--->Total Bytes = 5107809
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer21_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=21 -prof_forward_direction=0
I1109 03:33:04.064440 145038 caffe.cpp:444] Use CPU.
I1109 03:33:20.910365 145038 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:33:20.965917 145038 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:33:20.977784 145038 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:33:20.988732 145038 cpu_info.cpp:461] Total number of processors: 272
I1109 03:33:20.999651 145038 cpu_info.cpp:464] GPU is used: no
I1109 03:33:21.008348 145038 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:33:21.019999 145038 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:33:21.031083 145038 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:33:29.725384 145038 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:33:29.758244 145038 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:33:30.389441 145038 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:33:32.834697 145038 layer_factory.hpp:114] Creating layer data
I1109 03:33:32.980923 145038 net.cpp:160] Creating Layer data
I1109 03:33:33.029307 145038 net.cpp:570] data -> data
I1109 03:33:33.491943 145038 net.cpp:570] data -> label
I1109 03:33:40.514871 145038 net.cpp:210] Setting up data
I1109 03:33:40.594156 145038 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:33:40.698868 145038 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:33:40.706064 145038 net.cpp:225] Memory required for data: 19787264
I1109 03:33:40.773466 145038 layer_factory.hpp:114] Creating layer conv1
I1109 03:33:41.100891 145038 net.cpp:160] Creating Layer conv1
I1109 03:33:41.150722 145038 net.cpp:596] conv1 <- data
I1109 03:33:41.269964 145038 net.cpp:570] conv1 -> conv1
I1109 03:34:13.963341 145038 net.cpp:210] Setting up conv1
I1109 03:34:13.970616 145038 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:34:13.971001 145038 net.cpp:225] Memory required for data: 56958464
I1109 03:34:14.253644 145038 layer_factory.hpp:114] Creating layer relu1
I1109 03:34:14.375411 145038 net.cpp:160] Creating Layer relu1
I1109 03:34:14.380086 145038 net.cpp:596] relu1 <- conv1
I1109 03:34:14.413959 145038 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:34:14.611484 145038 net.cpp:210] Setting up relu1
I1109 03:34:14.613941 145038 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:34:14.614295 145038 net.cpp:225] Memory required for data: 94129664
I1109 03:34:14.614511 145038 layer_factory.hpp:114] Creating layer norm1
I1109 03:34:14.723565 145038 net.cpp:160] Creating Layer norm1
I1109 03:34:14.723881 145038 net.cpp:596] norm1 <- conv1
I1109 03:34:14.726529 145038 net.cpp:570] norm1 -> norm1
I1109 03:34:14.961781 145038 net.cpp:210] Setting up norm1
I1109 03:34:14.974897 145038 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:34:14.975280 145038 net.cpp:225] Memory required for data: 131300864
I1109 03:34:14.975584 145038 layer_factory.hpp:114] Creating layer pool1
I1109 03:34:15.070410 145038 net.cpp:160] Creating Layer pool1
I1109 03:34:15.070721 145038 net.cpp:596] pool1 <- norm1
I1109 03:34:15.085835 145038 net.cpp:570] pool1 -> pool1
I1109 03:34:15.391662 145038 net.cpp:210] Setting up pool1
I1109 03:34:15.394191 145038 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:34:15.394536 145038 net.cpp:225] Memory required for data: 140258816
I1109 03:34:15.394759 145038 layer_factory.hpp:114] Creating layer conv2
I1109 03:34:15.395140 145038 net.cpp:160] Creating Layer conv2
I1109 03:34:15.395371 145038 net.cpp:596] conv2 <- pool1
I1109 03:34:15.395618 145038 net.cpp:570] conv2 -> conv2
I1109 03:34:21.202111 145038 net.cpp:210] Setting up conv2
I1109 03:34:21.202426 145038 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:34:21.202822 145038 net.cpp:225] Memory required for data: 164146688
I1109 03:34:21.252377 145038 layer_factory.hpp:114] Creating layer relu2
I1109 03:34:21.252771 145038 net.cpp:160] Creating Layer relu2
I1109 03:34:21.253156 145038 net.cpp:596] relu2 <- conv2
I1109 03:34:21.253480 145038 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:34:21.253942 145038 net.cpp:210] Setting up relu2
I1109 03:34:21.254209 145038 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:34:21.254451 145038 net.cpp:225] Memory required for data: 188034560
I1109 03:34:21.254649 145038 layer_factory.hpp:114] Creating layer norm2
I1109 03:34:21.254909 145038 net.cpp:160] Creating Layer norm2
I1109 03:34:21.255115 145038 net.cpp:596] norm2 <- conv2
I1109 03:34:21.255352 145038 net.cpp:570] norm2 -> norm2
I1109 03:34:21.257470 145038 net.cpp:210] Setting up norm2
I1109 03:34:21.257779 145038 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:34:21.258008 145038 net.cpp:225] Memory required for data: 211922432
I1109 03:34:21.258231 145038 layer_factory.hpp:114] Creating layer pool2
I1109 03:34:21.258561 145038 net.cpp:160] Creating Layer pool2
I1109 03:34:21.258895 145038 net.cpp:596] pool2 <- norm2
I1109 03:34:21.259186 145038 net.cpp:570] pool2 -> pool2
I1109 03:34:21.259584 145038 net.cpp:210] Setting up pool2
I1109 03:34:21.259825 145038 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:34:21.260046 145038 net.cpp:225] Memory required for data: 217460224
I1109 03:34:21.260243 145038 layer_factory.hpp:114] Creating layer conv3
I1109 03:34:21.261214 145038 net.cpp:160] Creating Layer conv3
I1109 03:34:21.261615 145038 net.cpp:596] conv3 <- pool2
I1109 03:34:21.261945 145038 net.cpp:570] conv3 -> conv3
I1109 03:34:21.738649 145038 net.cpp:210] Setting up conv3
I1109 03:34:21.741153 145038 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:34:21.741521 145038 net.cpp:225] Memory required for data: 225766912
I1109 03:34:21.744716 145038 layer_factory.hpp:114] Creating layer relu3
I1109 03:34:21.745193 145038 net.cpp:160] Creating Layer relu3
I1109 03:34:21.745478 145038 net.cpp:596] relu3 <- conv3
I1109 03:34:21.745723 145038 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:34:21.749799 145038 net.cpp:210] Setting up relu3
I1109 03:34:21.750149 145038 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:34:21.750413 145038 net.cpp:225] Memory required for data: 234073600
I1109 03:34:21.750641 145038 layer_factory.hpp:114] Creating layer conv4
I1109 03:34:21.750996 145038 net.cpp:160] Creating Layer conv4
I1109 03:34:21.751241 145038 net.cpp:596] conv4 <- conv3
I1109 03:34:21.751482 145038 net.cpp:570] conv4 -> conv4
I1109 03:34:21.993850 145038 net.cpp:210] Setting up conv4
I1109 03:34:21.994236 145038 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:34:21.994654 145038 net.cpp:225] Memory required for data: 242380288
I1109 03:34:21.994966 145038 layer_factory.hpp:114] Creating layer relu4
I1109 03:34:21.995251 145038 net.cpp:160] Creating Layer relu4
I1109 03:34:21.995478 145038 net.cpp:596] relu4 <- conv4
I1109 03:34:21.995714 145038 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:34:22.007972 145038 net.cpp:210] Setting up relu4
I1109 03:34:22.008339 145038 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:34:22.008718 145038 net.cpp:225] Memory required for data: 250686976
I1109 03:34:22.009009 145038 layer_factory.hpp:114] Creating layer conv5
I1109 03:34:22.009377 145038 net.cpp:160] Creating Layer conv5
I1109 03:34:22.009620 145038 net.cpp:596] conv5 <- conv4
I1109 03:34:22.009869 145038 net.cpp:570] conv5 -> conv5
I1109 03:34:22.177930 145038 net.cpp:210] Setting up conv5
I1109 03:34:22.178329 145038 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:34:22.178766 145038 net.cpp:225] Memory required for data: 256224768
I1109 03:34:22.183401 145038 layer_factory.hpp:114] Creating layer relu5
I1109 03:34:22.183809 145038 net.cpp:160] Creating Layer relu5
I1109 03:34:22.184101 145038 net.cpp:596] relu5 <- conv5
I1109 03:34:22.184383 145038 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:34:22.184964 145038 net.cpp:210] Setting up relu5
I1109 03:34:22.185283 145038 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:34:22.185547 145038 net.cpp:225] Memory required for data: 261762560
I1109 03:34:22.185767 145038 layer_factory.hpp:114] Creating layer pool5
I1109 03:34:22.186038 145038 net.cpp:160] Creating Layer pool5
I1109 03:34:22.186265 145038 net.cpp:596] pool5 <- conv5
I1109 03:34:22.186499 145038 net.cpp:570] pool5 -> pool5
I1109 03:34:22.186918 145038 net.cpp:210] Setting up pool5
I1109 03:34:22.187181 145038 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:34:22.187417 145038 net.cpp:225] Memory required for data: 262942208
I1109 03:34:22.187611 145038 layer_factory.hpp:114] Creating layer fc6
I1109 03:34:22.242271 145038 net.cpp:160] Creating Layer fc6
I1109 03:34:22.242581 145038 net.cpp:596] fc6 <- pool5
I1109 03:34:22.242954 145038 net.cpp:570] fc6 -> fc6
I1109 03:34:26.330611 145038 net.cpp:210] Setting up fc6
I1109 03:34:26.330916 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:26.333046 145038 net.cpp:225] Memory required for data: 263466496
I1109 03:34:26.333359 145038 layer_factory.hpp:114] Creating layer relu6
I1109 03:34:26.335813 145038 net.cpp:160] Creating Layer relu6
I1109 03:34:26.336108 145038 net.cpp:596] relu6 <- fc6
I1109 03:34:26.336333 145038 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:34:26.336745 145038 net.cpp:210] Setting up relu6
I1109 03:34:26.337044 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:26.337308 145038 net.cpp:225] Memory required for data: 263990784
I1109 03:34:26.337507 145038 layer_factory.hpp:114] Creating layer drop6
I1109 03:34:26.357810 145038 net.cpp:160] Creating Layer drop6
I1109 03:34:26.358125 145038 net.cpp:596] drop6 <- fc6
I1109 03:34:26.358497 145038 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:34:26.463824 145038 net.cpp:210] Setting up drop6
I1109 03:34:26.464181 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:26.464673 145038 net.cpp:225] Memory required for data: 264515072
I1109 03:34:26.464967 145038 layer_factory.hpp:114] Creating layer fc7
I1109 03:34:26.465273 145038 net.cpp:160] Creating Layer fc7
I1109 03:34:26.465512 145038 net.cpp:596] fc7 <- fc6
I1109 03:34:26.465934 145038 net.cpp:570] fc7 -> fc7
I1109 03:34:28.176014 145038 net.cpp:210] Setting up fc7
I1109 03:34:28.176370 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:28.176762 145038 net.cpp:225] Memory required for data: 265039360
I1109 03:34:28.177155 145038 layer_factory.hpp:114] Creating layer relu7
I1109 03:34:28.177464 145038 net.cpp:160] Creating Layer relu7
I1109 03:34:28.177700 145038 net.cpp:596] relu7 <- fc7
I1109 03:34:28.177930 145038 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:34:28.178354 145038 net.cpp:210] Setting up relu7
I1109 03:34:28.178623 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:28.178855 145038 net.cpp:225] Memory required for data: 265563648
I1109 03:34:28.179088 145038 layer_factory.hpp:114] Creating layer drop7
I1109 03:34:28.179333 145038 net.cpp:160] Creating Layer drop7
I1109 03:34:28.179569 145038 net.cpp:596] drop7 <- fc7
I1109 03:34:28.179782 145038 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:34:28.180032 145038 net.cpp:210] Setting up drop7
I1109 03:34:28.180229 145038 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:34:28.180438 145038 net.cpp:225] Memory required for data: 266087936
I1109 03:34:28.180619 145038 layer_factory.hpp:114] Creating layer fc8
I1109 03:34:28.180929 145038 net.cpp:160] Creating Layer fc8
I1109 03:34:28.181154 145038 net.cpp:596] fc8 <- fc7
I1109 03:34:28.181381 145038 net.cpp:570] fc8 -> fc8
I1109 03:34:28.605120 145038 net.cpp:210] Setting up fc8
I1109 03:34:28.605494 145038 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:34:28.605953 145038 net.cpp:225] Memory required for data: 266215936
I1109 03:34:28.606276 145038 layer_factory.hpp:114] Creating layer loss
I1109 03:34:28.631203 145038 net.cpp:160] Creating Layer loss
I1109 03:34:28.631520 145038 net.cpp:596] loss <- fc8
I1109 03:34:28.632536 145038 net.cpp:596] loss <- label
I1109 03:34:28.660410 145038 net.cpp:570] loss -> loss
I1109 03:34:28.698667 145038 layer_factory.hpp:114] Creating layer loss
I1109 03:34:31.270828 145038 net.cpp:210] Setting up loss
I1109 03:34:31.320264 145038 net.cpp:217] Top shape: (1)
I1109 03:34:31.330202 145038 net.cpp:220]     with loss weight 1
I1109 03:34:31.458791 145038 net.cpp:225] Memory required for data: 266215940
I1109 03:34:31.516649 145038 net.cpp:287] loss needs backward computation.
I1109 03:34:31.619060 145038 net.cpp:287] fc8 needs backward computation.
I1109 03:34:31.627841 145038 net.cpp:287] drop7 needs backward computation.
I1109 03:34:31.638808 145038 net.cpp:287] relu7 needs backward computation.
I1109 03:34:31.639113 145038 net.cpp:287] fc7 needs backward computation.
I1109 03:34:31.641556 145038 net.cpp:287] drop6 needs backward computation.
I1109 03:34:31.641880 145038 net.cpp:287] relu6 needs backward computation.
I1109 03:34:31.642189 145038 net.cpp:287] fc6 needs backward computation.
I1109 03:34:31.643028 145038 net.cpp:287] pool5 needs backward computation.
I1109 03:34:31.643774 145038 net.cpp:287] relu5 needs backward computation.
I1109 03:34:31.644027 145038 net.cpp:287] conv5 needs backward computation.
I1109 03:34:31.644217 145038 net.cpp:287] relu4 needs backward computation.
I1109 03:34:31.644434 145038 net.cpp:287] conv4 needs backward computation.
I1109 03:34:31.644645 145038 net.cpp:287] relu3 needs backward computation.
I1109 03:34:31.644978 145038 net.cpp:287] conv3 needs backward computation.
I1109 03:34:31.657402 145038 net.cpp:287] pool2 needs backward computation.
I1109 03:34:31.657734 145038 net.cpp:287] norm2 needs backward computation.
I1109 03:34:31.658057 145038 net.cpp:287] relu2 needs backward computation.
I1109 03:34:31.658259 145038 net.cpp:287] conv2 needs backward computation.
I1109 03:34:31.658448 145038 net.cpp:287] pool1 needs backward computation.
I1109 03:34:31.658632 145038 net.cpp:287] norm1 needs backward computation.
I1109 03:34:31.658814 145038 net.cpp:287] relu1 needs backward computation.
I1109 03:34:31.658993 145038 net.cpp:287] conv1 needs backward computation.
I1109 03:34:31.671475 145038 net.cpp:289] data does not need backward computation.
I1109 03:34:31.695855 145038 net.cpp:331] This network produces output loss
I1109 03:34:31.769420 145038 net.cpp:345] Network initialization done.
I1109 03:34:31.937314 145038 caffe.cpp:452] Performing Forward
I1109 03:34:45.008661 145038 caffe.cpp:457] Initial loss: 6.88533
I1109 03:34:45.064837 145038 caffe.cpp:459] Performing Backward
I1109 03:34:49.908082 145038 caffe.cpp:468] *** Benchmark begins ***
I1109 03:34:49.919252 145038 caffe.cpp:469] Testing for 1 iterations.
I1109 03:34:50.065366 145038 caffe.cpp:485] Profiling Layer: drop7 backward
I1109 03:34:51.990389 145038 caffe.cpp:512] Iteration: 1 forward-backward time: 1922 ms.
I1109 03:34:52.153327 145038 caffe.cpp:519] Average time per layer: 
I1109 03:34:52.169627 145038 caffe.cpp:522]       data	forward: 545.966 ms.
I1109 03:34:52.240253 145038 caffe.cpp:526]       data	backward: 5.442 ms.
I1109 03:34:52.262305 145038 caffe.cpp:522]      conv1	forward: 120.936 ms.
I1109 03:34:52.268424 145038 caffe.cpp:526]      conv1	backward: 44.51 ms.
I1109 03:34:52.276114 145038 caffe.cpp:522]      relu1	forward: 21.912 ms.
I1109 03:34:52.283812 145038 caffe.cpp:526]      relu1	backward: 15.897 ms.
I1109 03:34:52.291618 145038 caffe.cpp:522]      norm1	forward: 18.296 ms.
I1109 03:34:52.298298 145038 caffe.cpp:526]      norm1	backward: 16.02 ms.
I1109 03:34:52.304728 145038 caffe.cpp:522]      pool1	forward: 18.318 ms.
I1109 03:34:52.310219 145038 caffe.cpp:526]      pool1	backward: 78.182 ms.
I1109 03:34:52.321231 145038 caffe.cpp:522]      conv2	forward: 58.966 ms.
I1109 03:34:52.325244 145038 caffe.cpp:526]      conv2	backward: 70.82 ms.
I1109 03:34:52.329107 145038 caffe.cpp:522]      relu2	forward: 19.564 ms.
I1109 03:34:52.340267 145038 caffe.cpp:526]      relu2	backward: 19.773 ms.
I1109 03:34:52.341675 145038 caffe.cpp:522]      norm2	forward: 11.17 ms.
I1109 03:34:52.341895 145038 caffe.cpp:526]      norm2	backward: 13.976 ms.
I1109 03:34:52.342102 145038 caffe.cpp:522]      pool2	forward: 11.628 ms.
I1109 03:34:52.342319 145038 caffe.cpp:526]      pool2	backward: 28.467 ms.
I1109 03:34:52.342550 145038 caffe.cpp:522]      conv3	forward: 28.171 ms.
I1109 03:34:52.342756 145038 caffe.cpp:526]      conv3	backward: 36.351 ms.
I1109 03:34:52.342960 145038 caffe.cpp:522]      relu3	forward: 17.49 ms.
I1109 03:34:52.343163 145038 caffe.cpp:526]      relu3	backward: 0.641 ms.
I1109 03:34:52.343364 145038 caffe.cpp:522]      conv4	forward: 31.691 ms.
I1109 03:34:52.343566 145038 caffe.cpp:526]      conv4	backward: 30.802 ms.
I1109 03:34:52.343768 145038 caffe.cpp:522]      relu4	forward: 15.124 ms.
I1109 03:34:52.343971 145038 caffe.cpp:526]      relu4	backward: 9.204 ms.
I1109 03:34:52.344873 145038 caffe.cpp:522]      conv5	forward: 32.394 ms.
I1109 03:34:52.345172 145038 caffe.cpp:526]      conv5	backward: 18.678 ms.
I1109 03:34:52.345384 145038 caffe.cpp:522]      relu5	forward: 16.181 ms.
I1109 03:34:52.345588 145038 caffe.cpp:526]      relu5	backward: 0.254 ms.
I1109 03:34:52.345791 145038 caffe.cpp:522]      pool5	forward: 13.967 ms.
I1109 03:34:52.345994 145038 caffe.cpp:526]      pool5	backward: 9.198 ms.
I1109 03:34:52.346194 145038 caffe.cpp:522]        fc6	forward: 46.244 ms.
I1109 03:34:52.346396 145038 caffe.cpp:526]        fc6	backward: 27.884 ms.
I1109 03:34:52.346598 145038 caffe.cpp:522]      relu6	forward: 32.995 ms.
I1109 03:34:52.346801 145038 caffe.cpp:526]      relu6	backward: 2.682 ms.
I1109 03:34:52.346997 145038 caffe.cpp:522]      drop6	forward: 29.982 ms.
I1109 03:34:52.347199 145038 caffe.cpp:526]      drop6	backward: 0.089 ms.
I1109 03:34:52.349822 145038 caffe.cpp:522]        fc7	forward: 13.922 ms.
I1109 03:34:52.350105 145038 caffe.cpp:526]        fc7	backward: 20.427 ms.
I1109 03:34:52.350436 145038 caffe.cpp:522]      relu7	forward: 8.797 ms.
I1109 03:34:52.350680 145038 caffe.cpp:526]      relu7	backward: 0.133 ms.
I1109 03:34:52.350870 145038 caffe.cpp:522]      drop7	forward: 25.007 ms.
I1109 03:34:52.351063 145038 caffe.cpp:526]      drop7	backward: 11.454 ms.
I1109 03:34:52.351253 145038 caffe.cpp:522]        fc8	forward: 25.409 ms.
I1109 03:34:52.351444 145038 caffe.cpp:526]        fc8	backward: 76.405 ms.
I1109 03:34:52.351634 145038 caffe.cpp:522]       loss	forward: 62.083 ms.
I1109 03:34:52.351824 145038 caffe.cpp:526]       loss	backward: 65.51 ms.
I1109 03:34:52.357396 145038 caffe.cpp:532] Average Forward pass: 1281.81 ms.
I1109 03:34:52.372174 145038 caffe.cpp:535] Average Backward pass: 611.617 ms.
I1109 03:34:52.383071 145038 caffe.cpp:537] Average Forward-Backward: 2393 ms.
I1109 03:34:52.397807 145038 caffe.cpp:540] Total Time: 2393 ms.
I1109 03:34:52.410089 145038 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 16384
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 262144
--->Total double-precision FLOPs = 0
--->Total FLOPs = 262144
mem-read-1 = 382428
mem-read-2 = 37
mem-read-4 = 3063176
mem-read-8 = 4214336
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 16384
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 731
mem-write-8 = 385829
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 8192
--->Total Bytes read = 47398470
--->Total Bytes written = 3613934
--->Total Bytes = 51012404
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer22_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=22 -prof_forward_direction=0
I1109 03:38:05.576231 145154 caffe.cpp:444] Use CPU.
I1109 03:38:22.477769 145154 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:38:22.533565 145154 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:38:22.545486 145154 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:38:22.557992 145154 cpu_info.cpp:461] Total number of processors: 272
I1109 03:38:22.569090 145154 cpu_info.cpp:464] GPU is used: no
I1109 03:38:22.578186 145154 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:38:22.586990 145154 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:38:22.598181 145154 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:38:31.341341 145154 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:38:31.374465 145154 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:38:32.016983 145154 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:38:34.472467 145154 layer_factory.hpp:114] Creating layer data
I1109 03:38:34.621644 145154 net.cpp:160] Creating Layer data
I1109 03:38:34.669729 145154 net.cpp:570] data -> data
I1109 03:38:35.135038 145154 net.cpp:570] data -> label
I1109 03:38:42.208150 145154 net.cpp:210] Setting up data
I1109 03:38:42.287233 145154 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:38:42.391479 145154 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:38:42.398689 145154 net.cpp:225] Memory required for data: 19787264
I1109 03:38:42.467300 145154 layer_factory.hpp:114] Creating layer conv1
I1109 03:38:42.801347 145154 net.cpp:160] Creating Layer conv1
I1109 03:38:42.851150 145154 net.cpp:596] conv1 <- data
I1109 03:38:42.970893 145154 net.cpp:570] conv1 -> conv1
I1109 03:39:15.910284 145154 net.cpp:210] Setting up conv1
I1109 03:39:15.917243 145154 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:39:15.917632 145154 net.cpp:225] Memory required for data: 56958464
I1109 03:39:16.209010 145154 layer_factory.hpp:114] Creating layer relu1
I1109 03:39:16.333528 145154 net.cpp:160] Creating Layer relu1
I1109 03:39:16.338184 145154 net.cpp:596] relu1 <- conv1
I1109 03:39:16.371799 145154 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:39:16.567484 145154 net.cpp:210] Setting up relu1
I1109 03:39:16.569944 145154 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:39:16.570292 145154 net.cpp:225] Memory required for data: 94129664
I1109 03:39:16.570499 145154 layer_factory.hpp:114] Creating layer norm1
I1109 03:39:16.679292 145154 net.cpp:160] Creating Layer norm1
I1109 03:39:16.679615 145154 net.cpp:596] norm1 <- conv1
I1109 03:39:16.682183 145154 net.cpp:570] norm1 -> norm1
I1109 03:39:16.921017 145154 net.cpp:210] Setting up norm1
I1109 03:39:16.934180 145154 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:39:16.934557 145154 net.cpp:225] Memory required for data: 131300864
I1109 03:39:16.934919 145154 layer_factory.hpp:114] Creating layer pool1
I1109 03:39:17.030390 145154 net.cpp:160] Creating Layer pool1
I1109 03:39:17.030699 145154 net.cpp:596] pool1 <- norm1
I1109 03:39:17.045724 145154 net.cpp:570] pool1 -> pool1
I1109 03:39:17.350558 145154 net.cpp:210] Setting up pool1
I1109 03:39:17.353130 145154 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:39:17.353485 145154 net.cpp:225] Memory required for data: 140258816
I1109 03:39:17.353708 145154 layer_factory.hpp:114] Creating layer conv2
I1109 03:39:17.354090 145154 net.cpp:160] Creating Layer conv2
I1109 03:39:17.354310 145154 net.cpp:596] conv2 <- pool1
I1109 03:39:17.354539 145154 net.cpp:570] conv2 -> conv2
I1109 03:39:23.250622 145154 net.cpp:210] Setting up conv2
I1109 03:39:23.250955 145154 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:39:23.251413 145154 net.cpp:225] Memory required for data: 164146688
I1109 03:39:23.302657 145154 layer_factory.hpp:114] Creating layer relu2
I1109 03:39:23.303084 145154 net.cpp:160] Creating Layer relu2
I1109 03:39:23.303455 145154 net.cpp:596] relu2 <- conv2
I1109 03:39:23.303719 145154 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:39:23.304152 145154 net.cpp:210] Setting up relu2
I1109 03:39:23.304415 145154 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:39:23.304644 145154 net.cpp:225] Memory required for data: 188034560
I1109 03:39:23.304878 145154 layer_factory.hpp:114] Creating layer norm2
I1109 03:39:23.305136 145154 net.cpp:160] Creating Layer norm2
I1109 03:39:23.305337 145154 net.cpp:596] norm2 <- conv2
I1109 03:39:23.305593 145154 net.cpp:570] norm2 -> norm2
I1109 03:39:23.307638 145154 net.cpp:210] Setting up norm2
I1109 03:39:23.307945 145154 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:39:23.308176 145154 net.cpp:225] Memory required for data: 211922432
I1109 03:39:23.308394 145154 layer_factory.hpp:114] Creating layer pool2
I1109 03:39:23.309378 145154 net.cpp:160] Creating Layer pool2
I1109 03:39:23.309691 145154 net.cpp:596] pool2 <- norm2
I1109 03:39:23.309948 145154 net.cpp:570] pool2 -> pool2
I1109 03:39:23.310370 145154 net.cpp:210] Setting up pool2
I1109 03:39:23.310633 145154 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:39:23.310868 145154 net.cpp:225] Memory required for data: 217460224
I1109 03:39:23.311071 145154 layer_factory.hpp:114] Creating layer conv3
I1109 03:39:23.311419 145154 net.cpp:160] Creating Layer conv3
I1109 03:39:23.311700 145154 net.cpp:596] conv3 <- pool2
I1109 03:39:23.312019 145154 net.cpp:570] conv3 -> conv3
I1109 03:39:23.791998 145154 net.cpp:210] Setting up conv3
I1109 03:39:23.794422 145154 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:39:23.794772 145154 net.cpp:225] Memory required for data: 225766912
I1109 03:39:23.797890 145154 layer_factory.hpp:114] Creating layer relu3
I1109 03:39:23.798305 145154 net.cpp:160] Creating Layer relu3
I1109 03:39:23.798585 145154 net.cpp:596] relu3 <- conv3
I1109 03:39:23.798823 145154 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:39:23.802942 145154 net.cpp:210] Setting up relu3
I1109 03:39:23.803293 145154 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:39:23.803552 145154 net.cpp:225] Memory required for data: 234073600
I1109 03:39:23.803758 145154 layer_factory.hpp:114] Creating layer conv4
I1109 03:39:23.804149 145154 net.cpp:160] Creating Layer conv4
I1109 03:39:23.804407 145154 net.cpp:596] conv4 <- conv3
I1109 03:39:23.804649 145154 net.cpp:570] conv4 -> conv4
I1109 03:39:24.049742 145154 net.cpp:210] Setting up conv4
I1109 03:39:24.050132 145154 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:39:24.050530 145154 net.cpp:225] Memory required for data: 242380288
I1109 03:39:24.050865 145154 layer_factory.hpp:114] Creating layer relu4
I1109 03:39:24.051161 145154 net.cpp:160] Creating Layer relu4
I1109 03:39:24.051393 145154 net.cpp:596] relu4 <- conv4
I1109 03:39:24.051630 145154 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:39:24.064075 145154 net.cpp:210] Setting up relu4
I1109 03:39:24.064447 145154 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:39:24.064894 145154 net.cpp:225] Memory required for data: 250686976
I1109 03:39:24.065143 145154 layer_factory.hpp:114] Creating layer conv5
I1109 03:39:24.065510 145154 net.cpp:160] Creating Layer conv5
I1109 03:39:24.065752 145154 net.cpp:596] conv5 <- conv4
I1109 03:39:24.065994 145154 net.cpp:570] conv5 -> conv5
I1109 03:39:24.234340 145154 net.cpp:210] Setting up conv5
I1109 03:39:24.234724 145154 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:39:24.235167 145154 net.cpp:225] Memory required for data: 256224768
I1109 03:39:24.239787 145154 layer_factory.hpp:114] Creating layer relu5
I1109 03:39:24.240234 145154 net.cpp:160] Creating Layer relu5
I1109 03:39:24.240492 145154 net.cpp:596] relu5 <- conv5
I1109 03:39:24.240871 145154 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:39:24.241381 145154 net.cpp:210] Setting up relu5
I1109 03:39:24.241670 145154 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:39:24.241916 145154 net.cpp:225] Memory required for data: 261762560
I1109 03:39:24.242120 145154 layer_factory.hpp:114] Creating layer pool5
I1109 03:39:24.242373 145154 net.cpp:160] Creating Layer pool5
I1109 03:39:24.242589 145154 net.cpp:596] pool5 <- conv5
I1109 03:39:24.242843 145154 net.cpp:570] pool5 -> pool5
I1109 03:39:24.243260 145154 net.cpp:210] Setting up pool5
I1109 03:39:24.243561 145154 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:39:24.243778 145154 net.cpp:225] Memory required for data: 262942208
I1109 03:39:24.243962 145154 layer_factory.hpp:114] Creating layer fc6
I1109 03:39:24.298899 145154 net.cpp:160] Creating Layer fc6
I1109 03:39:24.299208 145154 net.cpp:596] fc6 <- pool5
I1109 03:39:24.299602 145154 net.cpp:570] fc6 -> fc6
I1109 03:39:28.388984 145154 net.cpp:210] Setting up fc6
I1109 03:39:28.389291 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:28.391414 145154 net.cpp:225] Memory required for data: 263466496
I1109 03:39:28.391724 145154 layer_factory.hpp:114] Creating layer relu6
I1109 03:39:28.394273 145154 net.cpp:160] Creating Layer relu6
I1109 03:39:28.394573 145154 net.cpp:596] relu6 <- fc6
I1109 03:39:28.394798 145154 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:39:28.395215 145154 net.cpp:210] Setting up relu6
I1109 03:39:28.395473 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:28.395694 145154 net.cpp:225] Memory required for data: 263990784
I1109 03:39:28.395915 145154 layer_factory.hpp:114] Creating layer drop6
I1109 03:39:28.416108 145154 net.cpp:160] Creating Layer drop6
I1109 03:39:28.416416 145154 net.cpp:596] drop6 <- fc6
I1109 03:39:28.416831 145154 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:39:28.522912 145154 net.cpp:210] Setting up drop6
I1109 03:39:28.523213 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:28.523550 145154 net.cpp:225] Memory required for data: 264515072
I1109 03:39:28.523792 145154 layer_factory.hpp:114] Creating layer fc7
I1109 03:39:28.524062 145154 net.cpp:160] Creating Layer fc7
I1109 03:39:28.524276 145154 net.cpp:596] fc7 <- fc6
I1109 03:39:28.524660 145154 net.cpp:570] fc7 -> fc7
I1109 03:39:30.235255 145154 net.cpp:210] Setting up fc7
I1109 03:39:30.235591 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:30.235957 145154 net.cpp:225] Memory required for data: 265039360
I1109 03:39:30.236282 145154 layer_factory.hpp:114] Creating layer relu7
I1109 03:39:30.236582 145154 net.cpp:160] Creating Layer relu7
I1109 03:39:30.236842 145154 net.cpp:596] relu7 <- fc7
I1109 03:39:30.237090 145154 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:39:30.237514 145154 net.cpp:210] Setting up relu7
I1109 03:39:30.237783 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:30.238014 145154 net.cpp:225] Memory required for data: 265563648
I1109 03:39:30.238236 145154 layer_factory.hpp:114] Creating layer drop7
I1109 03:39:30.238473 145154 net.cpp:160] Creating Layer drop7
I1109 03:39:30.238677 145154 net.cpp:596] drop7 <- fc7
I1109 03:39:30.238978 145154 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:39:30.239266 145154 net.cpp:210] Setting up drop7
I1109 03:39:30.239461 145154 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:39:30.239670 145154 net.cpp:225] Memory required for data: 266087936
I1109 03:39:30.239848 145154 layer_factory.hpp:114] Creating layer fc8
I1109 03:39:30.240090 145154 net.cpp:160] Creating Layer fc8
I1109 03:39:30.240278 145154 net.cpp:596] fc8 <- fc7
I1109 03:39:30.240499 145154 net.cpp:570] fc8 -> fc8
I1109 03:39:30.664476 145154 net.cpp:210] Setting up fc8
I1109 03:39:30.664918 145154 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:39:30.665324 145154 net.cpp:225] Memory required for data: 266215936
I1109 03:39:30.665658 145154 layer_factory.hpp:114] Creating layer loss
I1109 03:39:30.690351 145154 net.cpp:160] Creating Layer loss
I1109 03:39:30.690665 145154 net.cpp:596] loss <- fc8
I1109 03:39:30.691699 145154 net.cpp:596] loss <- label
I1109 03:39:30.719081 145154 net.cpp:570] loss -> loss
I1109 03:39:30.757087 145154 layer_factory.hpp:114] Creating layer loss
I1109 03:39:33.344600 145154 net.cpp:210] Setting up loss
I1109 03:39:33.394805 145154 net.cpp:217] Top shape: (1)
I1109 03:39:33.404652 145154 net.cpp:220]     with loss weight 1
I1109 03:39:33.536586 145154 net.cpp:225] Memory required for data: 266215940
I1109 03:39:33.580140 145154 net.cpp:287] loss needs backward computation.
I1109 03:39:33.668668 145154 net.cpp:287] fc8 needs backward computation.
I1109 03:39:33.675894 145154 net.cpp:287] drop7 needs backward computation.
I1109 03:39:33.686962 145154 net.cpp:287] relu7 needs backward computation.
I1109 03:39:33.687285 145154 net.cpp:287] fc7 needs backward computation.
I1109 03:39:33.689820 145154 net.cpp:287] drop6 needs backward computation.
I1109 03:39:33.690230 145154 net.cpp:287] relu6 needs backward computation.
I1109 03:39:33.690495 145154 net.cpp:287] fc6 needs backward computation.
I1109 03:39:33.691175 145154 net.cpp:287] pool5 needs backward computation.
I1109 03:39:33.691916 145154 net.cpp:287] relu5 needs backward computation.
I1109 03:39:33.692179 145154 net.cpp:287] conv5 needs backward computation.
I1109 03:39:33.692415 145154 net.cpp:287] relu4 needs backward computation.
I1109 03:39:33.692629 145154 net.cpp:287] conv4 needs backward computation.
I1109 03:39:33.693006 145154 net.cpp:287] relu3 needs backward computation.
I1109 03:39:33.693203 145154 net.cpp:287] conv3 needs backward computation.
I1109 03:39:33.705580 145154 net.cpp:287] pool2 needs backward computation.
I1109 03:39:33.705905 145154 net.cpp:287] norm2 needs backward computation.
I1109 03:39:33.706104 145154 net.cpp:287] relu2 needs backward computation.
I1109 03:39:33.706316 145154 net.cpp:287] conv2 needs backward computation.
I1109 03:39:33.706513 145154 net.cpp:287] pool1 needs backward computation.
I1109 03:39:33.706763 145154 net.cpp:287] norm1 needs backward computation.
I1109 03:39:33.707041 145154 net.cpp:287] relu1 needs backward computation.
I1109 03:39:33.707252 145154 net.cpp:287] conv1 needs backward computation.
I1109 03:39:33.719668 145154 net.cpp:289] data does not need backward computation.
I1109 03:39:33.744614 145154 net.cpp:331] This network produces output loss
I1109 03:39:33.816488 145154 net.cpp:345] Network initialization done.
I1109 03:39:33.991325 145154 caffe.cpp:452] Performing Forward
I1109 03:39:47.000088 145154 caffe.cpp:457] Initial loss: 7.03892
I1109 03:39:47.052137 145154 caffe.cpp:459] Performing Backward
I1109 03:39:51.754902 145154 caffe.cpp:468] *** Benchmark begins ***
I1109 03:39:51.768137 145154 caffe.cpp:469] Testing for 1 iterations.
I1109 03:39:51.917495 145154 caffe.cpp:485] Profiling Layer: fc8 backward
I1109 03:39:54.000286 145154 caffe.cpp:512] Iteration: 1 forward-backward time: 2079 ms.
I1109 03:39:54.160722 145154 caffe.cpp:519] Average time per layer: 
I1109 03:39:54.179579 145154 caffe.cpp:522]       data	forward: 545.959 ms.
I1109 03:39:54.246481 145154 caffe.cpp:526]       data	backward: 4.928 ms.
I1109 03:39:54.265611 145154 caffe.cpp:522]      conv1	forward: 132.274 ms.
I1109 03:39:54.270730 145154 caffe.cpp:526]      conv1	backward: 49.123 ms.
I1109 03:39:54.276510 145154 caffe.cpp:522]      relu1	forward: 25.585 ms.
I1109 03:39:54.280227 145154 caffe.cpp:526]      relu1	backward: 13.027 ms.
I1109 03:39:54.283411 145154 caffe.cpp:522]      norm1	forward: 15.357 ms.
I1109 03:39:54.286851 145154 caffe.cpp:526]      norm1	backward: 21.801 ms.
I1109 03:39:54.288924 145154 caffe.cpp:522]      pool1	forward: 18.731 ms.
I1109 03:39:54.290729 145154 caffe.cpp:526]      pool1	backward: 97.074 ms.
I1109 03:39:54.299593 145154 caffe.cpp:522]      conv2	forward: 63.617 ms.
I1109 03:39:54.302033 145154 caffe.cpp:526]      conv2	backward: 44.953 ms.
I1109 03:39:54.303886 145154 caffe.cpp:522]      relu2	forward: 21.932 ms.
I1109 03:39:54.305460 145154 caffe.cpp:526]      relu2	backward: 0.695 ms.
I1109 03:39:54.307157 145154 caffe.cpp:522]      norm2	forward: 17.344 ms.
I1109 03:39:54.308020 145154 caffe.cpp:526]      norm2	backward: 2.113 ms.
I1109 03:39:54.309329 145154 caffe.cpp:522]      pool2	forward: 18.062 ms.
I1109 03:39:54.310514 145154 caffe.cpp:526]      pool2	backward: 22.518 ms.
I1109 03:39:54.311383 145154 caffe.cpp:522]      conv3	forward: 36.401 ms.
I1109 03:39:54.312477 145154 caffe.cpp:526]      conv3	backward: 36.485 ms.
I1109 03:39:54.313470 145154 caffe.cpp:522]      relu3	forward: 14.468 ms.
I1109 03:39:54.314086 145154 caffe.cpp:526]      relu3	backward: 0.658 ms.
I1109 03:39:54.314996 145154 caffe.cpp:522]      conv4	forward: 37.892 ms.
I1109 03:39:54.315919 145154 caffe.cpp:526]      conv4	backward: 27.961 ms.
I1109 03:39:54.316493 145154 caffe.cpp:522]      relu4	forward: 11.535 ms.
I1109 03:39:54.316951 145154 caffe.cpp:526]      relu4	backward: 7.479 ms.
I1109 03:39:54.317837 145154 caffe.cpp:522]      conv5	forward: 35.709 ms.
I1109 03:39:54.318636 145154 caffe.cpp:526]      conv5	backward: 21.491 ms.
I1109 03:39:54.319356 145154 caffe.cpp:522]      relu5	forward: 17.797 ms.
I1109 03:39:54.320257 145154 caffe.cpp:526]      relu5	backward: 0.238 ms.
I1109 03:39:54.320886 145154 caffe.cpp:522]      pool5	forward: 14.109 ms.
I1109 03:39:54.321662 145154 caffe.cpp:526]      pool5	backward: 11.934 ms.
I1109 03:39:54.322553 145154 caffe.cpp:522]        fc6	forward: 39.68 ms.
I1109 03:39:54.323447 145154 caffe.cpp:526]        fc6	backward: 39.346 ms.
I1109 03:39:54.324229 145154 caffe.cpp:522]      relu6	forward: 20.822 ms.
I1109 03:39:54.325147 145154 caffe.cpp:526]      relu6	backward: 0.085 ms.
I1109 03:39:54.330374 145154 caffe.cpp:522]      drop6	forward: 40.663 ms.
I1109 03:39:54.352993 145154 caffe.cpp:526]      drop6	backward: 0.084 ms.
I1109 03:39:54.353787 145154 caffe.cpp:522]        fc7	forward: 12.716 ms.
I1109 03:39:54.357812 145154 caffe.cpp:526]        fc7	backward: 62.442 ms.
I1109 03:39:54.358722 145154 caffe.cpp:522]      relu7	forward: 19.28 ms.
I1109 03:39:54.359498 145154 caffe.cpp:526]      relu7	backward: 9.799 ms.
I1109 03:39:54.361423 145154 caffe.cpp:522]      drop7	forward: 33.915 ms.
I1109 03:39:54.381635 145154 caffe.cpp:526]      drop7	backward: 25.59 ms.
I1109 03:39:54.381909 145154 caffe.cpp:522]        fc8	forward: 17.458 ms.
I1109 03:39:54.382124 145154 caffe.cpp:526]        fc8	backward: 135.513 ms.
I1109 03:39:54.382339 145154 caffe.cpp:522]       loss	forward: 63.206 ms.
I1109 03:39:54.382546 145154 caffe.cpp:526]       loss	backward: 75.345 ms.
I1109 03:39:54.388144 145154 caffe.cpp:532] Average Forward pass: 1330.13 ms.
I1109 03:39:54.401623 145154 caffe.cpp:535] Average Backward pass: 719.481 ms.
I1109 03:39:54.412896 145154 caffe.cpp:537] Average Forward-Backward: 2574 ms.
I1109 03:39:54.427989 145154 caffe.cpp:540] Total Time: 2574 ms.
I1109 03:39:54.440490 145154 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 918
elements_fp_single_4 = 1120
elements_fp_single_8 = 603824
elements_fp_single_16 = 33044704
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 533551254
--->Total double-precision FLOPs = 0
--->Total FLOPs = 533551254
mem-read-1 = 116064
mem-read-2 = 139
mem-read-4 = 17368652
mem-read-8 = 1508586
mem-read-16 = 115232
mem-read-32 = 539456
mem-read-64 = 4515656
mem-write-1 = 21843
mem-write-2 = 55
mem-write-4 = 4350
mem-write-8 = 145924
mem-write-16 = 18890
mem-write-32 = 589988
mem-write-64 = 284436
--->Total Bytes read = 389767926
--->Total Bytes written = 38592505
--->Total Bytes = 428360431
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer23_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=23 -prof_forward_direction=0
I1109 03:45:56.036170 145289 caffe.cpp:444] Use CPU.
I1109 03:46:12.871197 145289 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:46:12.927160 145289 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:46:12.939049 145289 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:46:12.951637 145289 cpu_info.cpp:461] Total number of processors: 272
I1109 03:46:12.962823 145289 cpu_info.cpp:464] GPU is used: no
I1109 03:46:12.971894 145289 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:46:12.980629 145289 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:46:12.991479 145289 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:46:21.701215 145289 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:46:21.733942 145289 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:46:22.364454 145289 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:46:24.806566 145289 layer_factory.hpp:114] Creating layer data
I1109 03:46:24.952742 145289 net.cpp:160] Creating Layer data
I1109 03:46:25.000514 145289 net.cpp:570] data -> data
I1109 03:46:25.466233 145289 net.cpp:570] data -> label
I1109 03:46:32.478268 145289 net.cpp:210] Setting up data
I1109 03:46:32.556699 145289 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:46:32.660876 145289 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:46:32.668020 145289 net.cpp:225] Memory required for data: 19787264
I1109 03:46:32.736702 145289 layer_factory.hpp:114] Creating layer conv1
I1109 03:46:33.062458 145289 net.cpp:160] Creating Layer conv1
I1109 03:46:33.111917 145289 net.cpp:596] conv1 <- data
I1109 03:46:33.230832 145289 net.cpp:570] conv1 -> conv1
I1109 03:47:06.065019 145289 net.cpp:210] Setting up conv1
I1109 03:47:06.072670 145289 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:47:06.073142 145289 net.cpp:225] Memory required for data: 56958464
I1109 03:47:06.354238 145289 layer_factory.hpp:114] Creating layer relu1
I1109 03:47:06.474045 145289 net.cpp:160] Creating Layer relu1
I1109 03:47:06.478597 145289 net.cpp:596] relu1 <- conv1
I1109 03:47:06.510627 145289 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:47:06.698797 145289 net.cpp:210] Setting up relu1
I1109 03:47:06.701273 145289 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:47:06.701616 145289 net.cpp:225] Memory required for data: 94129664
I1109 03:47:06.701859 145289 layer_factory.hpp:114] Creating layer norm1
I1109 03:47:06.805716 145289 net.cpp:160] Creating Layer norm1
I1109 03:47:06.806028 145289 net.cpp:596] norm1 <- conv1
I1109 03:47:06.808570 145289 net.cpp:570] norm1 -> norm1
I1109 03:47:07.032416 145289 net.cpp:210] Setting up norm1
I1109 03:47:07.045341 145289 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:47:07.045727 145289 net.cpp:225] Memory required for data: 131300864
I1109 03:47:07.046033 145289 layer_factory.hpp:114] Creating layer pool1
I1109 03:47:07.138649 145289 net.cpp:160] Creating Layer pool1
I1109 03:47:07.138967 145289 net.cpp:596] pool1 <- norm1
I1109 03:47:07.153781 145289 net.cpp:570] pool1 -> pool1
I1109 03:47:07.451979 145289 net.cpp:210] Setting up pool1
I1109 03:47:07.454505 145289 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:47:07.454875 145289 net.cpp:225] Memory required for data: 140258816
I1109 03:47:07.455109 145289 layer_factory.hpp:114] Creating layer conv2
I1109 03:47:07.455569 145289 net.cpp:160] Creating Layer conv2
I1109 03:47:07.455792 145289 net.cpp:596] conv2 <- pool1
I1109 03:47:07.456027 145289 net.cpp:570] conv2 -> conv2
I1109 03:47:13.198801 145289 net.cpp:210] Setting up conv2
I1109 03:47:13.199126 145289 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:47:13.199568 145289 net.cpp:225] Memory required for data: 164146688
I1109 03:47:13.249603 145289 layer_factory.hpp:114] Creating layer relu2
I1109 03:47:13.250001 145289 net.cpp:160] Creating Layer relu2
I1109 03:47:13.250366 145289 net.cpp:596] relu2 <- conv2
I1109 03:47:13.250641 145289 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:47:13.251093 145289 net.cpp:210] Setting up relu2
I1109 03:47:13.251368 145289 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:47:13.251619 145289 net.cpp:225] Memory required for data: 188034560
I1109 03:47:13.251814 145289 layer_factory.hpp:114] Creating layer norm2
I1109 03:47:13.252060 145289 net.cpp:160] Creating Layer norm2
I1109 03:47:13.252256 145289 net.cpp:596] norm2 <- conv2
I1109 03:47:13.252528 145289 net.cpp:570] norm2 -> norm2
I1109 03:47:13.254649 145289 net.cpp:210] Setting up norm2
I1109 03:47:13.254981 145289 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:47:13.255236 145289 net.cpp:225] Memory required for data: 211922432
I1109 03:47:13.255445 145289 layer_factory.hpp:114] Creating layer pool2
I1109 03:47:13.256379 145289 net.cpp:160] Creating Layer pool2
I1109 03:47:13.256682 145289 net.cpp:596] pool2 <- norm2
I1109 03:47:13.256999 145289 net.cpp:570] pool2 -> pool2
I1109 03:47:13.257452 145289 net.cpp:210] Setting up pool2
I1109 03:47:13.257700 145289 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:47:13.257967 145289 net.cpp:225] Memory required for data: 217460224
I1109 03:47:13.258235 145289 layer_factory.hpp:114] Creating layer conv3
I1109 03:47:13.258709 145289 net.cpp:160] Creating Layer conv3
I1109 03:47:13.258945 145289 net.cpp:596] conv3 <- pool2
I1109 03:47:13.259193 145289 net.cpp:570] conv3 -> conv3
I1109 03:47:13.709777 145289 net.cpp:210] Setting up conv3
I1109 03:47:13.712244 145289 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:47:13.712604 145289 net.cpp:225] Memory required for data: 225766912
I1109 03:47:13.715878 145289 layer_factory.hpp:114] Creating layer relu3
I1109 03:47:13.716325 145289 net.cpp:160] Creating Layer relu3
I1109 03:47:13.716593 145289 net.cpp:596] relu3 <- conv3
I1109 03:47:13.716889 145289 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:47:13.721077 145289 net.cpp:210] Setting up relu3
I1109 03:47:13.721416 145289 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:47:13.721699 145289 net.cpp:225] Memory required for data: 234073600
I1109 03:47:13.721920 145289 layer_factory.hpp:114] Creating layer conv4
I1109 03:47:13.722313 145289 net.cpp:160] Creating Layer conv4
I1109 03:47:13.722594 145289 net.cpp:596] conv4 <- conv3
I1109 03:47:13.722865 145289 net.cpp:570] conv4 -> conv4
I1109 03:47:13.965168 145289 net.cpp:210] Setting up conv4
I1109 03:47:13.965564 145289 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:47:13.965968 145289 net.cpp:225] Memory required for data: 242380288
I1109 03:47:13.966321 145289 layer_factory.hpp:114] Creating layer relu4
I1109 03:47:13.966630 145289 net.cpp:160] Creating Layer relu4
I1109 03:47:13.966873 145289 net.cpp:596] relu4 <- conv4
I1109 03:47:13.967118 145289 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:47:13.979461 145289 net.cpp:210] Setting up relu4
I1109 03:47:13.979811 145289 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:47:13.980188 145289 net.cpp:225] Memory required for data: 250686976
I1109 03:47:13.980445 145289 layer_factory.hpp:114] Creating layer conv5
I1109 03:47:13.980860 145289 net.cpp:160] Creating Layer conv5
I1109 03:47:13.981130 145289 net.cpp:596] conv5 <- conv4
I1109 03:47:13.981391 145289 net.cpp:570] conv5 -> conv5
I1109 03:47:14.151198 145289 net.cpp:210] Setting up conv5
I1109 03:47:14.151598 145289 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:47:14.152050 145289 net.cpp:225] Memory required for data: 256224768
I1109 03:47:14.156761 145289 layer_factory.hpp:114] Creating layer relu5
I1109 03:47:14.157245 145289 net.cpp:160] Creating Layer relu5
I1109 03:47:14.157546 145289 net.cpp:596] relu5 <- conv5
I1109 03:47:14.157829 145289 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:47:14.158299 145289 net.cpp:210] Setting up relu5
I1109 03:47:14.158596 145289 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:47:14.158860 145289 net.cpp:225] Memory required for data: 261762560
I1109 03:47:14.159081 145289 layer_factory.hpp:114] Creating layer pool5
I1109 03:47:14.159385 145289 net.cpp:160] Creating Layer pool5
I1109 03:47:14.159618 145289 net.cpp:596] pool5 <- conv5
I1109 03:47:14.159864 145289 net.cpp:570] pool5 -> pool5
I1109 03:47:14.160292 145289 net.cpp:210] Setting up pool5
I1109 03:47:14.160552 145289 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:47:14.160818 145289 net.cpp:225] Memory required for data: 262942208
I1109 03:47:14.161041 145289 layer_factory.hpp:114] Creating layer fc6
I1109 03:47:14.215605 145289 net.cpp:160] Creating Layer fc6
I1109 03:47:14.215917 145289 net.cpp:596] fc6 <- pool5
I1109 03:47:14.216320 145289 net.cpp:570] fc6 -> fc6
I1109 03:47:18.357745 145289 net.cpp:210] Setting up fc6
I1109 03:47:18.358096 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:18.360100 145289 net.cpp:225] Memory required for data: 263466496
I1109 03:47:18.360415 145289 layer_factory.hpp:114] Creating layer relu6
I1109 03:47:18.362911 145289 net.cpp:160] Creating Layer relu6
I1109 03:47:18.363211 145289 net.cpp:596] relu6 <- fc6
I1109 03:47:18.363445 145289 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:47:18.363862 145289 net.cpp:210] Setting up relu6
I1109 03:47:18.364151 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:18.364392 145289 net.cpp:225] Memory required for data: 263990784
I1109 03:47:18.364593 145289 layer_factory.hpp:114] Creating layer drop6
I1109 03:47:18.384451 145289 net.cpp:160] Creating Layer drop6
I1109 03:47:18.384759 145289 net.cpp:596] drop6 <- fc6
I1109 03:47:18.385176 145289 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:47:18.487960 145289 net.cpp:210] Setting up drop6
I1109 03:47:18.488263 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:18.488605 145289 net.cpp:225] Memory required for data: 264515072
I1109 03:47:18.488893 145289 layer_factory.hpp:114] Creating layer fc7
I1109 03:47:18.489171 145289 net.cpp:160] Creating Layer fc7
I1109 03:47:18.489389 145289 net.cpp:596] fc7 <- fc6
I1109 03:47:18.489775 145289 net.cpp:570] fc7 -> fc7
I1109 03:47:20.203610 145289 net.cpp:210] Setting up fc7
I1109 03:47:20.203966 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:20.204419 145289 net.cpp:225] Memory required for data: 265039360
I1109 03:47:20.204769 145289 layer_factory.hpp:114] Creating layer relu7
I1109 03:47:20.205150 145289 net.cpp:160] Creating Layer relu7
I1109 03:47:20.205399 145289 net.cpp:596] relu7 <- fc7
I1109 03:47:20.205651 145289 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:47:20.206096 145289 net.cpp:210] Setting up relu7
I1109 03:47:20.206374 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:20.206656 145289 net.cpp:225] Memory required for data: 265563648
I1109 03:47:20.206873 145289 layer_factory.hpp:114] Creating layer drop7
I1109 03:47:20.207128 145289 net.cpp:160] Creating Layer drop7
I1109 03:47:20.207371 145289 net.cpp:596] drop7 <- fc7
I1109 03:47:20.207623 145289 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:47:20.207890 145289 net.cpp:210] Setting up drop7
I1109 03:47:20.208096 145289 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:47:20.208317 145289 net.cpp:225] Memory required for data: 266087936
I1109 03:47:20.208504 145289 layer_factory.hpp:114] Creating layer fc8
I1109 03:47:20.208756 145289 net.cpp:160] Creating Layer fc8
I1109 03:47:20.209017 145289 net.cpp:596] fc8 <- fc7
I1109 03:47:20.209250 145289 net.cpp:570] fc8 -> fc8
I1109 03:47:20.632946 145289 net.cpp:210] Setting up fc8
I1109 03:47:20.633298 145289 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:47:20.633671 145289 net.cpp:225] Memory required for data: 266215936
I1109 03:47:20.634008 145289 layer_factory.hpp:114] Creating layer loss
I1109 03:47:20.658427 145289 net.cpp:160] Creating Layer loss
I1109 03:47:20.658741 145289 net.cpp:596] loss <- fc8
I1109 03:47:20.659761 145289 net.cpp:596] loss <- label
I1109 03:47:20.687185 145289 net.cpp:570] loss -> loss
I1109 03:47:20.724845 145289 layer_factory.hpp:114] Creating layer loss
I1109 03:47:23.239928 145289 net.cpp:210] Setting up loss
I1109 03:47:23.282415 145289 net.cpp:217] Top shape: (1)
I1109 03:47:23.300194 145289 net.cpp:220]     with loss weight 1
I1109 03:47:23.430538 145289 net.cpp:225] Memory required for data: 266215940
I1109 03:47:23.475111 145289 net.cpp:287] loss needs backward computation.
I1109 03:47:23.575119 145289 net.cpp:287] fc8 needs backward computation.
I1109 03:47:23.585865 145289 net.cpp:287] drop7 needs backward computation.
I1109 03:47:23.597141 145289 net.cpp:287] relu7 needs backward computation.
I1109 03:47:23.597442 145289 net.cpp:287] fc7 needs backward computation.
I1109 03:47:23.599840 145289 net.cpp:287] drop6 needs backward computation.
I1109 03:47:23.600178 145289 net.cpp:287] relu6 needs backward computation.
I1109 03:47:23.600476 145289 net.cpp:287] fc6 needs backward computation.
I1109 03:47:23.601390 145289 net.cpp:287] pool5 needs backward computation.
I1109 03:47:23.602141 145289 net.cpp:287] relu5 needs backward computation.
I1109 03:47:23.602396 145289 net.cpp:287] conv5 needs backward computation.
I1109 03:47:23.602589 145289 net.cpp:287] relu4 needs backward computation.
I1109 03:47:23.602808 145289 net.cpp:287] conv4 needs backward computation.
I1109 03:47:23.603013 145289 net.cpp:287] relu3 needs backward computation.
I1109 03:47:23.603312 145289 net.cpp:287] conv3 needs backward computation.
I1109 03:47:23.615898 145289 net.cpp:287] pool2 needs backward computation.
I1109 03:47:23.616235 145289 net.cpp:287] norm2 needs backward computation.
I1109 03:47:23.616602 145289 net.cpp:287] relu2 needs backward computation.
I1109 03:47:23.616912 145289 net.cpp:287] conv2 needs backward computation.
I1109 03:47:23.617121 145289 net.cpp:287] pool1 needs backward computation.
I1109 03:47:23.617346 145289 net.cpp:287] norm1 needs backward computation.
I1109 03:47:23.617533 145289 net.cpp:287] relu1 needs backward computation.
I1109 03:47:23.617713 145289 net.cpp:287] conv1 needs backward computation.
I1109 03:47:23.630158 145289 net.cpp:289] data does not need backward computation.
I1109 03:47:23.654325 145289 net.cpp:331] This network produces output loss
I1109 03:47:23.725409 145289 net.cpp:345] Network initialization done.
I1109 03:47:23.898471 145289 caffe.cpp:452] Performing Forward
I1109 03:47:36.812757 145289 caffe.cpp:457] Initial loss: 6.91162
I1109 03:47:36.868986 145289 caffe.cpp:459] Performing Backward
I1109 03:47:41.837617 145289 caffe.cpp:468] *** Benchmark begins ***
I1109 03:47:41.848436 145289 caffe.cpp:469] Testing for 1 iterations.
I1109 03:47:42.001912 145289 caffe.cpp:485] Profiling Layer: loss backward
I1109 03:47:44.362009 145289 caffe.cpp:512] Iteration: 1 forward-backward time: 2351 ms.
I1109 03:47:44.522501 145289 caffe.cpp:519] Average time per layer: 
I1109 03:47:44.537957 145289 caffe.cpp:522]       data	forward: 546.665 ms.
I1109 03:47:44.604836 145289 caffe.cpp:526]       data	backward: 5.39 ms.
I1109 03:47:44.632140 145289 caffe.cpp:522]      conv1	forward: 137.916 ms.
I1109 03:47:44.636474 145289 caffe.cpp:526]      conv1	backward: 38.768 ms.
I1109 03:47:44.646781 145289 caffe.cpp:522]      relu1	forward: 14.439 ms.
I1109 03:47:44.653254 145289 caffe.cpp:526]      relu1	backward: 18.179 ms.
I1109 03:47:44.666422 145289 caffe.cpp:522]      norm1	forward: 21.093 ms.
I1109 03:47:44.674506 145289 caffe.cpp:526]      norm1	backward: 19.784 ms.
I1109 03:47:44.683668 145289 caffe.cpp:522]      pool1	forward: 23.04 ms.
I1109 03:47:44.689832 145289 caffe.cpp:526]      pool1	backward: 80.303 ms.
I1109 03:47:44.696619 145289 caffe.cpp:522]      conv2	forward: 69.255 ms.
I1109 03:47:44.697044 145289 caffe.cpp:526]      conv2	backward: 79.616 ms.
I1109 03:47:44.697254 145289 caffe.cpp:522]      relu2	forward: 17.675 ms.
I1109 03:47:44.697448 145289 caffe.cpp:526]      relu2	backward: 17.616 ms.
I1109 03:47:44.697641 145289 caffe.cpp:522]      norm2	forward: 13.449 ms.
I1109 03:47:44.697831 145289 caffe.cpp:526]      norm2	backward: 16.34 ms.
I1109 03:47:44.698021 145289 caffe.cpp:522]      pool2	forward: 17.586 ms.
I1109 03:47:44.698210 145289 caffe.cpp:526]      pool2	backward: 72.969 ms.
I1109 03:47:44.698400 145289 caffe.cpp:522]      conv3	forward: 31.854 ms.
I1109 03:47:44.698588 145289 caffe.cpp:526]      conv3	backward: 78.184 ms.
I1109 03:47:44.698778 145289 caffe.cpp:522]      relu3	forward: 11.313 ms.
I1109 03:47:44.699000 145289 caffe.cpp:526]      relu3	backward: 29.449 ms.
I1109 03:47:44.699201 145289 caffe.cpp:522]      conv4	forward: 25.915 ms.
I1109 03:47:44.699435 145289 caffe.cpp:526]      conv4	backward: 74.121 ms.
I1109 03:47:44.699739 145289 caffe.cpp:522]      relu4	forward: 11.054 ms.
I1109 03:47:44.699934 145289 caffe.cpp:526]      relu4	backward: 43.041 ms.
I1109 03:47:44.700124 145289 caffe.cpp:522]      conv5	forward: 23.133 ms.
I1109 03:47:44.700314 145289 caffe.cpp:526]      conv5	backward: 77.25 ms.
I1109 03:47:44.700502 145289 caffe.cpp:522]      relu5	forward: 0.197 ms.
I1109 03:47:44.700690 145289 caffe.cpp:526]      relu5	backward: 17.626 ms.
I1109 03:47:44.700904 145289 caffe.cpp:522]      pool5	forward: 0.287 ms.
I1109 03:47:44.701092 145289 caffe.cpp:526]      pool5	backward: 56.812 ms.
I1109 03:47:44.701282 145289 caffe.cpp:522]        fc6	forward: 16.791 ms.
I1109 03:47:44.701469 145289 caffe.cpp:526]        fc6	backward: 111.354 ms.
I1109 03:47:44.701699 145289 caffe.cpp:522]      relu6	forward: 0.795 ms.
I1109 03:47:44.701900 145289 caffe.cpp:526]      relu6	backward: 20.788 ms.
I1109 03:47:44.702139 145289 caffe.cpp:522]      drop6	forward: 1.516 ms.
I1109 03:47:44.702404 145289 caffe.cpp:526]      drop6	backward: 16.057 ms.
I1109 03:47:44.702630 145289 caffe.cpp:522]        fc7	forward: 4.636 ms.
I1109 03:47:44.702816 145289 caffe.cpp:526]        fc7	backward: 126.193 ms.
I1109 03:47:44.703006 145289 caffe.cpp:522]      relu7	forward: 0.127 ms.
I1109 03:47:44.703193 145289 caffe.cpp:526]      relu7	backward: 16.888 ms.
I1109 03:47:44.703383 145289 caffe.cpp:522]      drop7	forward: 0.349 ms.
I1109 03:47:44.703570 145289 caffe.cpp:526]      drop7	backward: 20.898 ms.
I1109 03:47:44.703759 145289 caffe.cpp:522]        fc8	forward: 1.888 ms.
I1109 03:47:44.703943 145289 caffe.cpp:526]        fc8	backward: 138.828 ms.
I1109 03:47:44.704133 145289 caffe.cpp:522]       loss	forward: 44.829 ms.
I1109 03:47:44.704360 145289 caffe.cpp:526]       loss	backward: 46.477 ms.
I1109 03:47:44.709815 145289 caffe.cpp:532] Average Forward pass: 1090.65 ms.
I1109 03:47:44.722865 145289 caffe.cpp:535] Average Backward pass: 1233.17 ms.
I1109 03:47:44.733585 145289 caffe.cpp:537] Average Forward-Backward: 2814 ms.
I1109 03:47:44.748167 145289 caffe.cpp:540] Total Time: 2814 ms.
I1109 03:47:44.760233 145289 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 44
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 2000
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 32044
--->Total double-precision FLOPs = 0
--->Total FLOPs = 32044
mem-read-1 = 2680076
mem-read-2 = 52
mem-read-4 = 17048423
mem-read-8 = 29435020
mem-read-16 = 24
mem-read-32 = 0
mem-read-64 = 6000
mem-write-1 = 10437
mem-write-2 = 27
mem-write-4 = 1558
mem-write-8 = 2683864
mem-write-16 = 11
mem-write-32 = 1040
mem-write-64 = 4000
--->Total Bytes read = 306738416
--->Total Bytes written = 21777091
--->Total Bytes = 328515507
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer24_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=24 -prof_forward_direction=0
I1109 03:51:20.306756 145454 caffe.cpp:444] Use CPU.
I1109 03:51:37.141942 145454 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:51:37.197623 145454 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:51:37.209390 145454 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:51:37.221839 145454 cpu_info.cpp:461] Total number of processors: 272
I1109 03:51:37.233304 145454 cpu_info.cpp:464] GPU is used: no
I1109 03:51:37.242336 145454 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:51:37.251132 145454 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:51:37.262053 145454 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:51:45.959228 145454 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:51:45.992055 145454 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:51:46.621175 145454 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:51:49.073132 145454 layer_factory.hpp:114] Creating layer data
I1109 03:51:49.219354 145454 net.cpp:160] Creating Layer data
I1109 03:51:49.267467 145454 net.cpp:570] data -> data
I1109 03:51:49.731469 145454 net.cpp:570] data -> label
I1109 03:51:56.750504 145454 net.cpp:210] Setting up data
I1109 03:51:56.830611 145454 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:51:56.934705 145454 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:51:56.941859 145454 net.cpp:225] Memory required for data: 19787264
I1109 03:51:57.009217 145454 layer_factory.hpp:114] Creating layer conv1
I1109 03:51:57.339586 145454 net.cpp:160] Creating Layer conv1
I1109 03:51:57.390112 145454 net.cpp:596] conv1 <- data
I1109 03:51:57.509351 145454 net.cpp:570] conv1 -> conv1
I1109 03:52:30.125461 145454 net.cpp:210] Setting up conv1
I1109 03:52:30.132208 145454 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:52:30.132606 145454 net.cpp:225] Memory required for data: 56958464
I1109 03:52:30.414672 145454 layer_factory.hpp:114] Creating layer relu1
I1109 03:52:30.534092 145454 net.cpp:160] Creating Layer relu1
I1109 03:52:30.538696 145454 net.cpp:596] relu1 <- conv1
I1109 03:52:30.571880 145454 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:52:30.761239 145454 net.cpp:210] Setting up relu1
I1109 03:52:30.763697 145454 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:52:30.764052 145454 net.cpp:225] Memory required for data: 94129664
I1109 03:52:30.764271 145454 layer_factory.hpp:114] Creating layer norm1
I1109 03:52:30.869168 145454 net.cpp:160] Creating Layer norm1
I1109 03:52:30.869477 145454 net.cpp:596] norm1 <- conv1
I1109 03:52:30.871979 145454 net.cpp:570] norm1 -> norm1
I1109 03:52:31.093293 145454 net.cpp:210] Setting up norm1
I1109 03:52:31.105989 145454 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:52:31.106371 145454 net.cpp:225] Memory required for data: 131300864
I1109 03:52:31.106695 145454 layer_factory.hpp:114] Creating layer pool1
I1109 03:52:31.199167 145454 net.cpp:160] Creating Layer pool1
I1109 03:52:31.199481 145454 net.cpp:596] pool1 <- norm1
I1109 03:52:31.214210 145454 net.cpp:570] pool1 -> pool1
I1109 03:52:31.514143 145454 net.cpp:210] Setting up pool1
I1109 03:52:31.516561 145454 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:52:31.516940 145454 net.cpp:225] Memory required for data: 140258816
I1109 03:52:31.517192 145454 layer_factory.hpp:114] Creating layer conv2
I1109 03:52:31.517572 145454 net.cpp:160] Creating Layer conv2
I1109 03:52:31.517804 145454 net.cpp:596] conv2 <- pool1
I1109 03:52:31.518069 145454 net.cpp:570] conv2 -> conv2
I1109 03:52:37.242755 145454 net.cpp:210] Setting up conv2
I1109 03:52:37.243073 145454 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:52:37.243476 145454 net.cpp:225] Memory required for data: 164146688
I1109 03:52:37.293730 145454 layer_factory.hpp:114] Creating layer relu2
I1109 03:52:37.294128 145454 net.cpp:160] Creating Layer relu2
I1109 03:52:37.294500 145454 net.cpp:596] relu2 <- conv2
I1109 03:52:37.294771 145454 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:52:37.295222 145454 net.cpp:210] Setting up relu2
I1109 03:52:37.295490 145454 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:52:37.295732 145454 net.cpp:225] Memory required for data: 188034560
I1109 03:52:37.295922 145454 layer_factory.hpp:114] Creating layer norm2
I1109 03:52:37.296166 145454 net.cpp:160] Creating Layer norm2
I1109 03:52:37.296366 145454 net.cpp:596] norm2 <- conv2
I1109 03:52:37.296640 145454 net.cpp:570] norm2 -> norm2
I1109 03:52:37.298702 145454 net.cpp:210] Setting up norm2
I1109 03:52:37.299023 145454 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:52:37.299275 145454 net.cpp:225] Memory required for data: 211922432
I1109 03:52:37.299476 145454 layer_factory.hpp:114] Creating layer pool2
I1109 03:52:37.300371 145454 net.cpp:160] Creating Layer pool2
I1109 03:52:37.300673 145454 net.cpp:596] pool2 <- norm2
I1109 03:52:37.300988 145454 net.cpp:570] pool2 -> pool2
I1109 03:52:37.301436 145454 net.cpp:210] Setting up pool2
I1109 03:52:37.301674 145454 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:52:37.301897 145454 net.cpp:225] Memory required for data: 217460224
I1109 03:52:37.302134 145454 layer_factory.hpp:114] Creating layer conv3
I1109 03:52:37.302580 145454 net.cpp:160] Creating Layer conv3
I1109 03:52:37.302891 145454 net.cpp:596] conv3 <- pool2
I1109 03:52:37.303148 145454 net.cpp:570] conv3 -> conv3
I1109 03:52:37.760066 145454 net.cpp:210] Setting up conv3
I1109 03:52:37.762526 145454 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:52:37.762895 145454 net.cpp:225] Memory required for data: 225766912
I1109 03:52:37.766086 145454 layer_factory.hpp:114] Creating layer relu3
I1109 03:52:37.766577 145454 net.cpp:160] Creating Layer relu3
I1109 03:52:37.766860 145454 net.cpp:596] relu3 <- conv3
I1109 03:52:37.767107 145454 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:52:37.771244 145454 net.cpp:210] Setting up relu3
I1109 03:52:37.771626 145454 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:52:37.771917 145454 net.cpp:225] Memory required for data: 234073600
I1109 03:52:37.772114 145454 layer_factory.hpp:114] Creating layer conv4
I1109 03:52:37.772476 145454 net.cpp:160] Creating Layer conv4
I1109 03:52:37.772737 145454 net.cpp:596] conv4 <- conv3
I1109 03:52:37.773046 145454 net.cpp:570] conv4 -> conv4
I1109 03:52:38.021955 145454 net.cpp:210] Setting up conv4
I1109 03:52:38.022331 145454 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:52:38.022697 145454 net.cpp:225] Memory required for data: 242380288
I1109 03:52:38.023033 145454 layer_factory.hpp:114] Creating layer relu4
I1109 03:52:38.023314 145454 net.cpp:160] Creating Layer relu4
I1109 03:52:38.023532 145454 net.cpp:596] relu4 <- conv4
I1109 03:52:38.023766 145454 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:52:38.035867 145454 net.cpp:210] Setting up relu4
I1109 03:52:38.036201 145454 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:52:38.036579 145454 net.cpp:225] Memory required for data: 250686976
I1109 03:52:38.036825 145454 layer_factory.hpp:114] Creating layer conv5
I1109 03:52:38.037209 145454 net.cpp:160] Creating Layer conv5
I1109 03:52:38.037444 145454 net.cpp:596] conv5 <- conv4
I1109 03:52:38.037686 145454 net.cpp:570] conv5 -> conv5
I1109 03:52:38.205884 145454 net.cpp:210] Setting up conv5
I1109 03:52:38.206265 145454 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:52:38.206689 145454 net.cpp:225] Memory required for data: 256224768
I1109 03:52:38.211277 145454 layer_factory.hpp:114] Creating layer relu5
I1109 03:52:38.211684 145454 net.cpp:160] Creating Layer relu5
I1109 03:52:38.211963 145454 net.cpp:596] relu5 <- conv5
I1109 03:52:38.212231 145454 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:52:38.212692 145454 net.cpp:210] Setting up relu5
I1109 03:52:38.213032 145454 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:52:38.213285 145454 net.cpp:225] Memory required for data: 261762560
I1109 03:52:38.213495 145454 layer_factory.hpp:114] Creating layer pool5
I1109 03:52:38.213793 145454 net.cpp:160] Creating Layer pool5
I1109 03:52:38.214025 145454 net.cpp:596] pool5 <- conv5
I1109 03:52:38.214267 145454 net.cpp:570] pool5 -> pool5
I1109 03:52:38.214695 145454 net.cpp:210] Setting up pool5
I1109 03:52:38.214944 145454 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:52:38.215167 145454 net.cpp:225] Memory required for data: 262942208
I1109 03:52:38.215350 145454 layer_factory.hpp:114] Creating layer fc6
I1109 03:52:38.269662 145454 net.cpp:160] Creating Layer fc6
I1109 03:52:38.269971 145454 net.cpp:596] fc6 <- pool5
I1109 03:52:38.270339 145454 net.cpp:570] fc6 -> fc6
I1109 03:52:42.413460 145454 net.cpp:210] Setting up fc6
I1109 03:52:42.413764 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:42.415819 145454 net.cpp:225] Memory required for data: 263466496
I1109 03:52:42.416134 145454 layer_factory.hpp:114] Creating layer relu6
I1109 03:52:42.418707 145454 net.cpp:160] Creating Layer relu6
I1109 03:52:42.419008 145454 net.cpp:596] relu6 <- fc6
I1109 03:52:42.419241 145454 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:52:42.419704 145454 net.cpp:210] Setting up relu6
I1109 03:52:42.419973 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:42.420219 145454 net.cpp:225] Memory required for data: 263990784
I1109 03:52:42.420480 145454 layer_factory.hpp:114] Creating layer drop6
I1109 03:52:42.440408 145454 net.cpp:160] Creating Layer drop6
I1109 03:52:42.440716 145454 net.cpp:596] drop6 <- fc6
I1109 03:52:42.441140 145454 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:52:42.544759 145454 net.cpp:210] Setting up drop6
I1109 03:52:42.545101 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:42.545449 145454 net.cpp:225] Memory required for data: 264515072
I1109 03:52:42.545696 145454 layer_factory.hpp:114] Creating layer fc7
I1109 03:52:42.545969 145454 net.cpp:160] Creating Layer fc7
I1109 03:52:42.546180 145454 net.cpp:596] fc7 <- fc6
I1109 03:52:42.546562 145454 net.cpp:570] fc7 -> fc7
I1109 03:52:44.258692 145454 net.cpp:210] Setting up fc7
I1109 03:52:44.259039 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:44.259493 145454 net.cpp:225] Memory required for data: 265039360
I1109 03:52:44.259842 145454 layer_factory.hpp:114] Creating layer relu7
I1109 03:52:44.260226 145454 net.cpp:160] Creating Layer relu7
I1109 03:52:44.260470 145454 net.cpp:596] relu7 <- fc7
I1109 03:52:44.260721 145454 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:52:44.261222 145454 net.cpp:210] Setting up relu7
I1109 03:52:44.261502 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:44.261742 145454 net.cpp:225] Memory required for data: 265563648
I1109 03:52:44.261970 145454 layer_factory.hpp:114] Creating layer drop7
I1109 03:52:44.262220 145454 net.cpp:160] Creating Layer drop7
I1109 03:52:44.262435 145454 net.cpp:596] drop7 <- fc7
I1109 03:52:44.262714 145454 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:52:44.262987 145454 net.cpp:210] Setting up drop7
I1109 03:52:44.263191 145454 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:52:44.263407 145454 net.cpp:225] Memory required for data: 266087936
I1109 03:52:44.263591 145454 layer_factory.hpp:114] Creating layer fc8
I1109 03:52:44.263840 145454 net.cpp:160] Creating Layer fc8
I1109 03:52:44.264039 145454 net.cpp:596] fc8 <- fc7
I1109 03:52:44.264262 145454 net.cpp:570] fc8 -> fc8
I1109 03:52:44.686497 145454 net.cpp:210] Setting up fc8
I1109 03:52:44.686846 145454 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:52:44.687243 145454 net.cpp:225] Memory required for data: 266215936
I1109 03:52:44.687541 145454 layer_factory.hpp:114] Creating layer loss
I1109 03:52:44.712040 145454 net.cpp:160] Creating Layer loss
I1109 03:52:44.712352 145454 net.cpp:596] loss <- fc8
I1109 03:52:44.713318 145454 net.cpp:596] loss <- label
I1109 03:52:44.741678 145454 net.cpp:570] loss -> loss
I1109 03:52:44.780921 145454 layer_factory.hpp:114] Creating layer loss
I1109 03:52:47.374694 145454 net.cpp:210] Setting up loss
I1109 03:52:47.424094 145454 net.cpp:217] Top shape: (1)
I1109 03:52:47.438079 145454 net.cpp:220]     with loss weight 1
I1109 03:52:47.576141 145454 net.cpp:225] Memory required for data: 266215940
I1109 03:52:47.615396 145454 net.cpp:287] loss needs backward computation.
I1109 03:52:47.702368 145454 net.cpp:287] fc8 needs backward computation.
I1109 03:52:47.709630 145454 net.cpp:287] drop7 needs backward computation.
I1109 03:52:47.720736 145454 net.cpp:287] relu7 needs backward computation.
I1109 03:52:47.721103 145454 net.cpp:287] fc7 needs backward computation.
I1109 03:52:47.723556 145454 net.cpp:287] drop6 needs backward computation.
I1109 03:52:47.723976 145454 net.cpp:287] relu6 needs backward computation.
I1109 03:52:47.724225 145454 net.cpp:287] fc6 needs backward computation.
I1109 03:52:47.724947 145454 net.cpp:287] pool5 needs backward computation.
I1109 03:52:47.725682 145454 net.cpp:287] relu5 needs backward computation.
I1109 03:52:47.725955 145454 net.cpp:287] conv5 needs backward computation.
I1109 03:52:47.726194 145454 net.cpp:287] relu4 needs backward computation.
I1109 03:52:47.726415 145454 net.cpp:287] conv4 needs backward computation.
I1109 03:52:47.726727 145454 net.cpp:287] relu3 needs backward computation.
I1109 03:52:47.726954 145454 net.cpp:287] conv3 needs backward computation.
I1109 03:52:47.739485 145454 net.cpp:287] pool2 needs backward computation.
I1109 03:52:47.739835 145454 net.cpp:287] norm2 needs backward computation.
I1109 03:52:47.740144 145454 net.cpp:287] relu2 needs backward computation.
I1109 03:52:47.740382 145454 net.cpp:287] conv2 needs backward computation.
I1109 03:52:47.740574 145454 net.cpp:287] pool1 needs backward computation.
I1109 03:52:47.740754 145454 net.cpp:287] norm1 needs backward computation.
I1109 03:52:47.740974 145454 net.cpp:287] relu1 needs backward computation.
I1109 03:52:47.741153 145454 net.cpp:287] conv1 needs backward computation.
I1109 03:52:47.753535 145454 net.cpp:289] data does not need backward computation.
I1109 03:52:47.778645 145454 net.cpp:331] This network produces output loss
I1109 03:52:47.850123 145454 net.cpp:345] Network initialization done.
I1109 03:52:48.033762 145454 caffe.cpp:452] Performing Forward
I1109 03:53:01.284701 145454 caffe.cpp:457] Initial loss: 6.79103
I1109 03:53:01.335059 145454 caffe.cpp:459] Performing Backward
I1109 03:53:06.055460 145454 caffe.cpp:468] *** Benchmark begins ***
I1109 03:53:06.069978 145454 caffe.cpp:469] Testing for 1 iterations.
I1109 03:53:08.279062 145454 caffe.cpp:512] Iteration: 1 forward-backward time: 2081 ms.
I1109 03:53:08.436880 145454 caffe.cpp:519] Average time per layer: 
I1109 03:53:08.456432 145454 caffe.cpp:522]       data	forward: 552.924 ms.
I1109 03:53:08.523222 145454 caffe.cpp:526]       data	backward: 5.851 ms.
I1109 03:53:08.541154 145454 caffe.cpp:522]      conv1	forward: 110.565 ms.
I1109 03:53:08.541707 145454 caffe.cpp:526]      conv1	backward: 54.981 ms.
I1109 03:53:08.545039 145454 caffe.cpp:522]      relu1	forward: 1.303 ms.
I1109 03:53:08.545717 145454 caffe.cpp:526]      relu1	backward: 19.818 ms.
I1109 03:53:08.546110 145454 caffe.cpp:522]      norm1	forward: 7.071 ms.
I1109 03:53:08.546535 145454 caffe.cpp:526]      norm1	backward: 10.02 ms.
I1109 03:53:08.549762 145454 caffe.cpp:522]      pool1	forward: 3.61 ms.
I1109 03:53:08.550462 145454 caffe.cpp:526]      pool1	backward: 91.23 ms.
I1109 03:53:08.551607 145454 caffe.cpp:522]      conv2	forward: 40.869 ms.
I1109 03:53:08.551893 145454 caffe.cpp:526]      conv2	backward: 79.958 ms.
I1109 03:53:08.552199 145454 caffe.cpp:522]      relu2	forward: 0.521 ms.
I1109 03:53:08.552515 145454 caffe.cpp:526]      relu2	backward: 23.609 ms.
I1109 03:53:08.552865 145454 caffe.cpp:522]      norm2	forward: 3.319 ms.
I1109 03:53:08.553112 145454 caffe.cpp:526]      norm2	backward: 12.56 ms.
I1109 03:53:08.553395 145454 caffe.cpp:522]      pool2	forward: 1.173 ms.
I1109 03:53:08.553648 145454 caffe.cpp:526]      pool2	backward: 72.411 ms.
I1109 03:53:08.553942 145454 caffe.cpp:522]      conv3	forward: 9.808 ms.
I1109 03:53:08.554926 145454 caffe.cpp:526]      conv3	backward: 75.754 ms.
I1109 03:53:08.555250 145454 caffe.cpp:522]      relu3	forward: 0.257 ms.
I1109 03:53:08.555537 145454 caffe.cpp:526]      relu3	backward: 29.408 ms.
I1109 03:53:08.555816 145454 caffe.cpp:522]      conv4	forward: 7.58 ms.
I1109 03:53:08.556067 145454 caffe.cpp:526]      conv4	backward: 60.236 ms.
I1109 03:53:08.556360 145454 caffe.cpp:522]      relu4	forward: 0.244 ms.
I1109 03:53:08.556609 145454 caffe.cpp:526]      relu4	backward: 40.99 ms.
I1109 03:53:08.556928 145454 caffe.cpp:522]      conv5	forward: 5.272 ms.
I1109 03:53:08.557178 145454 caffe.cpp:526]      conv5	backward: 76.004 ms.
I1109 03:53:08.557462 145454 caffe.cpp:522]      relu5	forward: 0.192 ms.
I1109 03:53:08.557763 145454 caffe.cpp:526]      relu5	backward: 23.821 ms.
I1109 03:53:08.558056 145454 caffe.cpp:522]      pool5	forward: 0.304 ms.
I1109 03:53:08.558354 145454 caffe.cpp:526]      pool5	backward: 43.443 ms.
I1109 03:53:08.558640 145454 caffe.cpp:522]        fc6	forward: 16.714 ms.
I1109 03:53:08.558890 145454 caffe.cpp:526]        fc6	backward: 113.93 ms.
I1109 03:53:08.559168 145454 caffe.cpp:522]      relu6	forward: 0.791 ms.
I1109 03:53:08.559453 145454 caffe.cpp:526]      relu6	backward: 16.744 ms.
I1109 03:53:08.559696 145454 caffe.cpp:522]      drop6	forward: 1.442 ms.
I1109 03:53:08.559976 145454 caffe.cpp:526]      drop6	backward: 12.867 ms.
I1109 03:53:08.560226 145454 caffe.cpp:522]        fc7	forward: 4.633 ms.
I1109 03:53:08.560514 145454 caffe.cpp:526]        fc7	backward: 76.303 ms.
I1109 03:53:08.560825 145454 caffe.cpp:522]      relu7	forward: 0.127 ms.
I1109 03:53:08.561089 145454 caffe.cpp:526]      relu7	backward: 13.381 ms.
I1109 03:53:08.561336 145454 caffe.cpp:522]      drop7	forward: 0.301 ms.
I1109 03:53:08.561586 145454 caffe.cpp:526]      drop7	backward: 13.133 ms.
I1109 03:53:08.561830 145454 caffe.cpp:522]        fc8	forward: 5.702 ms.
I1109 03:53:08.562093 145454 caffe.cpp:526]        fc8	backward: 118.582 ms.
I1109 03:53:08.562338 145454 caffe.cpp:522]       loss	forward: 56.126 ms.
I1109 03:53:08.562577 145454 caffe.cpp:526]       loss	backward: 73.309 ms.
I1109 03:53:08.568658 145454 caffe.cpp:532] Average Forward pass: 887.363 ms.
I1109 03:53:08.582554 145454 caffe.cpp:535] Average Backward pass: 1167.17 ms.
I1109 03:53:08.594645 145454 caffe.cpp:537] Average Forward-Backward: 2452 ms.
I1109 03:53:08.610649 145454 caffe.cpp:540] Total Time: 2452 ms.
I1109 03:53:08.624359 145454 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 0
mem-read-2 = 0
mem-read-4 = 0
mem-read-8 = 0
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 0
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 0
--->Total Bytes written = 0
--->Total Bytes = 0
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer25_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=25 -prof_forward_direction=0
I1109 03:55:11.253947 145556 caffe.cpp:444] Use CPU.
I1109 03:55:27.980409 145556 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:55:28.035908 145556 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:55:28.047607 145556 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:55:28.059986 145556 cpu_info.cpp:461] Total number of processors: 272
I1109 03:55:28.071100 145556 cpu_info.cpp:464] GPU is used: no
I1109 03:55:28.080303 145556 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:55:28.089440 145556 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:55:28.100442 145556 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:55:36.756587 145556 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:55:36.789299 145556 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:55:37.422639 145556 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:55:39.852828 145556 layer_factory.hpp:114] Creating layer data
I1109 03:55:40.001150 145556 net.cpp:160] Creating Layer data
I1109 03:55:40.054266 145556 net.cpp:570] data -> data
I1109 03:55:40.518707 145556 net.cpp:570] data -> label
I1109 03:55:47.518584 145556 net.cpp:210] Setting up data
I1109 03:55:47.603444 145556 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:55:47.708478 145556 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:55:47.715868 145556 net.cpp:225] Memory required for data: 19787264
I1109 03:55:47.783007 145556 layer_factory.hpp:114] Creating layer conv1
I1109 03:55:48.111006 145556 net.cpp:160] Creating Layer conv1
I1109 03:55:48.162011 145556 net.cpp:596] conv1 <- data
I1109 03:55:48.281497 145556 net.cpp:570] conv1 -> conv1
I1109 03:56:21.061342 145556 net.cpp:210] Setting up conv1
I1109 03:56:21.068055 145556 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:56:21.068434 145556 net.cpp:225] Memory required for data: 56958464
I1109 03:56:21.351529 145556 layer_factory.hpp:114] Creating layer relu1
I1109 03:56:21.471922 145556 net.cpp:160] Creating Layer relu1
I1109 03:56:21.476501 145556 net.cpp:596] relu1 <- conv1
I1109 03:56:21.508586 145556 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:56:21.697294 145556 net.cpp:210] Setting up relu1
I1109 03:56:21.699714 145556 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:56:21.700088 145556 net.cpp:225] Memory required for data: 94129664
I1109 03:56:21.700307 145556 layer_factory.hpp:114] Creating layer norm1
I1109 03:56:21.804606 145556 net.cpp:160] Creating Layer norm1
I1109 03:56:21.804965 145556 net.cpp:596] norm1 <- conv1
I1109 03:56:21.807502 145556 net.cpp:570] norm1 -> norm1
I1109 03:56:22.030890 145556 net.cpp:210] Setting up norm1
I1109 03:56:22.043768 145556 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:56:22.044162 145556 net.cpp:225] Memory required for data: 131300864
I1109 03:56:22.044492 145556 layer_factory.hpp:114] Creating layer pool1
I1109 03:56:22.137253 145556 net.cpp:160] Creating Layer pool1
I1109 03:56:22.137569 145556 net.cpp:596] pool1 <- norm1
I1109 03:56:22.152375 145556 net.cpp:570] pool1 -> pool1
I1109 03:56:22.452823 145556 net.cpp:210] Setting up pool1
I1109 03:56:22.455288 145556 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:56:22.455664 145556 net.cpp:225] Memory required for data: 140258816
I1109 03:56:22.455895 145556 layer_factory.hpp:114] Creating layer conv2
I1109 03:56:22.456321 145556 net.cpp:160] Creating Layer conv2
I1109 03:56:22.456570 145556 net.cpp:596] conv2 <- pool1
I1109 03:56:22.456850 145556 net.cpp:570] conv2 -> conv2
I1109 03:56:28.191645 145556 net.cpp:210] Setting up conv2
I1109 03:56:28.191963 145556 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:56:28.192406 145556 net.cpp:225] Memory required for data: 164146688
I1109 03:56:28.242514 145556 layer_factory.hpp:114] Creating layer relu2
I1109 03:56:28.242916 145556 net.cpp:160] Creating Layer relu2
I1109 03:56:28.243294 145556 net.cpp:596] relu2 <- conv2
I1109 03:56:28.243566 145556 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:56:28.244009 145556 net.cpp:210] Setting up relu2
I1109 03:56:28.244273 145556 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:56:28.244509 145556 net.cpp:225] Memory required for data: 188034560
I1109 03:56:28.244699 145556 layer_factory.hpp:114] Creating layer norm2
I1109 03:56:28.244997 145556 net.cpp:160] Creating Layer norm2
I1109 03:56:28.245203 145556 net.cpp:596] norm2 <- conv2
I1109 03:56:28.245471 145556 net.cpp:570] norm2 -> norm2
I1109 03:56:28.247488 145556 net.cpp:210] Setting up norm2
I1109 03:56:28.247802 145556 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:56:28.248046 145556 net.cpp:225] Memory required for data: 211922432
I1109 03:56:28.248240 145556 layer_factory.hpp:114] Creating layer pool2
I1109 03:56:28.249166 145556 net.cpp:160] Creating Layer pool2
I1109 03:56:28.249487 145556 net.cpp:596] pool2 <- norm2
I1109 03:56:28.249752 145556 net.cpp:570] pool2 -> pool2
I1109 03:56:28.250177 145556 net.cpp:210] Setting up pool2
I1109 03:56:28.250434 145556 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:56:28.250676 145556 net.cpp:225] Memory required for data: 217460224
I1109 03:56:28.250890 145556 layer_factory.hpp:114] Creating layer conv3
I1109 03:56:28.251237 145556 net.cpp:160] Creating Layer conv3
I1109 03:56:28.251463 145556 net.cpp:596] conv3 <- pool2
I1109 03:56:28.251716 145556 net.cpp:570] conv3 -> conv3
I1109 03:56:28.725227 145556 net.cpp:210] Setting up conv3
I1109 03:56:28.727661 145556 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:56:28.728013 145556 net.cpp:225] Memory required for data: 225766912
I1109 03:56:28.731047 145556 layer_factory.hpp:114] Creating layer relu3
I1109 03:56:28.731494 145556 net.cpp:160] Creating Layer relu3
I1109 03:56:28.731756 145556 net.cpp:596] relu3 <- conv3
I1109 03:56:28.732048 145556 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:56:28.736215 145556 net.cpp:210] Setting up relu3
I1109 03:56:28.736526 145556 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:56:28.736862 145556 net.cpp:225] Memory required for data: 234073600
I1109 03:56:28.737113 145556 layer_factory.hpp:114] Creating layer conv4
I1109 03:56:28.737565 145556 net.cpp:160] Creating Layer conv4
I1109 03:56:28.737838 145556 net.cpp:596] conv4 <- conv3
I1109 03:56:28.738103 145556 net.cpp:570] conv4 -> conv4
I1109 03:56:28.981603 145556 net.cpp:210] Setting up conv4
I1109 03:56:28.982017 145556 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:56:28.982475 145556 net.cpp:225] Memory required for data: 242380288
I1109 03:56:28.982836 145556 layer_factory.hpp:114] Creating layer relu4
I1109 03:56:28.983158 145556 net.cpp:160] Creating Layer relu4
I1109 03:56:28.983386 145556 net.cpp:596] relu4 <- conv4
I1109 03:56:28.983628 145556 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:56:28.995862 145556 net.cpp:210] Setting up relu4
I1109 03:56:28.996208 145556 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:56:28.996613 145556 net.cpp:225] Memory required for data: 250686976
I1109 03:56:28.996865 145556 layer_factory.hpp:114] Creating layer conv5
I1109 03:56:28.997237 145556 net.cpp:160] Creating Layer conv5
I1109 03:56:28.997479 145556 net.cpp:596] conv5 <- conv4
I1109 03:56:28.997725 145556 net.cpp:570] conv5 -> conv5
I1109 03:56:29.165032 145556 net.cpp:210] Setting up conv5
I1109 03:56:29.165418 145556 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:56:29.165861 145556 net.cpp:225] Memory required for data: 256224768
I1109 03:56:29.170516 145556 layer_factory.hpp:114] Creating layer relu5
I1109 03:56:29.170919 145556 net.cpp:160] Creating Layer relu5
I1109 03:56:29.171216 145556 net.cpp:596] relu5 <- conv5
I1109 03:56:29.171502 145556 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:56:29.172066 145556 net.cpp:210] Setting up relu5
I1109 03:56:29.172349 145556 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:56:29.172605 145556 net.cpp:225] Memory required for data: 261762560
I1109 03:56:29.172855 145556 layer_factory.hpp:114] Creating layer pool5
I1109 03:56:29.173142 145556 net.cpp:160] Creating Layer pool5
I1109 03:56:29.173362 145556 net.cpp:596] pool5 <- conv5
I1109 03:56:29.173589 145556 net.cpp:570] pool5 -> pool5
I1109 03:56:29.174036 145556 net.cpp:210] Setting up pool5
I1109 03:56:29.174304 145556 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:56:29.174551 145556 net.cpp:225] Memory required for data: 262942208
I1109 03:56:29.174752 145556 layer_factory.hpp:114] Creating layer fc6
I1109 03:56:29.229241 145556 net.cpp:160] Creating Layer fc6
I1109 03:56:29.229554 145556 net.cpp:596] fc6 <- pool5
I1109 03:56:29.229931 145556 net.cpp:570] fc6 -> fc6
I1109 03:56:33.351553 145556 net.cpp:210] Setting up fc6
I1109 03:56:33.351869 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:33.354048 145556 net.cpp:225] Memory required for data: 263466496
I1109 03:56:33.354365 145556 layer_factory.hpp:114] Creating layer relu6
I1109 03:56:33.356956 145556 net.cpp:160] Creating Layer relu6
I1109 03:56:33.357257 145556 net.cpp:596] relu6 <- fc6
I1109 03:56:33.357491 145556 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:56:33.357918 145556 net.cpp:210] Setting up relu6
I1109 03:56:33.358182 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:33.358456 145556 net.cpp:225] Memory required for data: 263990784
I1109 03:56:33.358657 145556 layer_factory.hpp:114] Creating layer drop6
I1109 03:56:33.378640 145556 net.cpp:160] Creating Layer drop6
I1109 03:56:33.378949 145556 net.cpp:596] drop6 <- fc6
I1109 03:56:33.379328 145556 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:56:33.483005 145556 net.cpp:210] Setting up drop6
I1109 03:56:33.483309 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:33.483661 145556 net.cpp:225] Memory required for data: 264515072
I1109 03:56:33.483912 145556 layer_factory.hpp:114] Creating layer fc7
I1109 03:56:33.484187 145556 net.cpp:160] Creating Layer fc7
I1109 03:56:33.484406 145556 net.cpp:596] fc7 <- fc6
I1109 03:56:33.484838 145556 net.cpp:570] fc7 -> fc7
I1109 03:56:35.198978 145556 net.cpp:210] Setting up fc7
I1109 03:56:35.199321 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:35.199749 145556 net.cpp:225] Memory required for data: 265039360
I1109 03:56:35.200098 145556 layer_factory.hpp:114] Creating layer relu7
I1109 03:56:35.200399 145556 net.cpp:160] Creating Layer relu7
I1109 03:56:35.200623 145556 net.cpp:596] relu7 <- fc7
I1109 03:56:35.200898 145556 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:56:35.201347 145556 net.cpp:210] Setting up relu7
I1109 03:56:35.201618 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:35.201850 145556 net.cpp:225] Memory required for data: 265563648
I1109 03:56:35.202078 145556 layer_factory.hpp:114] Creating layer drop7
I1109 03:56:35.202337 145556 net.cpp:160] Creating Layer drop7
I1109 03:56:35.202685 145556 net.cpp:596] drop7 <- fc7
I1109 03:56:35.202970 145556 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:56:35.203244 145556 net.cpp:210] Setting up drop7
I1109 03:56:35.203441 145556 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:56:35.203660 145556 net.cpp:225] Memory required for data: 266087936
I1109 03:56:35.203840 145556 layer_factory.hpp:114] Creating layer fc8
I1109 03:56:35.204087 145556 net.cpp:160] Creating Layer fc8
I1109 03:56:35.204277 145556 net.cpp:596] fc8 <- fc7
I1109 03:56:35.204499 145556 net.cpp:570] fc8 -> fc8
I1109 03:56:35.626912 145556 net.cpp:210] Setting up fc8
I1109 03:56:35.627275 145556 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:56:35.627686 145556 net.cpp:225] Memory required for data: 266215936
I1109 03:56:35.628033 145556 layer_factory.hpp:114] Creating layer loss
I1109 03:56:35.653066 145556 net.cpp:160] Creating Layer loss
I1109 03:56:35.653386 145556 net.cpp:596] loss <- fc8
I1109 03:56:35.654427 145556 net.cpp:596] loss <- label
I1109 03:56:35.682013 145556 net.cpp:570] loss -> loss
I1109 03:56:35.719872 145556 layer_factory.hpp:114] Creating layer loss
I1109 03:56:38.266595 145556 net.cpp:210] Setting up loss
I1109 03:56:38.315219 145556 net.cpp:217] Top shape: (1)
I1109 03:56:38.328034 145556 net.cpp:220]     with loss weight 1
I1109 03:56:38.462915 145556 net.cpp:225] Memory required for data: 266215940
I1109 03:56:38.504592 145556 net.cpp:287] loss needs backward computation.
I1109 03:56:38.592602 145556 net.cpp:287] fc8 needs backward computation.
I1109 03:56:38.599874 145556 net.cpp:287] drop7 needs backward computation.
I1109 03:56:38.610994 145556 net.cpp:287] relu7 needs backward computation.
I1109 03:56:38.611305 145556 net.cpp:287] fc7 needs backward computation.
I1109 03:56:38.613736 145556 net.cpp:287] drop6 needs backward computation.
I1109 03:56:38.614085 145556 net.cpp:287] relu6 needs backward computation.
I1109 03:56:38.614397 145556 net.cpp:287] fc6 needs backward computation.
I1109 03:56:38.615272 145556 net.cpp:287] pool5 needs backward computation.
I1109 03:56:38.616008 145556 net.cpp:287] relu5 needs backward computation.
I1109 03:56:38.616261 145556 net.cpp:287] conv5 needs backward computation.
I1109 03:56:38.616451 145556 net.cpp:287] relu4 needs backward computation.
I1109 03:56:38.616628 145556 net.cpp:287] conv4 needs backward computation.
I1109 03:56:38.616894 145556 net.cpp:287] relu3 needs backward computation.
I1109 03:56:38.617112 145556 net.cpp:287] conv3 needs backward computation.
I1109 03:56:38.629745 145556 net.cpp:287] pool2 needs backward computation.
I1109 03:56:38.630082 145556 net.cpp:287] norm2 needs backward computation.
I1109 03:56:38.630383 145556 net.cpp:287] relu2 needs backward computation.
I1109 03:56:38.630616 145556 net.cpp:287] conv2 needs backward computation.
I1109 03:56:38.630800 145556 net.cpp:287] pool1 needs backward computation.
I1109 03:56:38.630978 145556 net.cpp:287] norm1 needs backward computation.
I1109 03:56:38.631156 145556 net.cpp:287] relu1 needs backward computation.
I1109 03:56:38.631331 145556 net.cpp:287] conv1 needs backward computation.
I1109 03:56:38.643908 145556 net.cpp:289] data does not need backward computation.
I1109 03:56:38.669020 145556 net.cpp:331] This network produces output loss
I1109 03:56:38.742311 145556 net.cpp:345] Network initialization done.
I1109 03:56:38.908009 145556 caffe.cpp:452] Performing Forward
I1109 03:56:52.191203 145556 caffe.cpp:457] Initial loss: 6.74268
I1109 03:56:52.251708 145556 caffe.cpp:459] Performing Backward
I1109 03:56:56.905043 145556 caffe.cpp:468] *** Benchmark begins ***
I1109 03:56:56.920145 145556 caffe.cpp:469] Testing for 1 iterations.
I1109 03:56:59.225797 145556 caffe.cpp:512] Iteration: 1 forward-backward time: 2178 ms.
I1109 03:56:59.386476 145556 caffe.cpp:519] Average time per layer: 
I1109 03:56:59.403728 145556 caffe.cpp:522]       data	forward: 560.035 ms.
I1109 03:56:59.478947 145556 caffe.cpp:526]       data	backward: 4.976 ms.
I1109 03:56:59.504667 145556 caffe.cpp:522]      conv1	forward: 126.027 ms.
I1109 03:56:59.519691 145556 caffe.cpp:526]      conv1	backward: 52.138 ms.
I1109 03:56:59.531605 145556 caffe.cpp:522]      relu1	forward: 24.425 ms.
I1109 03:56:59.535691 145556 caffe.cpp:526]      relu1	backward: 15.781 ms.
I1109 03:56:59.539692 145556 caffe.cpp:522]      norm1	forward: 15.879 ms.
I1109 03:56:59.542587 145556 caffe.cpp:526]      norm1	backward: 14.088 ms.
I1109 03:56:59.555835 145556 caffe.cpp:522]      pool1	forward: 20.36 ms.
I1109 03:56:59.563997 145556 caffe.cpp:526]      pool1	backward: 84.032 ms.
I1109 03:56:59.572178 145556 caffe.cpp:522]      conv2	forward: 55.413 ms.
I1109 03:56:59.572509 145556 caffe.cpp:526]      conv2	backward: 81.412 ms.
I1109 03:56:59.572707 145556 caffe.cpp:522]      relu2	forward: 0.6 ms.
I1109 03:56:59.572944 145556 caffe.cpp:526]      relu2	backward: 16.502 ms.
I1109 03:56:59.573137 145556 caffe.cpp:522]      norm2	forward: 3.318 ms.
I1109 03:56:59.573324 145556 caffe.cpp:526]      norm2	backward: 15.173 ms.
I1109 03:56:59.573515 145556 caffe.cpp:522]      pool2	forward: 1.823 ms.
I1109 03:56:59.573701 145556 caffe.cpp:526]      pool2	backward: 71.772 ms.
I1109 03:56:59.573892 145556 caffe.cpp:522]      conv3	forward: 11.661 ms.
I1109 03:56:59.574082 145556 caffe.cpp:526]      conv3	backward: 97.227 ms.
I1109 03:56:59.574306 145556 caffe.cpp:522]      relu3	forward: 0.265 ms.
I1109 03:56:59.574506 145556 caffe.cpp:526]      relu3	backward: 32.573 ms.
I1109 03:56:59.574735 145556 caffe.cpp:522]      conv4	forward: 7.627 ms.
I1109 03:56:59.575034 145556 caffe.cpp:526]      conv4	backward: 73.308 ms.
I1109 03:56:59.575292 145556 caffe.cpp:522]      relu4	forward: 0.256 ms.
I1109 03:56:59.575481 145556 caffe.cpp:526]      relu4	backward: 39.675 ms.
I1109 03:56:59.575671 145556 caffe.cpp:522]      conv5	forward: 5.252 ms.
I1109 03:56:59.575873 145556 caffe.cpp:526]      conv5	backward: 75.386 ms.
I1109 03:56:59.576064 145556 caffe.cpp:522]      relu5	forward: 0.206 ms.
I1109 03:56:59.576252 145556 caffe.cpp:526]      relu5	backward: 20.73 ms.
I1109 03:56:59.576442 145556 caffe.cpp:522]      pool5	forward: 0.283 ms.
I1109 03:56:59.576629 145556 caffe.cpp:526]      pool5	backward: 50.777 ms.
I1109 03:56:59.576843 145556 caffe.cpp:522]        fc6	forward: 16.413 ms.
I1109 03:56:59.577034 145556 caffe.cpp:526]        fc6	backward: 112.766 ms.
I1109 03:56:59.577260 145556 caffe.cpp:522]      relu6	forward: 0.91 ms.
I1109 03:56:59.577464 145556 caffe.cpp:526]      relu6	backward: 15.596 ms.
I1109 03:56:59.577692 145556 caffe.cpp:522]      drop6	forward: 1.517 ms.
I1109 03:56:59.577932 145556 caffe.cpp:526]      drop6	backward: 11.999 ms.
I1109 03:56:59.578166 145556 caffe.cpp:522]        fc7	forward: 4.43 ms.
I1109 03:56:59.578364 145556 caffe.cpp:526]        fc7	backward: 91.492 ms.
I1109 03:56:59.578567 145556 caffe.cpp:522]      relu7	forward: 0.13 ms.
I1109 03:56:59.578768 145556 caffe.cpp:526]      relu7	backward: 17.623 ms.
I1109 03:56:59.578970 145556 caffe.cpp:522]      drop7	forward: 0.322 ms.
I1109 03:56:59.579170 145556 caffe.cpp:526]      drop7	backward: 13.278 ms.
I1109 03:56:59.579373 145556 caffe.cpp:522]        fc8	forward: 1.951 ms.
I1109 03:56:59.579571 145556 caffe.cpp:526]        fc8	backward: 140.913 ms.
I1109 03:56:59.579776 145556 caffe.cpp:522]       loss	forward: 39.385 ms.
I1109 03:56:59.579979 145556 caffe.cpp:526]       loss	backward: 36.903 ms.
I1109 03:56:59.585572 145556 caffe.cpp:532] Average Forward pass: 955.794 ms.
I1109 03:56:59.598868 145556 caffe.cpp:535] Average Backward pass: 1196 ms.
I1109 03:56:59.613726 145556 caffe.cpp:537] Average Forward-Backward: 2620 ms.
I1109 03:56:59.628231 145556 caffe.cpp:540] Total Time: 2620 ms.
I1109 03:56:59.640372 145556 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 0
mem-read-2 = 0
mem-read-4 = 0
mem-read-8 = 0
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 0
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 0
--->Total Bytes written = 0
--->Total Bytes = 0

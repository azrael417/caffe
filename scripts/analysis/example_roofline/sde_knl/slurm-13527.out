total layers 26
/project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=100
I1108 22:52:56.885267 135167 caffe.cpp:444] Use CPU.
I1108 22:52:56.934800 135167 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 22:52:56.934876 135167 cpu_info.cpp:455] Total number of sockets: 1
I1108 22:52:56.934895 135167 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 22:52:56.934911 135167 cpu_info.cpp:461] Total number of processors: 272
I1108 22:52:56.934926 135167 cpu_info.cpp:464] GPU is used: no
I1108 22:52:56.934940 135167 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 22:52:56.934954 135167 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 22:52:56.934968 135167 cpu_info.cpp:473] Number of OpenMP threads: 64
I1108 22:52:56.970516 135167 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 22:52:56.970613 135167 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 22:52:56.970980 135167 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 22:52:56.974145 135167 layer_factory.hpp:114] Creating layer data
I1108 22:52:56.974210 135167 net.cpp:160] Creating Layer data
I1108 22:52:56.974242 135167 net.cpp:570] data -> data
I1108 22:52:56.974297 135167 net.cpp:570] data -> label
I1108 22:52:56.998416 135167 net.cpp:210] Setting up data
I1108 22:52:56.998505 135167 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 22:52:56.998561 135167 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 22:52:56.998594 135167 net.cpp:225] Memory required for data: 19787264
I1108 22:52:56.998626 135167 layer_factory.hpp:114] Creating layer conv1
I1108 22:52:56.998724 135167 net.cpp:160] Creating Layer conv1
I1108 22:52:56.998754 135167 net.cpp:596] conv1 <- data
I1108 22:52:56.998803 135167 net.cpp:570] conv1 -> conv1
I1108 22:52:57.090262 135167 net.cpp:210] Setting up conv1
I1108 22:52:57.090335 135167 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:52:57.090374 135167 net.cpp:225] Memory required for data: 56958464
I1108 22:52:57.090461 135167 layer_factory.hpp:114] Creating layer relu1
I1108 22:52:57.090519 135167 net.cpp:160] Creating Layer relu1
I1108 22:52:57.090539 135167 net.cpp:596] relu1 <- conv1
I1108 22:52:57.090571 135167 net.cpp:557] relu1 -> conv1 (in-place)
I1108 22:52:57.090665 135167 net.cpp:210] Setting up relu1
I1108 22:52:57.090687 135167 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:52:57.090711 135167 net.cpp:225] Memory required for data: 94129664
I1108 22:52:57.090731 135167 layer_factory.hpp:114] Creating layer norm1
I1108 22:52:57.090782 135167 net.cpp:160] Creating Layer norm1
I1108 22:52:57.090801 135167 net.cpp:596] norm1 <- conv1
I1108 22:52:57.090828 135167 net.cpp:570] norm1 -> norm1
I1108 22:52:57.090894 135167 net.cpp:210] Setting up norm1
I1108 22:52:57.090914 135167 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:52:57.091017 135167 net.cpp:225] Memory required for data: 131300864
I1108 22:52:57.091040 135167 layer_factory.hpp:114] Creating layer pool1
I1108 22:52:57.091083 135167 net.cpp:160] Creating Layer pool1
I1108 22:52:57.091101 135167 net.cpp:596] pool1 <- norm1
I1108 22:52:57.091137 135167 net.cpp:570] pool1 -> pool1
I1108 22:52:57.091222 135167 net.cpp:210] Setting up pool1
I1108 22:52:57.091245 135167 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 22:52:57.091271 135167 net.cpp:225] Memory required for data: 140258816
I1108 22:52:57.091290 135167 layer_factory.hpp:114] Creating layer conv2
I1108 22:52:57.091356 135167 net.cpp:160] Creating Layer conv2
I1108 22:52:57.091374 135167 net.cpp:596] conv2 <- pool1
I1108 22:52:57.091404 135167 net.cpp:570] conv2 -> conv2
I1108 22:52:57.195849 135167 net.cpp:210] Setting up conv2
I1108 22:52:57.195945 135167 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:52:57.195988 135167 net.cpp:225] Memory required for data: 164146688
I1108 22:52:57.196058 135167 layer_factory.hpp:114] Creating layer relu2
I1108 22:52:57.196123 135167 net.cpp:160] Creating Layer relu2
I1108 22:52:57.196151 135167 net.cpp:596] relu2 <- conv2
I1108 22:52:57.196221 135167 net.cpp:557] relu2 -> conv2 (in-place)
I1108 22:52:57.196326 135167 net.cpp:210] Setting up relu2
I1108 22:52:57.196413 135167 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:52:57.196444 135167 net.cpp:225] Memory required for data: 188034560
I1108 22:52:57.196466 135167 layer_factory.hpp:114] Creating layer norm2
I1108 22:52:57.196507 135167 net.cpp:160] Creating Layer norm2
I1108 22:52:57.196528 135167 net.cpp:596] norm2 <- conv2
I1108 22:52:57.196585 135167 net.cpp:570] norm2 -> norm2
I1108 22:52:57.196651 135167 net.cpp:210] Setting up norm2
I1108 22:52:57.196672 135167 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:52:57.196697 135167 net.cpp:225] Memory required for data: 211922432
I1108 22:52:57.196717 135167 layer_factory.hpp:114] Creating layer pool2
I1108 22:52:57.196815 135167 net.cpp:160] Creating Layer pool2
I1108 22:52:57.196843 135167 net.cpp:596] pool2 <- norm2
I1108 22:52:57.196873 135167 net.cpp:570] pool2 -> pool2
I1108 22:52:57.196949 135167 net.cpp:210] Setting up pool2
I1108 22:52:57.196970 135167 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:52:57.196996 135167 net.cpp:225] Memory required for data: 217460224
I1108 22:52:57.197016 135167 layer_factory.hpp:114] Creating layer conv3
I1108 22:52:57.197094 135167 net.cpp:160] Creating Layer conv3
I1108 22:52:57.197115 135167 net.cpp:596] conv3 <- pool2
I1108 22:52:57.197165 135167 net.cpp:570] conv3 -> conv3
I1108 22:52:57.299602 135167 net.cpp:210] Setting up conv3
I1108 22:52:57.299698 135167 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:52:57.299746 135167 net.cpp:225] Memory required for data: 225766912
I1108 22:52:57.299816 135167 layer_factory.hpp:114] Creating layer relu3
I1108 22:52:57.299943 135167 net.cpp:160] Creating Layer relu3
I1108 22:52:57.299983 135167 net.cpp:596] relu3 <- conv3
I1108 22:52:57.300029 135167 net.cpp:557] relu3 -> conv3 (in-place)
I1108 22:52:57.300137 135167 net.cpp:210] Setting up relu3
I1108 22:52:57.300173 135167 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:52:57.300209 135167 net.cpp:225] Memory required for data: 234073600
I1108 22:52:57.300262 135167 layer_factory.hpp:114] Creating layer conv4
I1108 22:52:57.300362 135167 net.cpp:160] Creating Layer conv4
I1108 22:52:57.300393 135167 net.cpp:596] conv4 <- conv3
I1108 22:52:57.300433 135167 net.cpp:570] conv4 -> conv4
I1108 22:52:57.392406 135167 net.cpp:210] Setting up conv4
I1108 22:52:57.392498 135167 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:52:57.392542 135167 net.cpp:225] Memory required for data: 242380288
I1108 22:52:57.392606 135167 layer_factory.hpp:114] Creating layer relu4
I1108 22:52:57.392683 135167 net.cpp:160] Creating Layer relu4
I1108 22:52:57.392752 135167 net.cpp:596] relu4 <- conv4
I1108 22:52:57.392834 135167 net.cpp:557] relu4 -> conv4 (in-place)
I1108 22:52:57.392951 135167 net.cpp:210] Setting up relu4
I1108 22:52:57.393129 135167 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:52:57.393172 135167 net.cpp:225] Memory required for data: 250686976
I1108 22:52:57.393203 135167 layer_factory.hpp:114] Creating layer conv5
I1108 22:52:57.393329 135167 net.cpp:160] Creating Layer conv5
I1108 22:52:57.393359 135167 net.cpp:596] conv5 <- conv4
I1108 22:52:57.393401 135167 net.cpp:570] conv5 -> conv5
I1108 22:52:57.468238 135167 net.cpp:210] Setting up conv5
I1108 22:52:57.468333 135167 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:52:57.468382 135167 net.cpp:225] Memory required for data: 256224768
I1108 22:52:57.468461 135167 layer_factory.hpp:114] Creating layer relu5
I1108 22:52:57.468577 135167 net.cpp:160] Creating Layer relu5
I1108 22:52:57.468617 135167 net.cpp:596] relu5 <- conv5
I1108 22:52:57.468662 135167 net.cpp:557] relu5 -> conv5 (in-place)
I1108 22:52:57.468860 135167 net.cpp:210] Setting up relu5
I1108 22:52:57.468905 135167 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:52:57.468940 135167 net.cpp:225] Memory required for data: 261762560
I1108 22:52:57.468964 135167 layer_factory.hpp:114] Creating layer pool5
I1108 22:52:57.469013 135167 net.cpp:160] Creating Layer pool5
I1108 22:52:57.469035 135167 net.cpp:596] pool5 <- conv5
I1108 22:52:57.469069 135167 net.cpp:570] pool5 -> pool5
I1108 22:52:57.469166 135167 net.cpp:210] Setting up pool5
I1108 22:52:57.469192 135167 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 22:52:57.469221 135167 net.cpp:225] Memory required for data: 262942208
I1108 22:52:57.469244 135167 layer_factory.hpp:114] Creating layer fc6
I1108 22:52:57.469327 135167 net.cpp:160] Creating Layer fc6
I1108 22:52:57.469353 135167 net.cpp:596] fc6 <- pool5
I1108 22:52:57.469391 135167 net.cpp:570] fc6 -> fc6
I1108 22:52:59.230203 135167 net.cpp:210] Setting up fc6
I1108 22:52:59.230324 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:52:59.230370 135167 net.cpp:225] Memory required for data: 263466496
I1108 22:52:59.230454 135167 layer_factory.hpp:114] Creating layer relu6
I1108 22:52:59.230589 135167 net.cpp:160] Creating Layer relu6
I1108 22:52:59.230628 135167 net.cpp:596] relu6 <- fc6
I1108 22:52:59.230682 135167 net.cpp:557] relu6 -> fc6 (in-place)
I1108 22:52:59.230803 135167 net.cpp:210] Setting up relu6
I1108 22:52:59.230829 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:52:59.230888 135167 net.cpp:225] Memory required for data: 263990784
I1108 22:52:59.230912 135167 layer_factory.hpp:114] Creating layer drop6
I1108 22:52:59.230969 135167 net.cpp:160] Creating Layer drop6
I1108 22:52:59.230993 135167 net.cpp:596] drop6 <- fc6
I1108 22:52:59.231024 135167 net.cpp:557] drop6 -> fc6 (in-place)
I1108 22:52:59.231075 135167 net.cpp:210] Setting up drop6
I1108 22:52:59.231093 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:52:59.231118 135167 net.cpp:225] Memory required for data: 264515072
I1108 22:52:59.231137 135167 layer_factory.hpp:114] Creating layer fc7
I1108 22:52:59.231195 135167 net.cpp:160] Creating Layer fc7
I1108 22:52:59.231217 135167 net.cpp:596] fc7 <- fc6
I1108 22:52:59.231254 135167 net.cpp:570] fc7 -> fc7
I1108 22:53:00.016641 135167 net.cpp:210] Setting up fc7
I1108 22:53:00.016765 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:53:00.016880 135167 net.cpp:225] Memory required for data: 265039360
I1108 22:53:00.016973 135167 layer_factory.hpp:114] Creating layer relu7
I1108 22:53:00.017082 135167 net.cpp:160] Creating Layer relu7
I1108 22:53:00.017129 135167 net.cpp:596] relu7 <- fc7
I1108 22:53:00.017179 135167 net.cpp:557] relu7 -> fc7 (in-place)
I1108 22:53:00.017302 135167 net.cpp:210] Setting up relu7
I1108 22:53:00.017331 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:53:00.017364 135167 net.cpp:225] Memory required for data: 265563648
I1108 22:53:00.017390 135167 layer_factory.hpp:114] Creating layer drop7
I1108 22:53:00.017438 135167 net.cpp:160] Creating Layer drop7
I1108 22:53:00.017459 135167 net.cpp:596] drop7 <- fc7
I1108 22:53:00.017490 135167 net.cpp:557] drop7 -> fc7 (in-place)
I1108 22:53:00.017623 135167 net.cpp:210] Setting up drop7
I1108 22:53:00.017648 135167 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:53:00.017676 135167 net.cpp:225] Memory required for data: 266087936
I1108 22:53:00.017699 135167 layer_factory.hpp:114] Creating layer fc8
I1108 22:53:00.017761 135167 net.cpp:160] Creating Layer fc8
I1108 22:53:00.017786 135167 net.cpp:596] fc8 <- fc7
I1108 22:53:00.017824 135167 net.cpp:570] fc8 -> fc8
I1108 22:53:00.210005 135167 net.cpp:210] Setting up fc8
I1108 22:53:00.210121 135167 net.cpp:217] Top shape: 32 1000 (32000)
I1108 22:53:00.210163 135167 net.cpp:225] Memory required for data: 266215936
I1108 22:53:00.210239 135167 layer_factory.hpp:114] Creating layer loss
I1108 22:53:00.210348 135167 net.cpp:160] Creating Layer loss
I1108 22:53:00.210389 135167 net.cpp:596] loss <- fc8
I1108 22:53:00.210425 135167 net.cpp:596] loss <- label
I1108 22:53:00.210501 135167 net.cpp:570] loss -> loss
I1108 22:53:00.210574 135167 layer_factory.hpp:114] Creating layer loss
I1108 22:53:00.241024 135167 net.cpp:210] Setting up loss
I1108 22:53:00.241112 135167 net.cpp:217] Top shape: (1)
I1108 22:53:00.241163 135167 net.cpp:220]     with loss weight 1
I1108 22:53:00.241297 135167 net.cpp:225] Memory required for data: 266215940
I1108 22:53:00.241346 135167 net.cpp:287] loss needs backward computation.
I1108 22:53:00.241385 135167 net.cpp:287] fc8 needs backward computation.
I1108 22:53:00.241416 135167 net.cpp:287] drop7 needs backward computation.
I1108 22:53:00.241454 135167 net.cpp:287] relu7 needs backward computation.
I1108 22:53:00.241482 135167 net.cpp:287] fc7 needs backward computation.
I1108 22:53:00.241516 135167 net.cpp:287] drop6 needs backward computation.
I1108 22:53:00.241540 135167 net.cpp:287] relu6 needs backward computation.
I1108 22:53:00.241561 135167 net.cpp:287] fc6 needs backward computation.
I1108 22:53:00.241582 135167 net.cpp:287] pool5 needs backward computation.
I1108 22:53:00.241605 135167 net.cpp:287] relu5 needs backward computation.
I1108 22:53:00.241632 135167 net.cpp:287] conv5 needs backward computation.
I1108 22:53:00.241657 135167 net.cpp:287] relu4 needs backward computation.
I1108 22:53:00.241684 135167 net.cpp:287] conv4 needs backward computation.
I1108 22:53:00.241705 135167 net.cpp:287] relu3 needs backward computation.
I1108 22:53:00.241731 135167 net.cpp:287] conv3 needs backward computation.
I1108 22:53:00.241755 135167 net.cpp:287] pool2 needs backward computation.
I1108 22:53:00.241778 135167 net.cpp:287] norm2 needs backward computation.
I1108 22:53:00.241799 135167 net.cpp:287] relu2 needs backward computation.
I1108 22:53:00.241818 135167 net.cpp:287] conv2 needs backward computation.
I1108 22:53:00.241838 135167 net.cpp:287] pool1 needs backward computation.
I1108 22:53:00.241858 135167 net.cpp:287] norm1 needs backward computation.
I1108 22:53:00.241883 135167 net.cpp:287] relu1 needs backward computation.
I1108 22:53:00.241906 135167 net.cpp:287] conv1 needs backward computation.
I1108 22:53:00.241927 135167 net.cpp:289] data does not need backward computation.
I1108 22:53:00.241946 135167 net.cpp:331] This network produces output loss
I1108 22:53:00.242003 135167 net.cpp:345] Network initialization done.
I1108 22:53:00.242419 135167 caffe.cpp:452] Performing Forward
I1108 22:53:00.609964 135167 caffe.cpp:457] Initial loss: 7.00151
I1108 22:53:00.610067 135167 caffe.cpp:459] Performing Backward
I1108 22:53:00.726815 135167 caffe.cpp:468] *** Benchmark begins ***
I1108 22:53:00.726897 135167 caffe.cpp:469] Testing for 100 iterations.
I1108 22:53:01.043684 135167 caffe.cpp:512] Iteration: 1 forward-backward time: 316 ms.
I1108 22:53:01.363595 135167 caffe.cpp:512] Iteration: 2 forward-backward time: 319 ms.
I1108 22:53:01.681140 135167 caffe.cpp:512] Iteration: 3 forward-backward time: 317 ms.
I1108 22:53:02.005935 135167 caffe.cpp:512] Iteration: 4 forward-backward time: 324 ms.
I1108 22:53:02.325573 135167 caffe.cpp:512] Iteration: 5 forward-backward time: 319 ms.
I1108 22:53:02.653828 135167 caffe.cpp:512] Iteration: 6 forward-backward time: 328 ms.
I1108 22:53:02.972903 135167 caffe.cpp:512] Iteration: 7 forward-backward time: 318 ms.
I1108 22:53:03.293689 135167 caffe.cpp:512] Iteration: 8 forward-backward time: 320 ms.
I1108 22:53:03.612887 135167 caffe.cpp:512] Iteration: 9 forward-backward time: 319 ms.
I1108 22:53:03.937922 135167 caffe.cpp:512] Iteration: 10 forward-backward time: 324 ms.
I1108 22:53:04.258951 135167 caffe.cpp:512] Iteration: 11 forward-backward time: 320 ms.
I1108 22:53:04.581430 135167 caffe.cpp:512] Iteration: 12 forward-backward time: 322 ms.
I1108 22:53:04.900372 135167 caffe.cpp:512] Iteration: 13 forward-backward time: 318 ms.
I1108 22:53:05.220268 135167 caffe.cpp:512] Iteration: 14 forward-backward time: 319 ms.
I1108 22:53:05.546219 135167 caffe.cpp:512] Iteration: 15 forward-backward time: 325 ms.
I1108 22:53:05.862151 135167 caffe.cpp:512] Iteration: 16 forward-backward time: 315 ms.
I1108 22:53:06.178242 135167 caffe.cpp:512] Iteration: 17 forward-backward time: 316 ms.
I1108 22:53:06.498348 135167 caffe.cpp:512] Iteration: 18 forward-backward time: 320 ms.
I1108 22:53:06.817399 135167 caffe.cpp:512] Iteration: 19 forward-backward time: 318 ms.
I1108 22:53:07.134537 135167 caffe.cpp:512] Iteration: 20 forward-backward time: 317 ms.
I1108 22:53:07.451750 135167 caffe.cpp:512] Iteration: 21 forward-backward time: 317 ms.
I1108 22:53:07.773752 135167 caffe.cpp:512] Iteration: 22 forward-backward time: 321 ms.
I1108 22:53:08.091812 135167 caffe.cpp:512] Iteration: 23 forward-backward time: 317 ms.
I1108 22:53:08.410073 135167 caffe.cpp:512] Iteration: 24 forward-backward time: 318 ms.
I1108 22:53:08.730020 135167 caffe.cpp:512] Iteration: 25 forward-backward time: 319 ms.
I1108 22:53:09.057648 135167 caffe.cpp:512] Iteration: 26 forward-backward time: 327 ms.
I1108 22:53:09.378188 135167 caffe.cpp:512] Iteration: 27 forward-backward time: 320 ms.
I1108 22:53:09.698902 135167 caffe.cpp:512] Iteration: 28 forward-backward time: 320 ms.
I1108 22:53:10.018087 135167 caffe.cpp:512] Iteration: 29 forward-backward time: 319 ms.
I1108 22:53:10.346004 135167 caffe.cpp:512] Iteration: 30 forward-backward time: 327 ms.
I1108 22:53:10.666290 135167 caffe.cpp:512] Iteration: 31 forward-backward time: 320 ms.
I1108 22:53:10.982146 135167 caffe.cpp:512] Iteration: 32 forward-backward time: 315 ms.
I1108 22:53:11.329251 135167 caffe.cpp:512] Iteration: 33 forward-backward time: 347 ms.
I1108 22:53:11.647677 135167 caffe.cpp:512] Iteration: 34 forward-backward time: 318 ms.
I1108 22:53:11.964681 135167 caffe.cpp:512] Iteration: 35 forward-backward time: 316 ms.
I1108 22:53:12.287300 135167 caffe.cpp:512] Iteration: 36 forward-backward time: 322 ms.
I1108 22:53:12.604933 135167 caffe.cpp:512] Iteration: 37 forward-backward time: 317 ms.
I1108 22:53:12.924429 135167 caffe.cpp:512] Iteration: 38 forward-backward time: 319 ms.
I1108 22:53:13.242307 135167 caffe.cpp:512] Iteration: 39 forward-backward time: 317 ms.
I1108 22:53:13.601434 135167 caffe.cpp:512] Iteration: 40 forward-backward time: 359 ms.
I1108 22:53:13.929664 135167 caffe.cpp:512] Iteration: 41 forward-backward time: 328 ms.
I1108 22:53:14.250422 135167 caffe.cpp:512] Iteration: 42 forward-backward time: 320 ms.
I1108 22:53:14.569628 135167 caffe.cpp:512] Iteration: 43 forward-backward time: 319 ms.
I1108 22:53:14.889400 135167 caffe.cpp:512] Iteration: 44 forward-backward time: 319 ms.
I1108 22:53:15.209631 135167 caffe.cpp:512] Iteration: 45 forward-backward time: 320 ms.
I1108 22:53:15.529924 135167 caffe.cpp:512] Iteration: 46 forward-backward time: 320 ms.
I1108 22:53:15.861930 135167 caffe.cpp:512] Iteration: 47 forward-backward time: 331 ms.
I1108 22:53:16.179635 135167 caffe.cpp:512] Iteration: 48 forward-backward time: 317 ms.
I1108 22:53:16.504709 135167 caffe.cpp:512] Iteration: 49 forward-backward time: 324 ms.
I1108 22:53:16.824255 135167 caffe.cpp:512] Iteration: 50 forward-backward time: 319 ms.
I1108 22:53:17.142366 135167 caffe.cpp:512] Iteration: 51 forward-backward time: 318 ms.
I1108 22:53:17.462064 135167 caffe.cpp:512] Iteration: 52 forward-backward time: 319 ms.
I1108 22:53:17.777376 135167 caffe.cpp:512] Iteration: 53 forward-backward time: 315 ms.
I1108 22:53:18.097404 135167 caffe.cpp:512] Iteration: 54 forward-backward time: 319 ms.
I1108 22:53:18.414254 135167 caffe.cpp:512] Iteration: 55 forward-backward time: 316 ms.
I1108 22:53:18.743002 135167 caffe.cpp:512] Iteration: 56 forward-backward time: 328 ms.
I1108 22:53:19.062366 135167 caffe.cpp:512] Iteration: 57 forward-backward time: 319 ms.
I1108 22:53:19.382072 135167 caffe.cpp:512] Iteration: 58 forward-backward time: 319 ms.
I1108 22:53:19.701548 135167 caffe.cpp:512] Iteration: 59 forward-backward time: 319 ms.
I1108 22:53:20.021046 135167 caffe.cpp:512] Iteration: 60 forward-backward time: 319 ms.
I1108 22:53:20.338415 135167 caffe.cpp:512] Iteration: 61 forward-backward time: 317 ms.
I1108 22:53:20.655771 135167 caffe.cpp:512] Iteration: 62 forward-backward time: 317 ms.
I1108 22:53:20.971293 135167 caffe.cpp:512] Iteration: 63 forward-backward time: 315 ms.
I1108 22:53:21.286180 135167 caffe.cpp:512] Iteration: 64 forward-backward time: 314 ms.
I1108 22:53:21.601650 135167 caffe.cpp:512] Iteration: 65 forward-backward time: 315 ms.
I1108 22:53:21.924115 135167 caffe.cpp:512] Iteration: 66 forward-backward time: 322 ms.
I1108 22:53:22.242553 135167 caffe.cpp:512] Iteration: 67 forward-backward time: 318 ms.
I1108 22:53:22.558598 135167 caffe.cpp:512] Iteration: 68 forward-backward time: 315 ms.
I1108 22:53:22.875178 135167 caffe.cpp:512] Iteration: 69 forward-backward time: 316 ms.
I1108 22:53:23.193148 135167 caffe.cpp:512] Iteration: 70 forward-backward time: 317 ms.
I1108 22:53:23.514415 135167 caffe.cpp:512] Iteration: 71 forward-backward time: 321 ms.
I1108 22:53:23.833755 135167 caffe.cpp:512] Iteration: 72 forward-backward time: 319 ms.
I1108 22:53:24.151238 135167 caffe.cpp:512] Iteration: 73 forward-backward time: 317 ms.
I1108 22:53:24.508711 135167 caffe.cpp:512] Iteration: 74 forward-backward time: 357 ms.
I1108 22:53:24.833379 135167 caffe.cpp:512] Iteration: 75 forward-backward time: 324 ms.
I1108 22:53:25.151765 135167 caffe.cpp:512] Iteration: 76 forward-backward time: 318 ms.
I1108 22:53:25.467327 135167 caffe.cpp:512] Iteration: 77 forward-backward time: 315 ms.
I1108 22:53:25.782052 135167 caffe.cpp:512] Iteration: 78 forward-backward time: 314 ms.
I1108 22:53:26.101884 135167 caffe.cpp:512] Iteration: 79 forward-backward time: 319 ms.
I1108 22:53:26.416877 135167 caffe.cpp:512] Iteration: 80 forward-backward time: 314 ms.
I1108 22:53:26.773303 135167 caffe.cpp:512] Iteration: 81 forward-backward time: 356 ms.
I1108 22:53:27.093920 135167 caffe.cpp:512] Iteration: 82 forward-backward time: 320 ms.
I1108 22:53:27.399035 135167 caffe.cpp:512] Iteration: 83 forward-backward time: 304 ms.
I1108 22:53:27.702049 135167 caffe.cpp:512] Iteration: 84 forward-backward time: 302 ms.
I1108 22:53:28.007921 135167 caffe.cpp:512] Iteration: 85 forward-backward time: 305 ms.
I1108 22:53:28.312659 135167 caffe.cpp:512] Iteration: 86 forward-backward time: 304 ms.
I1108 22:53:28.617225 135167 caffe.cpp:512] Iteration: 87 forward-backward time: 304 ms.
I1108 22:53:28.959694 135167 caffe.cpp:512] Iteration: 88 forward-backward time: 342 ms.
I1108 22:53:29.264775 135167 caffe.cpp:512] Iteration: 89 forward-backward time: 305 ms.
I1108 22:53:29.569025 135167 caffe.cpp:512] Iteration: 90 forward-backward time: 304 ms.
I1108 22:53:29.870414 135167 caffe.cpp:512] Iteration: 91 forward-backward time: 301 ms.
I1108 22:53:30.173804 135167 caffe.cpp:512] Iteration: 92 forward-backward time: 303 ms.
I1108 22:53:30.476075 135167 caffe.cpp:512] Iteration: 93 forward-backward time: 302 ms.
I1108 22:53:30.777412 135167 caffe.cpp:512] Iteration: 94 forward-backward time: 301 ms.
I1108 22:53:31.114703 135167 caffe.cpp:512] Iteration: 95 forward-backward time: 337 ms.
I1108 22:53:31.417989 135167 caffe.cpp:512] Iteration: 96 forward-backward time: 303 ms.
I1108 22:53:31.721552 135167 caffe.cpp:512] Iteration: 97 forward-backward time: 303 ms.
I1108 22:53:32.025264 135167 caffe.cpp:512] Iteration: 98 forward-backward time: 303 ms.
I1108 22:53:32.328860 135167 caffe.cpp:512] Iteration: 99 forward-backward time: 303 ms.
I1108 22:53:32.638870 135167 caffe.cpp:512] Iteration: 100 forward-backward time: 309 ms.
I1108 22:53:32.638989 135167 caffe.cpp:519] Average time per layer: 
I1108 22:53:32.639016 135167 caffe.cpp:522]       data	forward: 250.865 ms.
I1108 22:53:32.639050 135167 caffe.cpp:526]       data	backward: 0.00565 ms.
I1108 22:53:32.639082 135167 caffe.cpp:522]      conv1	forward: 3.46182 ms.
I1108 22:53:32.639118 135167 caffe.cpp:526]      conv1	backward: 3.31907 ms.
I1108 22:53:32.639148 135167 caffe.cpp:522]      relu1	forward: 0.29525 ms.
I1108 22:53:32.639181 135167 caffe.cpp:526]      relu1	backward: 0.45918 ms.
I1108 22:53:32.639214 135167 caffe.cpp:522]      norm1	forward: 1.28644 ms.
I1108 22:53:32.639243 135167 caffe.cpp:526]      norm1	backward: 0.82575 ms.
I1108 22:53:32.639272 135167 caffe.cpp:522]      pool1	forward: 0.40953 ms.
I1108 22:53:32.639302 135167 caffe.cpp:526]      pool1	backward: 0.96365 ms.
I1108 22:53:32.639333 135167 caffe.cpp:522]      conv2	forward: 3.26674 ms.
I1108 22:53:32.639356 135167 caffe.cpp:526]      conv2	backward: 7.33769 ms.
I1108 22:53:32.639379 135167 caffe.cpp:522]      relu2	forward: 0.15533 ms.
I1108 22:53:32.639403 135167 caffe.cpp:526]      relu2	backward: 0.31346 ms.
I1108 22:53:32.639426 135167 caffe.cpp:522]      norm2	forward: 0.88443 ms.
I1108 22:53:32.639451 135167 caffe.cpp:526]      norm2	backward: 0.58084 ms.
I1108 22:53:32.639473 135167 caffe.cpp:522]      pool2	forward: 0.36988 ms.
I1108 22:53:32.639497 135167 caffe.cpp:526]      pool2	backward: 0.92555 ms.
I1108 22:53:32.639519 135167 caffe.cpp:522]      conv3	forward: 2.49013 ms.
I1108 22:53:32.639542 135167 caffe.cpp:526]      conv3	backward: 5.84807 ms.
I1108 22:53:32.639565 135167 caffe.cpp:522]      relu3	forward: 0.07397 ms.
I1108 22:53:32.639590 135167 caffe.cpp:526]      relu3	backward: 0.4431 ms.
I1108 22:53:32.639612 135167 caffe.cpp:522]      conv4	forward: 1.91577 ms.
I1108 22:53:32.639636 135167 caffe.cpp:526]      conv4	backward: 4.56085 ms.
I1108 22:53:32.639657 135167 caffe.cpp:522]      relu4	forward: 0.08167 ms.
I1108 22:53:32.639688 135167 caffe.cpp:526]      relu4	backward: 0.28968 ms.
I1108 22:53:32.639713 135167 caffe.cpp:522]      conv5	forward: 1.35462 ms.
I1108 22:53:32.639735 135167 caffe.cpp:526]      conv5	backward: 2.97705 ms.
I1108 22:53:32.639757 135167 caffe.cpp:522]      relu5	forward: 0.06729 ms.
I1108 22:53:32.639781 135167 caffe.cpp:526]      relu5	backward: 0.05816 ms.
I1108 22:53:32.639804 135167 caffe.cpp:522]      pool5	forward: 0.08541 ms.
I1108 22:53:32.639833 135167 caffe.cpp:526]      pool5	backward: 0.18723 ms.
I1108 22:53:32.639916 135167 caffe.cpp:522]        fc6	forward: 2.46137 ms.
I1108 22:53:32.639941 135167 caffe.cpp:526]        fc6	backward: 7.05614 ms.
I1108 22:53:32.639964 135167 caffe.cpp:522]      relu6	forward: 0.07479 ms.
I1108 22:53:32.639988 135167 caffe.cpp:526]      relu6	backward: 0.04255 ms.
I1108 22:53:32.640012 135167 caffe.cpp:522]      drop6	forward: 0.11448 ms.
I1108 22:53:32.640036 135167 caffe.cpp:526]      drop6	backward: 0.04775 ms.
I1108 22:53:32.640059 135167 caffe.cpp:522]        fc7	forward: 1.36579 ms.
I1108 22:53:32.640082 135167 caffe.cpp:526]        fc7	backward: 5.57058 ms.
I1108 22:53:32.640105 135167 caffe.cpp:522]      relu7	forward: 0.07555 ms.
I1108 22:53:32.640130 135167 caffe.cpp:526]      relu7	backward: 0.04148 ms.
I1108 22:53:32.640152 135167 caffe.cpp:522]      drop7	forward: 0.08424 ms.
I1108 22:53:32.640182 135167 caffe.cpp:526]      drop7	backward: 0.04299 ms.
I1108 22:53:32.640205 135167 caffe.cpp:522]        fc8	forward: 0.82905 ms.
I1108 22:53:32.640228 135167 caffe.cpp:526]        fc8	backward: 2.32826 ms.
I1108 22:53:32.640251 135167 caffe.cpp:522]       loss	forward: 1.66905 ms.
I1108 22:53:32.640275 135167 caffe.cpp:526]       loss	backward: 0.54929 ms.
I1108 22:53:32.640303 135167 caffe.cpp:532] Average Forward pass: 273.959 ms.
I1108 22:53:32.640328 135167 caffe.cpp:535] Average Backward pass: 45.0067 ms.
I1108 22:53:32.640352 135167 caffe.cpp:537] Average Forward-Backward: 319.13 ms.
I1108 22:53:32.640378 135167 caffe.cpp:540] Total Time: 31913 ms.
I1108 22:53:32.640404 135167 caffe.cpp:541] *** Benchmark ends ***
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer0_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=0 -prof_forward_direction=1
I1108 22:54:42.577602 135237 caffe.cpp:444] Use CPU.
I1108 22:54:59.509038 135237 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 22:54:59.566431 135237 cpu_info.cpp:455] Total number of sockets: 1
I1108 22:54:59.578382 135237 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 22:54:59.590914 135237 cpu_info.cpp:461] Total number of processors: 272
I1108 22:54:59.602396 135237 cpu_info.cpp:464] GPU is used: no
I1108 22:54:59.611516 135237 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 22:54:59.620635 135237 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 22:54:59.632076 135237 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 22:55:08.349836 135237 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 22:55:08.382386 135237 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 22:55:09.010715 135237 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 22:55:11.446563 135237 layer_factory.hpp:114] Creating layer data
I1108 22:55:11.595515 135237 net.cpp:160] Creating Layer data
I1108 22:55:11.643731 135237 net.cpp:570] data -> data
I1108 22:55:12.109547 135237 net.cpp:570] data -> label
I1108 22:55:19.121134 135237 net.cpp:210] Setting up data
I1108 22:55:19.202081 135237 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 22:55:19.306342 135237 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 22:55:19.313642 135237 net.cpp:225] Memory required for data: 19787264
I1108 22:55:19.382900 135237 layer_factory.hpp:114] Creating layer conv1
I1108 22:55:19.711841 135237 net.cpp:160] Creating Layer conv1
I1108 22:55:19.761945 135237 net.cpp:596] conv1 <- data
I1108 22:55:19.880672 135237 net.cpp:570] conv1 -> conv1
I1108 22:55:52.451669 135237 net.cpp:210] Setting up conv1
I1108 22:55:52.458849 135237 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:55:52.459271 135237 net.cpp:225] Memory required for data: 56958464
I1108 22:55:52.740504 135237 layer_factory.hpp:114] Creating layer relu1
I1108 22:55:52.859885 135237 net.cpp:160] Creating Layer relu1
I1108 22:55:52.864418 135237 net.cpp:596] relu1 <- conv1
I1108 22:55:52.896556 135237 net.cpp:557] relu1 -> conv1 (in-place)
I1108 22:55:53.084704 135237 net.cpp:210] Setting up relu1
I1108 22:55:53.087167 135237 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:55:53.087539 135237 net.cpp:225] Memory required for data: 94129664
I1108 22:55:53.087759 135237 layer_factory.hpp:114] Creating layer norm1
I1108 22:55:53.191020 135237 net.cpp:160] Creating Layer norm1
I1108 22:55:53.191330 135237 net.cpp:596] norm1 <- conv1
I1108 22:55:53.193882 135237 net.cpp:570] norm1 -> norm1
I1108 22:55:53.419433 135237 net.cpp:210] Setting up norm1
I1108 22:55:53.432224 135237 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 22:55:53.432602 135237 net.cpp:225] Memory required for data: 131300864
I1108 22:55:53.432993 135237 layer_factory.hpp:114] Creating layer pool1
I1108 22:55:53.526024 135237 net.cpp:160] Creating Layer pool1
I1108 22:55:53.526330 135237 net.cpp:596] pool1 <- norm1
I1108 22:55:53.541268 135237 net.cpp:570] pool1 -> pool1
I1108 22:55:53.839143 135237 net.cpp:210] Setting up pool1
I1108 22:55:53.841620 135237 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 22:55:53.841974 135237 net.cpp:225] Memory required for data: 140258816
I1108 22:55:53.842200 135237 layer_factory.hpp:114] Creating layer conv2
I1108 22:55:53.842630 135237 net.cpp:160] Creating Layer conv2
I1108 22:55:53.842881 135237 net.cpp:596] conv2 <- pool1
I1108 22:55:53.843112 135237 net.cpp:570] conv2 -> conv2
I1108 22:55:59.561146 135237 net.cpp:210] Setting up conv2
I1108 22:55:59.561465 135237 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:55:59.561879 135237 net.cpp:225] Memory required for data: 164146688
I1108 22:55:59.612397 135237 layer_factory.hpp:114] Creating layer relu2
I1108 22:55:59.612838 135237 net.cpp:160] Creating Layer relu2
I1108 22:55:59.613157 135237 net.cpp:596] relu2 <- conv2
I1108 22:55:59.613440 135237 net.cpp:557] relu2 -> conv2 (in-place)
I1108 22:55:59.613900 135237 net.cpp:210] Setting up relu2
I1108 22:55:59.614174 135237 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:55:59.614423 135237 net.cpp:225] Memory required for data: 188034560
I1108 22:55:59.614625 135237 layer_factory.hpp:114] Creating layer norm2
I1108 22:55:59.614903 135237 net.cpp:160] Creating Layer norm2
I1108 22:55:59.615149 135237 net.cpp:596] norm2 <- conv2
I1108 22:55:59.615442 135237 net.cpp:570] norm2 -> norm2
I1108 22:55:59.617629 135237 net.cpp:210] Setting up norm2
I1108 22:55:59.617959 135237 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 22:55:59.618345 135237 net.cpp:225] Memory required for data: 211922432
I1108 22:55:59.618580 135237 layer_factory.hpp:114] Creating layer pool2
I1108 22:55:59.619398 135237 net.cpp:160] Creating Layer pool2
I1108 22:55:59.619678 135237 net.cpp:596] pool2 <- norm2
I1108 22:55:59.619920 135237 net.cpp:570] pool2 -> pool2
I1108 22:55:59.620360 135237 net.cpp:210] Setting up pool2
I1108 22:55:59.620725 135237 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:55:59.621099 135237 net.cpp:225] Memory required for data: 217460224
I1108 22:55:59.621404 135237 layer_factory.hpp:114] Creating layer conv3
I1108 22:55:59.621737 135237 net.cpp:160] Creating Layer conv3
I1108 22:55:59.621953 135237 net.cpp:596] conv3 <- pool2
I1108 22:55:59.622189 135237 net.cpp:570] conv3 -> conv3
I1108 22:56:00.101559 135237 net.cpp:210] Setting up conv3
I1108 22:56:00.103991 135237 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:56:00.104346 135237 net.cpp:225] Memory required for data: 225766912
I1108 22:56:00.107553 135237 layer_factory.hpp:114] Creating layer relu3
I1108 22:56:00.107964 135237 net.cpp:160] Creating Layer relu3
I1108 22:56:00.108224 135237 net.cpp:596] relu3 <- conv3
I1108 22:56:00.108479 135237 net.cpp:557] relu3 -> conv3 (in-place)
I1108 22:56:00.112715 135237 net.cpp:210] Setting up relu3
I1108 22:56:00.113111 135237 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:56:00.113420 135237 net.cpp:225] Memory required for data: 234073600
I1108 22:56:00.113628 135237 layer_factory.hpp:114] Creating layer conv4
I1108 22:56:00.113997 135237 net.cpp:160] Creating Layer conv4
I1108 22:56:00.114284 135237 net.cpp:596] conv4 <- conv3
I1108 22:56:00.114552 135237 net.cpp:570] conv4 -> conv4
I1108 22:56:00.354611 135237 net.cpp:210] Setting up conv4
I1108 22:56:00.354995 135237 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:56:00.355461 135237 net.cpp:225] Memory required for data: 242380288
I1108 22:56:00.355813 135237 layer_factory.hpp:114] Creating layer relu4
I1108 22:56:00.356112 135237 net.cpp:160] Creating Layer relu4
I1108 22:56:00.356343 135237 net.cpp:596] relu4 <- conv4
I1108 22:56:00.356590 135237 net.cpp:557] relu4 -> conv4 (in-place)
I1108 22:56:00.368942 135237 net.cpp:210] Setting up relu4
I1108 22:56:00.369284 135237 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 22:56:00.369690 135237 net.cpp:225] Memory required for data: 250686976
I1108 22:56:00.369909 135237 layer_factory.hpp:114] Creating layer conv5
I1108 22:56:00.370277 135237 net.cpp:160] Creating Layer conv5
I1108 22:56:00.370518 135237 net.cpp:596] conv5 <- conv4
I1108 22:56:00.370767 135237 net.cpp:570] conv5 -> conv5
I1108 22:56:00.566686 135237 net.cpp:210] Setting up conv5
I1108 22:56:00.567087 135237 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:56:00.567554 135237 net.cpp:225] Memory required for data: 256224768
I1108 22:56:00.572291 135237 layer_factory.hpp:114] Creating layer relu5
I1108 22:56:00.572710 135237 net.cpp:160] Creating Layer relu5
I1108 22:56:00.573040 135237 net.cpp:596] relu5 <- conv5
I1108 22:56:00.573366 135237 net.cpp:557] relu5 -> conv5 (in-place)
I1108 22:56:00.573837 135237 net.cpp:210] Setting up relu5
I1108 22:56:00.574131 135237 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 22:56:00.574390 135237 net.cpp:225] Memory required for data: 261762560
I1108 22:56:00.574610 135237 layer_factory.hpp:114] Creating layer pool5
I1108 22:56:00.574910 135237 net.cpp:160] Creating Layer pool5
I1108 22:56:00.575148 135237 net.cpp:596] pool5 <- conv5
I1108 22:56:00.575402 135237 net.cpp:570] pool5 -> pool5
I1108 22:56:00.575901 135237 net.cpp:210] Setting up pool5
I1108 22:56:00.576162 135237 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 22:56:00.576396 135237 net.cpp:225] Memory required for data: 262942208
I1108 22:56:00.576584 135237 layer_factory.hpp:114] Creating layer fc6
I1108 22:56:00.631346 135237 net.cpp:160] Creating Layer fc6
I1108 22:56:00.631655 135237 net.cpp:596] fc6 <- pool5
I1108 22:56:00.632038 135237 net.cpp:570] fc6 -> fc6
I1108 22:56:04.727705 135237 net.cpp:210] Setting up fc6
I1108 22:56:04.728008 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:04.730059 135237 net.cpp:225] Memory required for data: 263466496
I1108 22:56:04.730372 135237 layer_factory.hpp:114] Creating layer relu6
I1108 22:56:04.732874 135237 net.cpp:160] Creating Layer relu6
I1108 22:56:04.733173 135237 net.cpp:596] relu6 <- fc6
I1108 22:56:04.733407 135237 net.cpp:557] relu6 -> fc6 (in-place)
I1108 22:56:04.733836 135237 net.cpp:210] Setting up relu6
I1108 22:56:04.734089 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:04.734365 135237 net.cpp:225] Memory required for data: 263990784
I1108 22:56:04.734571 135237 layer_factory.hpp:114] Creating layer drop6
I1108 22:56:04.754423 135237 net.cpp:160] Creating Layer drop6
I1108 22:56:04.754725 135237 net.cpp:596] drop6 <- fc6
I1108 22:56:04.755097 135237 net.cpp:557] drop6 -> fc6 (in-place)
I1108 22:56:04.858238 135237 net.cpp:210] Setting up drop6
I1108 22:56:04.858531 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:04.858876 135237 net.cpp:225] Memory required for data: 264515072
I1108 22:56:04.859127 135237 layer_factory.hpp:114] Creating layer fc7
I1108 22:56:04.859405 135237 net.cpp:160] Creating Layer fc7
I1108 22:56:04.859622 135237 net.cpp:596] fc7 <- fc6
I1108 22:56:04.860010 135237 net.cpp:570] fc7 -> fc7
I1108 22:56:06.573959 135237 net.cpp:210] Setting up fc7
I1108 22:56:06.574383 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:06.574797 135237 net.cpp:225] Memory required for data: 265039360
I1108 22:56:06.575109 135237 layer_factory.hpp:114] Creating layer relu7
I1108 22:56:06.575417 135237 net.cpp:160] Creating Layer relu7
I1108 22:56:06.575644 135237 net.cpp:596] relu7 <- fc7
I1108 22:56:06.575881 135237 net.cpp:557] relu7 -> fc7 (in-place)
I1108 22:56:06.576310 135237 net.cpp:210] Setting up relu7
I1108 22:56:06.576582 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:06.576890 135237 net.cpp:225] Memory required for data: 265563648
I1108 22:56:06.577105 135237 layer_factory.hpp:114] Creating layer drop7
I1108 22:56:06.577349 135237 net.cpp:160] Creating Layer drop7
I1108 22:56:06.577554 135237 net.cpp:596] drop7 <- fc7
I1108 22:56:06.577827 135237 net.cpp:557] drop7 -> fc7 (in-place)
I1108 22:56:06.578088 135237 net.cpp:210] Setting up drop7
I1108 22:56:06.578285 135237 net.cpp:217] Top shape: 32 4096 (131072)
I1108 22:56:06.578497 135237 net.cpp:225] Memory required for data: 266087936
I1108 22:56:06.578677 135237 layer_factory.hpp:114] Creating layer fc8
I1108 22:56:06.578922 135237 net.cpp:160] Creating Layer fc8
I1108 22:56:06.579110 135237 net.cpp:596] fc8 <- fc7
I1108 22:56:06.579329 135237 net.cpp:570] fc8 -> fc8
I1108 22:56:07.002564 135237 net.cpp:210] Setting up fc8
I1108 22:56:07.006983 135237 net.cpp:217] Top shape: 32 1000 (32000)
I1108 22:56:07.007395 135237 net.cpp:225] Memory required for data: 266215936
I1108 22:56:07.007730 135237 layer_factory.hpp:114] Creating layer loss
I1108 22:56:07.032042 135237 net.cpp:160] Creating Layer loss
I1108 22:56:07.032354 135237 net.cpp:596] loss <- fc8
I1108 22:56:07.033393 135237 net.cpp:596] loss <- label
I1108 22:56:07.060539 135237 net.cpp:570] loss -> loss
I1108 22:56:07.098253 135237 layer_factory.hpp:114] Creating layer loss
I1108 22:56:09.697510 135237 net.cpp:210] Setting up loss
I1108 22:56:09.749622 135237 net.cpp:217] Top shape: (1)
I1108 22:56:09.758886 135237 net.cpp:220]     with loss weight 1
I1108 22:56:09.888708 135237 net.cpp:225] Memory required for data: 266215940
I1108 22:56:09.934710 135237 net.cpp:287] loss needs backward computation.
I1108 22:56:10.025460 135237 net.cpp:287] fc8 needs backward computation.
I1108 22:56:10.032615 135237 net.cpp:287] drop7 needs backward computation.
I1108 22:56:10.043591 135237 net.cpp:287] relu7 needs backward computation.
I1108 22:56:10.043898 135237 net.cpp:287] fc7 needs backward computation.
I1108 22:56:10.046368 135237 net.cpp:287] drop6 needs backward computation.
I1108 22:56:10.046768 135237 net.cpp:287] relu6 needs backward computation.
I1108 22:56:10.047063 135237 net.cpp:287] fc6 needs backward computation.
I1108 22:56:10.047824 135237 net.cpp:287] pool5 needs backward computation.
I1108 22:56:10.048557 135237 net.cpp:287] relu5 needs backward computation.
I1108 22:56:10.048880 135237 net.cpp:287] conv5 needs backward computation.
I1108 22:56:10.049098 135237 net.cpp:287] relu4 needs backward computation.
I1108 22:56:10.049387 135237 net.cpp:287] conv4 needs backward computation.
I1108 22:56:10.049650 135237 net.cpp:287] relu3 needs backward computation.
I1108 22:56:10.049834 135237 net.cpp:287] conv3 needs backward computation.
I1108 22:56:10.062119 135237 net.cpp:287] pool2 needs backward computation.
I1108 22:56:10.062448 135237 net.cpp:287] norm2 needs backward computation.
I1108 22:56:10.062763 135237 net.cpp:287] relu2 needs backward computation.
I1108 22:56:10.063004 135237 net.cpp:287] conv2 needs backward computation.
I1108 22:56:10.063195 135237 net.cpp:287] pool1 needs backward computation.
I1108 22:56:10.063381 135237 net.cpp:287] norm1 needs backward computation.
I1108 22:56:10.063565 135237 net.cpp:287] relu1 needs backward computation.
I1108 22:56:10.063745 135237 net.cpp:287] conv1 needs backward computation.
I1108 22:56:10.076293 135237 net.cpp:289] data does not need backward computation.
I1108 22:56:10.100631 135237 net.cpp:331] This network produces output loss
I1108 22:56:10.173678 135237 net.cpp:345] Network initialization done.
I1108 22:56:10.337824 135237 caffe.cpp:452] Performing Forward
I1108 22:56:23.392770 135237 caffe.cpp:457] Initial loss: 6.9583
I1108 22:56:23.444433 135237 caffe.cpp:459] Performing Backward
I1108 22:56:28.487901 135237 caffe.cpp:468] *** Benchmark begins ***
I1108 22:56:28.506377 135237 caffe.cpp:469] Testing for 1 iterations.
I1108 22:56:28.649024 135237 caffe.cpp:482] Profiling Layer: data forward
I1108 22:56:31.470274 135237 caffe.cpp:512] Iteration: 1 forward-backward time: 2818 ms.
I1108 22:56:31.631691 135237 caffe.cpp:519] Average time per layer: 
I1108 22:56:31.649456 135237 caffe.cpp:522]       data	forward: 554.547 ms.
I1108 22:56:31.724951 135237 caffe.cpp:526]       data	backward: 7.112 ms.
I1108 22:56:31.747339 135237 caffe.cpp:522]      conv1	forward: 130.213 ms.
I1108 22:56:31.759250 135237 caffe.cpp:526]      conv1	backward: 45.385 ms.
I1108 22:56:31.770738 135237 caffe.cpp:522]      relu1	forward: 15.189 ms.
I1108 22:56:31.779160 135237 caffe.cpp:526]      relu1	backward: 9.829 ms.
I1108 22:56:31.783118 135237 caffe.cpp:522]      norm1	forward: 18.72 ms.
I1108 22:56:31.785243 135237 caffe.cpp:526]      norm1	backward: 22.463 ms.
I1108 22:56:31.787643 135237 caffe.cpp:522]      pool1	forward: 22.745 ms.
I1108 22:56:31.797077 135237 caffe.cpp:526]      pool1	backward: 76.265 ms.
I1108 22:56:31.801786 135237 caffe.cpp:522]      conv2	forward: 61.278 ms.
I1108 22:56:31.811125 135237 caffe.cpp:526]      conv2	backward: 81.018 ms.
I1108 22:56:31.816293 135237 caffe.cpp:522]      relu2	forward: 14.177 ms.
I1108 22:56:31.818286 135237 caffe.cpp:526]      relu2	backward: 21.546 ms.
I1108 22:56:31.825485 135237 caffe.cpp:522]      norm2	forward: 14.836 ms.
I1108 22:56:31.826432 135237 caffe.cpp:526]      norm2	backward: 16.477 ms.
I1108 22:56:31.826653 135237 caffe.cpp:522]      pool2	forward: 13.716 ms.
I1108 22:56:31.826858 135237 caffe.cpp:526]      pool2	backward: 71.772 ms.
I1108 22:56:31.827064 135237 caffe.cpp:522]      conv3	forward: 34.742 ms.
I1108 22:56:31.827265 135237 caffe.cpp:526]      conv3	backward: 71.063 ms.
I1108 22:56:31.827468 135237 caffe.cpp:522]      relu3	forward: 16.068 ms.
I1108 22:56:31.827673 135237 caffe.cpp:526]      relu3	backward: 37.016 ms.
I1108 22:56:31.827910 135237 caffe.cpp:522]      conv4	forward: 32.62 ms.
I1108 22:56:31.828126 135237 caffe.cpp:526]      conv4	backward: 69.341 ms.
I1108 22:56:31.828333 135237 caffe.cpp:522]      relu4	forward: 17.915 ms.
I1108 22:56:31.828539 135237 caffe.cpp:526]      relu4	backward: 37.156 ms.
I1108 22:56:31.828743 135237 caffe.cpp:522]      conv5	forward: 22.972 ms.
I1108 22:56:31.828989 135237 caffe.cpp:526]      conv5	backward: 68.95 ms.
I1108 22:56:31.829192 135237 caffe.cpp:522]      relu5	forward: 0.202 ms.
I1108 22:56:31.829416 135237 caffe.cpp:526]      relu5	backward: 13.561 ms.
I1108 22:56:31.829619 135237 caffe.cpp:522]      pool5	forward: 0.285 ms.
I1108 22:56:31.829819 135237 caffe.cpp:526]      pool5	backward: 50.875 ms.
I1108 22:56:31.830025 135237 caffe.cpp:522]        fc6	forward: 16.377 ms.
I1108 22:56:31.830265 135237 caffe.cpp:526]        fc6	backward: 350.219 ms.
I1108 22:56:31.830482 135237 caffe.cpp:522]      relu6	forward: 0.868 ms.
I1108 22:56:31.830687 135237 caffe.cpp:526]      relu6	backward: 19.885 ms.
I1108 22:56:31.830890 135237 caffe.cpp:522]      drop6	forward: 1.486 ms.
I1108 22:56:31.831087 135237 caffe.cpp:526]      drop6	backward: 25.245 ms.
I1108 22:56:31.831290 135237 caffe.cpp:522]        fc7	forward: 4.465 ms.
I1108 22:56:31.831486 135237 caffe.cpp:526]        fc7	backward: 258.339 ms.
I1108 22:56:31.831691 135237 caffe.cpp:522]      relu7	forward: 0.128 ms.
I1108 22:56:31.831889 135237 caffe.cpp:526]      relu7	backward: 27.423 ms.
I1108 22:56:31.832093 135237 caffe.cpp:522]      drop7	forward: 0.29 ms.
I1108 22:56:31.832293 135237 caffe.cpp:526]      drop7	backward: 11.938 ms.
I1108 22:56:31.832545 135237 caffe.cpp:522]        fc8	forward: 1.91 ms.
I1108 22:56:31.832756 135237 caffe.cpp:526]        fc8	backward: 244.301 ms.
I1108 22:56:31.833019 135237 caffe.cpp:522]       loss	forward: 36.316 ms.
I1108 22:56:31.833214 135237 caffe.cpp:526]       loss	backward: 52.111 ms.
I1108 22:56:31.838740 135237 caffe.cpp:532] Average Forward pass: 1089.76 ms.
I1108 22:56:31.852574 135237 caffe.cpp:535] Average Backward pass: 1699.29 ms.
I1108 22:56:31.863486 135237 caffe.cpp:537] Average Forward-Backward: 3288 ms.
I1108 22:56:31.878151 135237 caffe.cpp:540] Total Time: 3288 ms.
I1108 22:56:31.890974 135237 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 30876363
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 402702
elements_fp_double_1 = 182266
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 37319595
--->Total double-precision FLOPs = 182266
--->Total FLOPs = 37501861
mem-read-1 = 5178441
mem-read-2 = 137245
mem-read-4 = 32584645
mem-read-8 = 33036862
mem-read-16 = 146242
mem-read-32 = 581140
mem-read-64 = 2202546
mem-write-1 = 5007400
mem-write-2 = 1
mem-write-4 = 14984215
mem-write-8 = 15343141
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 330000
--->Total Bytes read = 561985703
--->Total Bytes written = 208809390
--->Total Bytes = 770795093
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer1_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=1 -prof_forward_direction=1
I1108 22:59:11.747221 135356 caffe.cpp:444] Use CPU.
I1108 22:59:28.686888 135356 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 22:59:28.742722 135356 cpu_info.cpp:455] Total number of sockets: 1
I1108 22:59:28.754669 135356 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 22:59:28.767230 135356 cpu_info.cpp:461] Total number of processors: 272
I1108 22:59:28.778571 135356 cpu_info.cpp:464] GPU is used: no
I1108 22:59:28.787514 135356 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 22:59:28.796281 135356 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 22:59:28.807212 135356 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 22:59:37.520016 135356 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 22:59:37.552739 135356 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 22:59:38.193861 135356 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 22:59:40.643092 135356 layer_factory.hpp:114] Creating layer data
I1108 22:59:40.790997 135356 net.cpp:160] Creating Layer data
I1108 22:59:40.838819 135356 net.cpp:570] data -> data
I1108 22:59:41.303371 135356 net.cpp:570] data -> label
I1108 22:59:48.325834 135356 net.cpp:210] Setting up data
I1108 22:59:48.405632 135356 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 22:59:48.509810 135356 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 22:59:48.517057 135356 net.cpp:225] Memory required for data: 19787264
I1108 22:59:48.584434 135356 layer_factory.hpp:114] Creating layer conv1
I1108 22:59:48.917017 135356 net.cpp:160] Creating Layer conv1
I1108 22:59:48.967031 135356 net.cpp:596] conv1 <- data
I1108 22:59:49.086750 135356 net.cpp:570] conv1 -> conv1
I1108 23:00:21.948822 135356 net.cpp:210] Setting up conv1
I1108 23:00:21.956295 135356 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:00:21.956634 135356 net.cpp:225] Memory required for data: 56958464
I1108 23:00:22.235836 135356 layer_factory.hpp:114] Creating layer relu1
I1108 23:00:22.355316 135356 net.cpp:160] Creating Layer relu1
I1108 23:00:22.359958 135356 net.cpp:596] relu1 <- conv1
I1108 23:00:22.392068 135356 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:00:22.580466 135356 net.cpp:210] Setting up relu1
I1108 23:00:22.582958 135356 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:00:22.583324 135356 net.cpp:225] Memory required for data: 94129664
I1108 23:00:22.583545 135356 layer_factory.hpp:114] Creating layer norm1
I1108 23:00:22.687782 135356 net.cpp:160] Creating Layer norm1
I1108 23:00:22.688098 135356 net.cpp:596] norm1 <- conv1
I1108 23:00:22.690721 135356 net.cpp:570] norm1 -> norm1
I1108 23:00:22.911474 135356 net.cpp:210] Setting up norm1
I1108 23:00:22.924244 135356 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:00:22.924624 135356 net.cpp:225] Memory required for data: 131300864
I1108 23:00:22.924975 135356 layer_factory.hpp:114] Creating layer pool1
I1108 23:00:23.022961 135356 net.cpp:160] Creating Layer pool1
I1108 23:00:23.023291 135356 net.cpp:596] pool1 <- norm1
I1108 23:00:23.038628 135356 net.cpp:570] pool1 -> pool1
I1108 23:00:23.339587 135356 net.cpp:210] Setting up pool1
I1108 23:00:23.342103 135356 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:00:23.342478 135356 net.cpp:225] Memory required for data: 140258816
I1108 23:00:23.342706 135356 layer_factory.hpp:114] Creating layer conv2
I1108 23:00:23.343060 135356 net.cpp:160] Creating Layer conv2
I1108 23:00:23.343292 135356 net.cpp:596] conv2 <- pool1
I1108 23:00:23.343539 135356 net.cpp:570] conv2 -> conv2
I1108 23:00:29.104037 135356 net.cpp:210] Setting up conv2
I1108 23:00:29.104385 135356 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:00:29.104815 135356 net.cpp:225] Memory required for data: 164146688
I1108 23:00:29.155097 135356 layer_factory.hpp:114] Creating layer relu2
I1108 23:00:29.155498 135356 net.cpp:160] Creating Layer relu2
I1108 23:00:29.155863 135356 net.cpp:596] relu2 <- conv2
I1108 23:00:29.156122 135356 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:00:29.156551 135356 net.cpp:210] Setting up relu2
I1108 23:00:29.156853 135356 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:00:29.157099 135356 net.cpp:225] Memory required for data: 188034560
I1108 23:00:29.157285 135356 layer_factory.hpp:114] Creating layer norm2
I1108 23:00:29.157527 135356 net.cpp:160] Creating Layer norm2
I1108 23:00:29.157762 135356 net.cpp:596] norm2 <- conv2
I1108 23:00:29.158006 135356 net.cpp:570] norm2 -> norm2
I1108 23:00:29.160060 135356 net.cpp:210] Setting up norm2
I1108 23:00:29.160372 135356 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:00:29.160641 135356 net.cpp:225] Memory required for data: 211922432
I1108 23:00:29.160919 135356 layer_factory.hpp:114] Creating layer pool2
I1108 23:00:29.161834 135356 net.cpp:160] Creating Layer pool2
I1108 23:00:29.162132 135356 net.cpp:596] pool2 <- norm2
I1108 23:00:29.162392 135356 net.cpp:570] pool2 -> pool2
I1108 23:00:29.162812 135356 net.cpp:210] Setting up pool2
I1108 23:00:29.163071 135356 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:00:29.163321 135356 net.cpp:225] Memory required for data: 217460224
I1108 23:00:29.163592 135356 layer_factory.hpp:114] Creating layer conv3
I1108 23:00:29.163978 135356 net.cpp:160] Creating Layer conv3
I1108 23:00:29.164213 135356 net.cpp:596] conv3 <- pool2
I1108 23:00:29.164470 135356 net.cpp:570] conv3 -> conv3
I1108 23:00:29.645650 135356 net.cpp:210] Setting up conv3
I1108 23:00:29.648006 135356 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:00:29.648385 135356 net.cpp:225] Memory required for data: 225766912
I1108 23:00:29.651438 135356 layer_factory.hpp:114] Creating layer relu3
I1108 23:00:29.651882 135356 net.cpp:160] Creating Layer relu3
I1108 23:00:29.652125 135356 net.cpp:596] relu3 <- conv3
I1108 23:00:29.652359 135356 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:00:29.656412 135356 net.cpp:210] Setting up relu3
I1108 23:00:29.656730 135356 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:00:29.657061 135356 net.cpp:225] Memory required for data: 234073600
I1108 23:00:29.657259 135356 layer_factory.hpp:114] Creating layer conv4
I1108 23:00:29.657615 135356 net.cpp:160] Creating Layer conv4
I1108 23:00:29.657866 135356 net.cpp:596] conv4 <- conv3
I1108 23:00:29.658108 135356 net.cpp:570] conv4 -> conv4
I1108 23:00:29.900307 135356 net.cpp:210] Setting up conv4
I1108 23:00:29.900705 135356 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:00:29.901159 135356 net.cpp:225] Memory required for data: 242380288
I1108 23:00:29.901499 135356 layer_factory.hpp:114] Creating layer relu4
I1108 23:00:29.901815 135356 net.cpp:160] Creating Layer relu4
I1108 23:00:29.902055 135356 net.cpp:596] relu4 <- conv4
I1108 23:00:29.902302 135356 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:00:29.914343 135356 net.cpp:210] Setting up relu4
I1108 23:00:29.914692 135356 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:00:29.915068 135356 net.cpp:225] Memory required for data: 250686976
I1108 23:00:29.915412 135356 layer_factory.hpp:114] Creating layer conv5
I1108 23:00:29.915801 135356 net.cpp:160] Creating Layer conv5
I1108 23:00:29.916059 135356 net.cpp:596] conv5 <- conv4
I1108 23:00:29.916323 135356 net.cpp:570] conv5 -> conv5
I1108 23:00:30.084158 135356 net.cpp:210] Setting up conv5
I1108 23:00:30.084545 135356 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:00:30.085023 135356 net.cpp:225] Memory required for data: 256224768
I1108 23:00:30.089507 135356 layer_factory.hpp:114] Creating layer relu5
I1108 23:00:30.089910 135356 net.cpp:160] Creating Layer relu5
I1108 23:00:30.090167 135356 net.cpp:596] relu5 <- conv5
I1108 23:00:30.090435 135356 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:00:30.090895 135356 net.cpp:210] Setting up relu5
I1108 23:00:30.091184 135356 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:00:30.091429 135356 net.cpp:225] Memory required for data: 261762560
I1108 23:00:30.091637 135356 layer_factory.hpp:114] Creating layer pool5
I1108 23:00:30.091904 135356 net.cpp:160] Creating Layer pool5
I1108 23:00:30.092118 135356 net.cpp:596] pool5 <- conv5
I1108 23:00:30.092344 135356 net.cpp:570] pool5 -> pool5
I1108 23:00:30.092746 135356 net.cpp:210] Setting up pool5
I1108 23:00:30.093061 135356 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:00:30.093293 135356 net.cpp:225] Memory required for data: 262942208
I1108 23:00:30.093515 135356 layer_factory.hpp:114] Creating layer fc6
I1108 23:00:30.147541 135356 net.cpp:160] Creating Layer fc6
I1108 23:00:30.147852 135356 net.cpp:596] fc6 <- pool5
I1108 23:00:30.148222 135356 net.cpp:570] fc6 -> fc6
I1108 23:00:34.264844 135356 net.cpp:210] Setting up fc6
I1108 23:00:34.265159 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:34.267196 135356 net.cpp:225] Memory required for data: 263466496
I1108 23:00:34.267516 135356 layer_factory.hpp:114] Creating layer relu6
I1108 23:00:34.270073 135356 net.cpp:160] Creating Layer relu6
I1108 23:00:34.270371 135356 net.cpp:596] relu6 <- fc6
I1108 23:00:34.270601 135356 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:00:34.271018 135356 net.cpp:210] Setting up relu6
I1108 23:00:34.271277 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:34.271500 135356 net.cpp:225] Memory required for data: 263990784
I1108 23:00:34.271687 135356 layer_factory.hpp:114] Creating layer drop6
I1108 23:00:34.293256 135356 net.cpp:160] Creating Layer drop6
I1108 23:00:34.293551 135356 net.cpp:596] drop6 <- fc6
I1108 23:00:34.293917 135356 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:00:34.396142 135356 net.cpp:210] Setting up drop6
I1108 23:00:34.396443 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:34.396809 135356 net.cpp:225] Memory required for data: 264515072
I1108 23:00:34.397064 135356 layer_factory.hpp:114] Creating layer fc7
I1108 23:00:34.397338 135356 net.cpp:160] Creating Layer fc7
I1108 23:00:34.397544 135356 net.cpp:596] fc7 <- fc6
I1108 23:00:34.397915 135356 net.cpp:570] fc7 -> fc7
I1108 23:00:36.121042 135356 net.cpp:210] Setting up fc7
I1108 23:00:36.121423 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:36.121876 135356 net.cpp:225] Memory required for data: 265039360
I1108 23:00:36.122215 135356 layer_factory.hpp:114] Creating layer relu7
I1108 23:00:36.122560 135356 net.cpp:160] Creating Layer relu7
I1108 23:00:36.122815 135356 net.cpp:596] relu7 <- fc7
I1108 23:00:36.123081 135356 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:00:36.123540 135356 net.cpp:210] Setting up relu7
I1108 23:00:36.123833 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:36.124119 135356 net.cpp:225] Memory required for data: 265563648
I1108 23:00:36.124333 135356 layer_factory.hpp:114] Creating layer drop7
I1108 23:00:36.124590 135356 net.cpp:160] Creating Layer drop7
I1108 23:00:36.124852 135356 net.cpp:596] drop7 <- fc7
I1108 23:00:36.125208 135356 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:00:36.125490 135356 net.cpp:210] Setting up drop7
I1108 23:00:36.125694 135356 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:00:36.125907 135356 net.cpp:225] Memory required for data: 266087936
I1108 23:00:36.126090 135356 layer_factory.hpp:114] Creating layer fc8
I1108 23:00:36.126339 135356 net.cpp:160] Creating Layer fc8
I1108 23:00:36.126538 135356 net.cpp:596] fc8 <- fc7
I1108 23:00:36.126765 135356 net.cpp:570] fc8 -> fc8
I1108 23:00:36.553017 135356 net.cpp:210] Setting up fc8
I1108 23:00:36.553381 135356 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:00:36.553786 135356 net.cpp:225] Memory required for data: 266215936
I1108 23:00:36.554128 135356 layer_factory.hpp:114] Creating layer loss
I1108 23:00:36.578989 135356 net.cpp:160] Creating Layer loss
I1108 23:00:36.579313 135356 net.cpp:596] loss <- fc8
I1108 23:00:36.580374 135356 net.cpp:596] loss <- label
I1108 23:00:36.610059 135356 net.cpp:570] loss -> loss
I1108 23:00:36.649125 135356 layer_factory.hpp:114] Creating layer loss
I1108 23:00:39.234586 135356 net.cpp:210] Setting up loss
I1108 23:00:39.278481 135356 net.cpp:217] Top shape: (1)
I1108 23:00:39.291321 135356 net.cpp:220]     with loss weight 1
I1108 23:00:39.417676 135356 net.cpp:225] Memory required for data: 266215940
I1108 23:00:39.462527 135356 net.cpp:287] loss needs backward computation.
I1108 23:00:39.559756 135356 net.cpp:287] fc8 needs backward computation.
I1108 23:00:39.570304 135356 net.cpp:287] drop7 needs backward computation.
I1108 23:00:39.581017 135356 net.cpp:287] relu7 needs backward computation.
I1108 23:00:39.581323 135356 net.cpp:287] fc7 needs backward computation.
I1108 23:00:39.583722 135356 net.cpp:287] drop6 needs backward computation.
I1108 23:00:39.584053 135356 net.cpp:287] relu6 needs backward computation.
I1108 23:00:39.584257 135356 net.cpp:287] fc6 needs backward computation.
I1108 23:00:39.585187 135356 net.cpp:287] pool5 needs backward computation.
I1108 23:00:39.585981 135356 net.cpp:287] relu5 needs backward computation.
I1108 23:00:39.586241 135356 net.cpp:287] conv5 needs backward computation.
I1108 23:00:39.586432 135356 net.cpp:287] relu4 needs backward computation.
I1108 23:00:39.586611 135356 net.cpp:287] conv4 needs backward computation.
I1108 23:00:39.586791 135356 net.cpp:287] relu3 needs backward computation.
I1108 23:00:39.587002 135356 net.cpp:287] conv3 needs backward computation.
I1108 23:00:39.599107 135356 net.cpp:287] pool2 needs backward computation.
I1108 23:00:39.599439 135356 net.cpp:287] norm2 needs backward computation.
I1108 23:00:39.599745 135356 net.cpp:287] relu2 needs backward computation.
I1108 23:00:39.599979 135356 net.cpp:287] conv2 needs backward computation.
I1108 23:00:39.600168 135356 net.cpp:287] pool1 needs backward computation.
I1108 23:00:39.600353 135356 net.cpp:287] norm1 needs backward computation.
I1108 23:00:39.600533 135356 net.cpp:287] relu1 needs backward computation.
I1108 23:00:39.600709 135356 net.cpp:287] conv1 needs backward computation.
I1108 23:00:39.613334 135356 net.cpp:289] data does not need backward computation.
I1108 23:00:39.637570 135356 net.cpp:331] This network produces output loss
I1108 23:00:39.707736 135356 net.cpp:345] Network initialization done.
I1108 23:00:39.880002 135356 caffe.cpp:452] Performing Forward
I1108 23:00:53.007611 135356 caffe.cpp:457] Initial loss: 6.98731
I1108 23:00:53.056721 135356 caffe.cpp:459] Performing Backward
I1108 23:00:57.662456 135356 caffe.cpp:468] *** Benchmark begins ***
I1108 23:00:57.672951 135356 caffe.cpp:469] Testing for 1 iterations.
I1108 23:00:57.820034 135356 caffe.cpp:482] Profiling Layer: conv1 forward
I1108 23:00:59.835661 135356 caffe.cpp:512] Iteration: 1 forward-backward time: 2010 ms.
I1108 23:00:59.994195 135356 caffe.cpp:519] Average time per layer: 
I1108 23:01:00.011510 135356 caffe.cpp:522]       data	forward: 551.711 ms.
I1108 23:01:00.087616 135356 caffe.cpp:526]       data	backward: 5.754 ms.
I1108 23:01:00.110676 135356 caffe.cpp:522]      conv1	forward: 135.896 ms.
I1108 23:01:00.122156 135356 caffe.cpp:526]      conv1	backward: 43.483 ms.
I1108 23:01:00.126943 135356 caffe.cpp:522]      relu1	forward: 23.48 ms.
I1108 23:01:00.136412 135356 caffe.cpp:526]      relu1	backward: 15.441 ms.
I1108 23:01:00.148821 135356 caffe.cpp:522]      norm1	forward: 22.078 ms.
I1108 23:01:00.160532 135356 caffe.cpp:526]      norm1	backward: 16.302 ms.
I1108 23:01:00.169193 135356 caffe.cpp:522]      pool1	forward: 16.038 ms.
I1108 23:01:00.169939 135356 caffe.cpp:526]      pool1	backward: 79.483 ms.
I1108 23:01:00.170722 135356 caffe.cpp:522]      conv2	forward: 63.962 ms.
I1108 23:01:00.170954 135356 caffe.cpp:526]      conv2	backward: 82.299 ms.
I1108 23:01:00.171161 135356 caffe.cpp:522]      relu2	forward: 13.406 ms.
I1108 23:01:00.171366 135356 caffe.cpp:526]      relu2	backward: 13.518 ms.
I1108 23:01:00.171572 135356 caffe.cpp:522]      norm2	forward: 13.684 ms.
I1108 23:01:00.171777 135356 caffe.cpp:526]      norm2	backward: 14.876 ms.
I1108 23:01:00.171982 135356 caffe.cpp:522]      pool2	forward: 16.675 ms.
I1108 23:01:00.172199 135356 caffe.cpp:526]      pool2	backward: 68.669 ms.
I1108 23:01:00.172463 135356 caffe.cpp:522]      conv3	forward: 26.626 ms.
I1108 23:01:00.172677 135356 caffe.cpp:526]      conv3	backward: 36.413 ms.
I1108 23:01:00.172930 135356 caffe.cpp:522]      relu3	forward: 12.104 ms.
I1108 23:01:00.173135 135356 caffe.cpp:526]      relu3	backward: 0.689 ms.
I1108 23:01:00.173337 135356 caffe.cpp:522]      conv4	forward: 37.378 ms.
I1108 23:01:00.173542 135356 caffe.cpp:526]      conv4	backward: 28.068 ms.
I1108 23:01:00.173745 135356 caffe.cpp:522]      relu4	forward: 12.595 ms.
I1108 23:01:00.173949 135356 caffe.cpp:526]      relu4	backward: 7.371 ms.
I1108 23:01:00.174149 135356 caffe.cpp:522]      conv5	forward: 35.74 ms.
I1108 23:01:00.174353 135356 caffe.cpp:526]      conv5	backward: 19.113 ms.
I1108 23:01:00.174558 135356 caffe.cpp:522]      relu5	forward: 15.656 ms.
I1108 23:01:00.174762 135356 caffe.cpp:526]      relu5	backward: 0.234 ms.
I1108 23:01:00.174963 135356 caffe.cpp:522]      pool5	forward: 17.487 ms.
I1108 23:01:00.175168 135356 caffe.cpp:526]      pool5	backward: 9.169 ms.
I1108 23:01:00.176041 135356 caffe.cpp:522]        fc6	forward: 42.201 ms.
I1108 23:01:00.176290 135356 caffe.cpp:526]        fc6	backward: 38.596 ms.
I1108 23:01:00.176498 135356 caffe.cpp:522]      relu6	forward: 17.687 ms.
I1108 23:01:00.176704 135356 caffe.cpp:526]      relu6	backward: 0.09 ms.
I1108 23:01:00.179340 135356 caffe.cpp:522]      drop6	forward: 45.272 ms.
I1108 23:01:00.179594 135356 caffe.cpp:526]      drop6	backward: 0.09 ms.
I1108 23:01:00.179791 135356 caffe.cpp:522]        fc7	forward: 19.168 ms.
I1108 23:01:00.179988 135356 caffe.cpp:526]        fc7	backward: 21.98 ms.
I1108 23:01:00.180183 135356 caffe.cpp:522]      relu7	forward: 13.778 ms.
I1108 23:01:00.180377 135356 caffe.cpp:526]      relu7	backward: 0.092 ms.
I1108 23:01:00.180567 135356 caffe.cpp:522]      drop7	forward: 23.57 ms.
I1108 23:01:00.180759 135356 caffe.cpp:526]      drop7	backward: 0.1 ms.
I1108 23:01:00.181037 135356 caffe.cpp:522]        fc8	forward: 15.427 ms.
I1108 23:01:00.181249 135356 caffe.cpp:526]        fc8	backward: 82.658 ms.
I1108 23:01:00.181581 135356 caffe.cpp:522]       loss	forward: 76.76 ms.
I1108 23:01:00.181870 135356 caffe.cpp:526]       loss	backward: 65.425 ms.
I1108 23:01:00.187175 135356 caffe.cpp:532] Average Forward pass: 1324.79 ms.
I1108 23:01:00.200422 135356 caffe.cpp:535] Average Backward pass: 658.808 ms.
I1108 23:01:00.211334 135356 caffe.cpp:537] Average Forward-Backward: 2467 ms.
I1108 23:01:00.225991 135356 caffe.cpp:540] Total Time: 2467 ms.
I1108 23:01:00.238237 135356 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 2
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 421660800
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 6746572802
--->Total double-precision FLOPs = 0
--->Total FLOPs = 6746572802
mem-read-1 = 280095
mem-read-2 = 77
mem-read-4 = 212024144
mem-read-8 = 1395878
mem-read-16 = 1
mem-read-32 = 43586
mem-read-64 = 16709030
mem-write-1 = 232436
mem-write-2 = 34
mem-write-4 = 565212
mem-write-8 = 303814
mem-write-16 = 1
mem-write-32 = 653762
mem-write-64 = 1161796
--->Total Bytes read = 1930316537
--->Total Bytes written = 100199208
--->Total Bytes = 2030515745
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer2_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=2 -prof_forward_direction=1
I1108 23:05:39.867167 135522 caffe.cpp:444] Use CPU.
I1108 23:05:56.735513 135522 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:05:56.791435 135522 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:05:56.803177 135522 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:05:56.815735 135522 cpu_info.cpp:461] Total number of processors: 272
I1108 23:05:56.827059 135522 cpu_info.cpp:464] GPU is used: no
I1108 23:05:56.836287 135522 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:05:56.845469 135522 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:05:56.856364 135522 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:06:05.638804 135522 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:06:05.671744 135522 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:06:06.308143 135522 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:06:08.764017 135522 layer_factory.hpp:114] Creating layer data
I1108 23:06:08.911413 135522 net.cpp:160] Creating Layer data
I1108 23:06:08.961443 135522 net.cpp:570] data -> data
I1108 23:06:09.427947 135522 net.cpp:570] data -> label
I1108 23:06:16.434437 135522 net.cpp:210] Setting up data
I1108 23:06:16.513334 135522 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:06:16.617125 135522 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:06:16.624459 135522 net.cpp:225] Memory required for data: 19787264
I1108 23:06:16.693898 135522 layer_factory.hpp:114] Creating layer conv1
I1108 23:06:17.022774 135522 net.cpp:160] Creating Layer conv1
I1108 23:06:17.072585 135522 net.cpp:596] conv1 <- data
I1108 23:06:17.192273 135522 net.cpp:570] conv1 -> conv1
I1108 23:06:49.845185 135522 net.cpp:210] Setting up conv1
I1108 23:06:49.852344 135522 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:06:49.852744 135522 net.cpp:225] Memory required for data: 56958464
I1108 23:06:50.134481 135522 layer_factory.hpp:114] Creating layer relu1
I1108 23:06:50.254590 135522 net.cpp:160] Creating Layer relu1
I1108 23:06:50.259168 135522 net.cpp:596] relu1 <- conv1
I1108 23:06:50.293102 135522 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:06:50.480983 135522 net.cpp:210] Setting up relu1
I1108 23:06:50.483335 135522 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:06:50.483711 135522 net.cpp:225] Memory required for data: 94129664
I1108 23:06:50.483922 135522 layer_factory.hpp:114] Creating layer norm1
I1108 23:06:50.588937 135522 net.cpp:160] Creating Layer norm1
I1108 23:06:50.589247 135522 net.cpp:596] norm1 <- conv1
I1108 23:06:50.591806 135522 net.cpp:570] norm1 -> norm1
I1108 23:06:50.813451 135522 net.cpp:210] Setting up norm1
I1108 23:06:50.826159 135522 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:06:50.826545 135522 net.cpp:225] Memory required for data: 131300864
I1108 23:06:50.826856 135522 layer_factory.hpp:114] Creating layer pool1
I1108 23:06:50.919724 135522 net.cpp:160] Creating Layer pool1
I1108 23:06:50.920040 135522 net.cpp:596] pool1 <- norm1
I1108 23:06:50.934878 135522 net.cpp:570] pool1 -> pool1
I1108 23:06:51.234938 135522 net.cpp:210] Setting up pool1
I1108 23:06:51.237438 135522 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:06:51.237764 135522 net.cpp:225] Memory required for data: 140258816
I1108 23:06:51.238008 135522 layer_factory.hpp:114] Creating layer conv2
I1108 23:06:51.238370 135522 net.cpp:160] Creating Layer conv2
I1108 23:06:51.238623 135522 net.cpp:596] conv2 <- pool1
I1108 23:06:51.238852 135522 net.cpp:570] conv2 -> conv2
I1108 23:06:56.975167 135522 net.cpp:210] Setting up conv2
I1108 23:06:56.975486 135522 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:06:56.975857 135522 net.cpp:225] Memory required for data: 164146688
I1108 23:06:57.025739 135522 layer_factory.hpp:114] Creating layer relu2
I1108 23:06:57.026134 135522 net.cpp:160] Creating Layer relu2
I1108 23:06:57.026468 135522 net.cpp:596] relu2 <- conv2
I1108 23:06:57.026768 135522 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:06:57.027211 135522 net.cpp:210] Setting up relu2
I1108 23:06:57.027482 135522 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:06:57.027722 135522 net.cpp:225] Memory required for data: 188034560
I1108 23:06:57.027911 135522 layer_factory.hpp:114] Creating layer norm2
I1108 23:06:57.028153 135522 net.cpp:160] Creating Layer norm2
I1108 23:06:57.028383 135522 net.cpp:596] norm2 <- conv2
I1108 23:06:57.028630 135522 net.cpp:570] norm2 -> norm2
I1108 23:06:57.030776 135522 net.cpp:210] Setting up norm2
I1108 23:06:57.031100 135522 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:06:57.031373 135522 net.cpp:225] Memory required for data: 211922432
I1108 23:06:57.031641 135522 layer_factory.hpp:114] Creating layer pool2
I1108 23:06:57.032517 135522 net.cpp:160] Creating Layer pool2
I1108 23:06:57.032860 135522 net.cpp:596] pool2 <- norm2
I1108 23:06:57.033129 135522 net.cpp:570] pool2 -> pool2
I1108 23:06:57.033562 135522 net.cpp:210] Setting up pool2
I1108 23:06:57.033850 135522 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:06:57.034196 135522 net.cpp:225] Memory required for data: 217460224
I1108 23:06:57.034468 135522 layer_factory.hpp:114] Creating layer conv3
I1108 23:06:57.034873 135522 net.cpp:160] Creating Layer conv3
I1108 23:06:57.035089 135522 net.cpp:596] conv3 <- pool2
I1108 23:06:57.035329 135522 net.cpp:570] conv3 -> conv3
I1108 23:06:57.540251 135522 net.cpp:210] Setting up conv3
I1108 23:06:57.542675 135522 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:06:57.543061 135522 net.cpp:225] Memory required for data: 225766912
I1108 23:06:57.546226 135522 layer_factory.hpp:114] Creating layer relu3
I1108 23:06:57.546638 135522 net.cpp:160] Creating Layer relu3
I1108 23:06:57.546892 135522 net.cpp:596] relu3 <- conv3
I1108 23:06:57.547130 135522 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:06:57.551455 135522 net.cpp:210] Setting up relu3
I1108 23:06:57.551772 135522 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:06:57.552022 135522 net.cpp:225] Memory required for data: 234073600
I1108 23:06:57.552218 135522 layer_factory.hpp:114] Creating layer conv4
I1108 23:06:57.552577 135522 net.cpp:160] Creating Layer conv4
I1108 23:06:57.552883 135522 net.cpp:596] conv4 <- conv3
I1108 23:06:57.553189 135522 net.cpp:570] conv4 -> conv4
I1108 23:06:57.794162 135522 net.cpp:210] Setting up conv4
I1108 23:06:57.794545 135522 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:06:57.794950 135522 net.cpp:225] Memory required for data: 242380288
I1108 23:06:57.795300 135522 layer_factory.hpp:114] Creating layer relu4
I1108 23:06:57.795593 135522 net.cpp:160] Creating Layer relu4
I1108 23:06:57.795815 135522 net.cpp:596] relu4 <- conv4
I1108 23:06:57.796049 135522 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:06:57.808261 135522 net.cpp:210] Setting up relu4
I1108 23:06:57.808603 135522 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:06:57.809056 135522 net.cpp:225] Memory required for data: 250686976
I1108 23:06:57.809273 135522 layer_factory.hpp:114] Creating layer conv5
I1108 23:06:57.809631 135522 net.cpp:160] Creating Layer conv5
I1108 23:06:57.809875 135522 net.cpp:596] conv5 <- conv4
I1108 23:06:57.810119 135522 net.cpp:570] conv5 -> conv5
I1108 23:06:57.979058 135522 net.cpp:210] Setting up conv5
I1108 23:06:57.979441 135522 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:06:57.979858 135522 net.cpp:225] Memory required for data: 256224768
I1108 23:06:57.984480 135522 layer_factory.hpp:114] Creating layer relu5
I1108 23:06:57.984932 135522 net.cpp:160] Creating Layer relu5
I1108 23:06:57.985205 135522 net.cpp:596] relu5 <- conv5
I1108 23:06:57.985507 135522 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:06:57.986033 135522 net.cpp:210] Setting up relu5
I1108 23:06:57.986315 135522 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:06:57.986557 135522 net.cpp:225] Memory required for data: 261762560
I1108 23:06:57.986768 135522 layer_factory.hpp:114] Creating layer pool5
I1108 23:06:57.987030 135522 net.cpp:160] Creating Layer pool5
I1108 23:06:57.987253 135522 net.cpp:596] pool5 <- conv5
I1108 23:06:57.987515 135522 net.cpp:570] pool5 -> pool5
I1108 23:06:57.987967 135522 net.cpp:210] Setting up pool5
I1108 23:06:57.988224 135522 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:06:57.988445 135522 net.cpp:225] Memory required for data: 262942208
I1108 23:06:57.988629 135522 layer_factory.hpp:114] Creating layer fc6
I1108 23:06:58.042986 135522 net.cpp:160] Creating Layer fc6
I1108 23:06:58.043301 135522 net.cpp:596] fc6 <- pool5
I1108 23:06:58.043673 135522 net.cpp:570] fc6 -> fc6
I1108 23:07:02.133033 135522 net.cpp:210] Setting up fc6
I1108 23:07:02.133333 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:02.135413 135522 net.cpp:225] Memory required for data: 263466496
I1108 23:07:02.135723 135522 layer_factory.hpp:114] Creating layer relu6
I1108 23:07:02.138274 135522 net.cpp:160] Creating Layer relu6
I1108 23:07:02.138571 135522 net.cpp:596] relu6 <- fc6
I1108 23:07:02.138795 135522 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:07:02.139214 135522 net.cpp:210] Setting up relu6
I1108 23:07:02.139472 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:02.139730 135522 net.cpp:225] Memory required for data: 263990784
I1108 23:07:02.139930 135522 layer_factory.hpp:114] Creating layer drop6
I1108 23:07:02.159728 135522 net.cpp:160] Creating Layer drop6
I1108 23:07:02.160034 135522 net.cpp:596] drop6 <- fc6
I1108 23:07:02.160432 135522 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:07:02.262789 135522 net.cpp:210] Setting up drop6
I1108 23:07:02.263083 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:02.263451 135522 net.cpp:225] Memory required for data: 264515072
I1108 23:07:02.263662 135522 layer_factory.hpp:114] Creating layer fc7
I1108 23:07:02.263929 135522 net.cpp:160] Creating Layer fc7
I1108 23:07:02.264137 135522 net.cpp:596] fc7 <- fc6
I1108 23:07:02.264514 135522 net.cpp:570] fc7 -> fc7
I1108 23:07:03.979109 135522 net.cpp:210] Setting up fc7
I1108 23:07:03.979470 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:03.979876 135522 net.cpp:225] Memory required for data: 265039360
I1108 23:07:03.980232 135522 layer_factory.hpp:114] Creating layer relu7
I1108 23:07:03.980556 135522 net.cpp:160] Creating Layer relu7
I1108 23:07:03.980842 135522 net.cpp:596] relu7 <- fc7
I1108 23:07:03.981115 135522 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:07:03.981569 135522 net.cpp:210] Setting up relu7
I1108 23:07:03.981849 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:03.982125 135522 net.cpp:225] Memory required for data: 265563648
I1108 23:07:03.982336 135522 layer_factory.hpp:114] Creating layer drop7
I1108 23:07:03.982584 135522 net.cpp:160] Creating Layer drop7
I1108 23:07:03.982800 135522 net.cpp:596] drop7 <- fc7
I1108 23:07:03.983075 135522 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:07:03.983346 135522 net.cpp:210] Setting up drop7
I1108 23:07:03.983556 135522 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:07:03.983772 135522 net.cpp:225] Memory required for data: 266087936
I1108 23:07:03.983953 135522 layer_factory.hpp:114] Creating layer fc8
I1108 23:07:03.984200 135522 net.cpp:160] Creating Layer fc8
I1108 23:07:03.984398 135522 net.cpp:596] fc8 <- fc7
I1108 23:07:03.984622 135522 net.cpp:570] fc8 -> fc8
I1108 23:07:04.408182 135522 net.cpp:210] Setting up fc8
I1108 23:07:04.408500 135522 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:07:04.408840 135522 net.cpp:225] Memory required for data: 266215936
I1108 23:07:04.409168 135522 layer_factory.hpp:114] Creating layer loss
I1108 23:07:04.432198 135522 net.cpp:160] Creating Layer loss
I1108 23:07:04.432502 135522 net.cpp:596] loss <- fc8
I1108 23:07:04.433395 135522 net.cpp:596] loss <- label
I1108 23:07:04.459942 135522 net.cpp:570] loss -> loss
I1108 23:07:04.496865 135522 layer_factory.hpp:114] Creating layer loss
I1108 23:07:07.064486 135522 net.cpp:210] Setting up loss
I1108 23:07:07.111347 135522 net.cpp:217] Top shape: (1)
I1108 23:07:07.125915 135522 net.cpp:220]     with loss weight 1
I1108 23:07:07.255924 135522 net.cpp:225] Memory required for data: 266215940
I1108 23:07:07.299072 135522 net.cpp:287] loss needs backward computation.
I1108 23:07:07.396558 135522 net.cpp:287] fc8 needs backward computation.
I1108 23:07:07.405396 135522 net.cpp:287] drop7 needs backward computation.
I1108 23:07:07.419764 135522 net.cpp:287] relu7 needs backward computation.
I1108 23:07:07.420107 135522 net.cpp:287] fc7 needs backward computation.
I1108 23:07:07.422555 135522 net.cpp:287] drop6 needs backward computation.
I1108 23:07:07.422938 135522 net.cpp:287] relu6 needs backward computation.
I1108 23:07:07.423183 135522 net.cpp:287] fc6 needs backward computation.
I1108 23:07:07.424005 135522 net.cpp:287] pool5 needs backward computation.
I1108 23:07:07.424700 135522 net.cpp:287] relu5 needs backward computation.
I1108 23:07:07.424988 135522 net.cpp:287] conv5 needs backward computation.
I1108 23:07:07.425174 135522 net.cpp:287] relu4 needs backward computation.
I1108 23:07:07.425349 135522 net.cpp:287] conv4 needs backward computation.
I1108 23:07:07.425528 135522 net.cpp:287] relu3 needs backward computation.
I1108 23:07:07.425701 135522 net.cpp:287] conv3 needs backward computation.
I1108 23:07:07.437553 135522 net.cpp:287] pool2 needs backward computation.
I1108 23:07:07.437882 135522 net.cpp:287] norm2 needs backward computation.
I1108 23:07:07.438199 135522 net.cpp:287] relu2 needs backward computation.
I1108 23:07:07.438393 135522 net.cpp:287] conv2 needs backward computation.
I1108 23:07:07.438576 135522 net.cpp:287] pool1 needs backward computation.
I1108 23:07:07.438755 135522 net.cpp:287] norm1 needs backward computation.
I1108 23:07:07.438935 135522 net.cpp:287] relu1 needs backward computation.
I1108 23:07:07.439110 135522 net.cpp:287] conv1 needs backward computation.
I1108 23:07:07.451320 135522 net.cpp:289] data does not need backward computation.
I1108 23:07:07.475286 135522 net.cpp:331] This network produces output loss
I1108 23:07:07.547360 135522 net.cpp:345] Network initialization done.
I1108 23:07:07.720194 135522 caffe.cpp:452] Performing Forward
I1108 23:07:20.784579 135522 caffe.cpp:457] Initial loss: 6.8613
I1108 23:07:20.833079 135522 caffe.cpp:459] Performing Backward
I1108 23:07:25.366766 135522 caffe.cpp:468] *** Benchmark begins ***
I1108 23:07:25.378386 135522 caffe.cpp:469] Testing for 1 iterations.
I1108 23:07:25.521652 135522 caffe.cpp:482] Profiling Layer: relu1 forward
I1108 23:07:27.763295 135522 caffe.cpp:512] Iteration: 1 forward-backward time: 2234 ms.
I1108 23:07:27.918624 135522 caffe.cpp:519] Average time per layer: 
I1108 23:07:27.937599 135522 caffe.cpp:522]       data	forward: 556.379 ms.
I1108 23:07:28.008419 135522 caffe.cpp:526]       data	backward: 5.445 ms.
I1108 23:07:28.032771 135522 caffe.cpp:522]      conv1	forward: 129.371 ms.
I1108 23:07:28.040575 135522 caffe.cpp:526]      conv1	backward: 53.601 ms.
I1108 23:07:28.045320 135522 caffe.cpp:522]      relu1	forward: 26.692 ms.
I1108 23:07:28.051354 135522 caffe.cpp:526]      relu1	backward: 12.868 ms.
I1108 23:07:28.057231 135522 caffe.cpp:522]      norm1	forward: 18.153 ms.
I1108 23:07:28.065574 135522 caffe.cpp:526]      norm1	backward: 12.095 ms.
I1108 23:07:28.077177 135522 caffe.cpp:522]      pool1	forward: 20.981 ms.
I1108 23:07:28.083217 135522 caffe.cpp:526]      pool1	backward: 79.576 ms.
I1108 23:07:28.092499 135522 caffe.cpp:522]      conv2	forward: 68.065 ms.
I1108 23:07:28.100260 135522 caffe.cpp:526]      conv2	backward: 79.927 ms.
I1108 23:07:28.107872 135522 caffe.cpp:522]      relu2	forward: 17.408 ms.
I1108 23:07:28.112828 135522 caffe.cpp:526]      relu2	backward: 20.374 ms.
I1108 23:07:28.113456 135522 caffe.cpp:522]      norm2	forward: 20.408 ms.
I1108 23:07:28.113657 135522 caffe.cpp:526]      norm2	backward: 15.825 ms.
I1108 23:07:28.113852 135522 caffe.cpp:522]      pool2	forward: 17.644 ms.
I1108 23:07:28.114043 135522 caffe.cpp:526]      pool2	backward: 73.127 ms.
I1108 23:07:28.114234 135522 caffe.cpp:522]      conv3	forward: 28.995 ms.
I1108 23:07:28.114425 135522 caffe.cpp:526]      conv3	backward: 72.033 ms.
I1108 23:07:28.114615 135522 caffe.cpp:522]      relu3	forward: 11.654 ms.
I1108 23:07:28.114806 135522 caffe.cpp:526]      relu3	backward: 27.453 ms.
I1108 23:07:28.115036 135522 caffe.cpp:522]      conv4	forward: 33.637 ms.
I1108 23:07:28.115245 135522 caffe.cpp:526]      conv4	backward: 69.294 ms.
I1108 23:07:28.115505 135522 caffe.cpp:522]      relu4	forward: 17.376 ms.
I1108 23:07:28.115702 135522 caffe.cpp:526]      relu4	backward: 42.949 ms.
I1108 23:07:28.115898 135522 caffe.cpp:522]      conv5	forward: 30.384 ms.
I1108 23:07:28.116091 135522 caffe.cpp:526]      conv5	backward: 71.753 ms.
I1108 23:07:28.116281 135522 caffe.cpp:522]      relu5	forward: 11.395 ms.
I1108 23:07:28.116471 135522 caffe.cpp:526]      relu5	backward: 22.66 ms.
I1108 23:07:28.116660 135522 caffe.cpp:522]      pool5	forward: 7.865 ms.
I1108 23:07:28.116916 135522 caffe.cpp:526]      pool5	backward: 59.312 ms.
I1108 23:07:28.117168 135522 caffe.cpp:522]        fc6	forward: 41.234 ms.
I1108 23:07:28.117372 135522 caffe.cpp:526]        fc6	backward: 61.895 ms.
I1108 23:07:28.117594 135522 caffe.cpp:522]      relu6	forward: 23.873 ms.
I1108 23:07:28.117882 135522 caffe.cpp:526]      relu6	backward: 0.083 ms.
I1108 23:07:28.120533 135522 caffe.cpp:522]      drop6	forward: 34.741 ms.
I1108 23:07:28.120841 135522 caffe.cpp:526]      drop6	backward: 0.088 ms.
I1108 23:07:28.121086 135522 caffe.cpp:522]        fc7	forward: 16.545 ms.
I1108 23:07:28.121281 135522 caffe.cpp:526]        fc7	backward: 25.087 ms.
I1108 23:07:28.121475 135522 caffe.cpp:522]      relu7	forward: 18.541 ms.
I1108 23:07:28.121668 135522 caffe.cpp:526]      relu7	backward: 0.09 ms.
I1108 23:07:28.121857 135522 caffe.cpp:522]      drop7	forward: 23.96 ms.
I1108 23:07:28.122048 135522 caffe.cpp:526]      drop7	backward: 0.118 ms.
I1108 23:07:28.123075 135522 caffe.cpp:522]        fc8	forward: 7.629 ms.
I1108 23:07:28.123337 135522 caffe.cpp:526]        fc8	backward: 76.841 ms.
I1108 23:07:28.123543 135522 caffe.cpp:522]       loss	forward: 28.444 ms.
I1108 23:07:28.123739 135522 caffe.cpp:526]       loss	backward: 48.451 ms.
I1108 23:07:28.129343 135522 caffe.cpp:532] Average Forward pass: 1266.57 ms.
I1108 23:07:28.144244 135522 caffe.cpp:535] Average Backward pass: 940.535 ms.
I1108 23:07:28.155166 135522 caffe.cpp:537] Average Forward-Backward: 2707 ms.
I1108 23:07:28.169831 135522 caffe.cpp:540] Total Time: 2707 ms.
I1108 23:07:28.181995 135522 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 580800
elements_fp_double_1 = 0
elements_fp_double_2 = 580800
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 9292801
--->Total double-precision FLOPs = 1161600
--->Total FLOPs = 10454401
mem-read-1 = 20812
mem-read-2 = 34
mem-read-4 = 167315
mem-read-8 = 232946
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 1161617
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 564
mem-write-8 = 22892
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 580801
--->Total Bytes read = 76897228
--->Total Bytes written = 37356772
--->Total Bytes = 114254000
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer3_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=3 -prof_forward_direction=1
I1108 23:10:52.211520 135640 caffe.cpp:444] Use CPU.
I1108 23:11:09.058244 135640 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:11:09.114225 135640 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:11:09.126076 135640 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:11:09.138591 135640 cpu_info.cpp:461] Total number of processors: 272
I1108 23:11:09.149857 135640 cpu_info.cpp:464] GPU is used: no
I1108 23:11:09.159023 135640 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:11:09.167888 135640 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:11:09.179183 135640 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:11:17.920369 135640 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:11:17.953588 135640 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:11:18.593402 135640 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:11:21.041486 135640 layer_factory.hpp:114] Creating layer data
I1108 23:11:21.187856 135640 net.cpp:160] Creating Layer data
I1108 23:11:21.235859 135640 net.cpp:570] data -> data
I1108 23:11:21.701627 135640 net.cpp:570] data -> label
I1108 23:11:28.713487 135640 net.cpp:210] Setting up data
I1108 23:11:28.793429 135640 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:11:28.902573 135640 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:11:28.909684 135640 net.cpp:225] Memory required for data: 19787264
I1108 23:11:28.978492 135640 layer_factory.hpp:114] Creating layer conv1
I1108 23:11:29.308212 135640 net.cpp:160] Creating Layer conv1
I1108 23:11:29.358000 135640 net.cpp:596] conv1 <- data
I1108 23:11:29.477545 135640 net.cpp:570] conv1 -> conv1
I1108 23:12:02.261039 135640 net.cpp:210] Setting up conv1
I1108 23:12:02.268102 135640 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:12:02.268499 135640 net.cpp:225] Memory required for data: 56958464
I1108 23:12:02.551621 135640 layer_factory.hpp:114] Creating layer relu1
I1108 23:12:02.672547 135640 net.cpp:160] Creating Layer relu1
I1108 23:12:02.677140 135640 net.cpp:596] relu1 <- conv1
I1108 23:12:02.709656 135640 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:12:02.899343 135640 net.cpp:210] Setting up relu1
I1108 23:12:02.901796 135640 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:12:02.902171 135640 net.cpp:225] Memory required for data: 94129664
I1108 23:12:02.902385 135640 layer_factory.hpp:114] Creating layer norm1
I1108 23:12:03.010536 135640 net.cpp:160] Creating Layer norm1
I1108 23:12:03.010884 135640 net.cpp:596] norm1 <- conv1
I1108 23:12:03.013711 135640 net.cpp:570] norm1 -> norm1
I1108 23:12:03.240726 135640 net.cpp:210] Setting up norm1
I1108 23:12:03.253584 135640 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:12:03.253967 135640 net.cpp:225] Memory required for data: 131300864
I1108 23:12:03.254271 135640 layer_factory.hpp:114] Creating layer pool1
I1108 23:12:03.347779 135640 net.cpp:160] Creating Layer pool1
I1108 23:12:03.348090 135640 net.cpp:596] pool1 <- norm1
I1108 23:12:03.363029 135640 net.cpp:570] pool1 -> pool1
I1108 23:12:03.668086 135640 net.cpp:210] Setting up pool1
I1108 23:12:03.670601 135640 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:12:03.670969 135640 net.cpp:225] Memory required for data: 140258816
I1108 23:12:03.671195 135640 layer_factory.hpp:114] Creating layer conv2
I1108 23:12:03.671561 135640 net.cpp:160] Creating Layer conv2
I1108 23:12:03.671797 135640 net.cpp:596] conv2 <- pool1
I1108 23:12:03.672044 135640 net.cpp:570] conv2 -> conv2
I1108 23:12:09.467525 135640 net.cpp:210] Setting up conv2
I1108 23:12:09.467872 135640 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:12:09.468272 135640 net.cpp:225] Memory required for data: 164146688
I1108 23:12:09.519587 135640 layer_factory.hpp:114] Creating layer relu2
I1108 23:12:09.520005 135640 net.cpp:160] Creating Layer relu2
I1108 23:12:09.520351 135640 net.cpp:596] relu2 <- conv2
I1108 23:12:09.520642 135640 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:12:09.521160 135640 net.cpp:210] Setting up relu2
I1108 23:12:09.521436 135640 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:12:09.521673 135640 net.cpp:225] Memory required for data: 188034560
I1108 23:12:09.521865 135640 layer_factory.hpp:114] Creating layer norm2
I1108 23:12:09.522116 135640 net.cpp:160] Creating Layer norm2
I1108 23:12:09.522354 135640 net.cpp:596] norm2 <- conv2
I1108 23:12:09.522603 135640 net.cpp:570] norm2 -> norm2
I1108 23:12:09.524682 135640 net.cpp:210] Setting up norm2
I1108 23:12:09.525073 135640 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:12:09.525329 135640 net.cpp:225] Memory required for data: 211922432
I1108 23:12:09.525641 135640 layer_factory.hpp:114] Creating layer pool2
I1108 23:12:09.526609 135640 net.cpp:160] Creating Layer pool2
I1108 23:12:09.526897 135640 net.cpp:596] pool2 <- norm2
I1108 23:12:09.527137 135640 net.cpp:570] pool2 -> pool2
I1108 23:12:09.527537 135640 net.cpp:210] Setting up pool2
I1108 23:12:09.527823 135640 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:12:09.528156 135640 net.cpp:225] Memory required for data: 217460224
I1108 23:12:09.528417 135640 layer_factory.hpp:114] Creating layer conv3
I1108 23:12:09.528831 135640 net.cpp:160] Creating Layer conv3
I1108 23:12:09.529072 135640 net.cpp:596] conv3 <- pool2
I1108 23:12:09.529319 135640 net.cpp:570] conv3 -> conv3
I1108 23:12:09.980413 135640 net.cpp:210] Setting up conv3
I1108 23:12:09.982887 135640 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:12:09.983258 135640 net.cpp:225] Memory required for data: 225766912
I1108 23:12:09.986348 135640 layer_factory.hpp:114] Creating layer relu3
I1108 23:12:09.986758 135640 net.cpp:160] Creating Layer relu3
I1108 23:12:09.987054 135640 net.cpp:596] relu3 <- conv3
I1108 23:12:09.987293 135640 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:12:09.991322 135640 net.cpp:210] Setting up relu3
I1108 23:12:09.991664 135640 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:12:09.991925 135640 net.cpp:225] Memory required for data: 234073600
I1108 23:12:09.992139 135640 layer_factory.hpp:114] Creating layer conv4
I1108 23:12:09.992548 135640 net.cpp:160] Creating Layer conv4
I1108 23:12:09.992841 135640 net.cpp:596] conv4 <- conv3
I1108 23:12:09.993144 135640 net.cpp:570] conv4 -> conv4
I1108 23:12:10.235625 135640 net.cpp:210] Setting up conv4
I1108 23:12:10.236011 135640 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:12:10.236403 135640 net.cpp:225] Memory required for data: 242380288
I1108 23:12:10.236752 135640 layer_factory.hpp:114] Creating layer relu4
I1108 23:12:10.237110 135640 net.cpp:160] Creating Layer relu4
I1108 23:12:10.237345 135640 net.cpp:596] relu4 <- conv4
I1108 23:12:10.237582 135640 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:12:10.249814 135640 net.cpp:210] Setting up relu4
I1108 23:12:10.250156 135640 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:12:10.250532 135640 net.cpp:225] Memory required for data: 250686976
I1108 23:12:10.250820 135640 layer_factory.hpp:114] Creating layer conv5
I1108 23:12:10.251227 135640 net.cpp:160] Creating Layer conv5
I1108 23:12:10.251472 135640 net.cpp:596] conv5 <- conv4
I1108 23:12:10.251723 135640 net.cpp:570] conv5 -> conv5
I1108 23:12:10.420184 135640 net.cpp:210] Setting up conv5
I1108 23:12:10.420572 135640 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:12:10.421056 135640 net.cpp:225] Memory required for data: 256224768
I1108 23:12:10.425683 135640 layer_factory.hpp:114] Creating layer relu5
I1108 23:12:10.426111 135640 net.cpp:160] Creating Layer relu5
I1108 23:12:10.426363 135640 net.cpp:596] relu5 <- conv5
I1108 23:12:10.426626 135640 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:12:10.427078 135640 net.cpp:210] Setting up relu5
I1108 23:12:10.427366 135640 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:12:10.427664 135640 net.cpp:225] Memory required for data: 261762560
I1108 23:12:10.427891 135640 layer_factory.hpp:114] Creating layer pool5
I1108 23:12:10.428189 135640 net.cpp:160] Creating Layer pool5
I1108 23:12:10.428405 135640 net.cpp:596] pool5 <- conv5
I1108 23:12:10.428635 135640 net.cpp:570] pool5 -> pool5
I1108 23:12:10.429082 135640 net.cpp:210] Setting up pool5
I1108 23:12:10.429361 135640 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:12:10.429590 135640 net.cpp:225] Memory required for data: 262942208
I1108 23:12:10.429780 135640 layer_factory.hpp:114] Creating layer fc6
I1108 23:12:10.483804 135640 net.cpp:160] Creating Layer fc6
I1108 23:12:10.484118 135640 net.cpp:596] fc6 <- pool5
I1108 23:12:10.484508 135640 net.cpp:570] fc6 -> fc6
I1108 23:12:14.575217 135640 net.cpp:210] Setting up fc6
I1108 23:12:14.575525 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:14.577673 135640 net.cpp:225] Memory required for data: 263466496
I1108 23:12:14.577986 135640 layer_factory.hpp:114] Creating layer relu6
I1108 23:12:14.580543 135640 net.cpp:160] Creating Layer relu6
I1108 23:12:14.580883 135640 net.cpp:596] relu6 <- fc6
I1108 23:12:14.581125 135640 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:12:14.581548 135640 net.cpp:210] Setting up relu6
I1108 23:12:14.581800 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:14.582032 135640 net.cpp:225] Memory required for data: 263990784
I1108 23:12:14.582263 135640 layer_factory.hpp:114] Creating layer drop6
I1108 23:12:14.602636 135640 net.cpp:160] Creating Layer drop6
I1108 23:12:14.602960 135640 net.cpp:596] drop6 <- fc6
I1108 23:12:14.603312 135640 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:12:14.708310 135640 net.cpp:210] Setting up drop6
I1108 23:12:14.708611 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:14.709004 135640 net.cpp:225] Memory required for data: 264515072
I1108 23:12:14.709252 135640 layer_factory.hpp:114] Creating layer fc7
I1108 23:12:14.709529 135640 net.cpp:160] Creating Layer fc7
I1108 23:12:14.709743 135640 net.cpp:596] fc7 <- fc6
I1108 23:12:14.710134 135640 net.cpp:570] fc7 -> fc7
I1108 23:12:16.421957 135640 net.cpp:210] Setting up fc7
I1108 23:12:16.422327 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:16.422747 135640 net.cpp:225] Memory required for data: 265039360
I1108 23:12:16.423102 135640 layer_factory.hpp:114] Creating layer relu7
I1108 23:12:16.423434 135640 net.cpp:160] Creating Layer relu7
I1108 23:12:16.423683 135640 net.cpp:596] relu7 <- fc7
I1108 23:12:16.423941 135640 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:12:16.424392 135640 net.cpp:210] Setting up relu7
I1108 23:12:16.424713 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:16.425034 135640 net.cpp:225] Memory required for data: 265563648
I1108 23:12:16.425256 135640 layer_factory.hpp:114] Creating layer drop7
I1108 23:12:16.425536 135640 net.cpp:160] Creating Layer drop7
I1108 23:12:16.425751 135640 net.cpp:596] drop7 <- fc7
I1108 23:12:16.425997 135640 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:12:16.426273 135640 net.cpp:210] Setting up drop7
I1108 23:12:16.426479 135640 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:12:16.426700 135640 net.cpp:225] Memory required for data: 266087936
I1108 23:12:16.426888 135640 layer_factory.hpp:114] Creating layer fc8
I1108 23:12:16.427145 135640 net.cpp:160] Creating Layer fc8
I1108 23:12:16.427348 135640 net.cpp:596] fc8 <- fc7
I1108 23:12:16.427608 135640 net.cpp:570] fc8 -> fc8
I1108 23:12:16.855275 135640 net.cpp:210] Setting up fc8
I1108 23:12:16.855634 135640 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:12:16.856026 135640 net.cpp:225] Memory required for data: 266215936
I1108 23:12:16.856367 135640 layer_factory.hpp:114] Creating layer loss
I1108 23:12:16.881271 135640 net.cpp:160] Creating Layer loss
I1108 23:12:16.881585 135640 net.cpp:596] loss <- fc8
I1108 23:12:16.882588 135640 net.cpp:596] loss <- label
I1108 23:12:16.910157 135640 net.cpp:570] loss -> loss
I1108 23:12:16.948308 135640 layer_factory.hpp:114] Creating layer loss
I1108 23:12:19.526451 135640 net.cpp:210] Setting up loss
I1108 23:12:19.574848 135640 net.cpp:217] Top shape: (1)
I1108 23:12:19.590425 135640 net.cpp:220]     with loss weight 1
I1108 23:12:19.719806 135640 net.cpp:225] Memory required for data: 266215940
I1108 23:12:19.759408 135640 net.cpp:287] loss needs backward computation.
I1108 23:12:19.846333 135640 net.cpp:287] fc8 needs backward computation.
I1108 23:12:19.853549 135640 net.cpp:287] drop7 needs backward computation.
I1108 23:12:19.864495 135640 net.cpp:287] relu7 needs backward computation.
I1108 23:12:19.864873 135640 net.cpp:287] fc7 needs backward computation.
I1108 23:12:19.867319 135640 net.cpp:287] drop6 needs backward computation.
I1108 23:12:19.867677 135640 net.cpp:287] relu6 needs backward computation.
I1108 23:12:19.867918 135640 net.cpp:287] fc6 needs backward computation.
I1108 23:12:19.868625 135640 net.cpp:287] pool5 needs backward computation.
I1108 23:12:19.869451 135640 net.cpp:287] relu5 needs backward computation.
I1108 23:12:19.869750 135640 net.cpp:287] conv5 needs backward computation.
I1108 23:12:19.869962 135640 net.cpp:287] relu4 needs backward computation.
I1108 23:12:19.870259 135640 net.cpp:287] conv4 needs backward computation.
I1108 23:12:19.870517 135640 net.cpp:287] relu3 needs backward computation.
I1108 23:12:19.870709 135640 net.cpp:287] conv3 needs backward computation.
I1108 23:12:19.883198 135640 net.cpp:287] pool2 needs backward computation.
I1108 23:12:19.883544 135640 net.cpp:287] norm2 needs backward computation.
I1108 23:12:19.883857 135640 net.cpp:287] relu2 needs backward computation.
I1108 23:12:19.884097 135640 net.cpp:287] conv2 needs backward computation.
I1108 23:12:19.884294 135640 net.cpp:287] pool1 needs backward computation.
I1108 23:12:19.884483 135640 net.cpp:287] norm1 needs backward computation.
I1108 23:12:19.884670 135640 net.cpp:287] relu1 needs backward computation.
I1108 23:12:19.884934 135640 net.cpp:287] conv1 needs backward computation.
I1108 23:12:19.897768 135640 net.cpp:289] data does not need backward computation.
I1108 23:12:19.922997 135640 net.cpp:331] This network produces output loss
I1108 23:12:19.996927 135640 net.cpp:345] Network initialization done.
I1108 23:12:20.167562 135640 caffe.cpp:452] Performing Forward
I1108 23:12:33.302853 135640 caffe.cpp:457] Initial loss: 6.90697
I1108 23:12:33.350416 135640 caffe.cpp:459] Performing Backward
I1108 23:12:38.056427 135640 caffe.cpp:468] *** Benchmark begins ***
I1108 23:12:38.069232 135640 caffe.cpp:469] Testing for 1 iterations.
I1108 23:12:38.213214 135640 caffe.cpp:482] Profiling Layer: norm1 forward
I1108 23:12:40.308408 135640 caffe.cpp:512] Iteration: 1 forward-backward time: 2091 ms.
I1108 23:12:40.472007 135640 caffe.cpp:519] Average time per layer: 
I1108 23:12:40.493077 135640 caffe.cpp:522]       data	forward: 554.435 ms.
I1108 23:12:40.564090 135640 caffe.cpp:526]       data	backward: 5.198 ms.
I1108 23:12:40.589948 135640 caffe.cpp:522]      conv1	forward: 129.102 ms.
I1108 23:12:40.598750 135640 caffe.cpp:526]      conv1	backward: 28.509 ms.
I1108 23:12:40.602814 135640 caffe.cpp:522]      relu1	forward: 13.673 ms.
I1108 23:12:40.606547 135640 caffe.cpp:526]      relu1	backward: 1.024 ms.
I1108 23:12:40.615955 135640 caffe.cpp:522]      norm1	forward: 27.365 ms.
I1108 23:12:40.626497 135640 caffe.cpp:526]      norm1	backward: 3.08 ms.
I1108 23:12:40.632755 135640 caffe.cpp:522]      pool1	forward: 21.553 ms.
I1108 23:12:40.640235 135640 caffe.cpp:526]      pool1	backward: 36.028 ms.
I1108 23:12:40.644708 135640 caffe.cpp:522]      conv2	forward: 61.358 ms.
I1108 23:12:40.651947 135640 caffe.cpp:526]      conv2	backward: 31.589 ms.
I1108 23:12:40.654081 135640 caffe.cpp:522]      relu2	forward: 17.525 ms.
I1108 23:12:40.661603 135640 caffe.cpp:526]      relu2	backward: 0.751 ms.
I1108 23:12:40.663978 135640 caffe.cpp:522]      norm2	forward: 11.167 ms.
I1108 23:12:40.673730 135640 caffe.cpp:526]      norm2	backward: 2.069 ms.
I1108 23:12:40.685619 135640 caffe.cpp:522]      pool2	forward: 16.524 ms.
I1108 23:12:40.690469 135640 caffe.cpp:526]      pool2	backward: 22.276 ms.
I1108 23:12:40.690758 135640 caffe.cpp:522]      conv3	forward: 35.845 ms.
I1108 23:12:40.691009 135640 caffe.cpp:526]      conv3	backward: 36.64 ms.
I1108 23:12:40.691236 135640 caffe.cpp:522]      relu3	forward: 10.156 ms.
I1108 23:12:40.693822 135640 caffe.cpp:526]      relu3	backward: 0.651 ms.
I1108 23:12:40.694128 135640 caffe.cpp:522]      conv4	forward: 27.38 ms.
I1108 23:12:40.694335 135640 caffe.cpp:526]      conv4	backward: 30.75 ms.
I1108 23:12:40.694532 135640 caffe.cpp:522]      relu4	forward: 13.514 ms.
I1108 23:12:40.694728 135640 caffe.cpp:526]      relu4	backward: 6.895 ms.
I1108 23:12:40.694918 135640 caffe.cpp:522]      conv5	forward: 27.452 ms.
I1108 23:12:40.695111 135640 caffe.cpp:526]      conv5	backward: 33.168 ms.
I1108 23:12:40.695304 135640 caffe.cpp:522]      relu5	forward: 14.455 ms.
I1108 23:12:40.695497 135640 caffe.cpp:526]      relu5	backward: 17.55 ms.
I1108 23:12:40.695688 135640 caffe.cpp:522]      pool5	forward: 15.57 ms.
I1108 23:12:40.695914 135640 caffe.cpp:526]      pool5	backward: 59.357 ms.
I1108 23:12:40.696120 135640 caffe.cpp:522]        fc6	forward: 49.689 ms.
I1108 23:12:40.696426 135640 caffe.cpp:526]        fc6	backward: 114.073 ms.
I1108 23:12:40.696669 135640 caffe.cpp:522]      relu6	forward: 13.678 ms.
I1108 23:12:40.696902 135640 caffe.cpp:526]      relu6	backward: 15.452 ms.
I1108 23:12:40.697098 135640 caffe.cpp:522]      drop6	forward: 19.719 ms.
I1108 23:12:40.697290 135640 caffe.cpp:526]      drop6	backward: 14.555 ms.
I1108 23:12:40.697484 135640 caffe.cpp:522]        fc7	forward: 15.617 ms.
I1108 23:12:40.697676 135640 caffe.cpp:526]        fc7	backward: 95.439 ms.
I1108 23:12:40.698467 135640 caffe.cpp:522]      relu7	forward: 17.997 ms.
I1108 23:12:40.698714 135640 caffe.cpp:526]      relu7	backward: 21.753 ms.
I1108 23:12:40.699025 135640 caffe.cpp:522]      drop7	forward: 28.968 ms.
I1108 23:12:40.699306 135640 caffe.cpp:526]      drop7	backward: 12.426 ms.
I1108 23:12:40.699533 135640 caffe.cpp:522]        fc8	forward: 13.993 ms.
I1108 23:12:40.699728 135640 caffe.cpp:526]        fc8	backward: 127.695 ms.
I1108 23:12:40.699923 135640 caffe.cpp:522]       loss	forward: 57.69 ms.
I1108 23:12:40.700115 135640 caffe.cpp:526]       loss	backward: 67.415 ms.
I1108 23:12:40.705777 135640 caffe.cpp:532] Average Forward pass: 1269.3 ms.
I1108 23:12:40.718696 135640 caffe.cpp:535] Average Backward pass: 793.198 ms.
I1108 23:12:40.729429 135640 caffe.cpp:537] Average Forward-Backward: 2592 ms.
I1108 23:12:40.746438 135640 caffe.cpp:540] Total Time: 2592 ms.
I1108 23:12:40.759341 135640 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 18004800
elements_fp_double_1 = 0
elements_fp_double_2 = 580800
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 288076801
--->Total double-precision FLOPs = 1161600
--->Total FLOPs = 289238401
mem-read-1 = 19532
mem-read-2 = 34
mem-read-4 = 7207940
mem-read-8 = 977542
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 2710404
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 50164
mem-write-8 = 32441
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 3581602
--->Total Bytes read = 210137584
--->Total Bytes written = 229682828
--->Total Bytes = 439820412
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer4_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=4 -prof_forward_direction=1
I1108 23:16:30.863229 135804 caffe.cpp:444] Use CPU.
I1108 23:16:47.724738 135804 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:16:47.780748 135804 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:16:47.792614 135804 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:16:47.805135 135804 cpu_info.cpp:461] Total number of processors: 272
I1108 23:16:47.816260 135804 cpu_info.cpp:464] GPU is used: no
I1108 23:16:47.825335 135804 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:16:47.834200 135804 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:16:47.845253 135804 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:16:56.563204 135804 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:16:56.595883 135804 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:16:57.231508 135804 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:16:59.685550 135804 layer_factory.hpp:114] Creating layer data
I1108 23:16:59.832526 135804 net.cpp:160] Creating Layer data
I1108 23:16:59.880563 135804 net.cpp:570] data -> data
I1108 23:17:00.342928 135804 net.cpp:570] data -> label
I1108 23:17:07.356407 135804 net.cpp:210] Setting up data
I1108 23:17:07.438402 135804 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:17:07.544626 135804 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:17:07.552248 135804 net.cpp:225] Memory required for data: 19787264
I1108 23:17:07.620393 135804 layer_factory.hpp:114] Creating layer conv1
I1108 23:17:07.951908 135804 net.cpp:160] Creating Layer conv1
I1108 23:17:08.002264 135804 net.cpp:596] conv1 <- data
I1108 23:17:08.124629 135804 net.cpp:570] conv1 -> conv1
I1108 23:17:40.872661 135804 net.cpp:210] Setting up conv1
I1108 23:17:40.880898 135804 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:17:40.881320 135804 net.cpp:225] Memory required for data: 56958464
I1108 23:17:41.165777 135804 layer_factory.hpp:114] Creating layer relu1
I1108 23:17:41.286469 135804 net.cpp:160] Creating Layer relu1
I1108 23:17:41.291098 135804 net.cpp:596] relu1 <- conv1
I1108 23:17:41.324692 135804 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:17:41.515121 135804 net.cpp:210] Setting up relu1
I1108 23:17:41.517559 135804 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:17:41.517895 135804 net.cpp:225] Memory required for data: 94129664
I1108 23:17:41.518132 135804 layer_factory.hpp:114] Creating layer norm1
I1108 23:17:41.622556 135804 net.cpp:160] Creating Layer norm1
I1108 23:17:41.622870 135804 net.cpp:596] norm1 <- conv1
I1108 23:17:41.625449 135804 net.cpp:570] norm1 -> norm1
I1108 23:17:41.850154 135804 net.cpp:210] Setting up norm1
I1108 23:17:41.862983 135804 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:17:41.863384 135804 net.cpp:225] Memory required for data: 131300864
I1108 23:17:41.863798 135804 layer_factory.hpp:114] Creating layer pool1
I1108 23:17:41.958770 135804 net.cpp:160] Creating Layer pool1
I1108 23:17:41.959097 135804 net.cpp:596] pool1 <- norm1
I1108 23:17:41.975633 135804 net.cpp:570] pool1 -> pool1
I1108 23:17:42.281015 135804 net.cpp:210] Setting up pool1
I1108 23:17:42.283571 135804 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:17:42.283932 135804 net.cpp:225] Memory required for data: 140258816
I1108 23:17:42.284159 135804 layer_factory.hpp:114] Creating layer conv2
I1108 23:17:42.284548 135804 net.cpp:160] Creating Layer conv2
I1108 23:17:42.284755 135804 net.cpp:596] conv2 <- pool1
I1108 23:17:42.285040 135804 net.cpp:570] conv2 -> conv2
I1108 23:17:48.079574 135804 net.cpp:210] Setting up conv2
I1108 23:17:48.079921 135804 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:17:48.080324 135804 net.cpp:225] Memory required for data: 164146688
I1108 23:17:48.131161 135804 layer_factory.hpp:114] Creating layer relu2
I1108 23:17:48.131585 135804 net.cpp:160] Creating Layer relu2
I1108 23:17:48.131916 135804 net.cpp:596] relu2 <- conv2
I1108 23:17:48.132194 135804 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:17:48.132664 135804 net.cpp:210] Setting up relu2
I1108 23:17:48.132982 135804 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:17:48.133216 135804 net.cpp:225] Memory required for data: 188034560
I1108 23:17:48.133407 135804 layer_factory.hpp:114] Creating layer norm2
I1108 23:17:48.133651 135804 net.cpp:160] Creating Layer norm2
I1108 23:17:48.133843 135804 net.cpp:596] norm2 <- conv2
I1108 23:17:48.134109 135804 net.cpp:570] norm2 -> norm2
I1108 23:17:48.136241 135804 net.cpp:210] Setting up norm2
I1108 23:17:48.136546 135804 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:17:48.136775 135804 net.cpp:225] Memory required for data: 211922432
I1108 23:17:48.137017 135804 layer_factory.hpp:114] Creating layer pool2
I1108 23:17:48.137977 135804 net.cpp:160] Creating Layer pool2
I1108 23:17:48.138308 135804 net.cpp:596] pool2 <- norm2
I1108 23:17:48.138551 135804 net.cpp:570] pool2 -> pool2
I1108 23:17:48.138944 135804 net.cpp:210] Setting up pool2
I1108 23:17:48.139189 135804 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:17:48.139408 135804 net.cpp:225] Memory required for data: 217460224
I1108 23:17:48.139603 135804 layer_factory.hpp:114] Creating layer conv3
I1108 23:17:48.139961 135804 net.cpp:160] Creating Layer conv3
I1108 23:17:48.140194 135804 net.cpp:596] conv3 <- pool2
I1108 23:17:48.140579 135804 net.cpp:570] conv3 -> conv3
I1108 23:17:48.591253 135804 net.cpp:210] Setting up conv3
I1108 23:17:48.593745 135804 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:17:48.594128 135804 net.cpp:225] Memory required for data: 225766912
I1108 23:17:48.597141 135804 layer_factory.hpp:114] Creating layer relu3
I1108 23:17:48.597573 135804 net.cpp:160] Creating Layer relu3
I1108 23:17:48.597877 135804 net.cpp:596] relu3 <- conv3
I1108 23:17:48.598109 135804 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:17:48.602408 135804 net.cpp:210] Setting up relu3
I1108 23:17:48.602735 135804 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:17:48.603024 135804 net.cpp:225] Memory required for data: 234073600
I1108 23:17:48.603224 135804 layer_factory.hpp:114] Creating layer conv4
I1108 23:17:48.603592 135804 net.cpp:160] Creating Layer conv4
I1108 23:17:48.603850 135804 net.cpp:596] conv4 <- conv3
I1108 23:17:48.604094 135804 net.cpp:570] conv4 -> conv4
I1108 23:17:48.871219 135804 net.cpp:210] Setting up conv4
I1108 23:17:48.871604 135804 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:17:48.871973 135804 net.cpp:225] Memory required for data: 242380288
I1108 23:17:48.872304 135804 layer_factory.hpp:114] Creating layer relu4
I1108 23:17:48.872586 135804 net.cpp:160] Creating Layer relu4
I1108 23:17:48.872833 135804 net.cpp:596] relu4 <- conv4
I1108 23:17:48.873073 135804 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:17:48.885449 135804 net.cpp:210] Setting up relu4
I1108 23:17:48.885795 135804 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:17:48.886149 135804 net.cpp:225] Memory required for data: 250686976
I1108 23:17:48.886385 135804 layer_factory.hpp:114] Creating layer conv5
I1108 23:17:48.886744 135804 net.cpp:160] Creating Layer conv5
I1108 23:17:48.886976 135804 net.cpp:596] conv5 <- conv4
I1108 23:17:48.887208 135804 net.cpp:570] conv5 -> conv5
I1108 23:17:49.057669 135804 net.cpp:210] Setting up conv5
I1108 23:17:49.058066 135804 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:17:49.058524 135804 net.cpp:225] Memory required for data: 256224768
I1108 23:17:49.063274 135804 layer_factory.hpp:114] Creating layer relu5
I1108 23:17:49.063694 135804 net.cpp:160] Creating Layer relu5
I1108 23:17:49.063987 135804 net.cpp:596] relu5 <- conv5
I1108 23:17:49.064256 135804 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:17:49.064723 135804 net.cpp:210] Setting up relu5
I1108 23:17:49.065075 135804 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:17:49.065325 135804 net.cpp:225] Memory required for data: 261762560
I1108 23:17:49.065564 135804 layer_factory.hpp:114] Creating layer pool5
I1108 23:17:49.065840 135804 net.cpp:160] Creating Layer pool5
I1108 23:17:49.066074 135804 net.cpp:596] pool5 <- conv5
I1108 23:17:49.066332 135804 net.cpp:570] pool5 -> pool5
I1108 23:17:49.066733 135804 net.cpp:210] Setting up pool5
I1108 23:17:49.067004 135804 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:17:49.067224 135804 net.cpp:225] Memory required for data: 262942208
I1108 23:17:49.067404 135804 layer_factory.hpp:114] Creating layer fc6
I1108 23:17:49.122565 135804 net.cpp:160] Creating Layer fc6
I1108 23:17:49.122871 135804 net.cpp:596] fc6 <- pool5
I1108 23:17:49.123221 135804 net.cpp:570] fc6 -> fc6
I1108 23:17:53.211522 135804 net.cpp:210] Setting up fc6
I1108 23:17:53.211827 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:53.213956 135804 net.cpp:225] Memory required for data: 263466496
I1108 23:17:53.214259 135804 layer_factory.hpp:114] Creating layer relu6
I1108 23:17:53.216754 135804 net.cpp:160] Creating Layer relu6
I1108 23:17:53.217100 135804 net.cpp:596] relu6 <- fc6
I1108 23:17:53.217325 135804 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:17:53.217735 135804 net.cpp:210] Setting up relu6
I1108 23:17:53.217985 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:53.218246 135804 net.cpp:225] Memory required for data: 263990784
I1108 23:17:53.218446 135804 layer_factory.hpp:114] Creating layer drop6
I1108 23:17:53.238427 135804 net.cpp:160] Creating Layer drop6
I1108 23:17:53.238729 135804 net.cpp:596] drop6 <- fc6
I1108 23:17:53.239084 135804 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:17:53.343025 135804 net.cpp:210] Setting up drop6
I1108 23:17:53.343322 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:53.343644 135804 net.cpp:225] Memory required for data: 264515072
I1108 23:17:53.343883 135804 layer_factory.hpp:114] Creating layer fc7
I1108 23:17:53.344144 135804 net.cpp:160] Creating Layer fc7
I1108 23:17:53.344350 135804 net.cpp:596] fc7 <- fc6
I1108 23:17:53.344724 135804 net.cpp:570] fc7 -> fc7
I1108 23:17:55.055639 135804 net.cpp:210] Setting up fc7
I1108 23:17:55.056001 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:55.056418 135804 net.cpp:225] Memory required for data: 265039360
I1108 23:17:55.056776 135804 layer_factory.hpp:114] Creating layer relu7
I1108 23:17:55.057152 135804 net.cpp:160] Creating Layer relu7
I1108 23:17:55.057399 135804 net.cpp:596] relu7 <- fc7
I1108 23:17:55.057651 135804 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:17:55.058094 135804 net.cpp:210] Setting up relu7
I1108 23:17:55.058383 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:55.058663 135804 net.cpp:225] Memory required for data: 265563648
I1108 23:17:55.058871 135804 layer_factory.hpp:114] Creating layer drop7
I1108 23:17:55.059118 135804 net.cpp:160] Creating Layer drop7
I1108 23:17:55.059394 135804 net.cpp:596] drop7 <- fc7
I1108 23:17:55.059670 135804 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:17:55.059947 135804 net.cpp:210] Setting up drop7
I1108 23:17:55.060155 135804 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:17:55.060370 135804 net.cpp:225] Memory required for data: 266087936
I1108 23:17:55.060554 135804 layer_factory.hpp:114] Creating layer fc8
I1108 23:17:55.060844 135804 net.cpp:160] Creating Layer fc8
I1108 23:17:55.061066 135804 net.cpp:596] fc8 <- fc7
I1108 23:17:55.061297 135804 net.cpp:570] fc8 -> fc8
I1108 23:17:55.485765 135804 net.cpp:210] Setting up fc8
I1108 23:17:55.486135 135804 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:17:55.486568 135804 net.cpp:225] Memory required for data: 266215936
I1108 23:17:55.486892 135804 layer_factory.hpp:114] Creating layer loss
I1108 23:17:55.512042 135804 net.cpp:160] Creating Layer loss
I1108 23:17:55.512358 135804 net.cpp:596] loss <- fc8
I1108 23:17:55.513327 135804 net.cpp:596] loss <- label
I1108 23:17:55.541708 135804 net.cpp:570] loss -> loss
I1108 23:17:55.582121 135804 layer_factory.hpp:114] Creating layer loss
I1108 23:17:58.154209 135804 net.cpp:210] Setting up loss
I1108 23:17:58.202654 135804 net.cpp:217] Top shape: (1)
I1108 23:17:58.218267 135804 net.cpp:220]     with loss weight 1
I1108 23:17:58.346788 135804 net.cpp:225] Memory required for data: 266215940
I1108 23:17:58.390023 135804 net.cpp:287] loss needs backward computation.
I1108 23:17:58.477746 135804 net.cpp:287] fc8 needs backward computation.
I1108 23:17:58.485013 135804 net.cpp:287] drop7 needs backward computation.
I1108 23:17:58.495995 135804 net.cpp:287] relu7 needs backward computation.
I1108 23:17:58.496315 135804 net.cpp:287] fc7 needs backward computation.
I1108 23:17:58.498865 135804 net.cpp:287] drop6 needs backward computation.
I1108 23:17:58.499281 135804 net.cpp:287] relu6 needs backward computation.
I1108 23:17:58.499543 135804 net.cpp:287] fc6 needs backward computation.
I1108 23:17:58.500218 135804 net.cpp:287] pool5 needs backward computation.
I1108 23:17:58.501019 135804 net.cpp:287] relu5 needs backward computation.
I1108 23:17:58.501298 135804 net.cpp:287] conv5 needs backward computation.
I1108 23:17:58.501492 135804 net.cpp:287] relu4 needs backward computation.
I1108 23:17:58.501677 135804 net.cpp:287] conv4 needs backward computation.
I1108 23:17:58.501893 135804 net.cpp:287] relu3 needs backward computation.
I1108 23:17:58.502086 135804 net.cpp:287] conv3 needs backward computation.
I1108 23:17:58.514703 135804 net.cpp:287] pool2 needs backward computation.
I1108 23:17:58.515055 135804 net.cpp:287] norm2 needs backward computation.
I1108 23:17:58.515364 135804 net.cpp:287] relu2 needs backward computation.
I1108 23:17:58.515594 135804 net.cpp:287] conv2 needs backward computation.
I1108 23:17:58.515781 135804 net.cpp:287] pool1 needs backward computation.
I1108 23:17:58.515961 135804 net.cpp:287] norm1 needs backward computation.
I1108 23:17:58.516140 135804 net.cpp:287] relu1 needs backward computation.
I1108 23:17:58.516315 135804 net.cpp:287] conv1 needs backward computation.
I1108 23:17:58.528534 135804 net.cpp:289] data does not need backward computation.
I1108 23:17:58.553378 135804 net.cpp:331] This network produces output loss
I1108 23:17:58.624287 135804 net.cpp:345] Network initialization done.
I1108 23:17:58.791282 135804 caffe.cpp:452] Performing Forward
I1108 23:18:12.056125 135804 caffe.cpp:457] Initial loss: 6.87554
I1108 23:18:12.118574 135804 caffe.cpp:459] Performing Backward
I1108 23:18:16.668658 135804 caffe.cpp:468] *** Benchmark begins ***
I1108 23:18:16.678055 135804 caffe.cpp:469] Testing for 1 iterations.
I1108 23:18:16.825978 135804 caffe.cpp:482] Profiling Layer: pool1 forward
I1108 23:18:19.140429 135804 caffe.cpp:512] Iteration: 1 forward-backward time: 2308 ms.
I1108 23:18:19.301728 135804 caffe.cpp:519] Average time per layer: 
I1108 23:18:19.320428 135804 caffe.cpp:522]       data	forward: 554.141 ms.
I1108 23:18:19.388967 135804 caffe.cpp:526]       data	backward: 5.199 ms.
I1108 23:18:19.415309 135804 caffe.cpp:522]      conv1	forward: 125.187 ms.
I1108 23:18:19.424679 135804 caffe.cpp:526]      conv1	backward: 42.949 ms.
I1108 23:18:19.429080 135804 caffe.cpp:522]      relu1	forward: 20.609 ms.
I1108 23:18:19.439613 135804 caffe.cpp:526]      relu1	backward: 15.565 ms.
I1108 23:18:19.441985 135804 caffe.cpp:522]      norm1	forward: 19.442 ms.
I1108 23:18:19.448026 135804 caffe.cpp:526]      norm1	backward: 12.567 ms.
I1108 23:18:19.454018 135804 caffe.cpp:522]      pool1	forward: 32.803 ms.
I1108 23:18:19.457984 135804 caffe.cpp:526]      pool1	backward: 77.093 ms.
I1108 23:18:19.469038 135804 caffe.cpp:522]      conv2	forward: 71.825 ms.
I1108 23:18:19.475962 135804 caffe.cpp:526]      conv2	backward: 73.788 ms.
I1108 23:18:19.483381 135804 caffe.cpp:522]      relu2	forward: 15.296 ms.
I1108 23:18:19.489262 135804 caffe.cpp:526]      relu2	backward: 22.329 ms.
I1108 23:18:19.494956 135804 caffe.cpp:522]      norm2	forward: 17.775 ms.
I1108 23:18:19.495746 135804 caffe.cpp:526]      norm2	backward: 13.033 ms.
I1108 23:18:19.496078 135804 caffe.cpp:522]      pool2	forward: 19.341 ms.
I1108 23:18:19.496273 135804 caffe.cpp:526]      pool2	backward: 57.695 ms.
I1108 23:18:19.496464 135804 caffe.cpp:522]      conv3	forward: 32.954 ms.
I1108 23:18:19.496654 135804 caffe.cpp:526]      conv3	backward: 78.506 ms.
I1108 23:18:19.496886 135804 caffe.cpp:522]      relu3	forward: 9.056 ms.
I1108 23:18:19.497704 135804 caffe.cpp:526]      relu3	backward: 31.706 ms.
I1108 23:18:19.497968 135804 caffe.cpp:522]      conv4	forward: 32.444 ms.
I1108 23:18:19.498180 135804 caffe.cpp:526]      conv4	backward: 71.775 ms.
I1108 23:18:19.498467 135804 caffe.cpp:522]      relu4	forward: 20.351 ms.
I1108 23:18:19.498695 135804 caffe.cpp:526]      relu4	backward: 46.503 ms.
I1108 23:18:19.498888 135804 caffe.cpp:522]      conv5	forward: 30.735 ms.
I1108 23:18:19.499079 135804 caffe.cpp:526]      conv5	backward: 68.846 ms.
I1108 23:18:19.499269 135804 caffe.cpp:522]      relu5	forward: 16.612 ms.
I1108 23:18:19.499459 135804 caffe.cpp:526]      relu5	backward: 17.898 ms.
I1108 23:18:19.499650 135804 caffe.cpp:522]      pool5	forward: 13.468 ms.
I1108 23:18:19.499840 135804 caffe.cpp:526]      pool5	backward: 53.51 ms.
I1108 23:18:19.500030 135804 caffe.cpp:522]        fc6	forward: 38.181 ms.
I1108 23:18:19.500219 135804 caffe.cpp:526]        fc6	backward: 95.724 ms.
I1108 23:18:19.500411 135804 caffe.cpp:522]      relu6	forward: 21.683 ms.
I1108 23:18:19.500600 135804 caffe.cpp:526]      relu6	backward: 15.402 ms.
I1108 23:18:19.500862 135804 caffe.cpp:522]      drop6	forward: 29.263 ms.
I1108 23:18:19.501081 135804 caffe.cpp:526]      drop6	backward: 17.128 ms.
I1108 23:18:19.501363 135804 caffe.cpp:522]        fc7	forward: 14.529 ms.
I1108 23:18:19.501597 135804 caffe.cpp:526]        fc7	backward: 54.095 ms.
I1108 23:18:19.501855 135804 caffe.cpp:522]      relu7	forward: 12.063 ms.
I1108 23:18:19.502045 135804 caffe.cpp:526]      relu7	backward: 0.092 ms.
I1108 23:18:19.504667 135804 caffe.cpp:522]      drop7	forward: 22.797 ms.
I1108 23:18:19.504963 135804 caffe.cpp:526]      drop7	backward: 0.094 ms.
I1108 23:18:19.505162 135804 caffe.cpp:522]        fc8	forward: 5.853 ms.
I1108 23:18:19.505349 135804 caffe.cpp:526]        fc8	backward: 92.468 ms.
I1108 23:18:19.505542 135804 caffe.cpp:522]       loss	forward: 37.798 ms.
I1108 23:18:19.505733 135804 caffe.cpp:526]       loss	backward: 37.305 ms.
I1108 23:18:19.511267 135804 caffe.cpp:532] Average Forward pass: 1269.07 ms.
I1108 23:18:19.527005 135804 caffe.cpp:535] Average Backward pass: 1011.08 ms.
I1108 23:18:19.538344 135804 caffe.cpp:537] Average Forward-Backward: 2787 ms.
I1108 23:18:19.553812 135804 caffe.cpp:540] Total Time: 2787 ms.
I1108 23:18:19.566289 135804 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 25
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 1259712
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 25
--->Total double-precision FLOPs = 2519424
--->Total FLOPs = 2519449
mem-read-1 = 27727
mem-read-2 = 35
mem-read-4 = 705462
mem-read-8 = 459681
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 3779153
mem-write-1 = 52
mem-write-2 = 17
mem-write-4 = 21767
mem-write-8 = 30142
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 2799361
--->Total Bytes read = 248392917
--->Total Bytes written = 179487426
--->Total Bytes = 427880343
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer5_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=5 -prof_forward_direction=1
I1108 23:22:02.035553 135921 caffe.cpp:444] Use CPU.
I1108 23:22:18.910115 135921 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:22:18.966209 135921 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:22:18.978077 135921 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:22:18.990456 135921 cpu_info.cpp:461] Total number of processors: 272
I1108 23:22:19.001739 135921 cpu_info.cpp:464] GPU is used: no
I1108 23:22:19.015004 135921 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:22:19.023759 135921 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:22:19.034731 135921 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:22:27.792080 135921 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:22:27.824672 135921 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:22:28.465562 135921 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:22:30.922224 135921 layer_factory.hpp:114] Creating layer data
I1108 23:22:31.069957 135921 net.cpp:160] Creating Layer data
I1108 23:22:31.118141 135921 net.cpp:570] data -> data
I1108 23:22:31.587808 135921 net.cpp:570] data -> label
I1108 23:22:38.636988 135921 net.cpp:210] Setting up data
I1108 23:22:38.718534 135921 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:22:38.823364 135921 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:22:38.830637 135921 net.cpp:225] Memory required for data: 19787264
I1108 23:22:38.897900 135921 layer_factory.hpp:114] Creating layer conv1
I1108 23:22:39.225201 135921 net.cpp:160] Creating Layer conv1
I1108 23:22:39.275029 135921 net.cpp:596] conv1 <- data
I1108 23:22:39.393996 135921 net.cpp:570] conv1 -> conv1
I1108 23:23:12.323781 135921 net.cpp:210] Setting up conv1
I1108 23:23:12.330140 135921 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:23:12.330513 135921 net.cpp:225] Memory required for data: 56958464
I1108 23:23:12.617314 135921 layer_factory.hpp:114] Creating layer relu1
I1108 23:23:12.737874 135921 net.cpp:160] Creating Layer relu1
I1108 23:23:12.742494 135921 net.cpp:596] relu1 <- conv1
I1108 23:23:12.774865 135921 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:23:12.964205 135921 net.cpp:210] Setting up relu1
I1108 23:23:12.966639 135921 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:23:12.967018 135921 net.cpp:225] Memory required for data: 94129664
I1108 23:23:12.967236 135921 layer_factory.hpp:114] Creating layer norm1
I1108 23:23:13.072212 135921 net.cpp:160] Creating Layer norm1
I1108 23:23:13.072530 135921 net.cpp:596] norm1 <- conv1
I1108 23:23:13.075057 135921 net.cpp:570] norm1 -> norm1
I1108 23:23:13.296547 135921 net.cpp:210] Setting up norm1
I1108 23:23:13.309273 135921 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:23:13.309654 135921 net.cpp:225] Memory required for data: 131300864
I1108 23:23:13.309981 135921 layer_factory.hpp:114] Creating layer pool1
I1108 23:23:13.408632 135921 net.cpp:160] Creating Layer pool1
I1108 23:23:13.409147 135921 net.cpp:596] pool1 <- norm1
I1108 23:23:13.425865 135921 net.cpp:570] pool1 -> pool1
I1108 23:23:13.734673 135921 net.cpp:210] Setting up pool1
I1108 23:23:13.737222 135921 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:23:13.737588 135921 net.cpp:225] Memory required for data: 140258816
I1108 23:23:13.737818 135921 layer_factory.hpp:114] Creating layer conv2
I1108 23:23:13.738173 135921 net.cpp:160] Creating Layer conv2
I1108 23:23:13.738404 135921 net.cpp:596] conv2 <- pool1
I1108 23:23:13.738652 135921 net.cpp:570] conv2 -> conv2
I1108 23:23:19.494029 135921 net.cpp:210] Setting up conv2
I1108 23:23:19.494379 135921 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:23:19.494825 135921 net.cpp:225] Memory required for data: 164146688
I1108 23:23:19.546726 135921 layer_factory.hpp:114] Creating layer relu2
I1108 23:23:19.547168 135921 net.cpp:160] Creating Layer relu2
I1108 23:23:19.547556 135921 net.cpp:596] relu2 <- conv2
I1108 23:23:19.547834 135921 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:23:19.548321 135921 net.cpp:210] Setting up relu2
I1108 23:23:19.548605 135921 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:23:19.548899 135921 net.cpp:225] Memory required for data: 188034560
I1108 23:23:19.549105 135921 layer_factory.hpp:114] Creating layer norm2
I1108 23:23:19.549365 135921 net.cpp:160] Creating Layer norm2
I1108 23:23:19.549602 135921 net.cpp:596] norm2 <- conv2
I1108 23:23:19.549855 135921 net.cpp:570] norm2 -> norm2
I1108 23:23:19.551970 135921 net.cpp:210] Setting up norm2
I1108 23:23:19.552317 135921 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:23:19.552577 135921 net.cpp:225] Memory required for data: 211922432
I1108 23:23:19.552961 135921 layer_factory.hpp:114] Creating layer pool2
I1108 23:23:19.553918 135921 net.cpp:160] Creating Layer pool2
I1108 23:23:19.554225 135921 net.cpp:596] pool2 <- norm2
I1108 23:23:19.554492 135921 net.cpp:570] pool2 -> pool2
I1108 23:23:19.554936 135921 net.cpp:210] Setting up pool2
I1108 23:23:19.555215 135921 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:23:19.555459 135921 net.cpp:225] Memory required for data: 217460224
I1108 23:23:19.555794 135921 layer_factory.hpp:114] Creating layer conv3
I1108 23:23:19.556210 135921 net.cpp:160] Creating Layer conv3
I1108 23:23:19.556437 135921 net.cpp:596] conv3 <- pool2
I1108 23:23:19.556684 135921 net.cpp:570] conv3 -> conv3
I1108 23:23:20.065652 135921 net.cpp:210] Setting up conv3
I1108 23:23:20.068017 135921 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:23:20.068372 135921 net.cpp:225] Memory required for data: 225766912
I1108 23:23:20.071480 135921 layer_factory.hpp:114] Creating layer relu3
I1108 23:23:20.071904 135921 net.cpp:160] Creating Layer relu3
I1108 23:23:20.072177 135921 net.cpp:596] relu3 <- conv3
I1108 23:23:20.072522 135921 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:23:20.076699 135921 net.cpp:210] Setting up relu3
I1108 23:23:20.077075 135921 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:23:20.077348 135921 net.cpp:225] Memory required for data: 234073600
I1108 23:23:20.077587 135921 layer_factory.hpp:114] Creating layer conv4
I1108 23:23:20.077960 135921 net.cpp:160] Creating Layer conv4
I1108 23:23:20.078218 135921 net.cpp:596] conv4 <- conv3
I1108 23:23:20.078470 135921 net.cpp:570] conv4 -> conv4
I1108 23:23:20.318938 135921 net.cpp:210] Setting up conv4
I1108 23:23:20.319326 135921 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:23:20.319712 135921 net.cpp:225] Memory required for data: 242380288
I1108 23:23:20.320060 135921 layer_factory.hpp:114] Creating layer relu4
I1108 23:23:20.320354 135921 net.cpp:160] Creating Layer relu4
I1108 23:23:20.320582 135921 net.cpp:596] relu4 <- conv4
I1108 23:23:20.320866 135921 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:23:20.333097 135921 net.cpp:210] Setting up relu4
I1108 23:23:20.333447 135921 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:23:20.333847 135921 net.cpp:225] Memory required for data: 250686976
I1108 23:23:20.334061 135921 layer_factory.hpp:114] Creating layer conv5
I1108 23:23:20.334430 135921 net.cpp:160] Creating Layer conv5
I1108 23:23:20.334681 135921 net.cpp:596] conv5 <- conv4
I1108 23:23:20.334926 135921 net.cpp:570] conv5 -> conv5
I1108 23:23:20.503156 135921 net.cpp:210] Setting up conv5
I1108 23:23:20.503545 135921 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:23:20.503983 135921 net.cpp:225] Memory required for data: 256224768
I1108 23:23:20.508646 135921 layer_factory.hpp:114] Creating layer relu5
I1108 23:23:20.509119 135921 net.cpp:160] Creating Layer relu5
I1108 23:23:20.509414 135921 net.cpp:596] relu5 <- conv5
I1108 23:23:20.509690 135921 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:23:20.510150 135921 net.cpp:210] Setting up relu5
I1108 23:23:20.510442 135921 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:23:20.510694 135921 net.cpp:225] Memory required for data: 261762560
I1108 23:23:20.510906 135921 layer_factory.hpp:114] Creating layer pool5
I1108 23:23:20.511207 135921 net.cpp:160] Creating Layer pool5
I1108 23:23:20.511438 135921 net.cpp:596] pool5 <- conv5
I1108 23:23:20.511678 135921 net.cpp:570] pool5 -> pool5
I1108 23:23:20.512176 135921 net.cpp:210] Setting up pool5
I1108 23:23:20.512434 135921 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:23:20.512661 135921 net.cpp:225] Memory required for data: 262942208
I1108 23:23:20.512902 135921 layer_factory.hpp:114] Creating layer fc6
I1108 23:23:20.569613 135921 net.cpp:160] Creating Layer fc6
I1108 23:23:20.569941 135921 net.cpp:596] fc6 <- pool5
I1108 23:23:20.570343 135921 net.cpp:570] fc6 -> fc6
I1108 23:23:24.659901 135921 net.cpp:210] Setting up fc6
I1108 23:23:24.660212 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:24.662287 135921 net.cpp:225] Memory required for data: 263466496
I1108 23:23:24.662606 135921 layer_factory.hpp:114] Creating layer relu6
I1108 23:23:24.665186 135921 net.cpp:160] Creating Layer relu6
I1108 23:23:24.665485 135921 net.cpp:596] relu6 <- fc6
I1108 23:23:24.665714 135921 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:23:24.666131 135921 net.cpp:210] Setting up relu6
I1108 23:23:24.666383 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:24.666651 135921 net.cpp:225] Memory required for data: 263990784
I1108 23:23:24.666852 135921 layer_factory.hpp:114] Creating layer drop6
I1108 23:23:24.686770 135921 net.cpp:160] Creating Layer drop6
I1108 23:23:24.687077 135921 net.cpp:596] drop6 <- fc6
I1108 23:23:24.687450 135921 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:23:24.790158 135921 net.cpp:210] Setting up drop6
I1108 23:23:24.790463 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:24.790814 135921 net.cpp:225] Memory required for data: 264515072
I1108 23:23:24.791062 135921 layer_factory.hpp:114] Creating layer fc7
I1108 23:23:24.791343 135921 net.cpp:160] Creating Layer fc7
I1108 23:23:24.791555 135921 net.cpp:596] fc7 <- fc6
I1108 23:23:24.791940 135921 net.cpp:570] fc7 -> fc7
I1108 23:23:26.503654 135921 net.cpp:210] Setting up fc7
I1108 23:23:26.504001 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:26.504432 135921 net.cpp:225] Memory required for data: 265039360
I1108 23:23:26.504772 135921 layer_factory.hpp:114] Creating layer relu7
I1108 23:23:26.505126 135921 net.cpp:160] Creating Layer relu7
I1108 23:23:26.505352 135921 net.cpp:596] relu7 <- fc7
I1108 23:23:26.505586 135921 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:23:26.506012 135921 net.cpp:210] Setting up relu7
I1108 23:23:26.506278 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:26.506515 135921 net.cpp:225] Memory required for data: 265563648
I1108 23:23:26.506702 135921 layer_factory.hpp:114] Creating layer drop7
I1108 23:23:26.506961 135921 net.cpp:160] Creating Layer drop7
I1108 23:23:26.507166 135921 net.cpp:596] drop7 <- fc7
I1108 23:23:26.507411 135921 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:23:26.507711 135921 net.cpp:210] Setting up drop7
I1108 23:23:26.507912 135921 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:23:26.508123 135921 net.cpp:225] Memory required for data: 266087936
I1108 23:23:26.508302 135921 layer_factory.hpp:114] Creating layer fc8
I1108 23:23:26.508546 135921 net.cpp:160] Creating Layer fc8
I1108 23:23:26.508739 135921 net.cpp:596] fc8 <- fc7
I1108 23:23:26.509021 135921 net.cpp:570] fc8 -> fc8
I1108 23:23:26.934340 135921 net.cpp:210] Setting up fc8
I1108 23:23:26.934686 135921 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:23:26.935080 135921 net.cpp:225] Memory required for data: 266215936
I1108 23:23:26.935379 135921 layer_factory.hpp:114] Creating layer loss
I1108 23:23:26.959805 135921 net.cpp:160] Creating Layer loss
I1108 23:23:26.960127 135921 net.cpp:596] loss <- fc8
I1108 23:23:26.961115 135921 net.cpp:596] loss <- label
I1108 23:23:26.988317 135921 net.cpp:570] loss -> loss
I1108 23:23:27.026202 135921 layer_factory.hpp:114] Creating layer loss
I1108 23:23:29.588621 135921 net.cpp:210] Setting up loss
I1108 23:23:29.636327 135921 net.cpp:217] Top shape: (1)
I1108 23:23:29.652288 135921 net.cpp:220]     with loss weight 1
I1108 23:23:29.785418 135921 net.cpp:225] Memory required for data: 266215940
I1108 23:23:29.833783 135921 net.cpp:287] loss needs backward computation.
I1108 23:23:29.922683 135921 net.cpp:287] fc8 needs backward computation.
I1108 23:23:29.929993 135921 net.cpp:287] drop7 needs backward computation.
I1108 23:23:29.941030 135921 net.cpp:287] relu7 needs backward computation.
I1108 23:23:29.941354 135921 net.cpp:287] fc7 needs backward computation.
I1108 23:23:29.943837 135921 net.cpp:287] drop6 needs backward computation.
I1108 23:23:29.944274 135921 net.cpp:287] relu6 needs backward computation.
I1108 23:23:29.944525 135921 net.cpp:287] fc6 needs backward computation.
I1108 23:23:29.945237 135921 net.cpp:287] pool5 needs backward computation.
I1108 23:23:29.945973 135921 net.cpp:287] relu5 needs backward computation.
I1108 23:23:29.946245 135921 net.cpp:287] conv5 needs backward computation.
I1108 23:23:29.946487 135921 net.cpp:287] relu4 needs backward computation.
I1108 23:23:29.946740 135921 net.cpp:287] conv4 needs backward computation.
I1108 23:23:29.947031 135921 net.cpp:287] relu3 needs backward computation.
I1108 23:23:29.947262 135921 net.cpp:287] conv3 needs backward computation.
I1108 23:23:29.960021 135921 net.cpp:287] pool2 needs backward computation.
I1108 23:23:29.960378 135921 net.cpp:287] norm2 needs backward computation.
I1108 23:23:29.960698 135921 net.cpp:287] relu2 needs backward computation.
I1108 23:23:29.960978 135921 net.cpp:287] conv2 needs backward computation.
I1108 23:23:29.961170 135921 net.cpp:287] pool1 needs backward computation.
I1108 23:23:29.961352 135921 net.cpp:287] norm1 needs backward computation.
I1108 23:23:29.961534 135921 net.cpp:287] relu1 needs backward computation.
I1108 23:23:29.961710 135921 net.cpp:287] conv1 needs backward computation.
I1108 23:23:29.974133 135921 net.cpp:289] data does not need backward computation.
I1108 23:23:29.999421 135921 net.cpp:331] This network produces output loss
I1108 23:23:30.074869 135921 net.cpp:345] Network initialization done.
I1108 23:23:30.244295 135921 caffe.cpp:452] Performing Forward
I1108 23:23:43.211311 135921 caffe.cpp:457] Initial loss: 6.87542
I1108 23:23:43.273614 135921 caffe.cpp:459] Performing Backward
I1108 23:23:47.833433 135921 caffe.cpp:468] *** Benchmark begins ***
I1108 23:23:47.848604 135921 caffe.cpp:469] Testing for 1 iterations.
I1108 23:23:47.993974 135921 caffe.cpp:482] Profiling Layer: conv2 forward
I1108 23:23:50.337704 135921 caffe.cpp:512] Iteration: 1 forward-backward time: 2338 ms.
I1108 23:23:50.492877 135921 caffe.cpp:519] Average time per layer: 
I1108 23:23:50.512089 135921 caffe.cpp:522]       data	forward: 556.083 ms.
I1108 23:23:50.585963 135921 caffe.cpp:526]       data	backward: 5.488 ms.
I1108 23:23:50.610890 135921 caffe.cpp:522]      conv1	forward: 132.707 ms.
I1108 23:23:50.618456 135921 caffe.cpp:526]      conv1	backward: 49.145 ms.
I1108 23:23:50.629189 135921 caffe.cpp:522]      relu1	forward: 18.492 ms.
I1108 23:23:50.633443 135921 caffe.cpp:526]      relu1	backward: 14.38 ms.
I1108 23:23:50.643025 135921 caffe.cpp:522]      norm1	forward: 28.155 ms.
I1108 23:23:50.651056 135921 caffe.cpp:526]      norm1	backward: 12.948 ms.
I1108 23:23:50.661758 135921 caffe.cpp:522]      pool1	forward: 28.011 ms.
I1108 23:23:50.674682 135921 caffe.cpp:526]      pool1	backward: 83.674 ms.
I1108 23:23:50.685703 135921 caffe.cpp:522]      conv2	forward: 78.859 ms.
I1108 23:23:50.687127 135921 caffe.cpp:526]      conv2	backward: 70.723 ms.
I1108 23:23:50.687381 135921 caffe.cpp:522]      relu2	forward: 14.112 ms.
I1108 23:23:50.687577 135921 caffe.cpp:526]      relu2	backward: 11.838 ms.
I1108 23:23:50.687769 135921 caffe.cpp:522]      norm2	forward: 18.351 ms.
I1108 23:23:50.687960 135921 caffe.cpp:526]      norm2	backward: 15.559 ms.
I1108 23:23:50.688150 135921 caffe.cpp:522]      pool2	forward: 19.962 ms.
I1108 23:23:50.688374 135921 caffe.cpp:526]      pool2	backward: 66.297 ms.
I1108 23:23:50.688577 135921 caffe.cpp:522]      conv3	forward: 40.97 ms.
I1108 23:23:50.688838 135921 caffe.cpp:526]      conv3	backward: 74.506 ms.
I1108 23:23:50.689031 135921 caffe.cpp:522]      relu3	forward: 15.279 ms.
I1108 23:23:50.689223 135921 caffe.cpp:526]      relu3	backward: 37.352 ms.
I1108 23:23:50.689412 135921 caffe.cpp:522]      conv4	forward: 31.701 ms.
I1108 23:23:50.689601 135921 caffe.cpp:526]      conv4	backward: 77.54 ms.
I1108 23:23:50.689791 135921 caffe.cpp:522]      relu4	forward: 15.283 ms.
I1108 23:23:50.689981 135921 caffe.cpp:526]      relu4	backward: 32.238 ms.
I1108 23:23:50.690171 135921 caffe.cpp:522]      conv5	forward: 33.873 ms.
I1108 23:23:50.690361 135921 caffe.cpp:526]      conv5	backward: 66.525 ms.
I1108 23:23:50.690551 135921 caffe.cpp:522]      relu5	forward: 11.588 ms.
I1108 23:23:50.690740 135921 caffe.cpp:526]      relu5	backward: 16.242 ms.
I1108 23:23:50.690929 135921 caffe.cpp:522]      pool5	forward: 12.152 ms.
I1108 23:23:50.691119 135921 caffe.cpp:526]      pool5	backward: 44.311 ms.
I1108 23:23:50.691309 135921 caffe.cpp:522]        fc6	forward: 33.873 ms.
I1108 23:23:50.691499 135921 caffe.cpp:526]        fc6	backward: 115.449 ms.
I1108 23:23:50.691691 135921 caffe.cpp:522]      relu6	forward: 14.062 ms.
I1108 23:23:50.691880 135921 caffe.cpp:526]      relu6	backward: 17.688 ms.
I1108 23:23:50.692070 135921 caffe.cpp:522]      drop6	forward: 36.054 ms.
I1108 23:23:50.692260 135921 caffe.cpp:526]      drop6	backward: 14.958 ms.
I1108 23:23:50.692451 135921 caffe.cpp:522]        fc7	forward: 18.835 ms.
I1108 23:23:50.692639 135921 caffe.cpp:526]        fc7	backward: 86.852 ms.
I1108 23:23:50.692843 135921 caffe.cpp:522]      relu7	forward: 7.9 ms.
I1108 23:23:50.693029 135921 caffe.cpp:526]      relu7	backward: 0.089 ms.
I1108 23:23:50.695390 135921 caffe.cpp:522]      drop7	forward: 0.332 ms.
I1108 23:23:50.695636 135921 caffe.cpp:526]      drop7	backward: 0.093 ms.
I1108 23:23:50.695832 135921 caffe.cpp:522]        fc8	forward: 1.729 ms.
I1108 23:23:50.696020 135921 caffe.cpp:526]        fc8	backward: 74.576 ms.
I1108 23:23:50.696218 135921 caffe.cpp:522]       loss	forward: 41.701 ms.
I1108 23:23:50.696408 135921 caffe.cpp:526]       loss	backward: 43.173 ms.
I1108 23:23:50.701578 135921 caffe.cpp:532] Average Forward pass: 1266.92 ms.
I1108 23:23:50.714867 135921 caffe.cpp:535] Average Backward pass: 1041.78 ms.
I1108 23:23:50.725750 135921 caffe.cpp:537] Average Forward-Backward: 2807 ms.
I1108 23:23:50.740558 135921 caffe.cpp:540] Total Time: 2807 ms.
I1108 23:23:50.752753 135921 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 2
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 819058176
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 13104930818
--->Total double-precision FLOPs = 0
--->Total FLOPs = 13104930818
mem-read-1 = 46725
mem-read-2 = 75
mem-read-4 = 409888277
mem-read-8 = 2229922
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 41123525
mem-write-1 = 114
mem-write-2 = 34
mem-write-4 = 42853
mem-write-8 = 1109997
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 1677572
--->Total Bytes read = 4289345023
--->Total Bytes written = 116416242
--->Total Bytes = 4405761265
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer6_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=6 -prof_forward_direction=1
I1108 23:27:55.164598 136042 caffe.cpp:444] Use CPU.
I1108 23:28:11.983562 136042 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:28:12.039065 136042 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:28:12.051154 136042 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:28:12.063665 136042 cpu_info.cpp:461] Total number of processors: 272
I1108 23:28:12.074959 136042 cpu_info.cpp:464] GPU is used: no
I1108 23:28:12.083859 136042 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:28:12.092738 136042 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:28:12.103850 136042 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:28:20.829848 136042 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:28:20.862455 136042 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:28:21.487121 136042 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:28:23.910548 136042 layer_factory.hpp:114] Creating layer data
I1108 23:28:24.056545 136042 net.cpp:160] Creating Layer data
I1108 23:28:24.104398 136042 net.cpp:570] data -> data
I1108 23:28:24.569362 136042 net.cpp:570] data -> label
I1108 23:28:31.536248 136042 net.cpp:210] Setting up data
I1108 23:28:31.618154 136042 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:28:31.721978 136042 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:28:31.729212 136042 net.cpp:225] Memory required for data: 19787264
I1108 23:28:31.795910 136042 layer_factory.hpp:114] Creating layer conv1
I1108 23:28:32.119140 136042 net.cpp:160] Creating Layer conv1
I1108 23:28:32.168274 136042 net.cpp:596] conv1 <- data
I1108 23:28:32.291317 136042 net.cpp:570] conv1 -> conv1
I1108 23:29:04.977851 136042 net.cpp:210] Setting up conv1
I1108 23:29:04.984694 136042 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:29:04.985158 136042 net.cpp:225] Memory required for data: 56958464
I1108 23:29:05.263978 136042 layer_factory.hpp:114] Creating layer relu1
I1108 23:29:05.383131 136042 net.cpp:160] Creating Layer relu1
I1108 23:29:05.387699 136042 net.cpp:596] relu1 <- conv1
I1108 23:29:05.419469 136042 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:29:05.611632 136042 net.cpp:210] Setting up relu1
I1108 23:29:05.614127 136042 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:29:05.614498 136042 net.cpp:225] Memory required for data: 94129664
I1108 23:29:05.614715 136042 layer_factory.hpp:114] Creating layer norm1
I1108 23:29:05.718842 136042 net.cpp:160] Creating Layer norm1
I1108 23:29:05.719154 136042 net.cpp:596] norm1 <- conv1
I1108 23:29:05.721709 136042 net.cpp:570] norm1 -> norm1
I1108 23:29:05.944649 136042 net.cpp:210] Setting up norm1
I1108 23:29:05.957506 136042 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:29:05.957880 136042 net.cpp:225] Memory required for data: 131300864
I1108 23:29:05.958214 136042 layer_factory.hpp:114] Creating layer pool1
I1108 23:29:06.050983 136042 net.cpp:160] Creating Layer pool1
I1108 23:29:06.051293 136042 net.cpp:596] pool1 <- norm1
I1108 23:29:06.065979 136042 net.cpp:570] pool1 -> pool1
I1108 23:29:06.363966 136042 net.cpp:210] Setting up pool1
I1108 23:29:06.366437 136042 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:29:06.366762 136042 net.cpp:225] Memory required for data: 140258816
I1108 23:29:06.367007 136042 layer_factory.hpp:114] Creating layer conv2
I1108 23:29:06.367374 136042 net.cpp:160] Creating Layer conv2
I1108 23:29:06.367591 136042 net.cpp:596] conv2 <- pool1
I1108 23:29:06.367828 136042 net.cpp:570] conv2 -> conv2
I1108 23:29:12.077703 136042 net.cpp:210] Setting up conv2
I1108 23:29:12.078016 136042 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:29:12.078408 136042 net.cpp:225] Memory required for data: 164146688
I1108 23:29:12.129670 136042 layer_factory.hpp:114] Creating layer relu2
I1108 23:29:12.130084 136042 net.cpp:160] Creating Layer relu2
I1108 23:29:12.130447 136042 net.cpp:596] relu2 <- conv2
I1108 23:29:12.130731 136042 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:29:12.131166 136042 net.cpp:210] Setting up relu2
I1108 23:29:12.131429 136042 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:29:12.131661 136042 net.cpp:225] Memory required for data: 188034560
I1108 23:29:12.131846 136042 layer_factory.hpp:114] Creating layer norm2
I1108 23:29:12.132082 136042 net.cpp:160] Creating Layer norm2
I1108 23:29:12.132272 136042 net.cpp:596] norm2 <- conv2
I1108 23:29:12.132535 136042 net.cpp:570] norm2 -> norm2
I1108 23:29:12.134579 136042 net.cpp:210] Setting up norm2
I1108 23:29:12.134902 136042 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:29:12.135145 136042 net.cpp:225] Memory required for data: 211922432
I1108 23:29:12.135344 136042 layer_factory.hpp:114] Creating layer pool2
I1108 23:29:12.136248 136042 net.cpp:160] Creating Layer pool2
I1108 23:29:12.136554 136042 net.cpp:596] pool2 <- norm2
I1108 23:29:12.136858 136042 net.cpp:570] pool2 -> pool2
I1108 23:29:12.137331 136042 net.cpp:210] Setting up pool2
I1108 23:29:12.137578 136042 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:29:12.137796 136042 net.cpp:225] Memory required for data: 217460224
I1108 23:29:12.137992 136042 layer_factory.hpp:114] Creating layer conv3
I1108 23:29:12.138365 136042 net.cpp:160] Creating Layer conv3
I1108 23:29:12.138725 136042 net.cpp:596] conv3 <- pool2
I1108 23:29:12.139047 136042 net.cpp:570] conv3 -> conv3
I1108 23:29:12.635665 136042 net.cpp:210] Setting up conv3
I1108 23:29:12.638025 136042 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:29:12.638366 136042 net.cpp:225] Memory required for data: 225766912
I1108 23:29:12.641361 136042 layer_factory.hpp:114] Creating layer relu3
I1108 23:29:12.641788 136042 net.cpp:160] Creating Layer relu3
I1108 23:29:12.642036 136042 net.cpp:596] relu3 <- conv3
I1108 23:29:12.642282 136042 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:29:12.646361 136042 net.cpp:210] Setting up relu3
I1108 23:29:12.646666 136042 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:29:12.646905 136042 net.cpp:225] Memory required for data: 234073600
I1108 23:29:12.647099 136042 layer_factory.hpp:114] Creating layer conv4
I1108 23:29:12.647482 136042 net.cpp:160] Creating Layer conv4
I1108 23:29:12.647742 136042 net.cpp:596] conv4 <- conv3
I1108 23:29:12.647999 136042 net.cpp:570] conv4 -> conv4
I1108 23:29:12.893352 136042 net.cpp:210] Setting up conv4
I1108 23:29:12.893753 136042 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:29:12.894177 136042 net.cpp:225] Memory required for data: 242380288
I1108 23:29:12.894502 136042 layer_factory.hpp:114] Creating layer relu4
I1108 23:29:12.894814 136042 net.cpp:160] Creating Layer relu4
I1108 23:29:12.895038 136042 net.cpp:596] relu4 <- conv4
I1108 23:29:12.895269 136042 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:29:12.907492 136042 net.cpp:210] Setting up relu4
I1108 23:29:12.907829 136042 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:29:12.908219 136042 net.cpp:225] Memory required for data: 250686976
I1108 23:29:12.908432 136042 layer_factory.hpp:114] Creating layer conv5
I1108 23:29:12.908838 136042 net.cpp:160] Creating Layer conv5
I1108 23:29:12.909101 136042 net.cpp:596] conv5 <- conv4
I1108 23:29:12.909348 136042 net.cpp:570] conv5 -> conv5
I1108 23:29:13.078950 136042 net.cpp:210] Setting up conv5
I1108 23:29:13.079329 136042 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:29:13.079722 136042 net.cpp:225] Memory required for data: 256224768
I1108 23:29:13.084386 136042 layer_factory.hpp:114] Creating layer relu5
I1108 23:29:13.084836 136042 net.cpp:160] Creating Layer relu5
I1108 23:29:13.085125 136042 net.cpp:596] relu5 <- conv5
I1108 23:29:13.085386 136042 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:29:13.085824 136042 net.cpp:210] Setting up relu5
I1108 23:29:13.086109 136042 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:29:13.086347 136042 net.cpp:225] Memory required for data: 261762560
I1108 23:29:13.086554 136042 layer_factory.hpp:114] Creating layer pool5
I1108 23:29:13.086810 136042 net.cpp:160] Creating Layer pool5
I1108 23:29:13.087016 136042 net.cpp:596] pool5 <- conv5
I1108 23:29:13.087268 136042 net.cpp:570] pool5 -> pool5
I1108 23:29:13.087676 136042 net.cpp:210] Setting up pool5
I1108 23:29:13.087963 136042 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:29:13.088181 136042 net.cpp:225] Memory required for data: 262942208
I1108 23:29:13.088361 136042 layer_factory.hpp:114] Creating layer fc6
I1108 23:29:13.142213 136042 net.cpp:160] Creating Layer fc6
I1108 23:29:13.142518 136042 net.cpp:596] fc6 <- pool5
I1108 23:29:13.142874 136042 net.cpp:570] fc6 -> fc6
I1108 23:29:17.375531 136042 net.cpp:210] Setting up fc6
I1108 23:29:17.375833 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:17.378042 136042 net.cpp:225] Memory required for data: 263466496
I1108 23:29:17.378355 136042 layer_factory.hpp:114] Creating layer relu6
I1108 23:29:17.380952 136042 net.cpp:160] Creating Layer relu6
I1108 23:29:17.381278 136042 net.cpp:596] relu6 <- fc6
I1108 23:29:17.381500 136042 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:29:17.381907 136042 net.cpp:210] Setting up relu6
I1108 23:29:17.382163 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:17.382380 136042 net.cpp:225] Memory required for data: 263990784
I1108 23:29:17.382561 136042 layer_factory.hpp:114] Creating layer drop6
I1108 23:29:17.403167 136042 net.cpp:160] Creating Layer drop6
I1108 23:29:17.403484 136042 net.cpp:596] drop6 <- fc6
I1108 23:29:17.403885 136042 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:29:17.507678 136042 net.cpp:210] Setting up drop6
I1108 23:29:17.507967 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:17.508357 136042 net.cpp:225] Memory required for data: 264515072
I1108 23:29:17.508608 136042 layer_factory.hpp:114] Creating layer fc7
I1108 23:29:17.508944 136042 net.cpp:160] Creating Layer fc7
I1108 23:29:17.509186 136042 net.cpp:596] fc7 <- fc6
I1108 23:29:17.509557 136042 net.cpp:570] fc7 -> fc7
I1108 23:29:19.235605 136042 net.cpp:210] Setting up fc7
I1108 23:29:19.235942 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:19.236311 136042 net.cpp:225] Memory required for data: 265039360
I1108 23:29:19.236640 136042 layer_factory.hpp:114] Creating layer relu7
I1108 23:29:19.236979 136042 net.cpp:160] Creating Layer relu7
I1108 23:29:19.237211 136042 net.cpp:596] relu7 <- fc7
I1108 23:29:19.237439 136042 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:29:19.237854 136042 net.cpp:210] Setting up relu7
I1108 23:29:19.238118 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:19.238346 136042 net.cpp:225] Memory required for data: 265563648
I1108 23:29:19.238533 136042 layer_factory.hpp:114] Creating layer drop7
I1108 23:29:19.238786 136042 net.cpp:160] Creating Layer drop7
I1108 23:29:19.238984 136042 net.cpp:596] drop7 <- fc7
I1108 23:29:19.239225 136042 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:29:19.239493 136042 net.cpp:210] Setting up drop7
I1108 23:29:19.239711 136042 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:29:19.239920 136042 net.cpp:225] Memory required for data: 266087936
I1108 23:29:19.240097 136042 layer_factory.hpp:114] Creating layer fc8
I1108 23:29:19.240334 136042 net.cpp:160] Creating Layer fc8
I1108 23:29:19.240525 136042 net.cpp:596] fc8 <- fc7
I1108 23:29:19.240742 136042 net.cpp:570] fc8 -> fc8
I1108 23:29:19.663746 136042 net.cpp:210] Setting up fc8
I1108 23:29:19.664106 136042 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:29:19.664510 136042 net.cpp:225] Memory required for data: 266215936
I1108 23:29:19.664894 136042 layer_factory.hpp:114] Creating layer loss
I1108 23:29:19.689699 136042 net.cpp:160] Creating Layer loss
I1108 23:29:19.690012 136042 net.cpp:596] loss <- fc8
I1108 23:29:19.690948 136042 net.cpp:596] loss <- label
I1108 23:29:19.718189 136042 net.cpp:570] loss -> loss
I1108 23:29:19.755893 136042 layer_factory.hpp:114] Creating layer loss
I1108 23:29:22.255797 136042 net.cpp:210] Setting up loss
I1108 23:29:22.301170 136042 net.cpp:217] Top shape: (1)
I1108 23:29:22.313973 136042 net.cpp:220]     with loss weight 1
I1108 23:29:22.442149 136042 net.cpp:225] Memory required for data: 266215940
I1108 23:29:22.481854 136042 net.cpp:287] loss needs backward computation.
I1108 23:29:22.567178 136042 net.cpp:287] fc8 needs backward computation.
I1108 23:29:22.574319 136042 net.cpp:287] drop7 needs backward computation.
I1108 23:29:22.585458 136042 net.cpp:287] relu7 needs backward computation.
I1108 23:29:22.585760 136042 net.cpp:287] fc7 needs backward computation.
I1108 23:29:22.588129 136042 net.cpp:287] drop6 needs backward computation.
I1108 23:29:22.588456 136042 net.cpp:287] relu6 needs backward computation.
I1108 23:29:22.588665 136042 net.cpp:287] fc6 needs backward computation.
I1108 23:29:22.589510 136042 net.cpp:287] pool5 needs backward computation.
I1108 23:29:22.590265 136042 net.cpp:287] relu5 needs backward computation.
I1108 23:29:22.590546 136042 net.cpp:287] conv5 needs backward computation.
I1108 23:29:22.590733 136042 net.cpp:287] relu4 needs backward computation.
I1108 23:29:22.590909 136042 net.cpp:287] conv4 needs backward computation.
I1108 23:29:22.591087 136042 net.cpp:287] relu3 needs backward computation.
I1108 23:29:22.591264 136042 net.cpp:287] conv3 needs backward computation.
I1108 23:29:22.603199 136042 net.cpp:287] pool2 needs backward computation.
I1108 23:29:22.603534 136042 net.cpp:287] norm2 needs backward computation.
I1108 23:29:22.603832 136042 net.cpp:287] relu2 needs backward computation.
I1108 23:29:22.604066 136042 net.cpp:287] conv2 needs backward computation.
I1108 23:29:22.604249 136042 net.cpp:287] pool1 needs backward computation.
I1108 23:29:22.604430 136042 net.cpp:287] norm1 needs backward computation.
I1108 23:29:22.604609 136042 net.cpp:287] relu1 needs backward computation.
I1108 23:29:22.604815 136042 net.cpp:287] conv1 needs backward computation.
I1108 23:29:22.617055 136042 net.cpp:289] data does not need backward computation.
I1108 23:29:22.643338 136042 net.cpp:331] This network produces output loss
I1108 23:29:22.716094 136042 net.cpp:345] Network initialization done.
I1108 23:29:22.882268 136042 caffe.cpp:452] Performing Forward
I1108 23:29:35.829942 136042 caffe.cpp:457] Initial loss: 6.95103
I1108 23:29:35.881341 136042 caffe.cpp:459] Performing Backward
I1108 23:29:40.622680 136042 caffe.cpp:468] *** Benchmark begins ***
I1108 23:29:40.635798 136042 caffe.cpp:469] Testing for 1 iterations.
I1108 23:29:40.780241 136042 caffe.cpp:482] Profiling Layer: relu2 forward
I1108 23:29:42.869884 136042 caffe.cpp:512] Iteration: 1 forward-backward time: 2079 ms.
I1108 23:29:43.028981 136042 caffe.cpp:519] Average time per layer: 
I1108 23:29:43.040374 136042 caffe.cpp:522]       data	forward: 559.845 ms.
I1108 23:29:43.110437 136042 caffe.cpp:526]       data	backward: 3.358 ms.
I1108 23:29:43.133406 136042 caffe.cpp:522]      conv1	forward: 124.683 ms.
I1108 23:29:43.139469 136042 caffe.cpp:526]      conv1	backward: 27.616 ms.
I1108 23:29:43.146299 136042 caffe.cpp:522]      relu1	forward: 19.528 ms.
I1108 23:29:43.155787 136042 caffe.cpp:526]      relu1	backward: 1.026 ms.
I1108 23:29:43.163362 136042 caffe.cpp:522]      norm1	forward: 16.349 ms.
I1108 23:29:43.171031 136042 caffe.cpp:526]      norm1	backward: 3.111 ms.
I1108 23:29:43.179075 136042 caffe.cpp:522]      pool1	forward: 18.476 ms.
I1108 23:29:43.189561 136042 caffe.cpp:526]      pool1	backward: 35.8 ms.
I1108 23:29:43.197654 136042 caffe.cpp:522]      conv2	forward: 64.714 ms.
I1108 23:29:43.210206 136042 caffe.cpp:526]      conv2	backward: 31.597 ms.
I1108 23:29:43.220387 136042 caffe.cpp:522]      relu2	forward: 25.874 ms.
I1108 23:29:43.228214 136042 caffe.cpp:526]      relu2	backward: 0.718 ms.
I1108 23:29:43.240964 136042 caffe.cpp:522]      norm2	forward: 14.424 ms.
I1108 23:29:43.248247 136042 caffe.cpp:526]      norm2	backward: 2.118 ms.
I1108 23:29:43.250156 136042 caffe.cpp:522]      pool2	forward: 13.15 ms.
I1108 23:29:43.250921 136042 caffe.cpp:526]      pool2	backward: 22.418 ms.
I1108 23:29:43.251143 136042 caffe.cpp:522]      conv3	forward: 39.195 ms.
I1108 23:29:43.251337 136042 caffe.cpp:526]      conv3	backward: 36.378 ms.
I1108 23:29:43.251528 136042 caffe.cpp:522]      relu3	forward: 15.357 ms.
I1108 23:29:43.251718 136042 caffe.cpp:526]      relu3	backward: 0.665 ms.
I1108 23:29:43.251909 136042 caffe.cpp:522]      conv4	forward: 36.016 ms.
I1108 23:29:43.252135 136042 caffe.cpp:526]      conv4	backward: 28.094 ms.
I1108 23:29:43.252343 136042 caffe.cpp:522]      relu4	forward: 14.143 ms.
I1108 23:29:43.252666 136042 caffe.cpp:526]      relu4	backward: 7.006 ms.
I1108 23:29:43.252960 136042 caffe.cpp:522]      conv5	forward: 34.944 ms.
I1108 23:29:43.253155 136042 caffe.cpp:526]      conv5	backward: 18.773 ms.
I1108 23:29:43.253346 136042 caffe.cpp:522]      relu5	forward: 13.963 ms.
I1108 23:29:43.253535 136042 caffe.cpp:526]      relu5	backward: 1.797 ms.
I1108 23:29:43.253721 136042 caffe.cpp:522]      pool5	forward: 11.417 ms.
I1108 23:29:43.253911 136042 caffe.cpp:526]      pool5	backward: 58.688 ms.
I1108 23:29:43.254101 136042 caffe.cpp:522]        fc6	forward: 45.295 ms.
I1108 23:29:43.254290 136042 caffe.cpp:526]        fc6	backward: 85.203 ms.
I1108 23:29:43.254480 136042 caffe.cpp:522]      relu6	forward: 21.09 ms.
I1108 23:29:43.254670 136042 caffe.cpp:526]      relu6	backward: 12.304 ms.
I1108 23:29:43.254896 136042 caffe.cpp:522]      drop6	forward: 27.744 ms.
I1108 23:29:43.255101 136042 caffe.cpp:526]      drop6	backward: 10.682 ms.
I1108 23:29:43.257510 136042 caffe.cpp:522]        fc7	forward: 15.409 ms.
I1108 23:29:43.257779 136042 caffe.cpp:526]        fc7	backward: 115.243 ms.
I1108 23:29:43.260195 136042 caffe.cpp:522]      relu7	forward: 17.695 ms.
I1108 23:29:43.260473 136042 caffe.cpp:526]      relu7	backward: 15.562 ms.
I1108 23:29:43.260829 136042 caffe.cpp:522]      drop7	forward: 33.998 ms.
I1108 23:29:43.261116 136042 caffe.cpp:526]      drop7	backward: 12.491 ms.
I1108 23:29:43.261404 136042 caffe.cpp:522]        fc8	forward: 18.602 ms.
I1108 23:29:43.261595 136042 caffe.cpp:526]        fc8	backward: 144.65 ms.
I1108 23:29:43.261787 136042 caffe.cpp:522]       loss	forward: 49.27 ms.
I1108 23:29:43.261976 136042 caffe.cpp:526]       loss	backward: 59.83 ms.
I1108 23:29:43.267531 136042 caffe.cpp:532] Average Forward pass: 1305.34 ms.
I1108 23:29:43.280266 136042 caffe.cpp:535] Average Backward pass: 746.047 ms.
I1108 23:29:43.290901 136042 caffe.cpp:537] Average Forward-Backward: 2586 ms.
I1108 23:29:43.306850 136042 caffe.cpp:540] Total Time: 2586 ms.
I1108 23:29:43.319012 136042 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 373248
elements_fp_double_1 = 0
elements_fp_double_2 = 373248
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 5971969
--->Total double-precision FLOPs = 746496
--->Total FLOPs = 6718465
mem-read-1 = 20300
mem-read-2 = 34
mem-read-4 = 163224
mem-read-8 = 227313
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 746513
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 568
mem-write-8 = 22380
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 373249
--->Total Bytes read = 50268632
--->Total Bytes written = 24069364
--->Total Bytes = 74337996
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer7_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=7 -prof_forward_direction=1
I1108 23:33:10.965839 136200 caffe.cpp:444] Use CPU.
I1108 23:33:27.840581 136200 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:33:27.896409 136200 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:33:27.908488 136200 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:33:27.921042 136200 cpu_info.cpp:461] Total number of processors: 272
I1108 23:33:27.932044 136200 cpu_info.cpp:464] GPU is used: no
I1108 23:33:27.941155 136200 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:33:27.949961 136200 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:33:27.960986 136200 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:33:36.693640 136200 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:33:36.726241 136200 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:33:37.363250 136200 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:33:39.809267 136200 layer_factory.hpp:114] Creating layer data
I1108 23:33:39.957386 136200 net.cpp:160] Creating Layer data
I1108 23:33:40.005403 136200 net.cpp:570] data -> data
I1108 23:33:40.474656 136200 net.cpp:570] data -> label
I1108 23:33:47.514199 136200 net.cpp:210] Setting up data
I1108 23:33:47.594912 136200 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:33:47.699923 136200 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:33:47.707167 136200 net.cpp:225] Memory required for data: 19787264
I1108 23:33:47.774557 136200 layer_factory.hpp:114] Creating layer conv1
I1108 23:33:48.103922 136200 net.cpp:160] Creating Layer conv1
I1108 23:33:48.153722 136200 net.cpp:596] conv1 <- data
I1108 23:33:48.272475 136200 net.cpp:570] conv1 -> conv1
I1108 23:34:21.469156 136200 net.cpp:210] Setting up conv1
I1108 23:34:21.475579 136200 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:34:21.475951 136200 net.cpp:225] Memory required for data: 56958464
I1108 23:34:21.759156 136200 layer_factory.hpp:114] Creating layer relu1
I1108 23:34:21.881623 136200 net.cpp:160] Creating Layer relu1
I1108 23:34:21.886256 136200 net.cpp:596] relu1 <- conv1
I1108 23:34:21.919867 136200 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:34:22.109496 136200 net.cpp:210] Setting up relu1
I1108 23:34:22.111873 136200 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:34:22.112206 136200 net.cpp:225] Memory required for data: 94129664
I1108 23:34:22.112442 136200 layer_factory.hpp:114] Creating layer norm1
I1108 23:34:22.217115 136200 net.cpp:160] Creating Layer norm1
I1108 23:34:22.217460 136200 net.cpp:596] norm1 <- conv1
I1108 23:34:22.220015 136200 net.cpp:570] norm1 -> norm1
I1108 23:34:22.443984 136200 net.cpp:210] Setting up norm1
I1108 23:34:22.456771 136200 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:34:22.457191 136200 net.cpp:225] Memory required for data: 131300864
I1108 23:34:22.457489 136200 layer_factory.hpp:114] Creating layer pool1
I1108 23:34:22.550849 136200 net.cpp:160] Creating Layer pool1
I1108 23:34:22.551162 136200 net.cpp:596] pool1 <- norm1
I1108 23:34:22.566001 136200 net.cpp:570] pool1 -> pool1
I1108 23:34:22.872593 136200 net.cpp:210] Setting up pool1
I1108 23:34:22.875124 136200 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:34:22.875481 136200 net.cpp:225] Memory required for data: 140258816
I1108 23:34:22.875699 136200 layer_factory.hpp:114] Creating layer conv2
I1108 23:34:22.876088 136200 net.cpp:160] Creating Layer conv2
I1108 23:34:22.876307 136200 net.cpp:596] conv2 <- pool1
I1108 23:34:22.876536 136200 net.cpp:570] conv2 -> conv2
I1108 23:34:28.657194 136200 net.cpp:210] Setting up conv2
I1108 23:34:28.657527 136200 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:34:28.657917 136200 net.cpp:225] Memory required for data: 164146688
I1108 23:34:28.708454 136200 layer_factory.hpp:114] Creating layer relu2
I1108 23:34:28.708976 136200 net.cpp:160] Creating Layer relu2
I1108 23:34:28.709309 136200 net.cpp:596] relu2 <- conv2
I1108 23:34:28.709578 136200 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:34:28.710062 136200 net.cpp:210] Setting up relu2
I1108 23:34:28.710347 136200 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:34:28.710593 136200 net.cpp:225] Memory required for data: 188034560
I1108 23:34:28.710793 136200 layer_factory.hpp:114] Creating layer norm2
I1108 23:34:28.711050 136200 net.cpp:160] Creating Layer norm2
I1108 23:34:28.711266 136200 net.cpp:596] norm2 <- conv2
I1108 23:34:28.711524 136200 net.cpp:570] norm2 -> norm2
I1108 23:34:28.713685 136200 net.cpp:210] Setting up norm2
I1108 23:34:28.713994 136200 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:34:28.714263 136200 net.cpp:225] Memory required for data: 211922432
I1108 23:34:28.714483 136200 layer_factory.hpp:114] Creating layer pool2
I1108 23:34:28.715466 136200 net.cpp:160] Creating Layer pool2
I1108 23:34:28.715749 136200 net.cpp:596] pool2 <- norm2
I1108 23:34:28.715989 136200 net.cpp:570] pool2 -> pool2
I1108 23:34:28.716387 136200 net.cpp:210] Setting up pool2
I1108 23:34:28.716629 136200 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:34:28.716930 136200 net.cpp:225] Memory required for data: 217460224
I1108 23:34:28.717152 136200 layer_factory.hpp:114] Creating layer conv3
I1108 23:34:28.717687 136200 net.cpp:160] Creating Layer conv3
I1108 23:34:28.718025 136200 net.cpp:596] conv3 <- pool2
I1108 23:34:28.718266 136200 net.cpp:570] conv3 -> conv3
I1108 23:34:29.195520 136200 net.cpp:210] Setting up conv3
I1108 23:34:29.197897 136200 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:34:29.198247 136200 net.cpp:225] Memory required for data: 225766912
I1108 23:34:29.201287 136200 layer_factory.hpp:114] Creating layer relu3
I1108 23:34:29.201699 136200 net.cpp:160] Creating Layer relu3
I1108 23:34:29.201962 136200 net.cpp:596] relu3 <- conv3
I1108 23:34:29.202216 136200 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:34:29.206374 136200 net.cpp:210] Setting up relu3
I1108 23:34:29.206688 136200 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:34:29.206950 136200 net.cpp:225] Memory required for data: 234073600
I1108 23:34:29.207157 136200 layer_factory.hpp:114] Creating layer conv4
I1108 23:34:29.207538 136200 net.cpp:160] Creating Layer conv4
I1108 23:34:29.207809 136200 net.cpp:596] conv4 <- conv3
I1108 23:34:29.208070 136200 net.cpp:570] conv4 -> conv4
I1108 23:34:29.448298 136200 net.cpp:210] Setting up conv4
I1108 23:34:29.448686 136200 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:34:29.449131 136200 net.cpp:225] Memory required for data: 242380288
I1108 23:34:29.449465 136200 layer_factory.hpp:114] Creating layer relu4
I1108 23:34:29.449769 136200 net.cpp:160] Creating Layer relu4
I1108 23:34:29.450002 136200 net.cpp:596] relu4 <- conv4
I1108 23:34:29.450254 136200 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:34:29.462384 136200 net.cpp:210] Setting up relu4
I1108 23:34:29.462725 136200 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:34:29.463096 136200 net.cpp:225] Memory required for data: 250686976
I1108 23:34:29.463340 136200 layer_factory.hpp:114] Creating layer conv5
I1108 23:34:29.463706 136200 net.cpp:160] Creating Layer conv5
I1108 23:34:29.463939 136200 net.cpp:596] conv5 <- conv4
I1108 23:34:29.464181 136200 net.cpp:570] conv5 -> conv5
I1108 23:34:29.659462 136200 net.cpp:210] Setting up conv5
I1108 23:34:29.659855 136200 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:34:29.660297 136200 net.cpp:225] Memory required for data: 256224768
I1108 23:34:29.664988 136200 layer_factory.hpp:114] Creating layer relu5
I1108 23:34:29.665402 136200 net.cpp:160] Creating Layer relu5
I1108 23:34:29.665681 136200 net.cpp:596] relu5 <- conv5
I1108 23:34:29.665951 136200 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:34:29.666406 136200 net.cpp:210] Setting up relu5
I1108 23:34:29.666697 136200 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:34:29.666949 136200 net.cpp:225] Memory required for data: 261762560
I1108 23:34:29.667165 136200 layer_factory.hpp:114] Creating layer pool5
I1108 23:34:29.667469 136200 net.cpp:160] Creating Layer pool5
I1108 23:34:29.667696 136200 net.cpp:596] pool5 <- conv5
I1108 23:34:29.667994 136200 net.cpp:570] pool5 -> pool5
I1108 23:34:29.668427 136200 net.cpp:210] Setting up pool5
I1108 23:34:29.668685 136200 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:34:29.668990 136200 net.cpp:225] Memory required for data: 262942208
I1108 23:34:29.669186 136200 layer_factory.hpp:114] Creating layer fc6
I1108 23:34:29.723719 136200 net.cpp:160] Creating Layer fc6
I1108 23:34:29.724030 136200 net.cpp:596] fc6 <- pool5
I1108 23:34:29.724396 136200 net.cpp:570] fc6 -> fc6
I1108 23:34:33.815064 136200 net.cpp:210] Setting up fc6
I1108 23:34:33.815369 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:33.817534 136200 net.cpp:225] Memory required for data: 263466496
I1108 23:34:33.817873 136200 layer_factory.hpp:114] Creating layer relu6
I1108 23:34:33.820320 136200 net.cpp:160] Creating Layer relu6
I1108 23:34:33.820616 136200 net.cpp:596] relu6 <- fc6
I1108 23:34:33.820883 136200 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:34:33.821322 136200 net.cpp:210] Setting up relu6
I1108 23:34:33.821580 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:33.821802 136200 net.cpp:225] Memory required for data: 263990784
I1108 23:34:33.821985 136200 layer_factory.hpp:114] Creating layer drop6
I1108 23:34:33.841861 136200 net.cpp:160] Creating Layer drop6
I1108 23:34:33.842165 136200 net.cpp:596] drop6 <- fc6
I1108 23:34:33.842556 136200 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:34:33.947190 136200 net.cpp:210] Setting up drop6
I1108 23:34:33.947484 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:33.947821 136200 net.cpp:225] Memory required for data: 264515072
I1108 23:34:33.948058 136200 layer_factory.hpp:114] Creating layer fc7
I1108 23:34:33.948323 136200 net.cpp:160] Creating Layer fc7
I1108 23:34:33.948530 136200 net.cpp:596] fc7 <- fc6
I1108 23:34:33.948956 136200 net.cpp:570] fc7 -> fc7
I1108 23:34:35.660156 136200 net.cpp:210] Setting up fc7
I1108 23:34:35.660511 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:35.660992 136200 net.cpp:225] Memory required for data: 265039360
I1108 23:34:35.661406 136200 layer_factory.hpp:114] Creating layer relu7
I1108 23:34:35.661761 136200 net.cpp:160] Creating Layer relu7
I1108 23:34:35.662020 136200 net.cpp:596] relu7 <- fc7
I1108 23:34:35.662289 136200 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:34:35.662755 136200 net.cpp:210] Setting up relu7
I1108 23:34:35.663074 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:35.663339 136200 net.cpp:225] Memory required for data: 265563648
I1108 23:34:35.663558 136200 layer_factory.hpp:114] Creating layer drop7
I1108 23:34:35.663842 136200 net.cpp:160] Creating Layer drop7
I1108 23:34:35.664055 136200 net.cpp:596] drop7 <- fc7
I1108 23:34:35.664306 136200 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:34:35.664587 136200 net.cpp:210] Setting up drop7
I1108 23:34:35.664841 136200 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:34:35.665083 136200 net.cpp:225] Memory required for data: 266087936
I1108 23:34:35.665274 136200 layer_factory.hpp:114] Creating layer fc8
I1108 23:34:35.665530 136200 net.cpp:160] Creating Layer fc8
I1108 23:34:35.665730 136200 net.cpp:596] fc8 <- fc7
I1108 23:34:35.665997 136200 net.cpp:570] fc8 -> fc8
I1108 23:34:36.088194 136200 net.cpp:210] Setting up fc8
I1108 23:34:36.088547 136200 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:34:36.089009 136200 net.cpp:225] Memory required for data: 266215936
I1108 23:34:36.089324 136200 layer_factory.hpp:114] Creating layer loss
I1108 23:34:36.114132 136200 net.cpp:160] Creating Layer loss
I1108 23:34:36.114445 136200 net.cpp:596] loss <- fc8
I1108 23:34:36.115386 136200 net.cpp:596] loss <- label
I1108 23:34:36.142833 136200 net.cpp:570] loss -> loss
I1108 23:34:36.180752 136200 layer_factory.hpp:114] Creating layer loss
I1108 23:34:38.755259 136200 net.cpp:210] Setting up loss
I1108 23:34:38.810443 136200 net.cpp:217] Top shape: (1)
I1108 23:34:38.820009 136200 net.cpp:220]     with loss weight 1
I1108 23:34:38.953586 136200 net.cpp:225] Memory required for data: 266215940
I1108 23:34:38.996632 136200 net.cpp:287] loss needs backward computation.
I1108 23:34:39.085683 136200 net.cpp:287] fc8 needs backward computation.
I1108 23:34:39.093225 136200 net.cpp:287] drop7 needs backward computation.
I1108 23:34:39.104473 136200 net.cpp:287] relu7 needs backward computation.
I1108 23:34:39.104856 136200 net.cpp:287] fc7 needs backward computation.
I1108 23:34:39.107429 136200 net.cpp:287] drop6 needs backward computation.
I1108 23:34:39.107832 136200 net.cpp:287] relu6 needs backward computation.
I1108 23:34:39.108129 136200 net.cpp:287] fc6 needs backward computation.
I1108 23:34:39.108855 136200 net.cpp:287] pool5 needs backward computation.
I1108 23:34:39.109629 136200 net.cpp:287] relu5 needs backward computation.
I1108 23:34:39.109904 136200 net.cpp:287] conv5 needs backward computation.
I1108 23:34:39.110141 136200 net.cpp:287] relu4 needs backward computation.
I1108 23:34:39.110368 136200 net.cpp:287] conv4 needs backward computation.
I1108 23:34:39.110679 136200 net.cpp:287] relu3 needs backward computation.
I1108 23:34:39.110910 136200 net.cpp:287] conv3 needs backward computation.
I1108 23:34:39.123452 136200 net.cpp:287] pool2 needs backward computation.
I1108 23:34:39.123805 136200 net.cpp:287] norm2 needs backward computation.
I1108 23:34:39.124176 136200 net.cpp:287] relu2 needs backward computation.
I1108 23:34:39.124415 136200 net.cpp:287] conv2 needs backward computation.
I1108 23:34:39.124603 136200 net.cpp:287] pool1 needs backward computation.
I1108 23:34:39.124816 136200 net.cpp:287] norm1 needs backward computation.
I1108 23:34:39.125005 136200 net.cpp:287] relu1 needs backward computation.
I1108 23:34:39.125180 136200 net.cpp:287] conv1 needs backward computation.
I1108 23:34:39.137658 136200 net.cpp:289] data does not need backward computation.
I1108 23:34:39.163208 136200 net.cpp:331] This network produces output loss
I1108 23:34:39.235715 136200 net.cpp:345] Network initialization done.
I1108 23:34:39.404011 136200 caffe.cpp:452] Performing Forward
I1108 23:34:52.331758 136200 caffe.cpp:457] Initial loss: 7.00284
I1108 23:34:52.386672 136200 caffe.cpp:459] Performing Backward
I1108 23:34:57.132597 136200 caffe.cpp:468] *** Benchmark begins ***
I1108 23:34:57.140506 136200 caffe.cpp:469] Testing for 1 iterations.
I1108 23:34:57.288321 136200 caffe.cpp:482] Profiling Layer: norm2 forward
I1108 23:34:59.512948 136200 caffe.cpp:512] Iteration: 1 forward-backward time: 2215 ms.
I1108 23:34:59.675557 136200 caffe.cpp:519] Average time per layer: 
I1108 23:34:59.692878 136200 caffe.cpp:522]       data	forward: 547.358 ms.
I1108 23:34:59.767884 136200 caffe.cpp:526]       data	backward: 3.619 ms.
I1108 23:34:59.783711 136200 caffe.cpp:522]      conv1	forward: 141.954 ms.
I1108 23:34:59.788957 136200 caffe.cpp:526]      conv1	backward: 21.319 ms.
I1108 23:34:59.793292 136200 caffe.cpp:522]      relu1	forward: 17.063 ms.
I1108 23:34:59.794335 136200 caffe.cpp:526]      relu1	backward: 1.031 ms.
I1108 23:34:59.794652 136200 caffe.cpp:522]      norm1	forward: 23.45 ms.
I1108 23:34:59.794996 136200 caffe.cpp:526]      norm1	backward: 3.105 ms.
I1108 23:34:59.795202 136200 caffe.cpp:522]      pool1	forward: 21.565 ms.
I1108 23:34:59.795400 136200 caffe.cpp:526]      pool1	backward: 35.682 ms.
I1108 23:34:59.795598 136200 caffe.cpp:522]      conv2	forward: 63.185 ms.
I1108 23:34:59.795791 136200 caffe.cpp:526]      conv2	backward: 31.486 ms.
I1108 23:34:59.795984 136200 caffe.cpp:522]      relu2	forward: 18.213 ms.
I1108 23:34:59.796176 136200 caffe.cpp:526]      relu2	backward: 0.735 ms.
I1108 23:34:59.796366 136200 caffe.cpp:522]      norm2	forward: 29.269 ms.
I1108 23:34:59.796557 136200 caffe.cpp:526]      norm2	backward: 2.316 ms.
I1108 23:34:59.796744 136200 caffe.cpp:522]      pool2	forward: 13.348 ms.
I1108 23:34:59.797025 136200 caffe.cpp:526]      pool2	backward: 22.345 ms.
I1108 23:34:59.797264 136200 caffe.cpp:522]      conv3	forward: 38.982 ms.
I1108 23:34:59.797533 136200 caffe.cpp:526]      conv3	backward: 36.28 ms.
I1108 23:34:59.797731 136200 caffe.cpp:522]      relu3	forward: 11.197 ms.
I1108 23:34:59.797926 136200 caffe.cpp:526]      relu3	backward: 0.811 ms.
I1108 23:34:59.798118 136200 caffe.cpp:522]      conv4	forward: 35.093 ms.
I1108 23:34:59.798310 136200 caffe.cpp:526]      conv4	backward: 59.631 ms.
I1108 23:34:59.798501 136200 caffe.cpp:522]      relu4	forward: 17.213 ms.
I1108 23:34:59.798693 136200 caffe.cpp:526]      relu4	backward: 53.958 ms.
I1108 23:34:59.798883 136200 caffe.cpp:522]      conv5	forward: 30.292 ms.
I1108 23:34:59.799075 136200 caffe.cpp:526]      conv5	backward: 63.291 ms.
I1108 23:34:59.799266 136200 caffe.cpp:522]      relu5	forward: 19.506 ms.
I1108 23:34:59.799489 136200 caffe.cpp:526]      relu5	backward: 11.446 ms.
I1108 23:34:59.799695 136200 caffe.cpp:522]      pool5	forward: 17.749 ms.
I1108 23:34:59.799942 136200 caffe.cpp:526]      pool5	backward: 54.334 ms.
I1108 23:34:59.800254 136200 caffe.cpp:522]        fc6	forward: 49.391 ms.
I1108 23:34:59.800449 136200 caffe.cpp:526]        fc6	backward: 89.165 ms.
I1108 23:34:59.801270 136200 caffe.cpp:522]      relu6	forward: 15.456 ms.
I1108 23:34:59.801501 136200 caffe.cpp:526]      relu6	backward: 13.175 ms.
I1108 23:34:59.801697 136200 caffe.cpp:522]      drop6	forward: 32.171 ms.
I1108 23:34:59.801890 136200 caffe.cpp:526]      drop6	backward: 14.091 ms.
I1108 23:34:59.802083 136200 caffe.cpp:522]        fc7	forward: 13.518 ms.
I1108 23:34:59.802273 136200 caffe.cpp:526]        fc7	backward: 92.655 ms.
I1108 23:34:59.802464 136200 caffe.cpp:522]      relu7	forward: 12.899 ms.
I1108 23:34:59.802655 136200 caffe.cpp:526]      relu7	backward: 9.999 ms.
I1108 23:34:59.803642 136200 caffe.cpp:522]      drop7	forward: 45.89 ms.
I1108 23:34:59.803899 136200 caffe.cpp:526]      drop7	backward: 12.31 ms.
I1108 23:34:59.804128 136200 caffe.cpp:522]        fc8	forward: 15.711 ms.
I1108 23:34:59.804322 136200 caffe.cpp:526]        fc8	backward: 124.304 ms.
I1108 23:34:59.804517 136200 caffe.cpp:522]       loss	forward: 59.131 ms.
I1108 23:34:59.804708 136200 caffe.cpp:526]       loss	backward: 77.492 ms.
I1108 23:34:59.810405 136200 caffe.cpp:532] Average Forward pass: 1346.94 ms.
I1108 23:34:59.823614 136200 caffe.cpp:535] Average Backward pass: 843.824 ms.
I1108 23:34:59.834424 136200 caffe.cpp:537] Average Forward-Backward: 2629 ms.
I1108 23:34:59.849220 136200 caffe.cpp:540] Total Time: 2629 ms.
I1108 23:34:59.861557 136200 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 11570688
elements_fp_double_1 = 0
elements_fp_double_2 = 373248
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 185131009
--->Total double-precision FLOPs = 746496
--->Total FLOPs = 185877505
mem-read-1 = 24492
mem-read-2 = 34
mem-read-4 = 4767667
mem-read-8 = 779065
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 1819588
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 59640
mem-write-8 = 40686
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 2262818
--->Total Bytes read = 141781412
--->Total Bytes written = 145384516
--->Total Bytes = 287165928
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer8_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=8 -prof_forward_direction=1
I1108 23:38:33.219743 136316 caffe.cpp:444] Use CPU.
I1108 23:38:50.088093 136316 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:38:50.143621 136316 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:38:50.155551 136316 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:38:50.168977 136316 cpu_info.cpp:461] Total number of processors: 272
I1108 23:38:50.180160 136316 cpu_info.cpp:464] GPU is used: no
I1108 23:38:50.189246 136316 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:38:50.197980 136316 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:38:50.208936 136316 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:38:58.912706 136316 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:38:58.945243 136316 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:38:59.579664 136316 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:39:02.019531 136316 layer_factory.hpp:114] Creating layer data
I1108 23:39:02.165750 136316 net.cpp:160] Creating Layer data
I1108 23:39:02.214783 136316 net.cpp:570] data -> data
I1108 23:39:02.677785 136316 net.cpp:570] data -> label
I1108 23:39:09.677114 136316 net.cpp:210] Setting up data
I1108 23:39:09.757635 136316 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:39:09.861387 136316 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:39:09.868643 136316 net.cpp:225] Memory required for data: 19787264
I1108 23:39:09.937053 136316 layer_factory.hpp:114] Creating layer conv1
I1108 23:39:10.263151 136316 net.cpp:160] Creating Layer conv1
I1108 23:39:10.315088 136316 net.cpp:596] conv1 <- data
I1108 23:39:10.436343 136316 net.cpp:570] conv1 -> conv1
I1108 23:39:43.213452 136316 net.cpp:210] Setting up conv1
I1108 23:39:43.220305 136316 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:39:43.220705 136316 net.cpp:225] Memory required for data: 56958464
I1108 23:39:43.500033 136316 layer_factory.hpp:114] Creating layer relu1
I1108 23:39:43.624229 136316 net.cpp:160] Creating Layer relu1
I1108 23:39:43.628837 136316 net.cpp:596] relu1 <- conv1
I1108 23:39:43.662266 136316 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:39:43.850898 136316 net.cpp:210] Setting up relu1
I1108 23:39:43.853409 136316 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:39:43.853751 136316 net.cpp:225] Memory required for data: 94129664
I1108 23:39:43.854001 136316 layer_factory.hpp:114] Creating layer norm1
I1108 23:39:43.960044 136316 net.cpp:160] Creating Layer norm1
I1108 23:39:43.960361 136316 net.cpp:596] norm1 <- conv1
I1108 23:39:43.962939 136316 net.cpp:570] norm1 -> norm1
I1108 23:39:44.184597 136316 net.cpp:210] Setting up norm1
I1108 23:39:44.197469 136316 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:39:44.197839 136316 net.cpp:225] Memory required for data: 131300864
I1108 23:39:44.198148 136316 layer_factory.hpp:114] Creating layer pool1
I1108 23:39:44.291127 136316 net.cpp:160] Creating Layer pool1
I1108 23:39:44.291440 136316 net.cpp:596] pool1 <- norm1
I1108 23:39:44.306047 136316 net.cpp:570] pool1 -> pool1
I1108 23:39:44.606139 136316 net.cpp:210] Setting up pool1
I1108 23:39:44.608667 136316 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:39:44.609081 136316 net.cpp:225] Memory required for data: 140258816
I1108 23:39:44.609313 136316 layer_factory.hpp:114] Creating layer conv2
I1108 23:39:44.609688 136316 net.cpp:160] Creating Layer conv2
I1108 23:39:44.609912 136316 net.cpp:596] conv2 <- pool1
I1108 23:39:44.610162 136316 net.cpp:570] conv2 -> conv2
I1108 23:39:50.363009 136316 net.cpp:210] Setting up conv2
I1108 23:39:50.363319 136316 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:39:50.363675 136316 net.cpp:225] Memory required for data: 164146688
I1108 23:39:50.413293 136316 layer_factory.hpp:114] Creating layer relu2
I1108 23:39:50.413703 136316 net.cpp:160] Creating Layer relu2
I1108 23:39:50.414028 136316 net.cpp:596] relu2 <- conv2
I1108 23:39:50.414319 136316 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:39:50.414741 136316 net.cpp:210] Setting up relu2
I1108 23:39:50.415000 136316 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:39:50.415232 136316 net.cpp:225] Memory required for data: 188034560
I1108 23:39:50.415424 136316 layer_factory.hpp:114] Creating layer norm2
I1108 23:39:50.415671 136316 net.cpp:160] Creating Layer norm2
I1108 23:39:50.415864 136316 net.cpp:596] norm2 <- conv2
I1108 23:39:50.416097 136316 net.cpp:570] norm2 -> norm2
I1108 23:39:50.418153 136316 net.cpp:210] Setting up norm2
I1108 23:39:50.418476 136316 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:39:50.418722 136316 net.cpp:225] Memory required for data: 211922432
I1108 23:39:50.418925 136316 layer_factory.hpp:114] Creating layer pool2
I1108 23:39:50.419764 136316 net.cpp:160] Creating Layer pool2
I1108 23:39:50.420071 136316 net.cpp:596] pool2 <- norm2
I1108 23:39:50.420397 136316 net.cpp:570] pool2 -> pool2
I1108 23:39:50.420871 136316 net.cpp:210] Setting up pool2
I1108 23:39:50.421162 136316 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:39:50.421383 136316 net.cpp:225] Memory required for data: 217460224
I1108 23:39:50.421579 136316 layer_factory.hpp:114] Creating layer conv3
I1108 23:39:50.421962 136316 net.cpp:160] Creating Layer conv3
I1108 23:39:50.422211 136316 net.cpp:596] conv3 <- pool2
I1108 23:39:50.422451 136316 net.cpp:570] conv3 -> conv3
I1108 23:39:50.900820 136316 net.cpp:210] Setting up conv3
I1108 23:39:50.903215 136316 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:39:50.903550 136316 net.cpp:225] Memory required for data: 225766912
I1108 23:39:50.906704 136316 layer_factory.hpp:114] Creating layer relu3
I1108 23:39:50.907155 136316 net.cpp:160] Creating Layer relu3
I1108 23:39:50.907414 136316 net.cpp:596] relu3 <- conv3
I1108 23:39:50.907688 136316 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:39:50.911741 136316 net.cpp:210] Setting up relu3
I1108 23:39:50.912045 136316 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:39:50.912293 136316 net.cpp:225] Memory required for data: 234073600
I1108 23:39:50.912489 136316 layer_factory.hpp:114] Creating layer conv4
I1108 23:39:50.912932 136316 net.cpp:160] Creating Layer conv4
I1108 23:39:50.913215 136316 net.cpp:596] conv4 <- conv3
I1108 23:39:50.913503 136316 net.cpp:570] conv4 -> conv4
I1108 23:39:51.182595 136316 net.cpp:210] Setting up conv4
I1108 23:39:51.182974 136316 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:39:51.183360 136316 net.cpp:225] Memory required for data: 242380288
I1108 23:39:51.183699 136316 layer_factory.hpp:114] Creating layer relu4
I1108 23:39:51.183980 136316 net.cpp:160] Creating Layer relu4
I1108 23:39:51.184208 136316 net.cpp:596] relu4 <- conv4
I1108 23:39:51.184442 136316 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:39:51.197065 136316 net.cpp:210] Setting up relu4
I1108 23:39:51.197432 136316 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:39:51.197803 136316 net.cpp:225] Memory required for data: 250686976
I1108 23:39:51.198051 136316 layer_factory.hpp:114] Creating layer conv5
I1108 23:39:51.198421 136316 net.cpp:160] Creating Layer conv5
I1108 23:39:51.198655 136316 net.cpp:596] conv5 <- conv4
I1108 23:39:51.198902 136316 net.cpp:570] conv5 -> conv5
I1108 23:39:51.366924 136316 net.cpp:210] Setting up conv5
I1108 23:39:51.367308 136316 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:39:51.367707 136316 net.cpp:225] Memory required for data: 256224768
I1108 23:39:51.372372 136316 layer_factory.hpp:114] Creating layer relu5
I1108 23:39:51.372818 136316 net.cpp:160] Creating Layer relu5
I1108 23:39:51.373091 136316 net.cpp:596] relu5 <- conv5
I1108 23:39:51.373375 136316 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:39:51.373849 136316 net.cpp:210] Setting up relu5
I1108 23:39:51.374145 136316 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:39:51.374483 136316 net.cpp:225] Memory required for data: 261762560
I1108 23:39:51.374696 136316 layer_factory.hpp:114] Creating layer pool5
I1108 23:39:51.374959 136316 net.cpp:160] Creating Layer pool5
I1108 23:39:51.375167 136316 net.cpp:596] pool5 <- conv5
I1108 23:39:51.375396 136316 net.cpp:570] pool5 -> pool5
I1108 23:39:51.375792 136316 net.cpp:210] Setting up pool5
I1108 23:39:51.376049 136316 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:39:51.376276 136316 net.cpp:225] Memory required for data: 262942208
I1108 23:39:51.376503 136316 layer_factory.hpp:114] Creating layer fc6
I1108 23:39:51.432492 136316 net.cpp:160] Creating Layer fc6
I1108 23:39:51.432858 136316 net.cpp:596] fc6 <- pool5
I1108 23:39:51.433219 136316 net.cpp:570] fc6 -> fc6
I1108 23:39:55.544816 136316 net.cpp:210] Setting up fc6
I1108 23:39:55.545204 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:55.547319 136316 net.cpp:225] Memory required for data: 263466496
I1108 23:39:55.547636 136316 layer_factory.hpp:114] Creating layer relu6
I1108 23:39:55.550217 136316 net.cpp:160] Creating Layer relu6
I1108 23:39:55.550519 136316 net.cpp:596] relu6 <- fc6
I1108 23:39:55.550755 136316 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:39:55.551172 136316 net.cpp:210] Setting up relu6
I1108 23:39:55.551437 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:55.551709 136316 net.cpp:225] Memory required for data: 263990784
I1108 23:39:55.551916 136316 layer_factory.hpp:114] Creating layer drop6
I1108 23:39:55.572268 136316 net.cpp:160] Creating Layer drop6
I1108 23:39:55.572572 136316 net.cpp:596] drop6 <- fc6
I1108 23:39:55.573011 136316 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:39:55.677805 136316 net.cpp:210] Setting up drop6
I1108 23:39:55.678097 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:55.678442 136316 net.cpp:225] Memory required for data: 264515072
I1108 23:39:55.678690 136316 layer_factory.hpp:114] Creating layer fc7
I1108 23:39:55.678961 136316 net.cpp:160] Creating Layer fc7
I1108 23:39:55.679167 136316 net.cpp:596] fc7 <- fc6
I1108 23:39:55.679544 136316 net.cpp:570] fc7 -> fc7
I1108 23:39:57.402263 136316 net.cpp:210] Setting up fc7
I1108 23:39:57.402628 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:57.403046 136316 net.cpp:225] Memory required for data: 265039360
I1108 23:39:57.403415 136316 layer_factory.hpp:114] Creating layer relu7
I1108 23:39:57.403740 136316 net.cpp:160] Creating Layer relu7
I1108 23:39:57.403995 136316 net.cpp:596] relu7 <- fc7
I1108 23:39:57.404253 136316 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:39:57.404695 136316 net.cpp:210] Setting up relu7
I1108 23:39:57.405072 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:57.405338 136316 net.cpp:225] Memory required for data: 265563648
I1108 23:39:57.405553 136316 layer_factory.hpp:114] Creating layer drop7
I1108 23:39:57.405809 136316 net.cpp:160] Creating Layer drop7
I1108 23:39:57.406051 136316 net.cpp:596] drop7 <- fc7
I1108 23:39:57.406293 136316 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:39:57.406570 136316 net.cpp:210] Setting up drop7
I1108 23:39:57.406776 136316 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:39:57.406996 136316 net.cpp:225] Memory required for data: 266087936
I1108 23:39:57.407183 136316 layer_factory.hpp:114] Creating layer fc8
I1108 23:39:57.407438 136316 net.cpp:160] Creating Layer fc8
I1108 23:39:57.407636 136316 net.cpp:596] fc8 <- fc7
I1108 23:39:57.407866 136316 net.cpp:570] fc8 -> fc8
I1108 23:39:57.832099 136316 net.cpp:210] Setting up fc8
I1108 23:39:57.832455 136316 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:39:57.832871 136316 net.cpp:225] Memory required for data: 266215936
I1108 23:39:57.833210 136316 layer_factory.hpp:114] Creating layer loss
I1108 23:39:57.857969 136316 net.cpp:160] Creating Layer loss
I1108 23:39:57.858285 136316 net.cpp:596] loss <- fc8
I1108 23:39:57.859282 136316 net.cpp:596] loss <- label
I1108 23:39:57.886967 136316 net.cpp:570] loss -> loss
I1108 23:39:57.926080 136316 layer_factory.hpp:114] Creating layer loss
I1108 23:40:00.463618 136316 net.cpp:210] Setting up loss
I1108 23:40:00.506433 136316 net.cpp:217] Top shape: (1)
I1108 23:40:00.521288 136316 net.cpp:220]     with loss weight 1
I1108 23:40:00.650511 136316 net.cpp:225] Memory required for data: 266215940
I1108 23:40:00.698971 136316 net.cpp:287] loss needs backward computation.
I1108 23:40:00.799778 136316 net.cpp:287] fc8 needs backward computation.
I1108 23:40:00.814788 136316 net.cpp:287] drop7 needs backward computation.
I1108 23:40:00.827579 136316 net.cpp:287] relu7 needs backward computation.
I1108 23:40:00.827924 136316 net.cpp:287] fc7 needs backward computation.
I1108 23:40:00.830296 136316 net.cpp:287] drop6 needs backward computation.
I1108 23:40:00.830605 136316 net.cpp:287] relu6 needs backward computation.
I1108 23:40:00.830911 136316 net.cpp:287] fc6 needs backward computation.
I1108 23:40:00.831629 136316 net.cpp:287] pool5 needs backward computation.
I1108 23:40:00.832314 136316 net.cpp:287] relu5 needs backward computation.
I1108 23:40:00.832553 136316 net.cpp:287] conv5 needs backward computation.
I1108 23:40:00.832746 136316 net.cpp:287] relu4 needs backward computation.
I1108 23:40:00.832978 136316 net.cpp:287] conv4 needs backward computation.
I1108 23:40:00.833163 136316 net.cpp:287] relu3 needs backward computation.
I1108 23:40:00.833345 136316 net.cpp:287] conv3 needs backward computation.
I1108 23:40:00.845373 136316 net.cpp:287] pool2 needs backward computation.
I1108 23:40:00.845710 136316 net.cpp:287] norm2 needs backward computation.
I1108 23:40:00.846046 136316 net.cpp:287] relu2 needs backward computation.
I1108 23:40:00.846248 136316 net.cpp:287] conv2 needs backward computation.
I1108 23:40:00.846439 136316 net.cpp:287] pool1 needs backward computation.
I1108 23:40:00.846628 136316 net.cpp:287] norm1 needs backward computation.
I1108 23:40:00.846818 136316 net.cpp:287] relu1 needs backward computation.
I1108 23:40:00.847004 136316 net.cpp:287] conv1 needs backward computation.
I1108 23:40:00.859403 136316 net.cpp:289] data does not need backward computation.
I1108 23:40:00.883440 136316 net.cpp:331] This network produces output loss
I1108 23:40:00.954462 136316 net.cpp:345] Network initialization done.
I1108 23:40:01.128397 136316 caffe.cpp:452] Performing Forward
I1108 23:40:14.321318 136316 caffe.cpp:457] Initial loss: 6.892
I1108 23:40:14.368289 136316 caffe.cpp:459] Performing Backward
I1108 23:40:19.251561 136316 caffe.cpp:468] *** Benchmark begins ***
I1108 23:40:19.265091 136316 caffe.cpp:469] Testing for 1 iterations.
I1108 23:40:19.409142 136316 caffe.cpp:482] Profiling Layer: pool2 forward
I1108 23:40:21.884588 136316 caffe.cpp:512] Iteration: 1 forward-backward time: 2468 ms.
I1108 23:40:22.042552 136316 caffe.cpp:519] Average time per layer: 
I1108 23:40:22.052382 136316 caffe.cpp:522]       data	forward: 553.47 ms.
I1108 23:40:22.125288 136316 caffe.cpp:526]       data	backward: 3.667 ms.
I1108 23:40:22.148216 136316 caffe.cpp:522]      conv1	forward: 127.535 ms.
I1108 23:40:22.156450 136316 caffe.cpp:526]      conv1	backward: 24.948 ms.
I1108 23:40:22.163806 136316 caffe.cpp:522]      relu1	forward: 29.12 ms.
I1108 23:40:22.171659 136316 caffe.cpp:526]      relu1	backward: 18.398 ms.
I1108 23:40:22.179606 136316 caffe.cpp:522]      norm1	forward: 22.756 ms.
I1108 23:40:22.188946 136316 caffe.cpp:526]      norm1	backward: 18.756 ms.
I1108 23:40:22.193033 136316 caffe.cpp:522]      pool1	forward: 18.09 ms.
I1108 23:40:22.200559 136316 caffe.cpp:526]      pool1	backward: 87.682 ms.
I1108 23:40:22.210336 136316 caffe.cpp:522]      conv2	forward: 65.182 ms.
I1108 23:40:22.221879 136316 caffe.cpp:526]      conv2	backward: 77.722 ms.
I1108 23:40:22.231222 136316 caffe.cpp:522]      relu2	forward: 9.609 ms.
I1108 23:40:22.241188 136316 caffe.cpp:526]      relu2	backward: 17.796 ms.
I1108 23:40:22.246809 136316 caffe.cpp:522]      norm2	forward: 16.67 ms.
I1108 23:40:22.252295 136316 caffe.cpp:526]      norm2	backward: 13.589 ms.
I1108 23:40:22.256176 136316 caffe.cpp:522]      pool2	forward: 30.106 ms.
I1108 23:40:22.260458 136316 caffe.cpp:526]      pool2	backward: 60.935 ms.
I1108 23:40:22.264467 136316 caffe.cpp:522]      conv3	forward: 33.24 ms.
I1108 23:40:22.268646 136316 caffe.cpp:526]      conv3	backward: 77.728 ms.
I1108 23:40:22.274581 136316 caffe.cpp:522]      relu3	forward: 17.081 ms.
I1108 23:40:22.276110 136316 caffe.cpp:526]      relu3	backward: 41.934 ms.
I1108 23:40:22.276320 136316 caffe.cpp:522]      conv4	forward: 38.147 ms.
I1108 23:40:22.276513 136316 caffe.cpp:526]      conv4	backward: 73.246 ms.
I1108 23:40:22.276705 136316 caffe.cpp:522]      relu4	forward: 16.295 ms.
I1108 23:40:22.276934 136316 caffe.cpp:526]      relu4	backward: 47.687 ms.
I1108 23:40:22.277125 136316 caffe.cpp:522]      conv5	forward: 35.583 ms.
I1108 23:40:22.277317 136316 caffe.cpp:526]      conv5	backward: 54.616 ms.
I1108 23:40:22.277508 136316 caffe.cpp:522]      relu5	forward: 15.602 ms.
I1108 23:40:22.277737 136316 caffe.cpp:526]      relu5	backward: 16.182 ms.
I1108 23:40:22.277945 136316 caffe.cpp:522]      pool5	forward: 19.399 ms.
I1108 23:40:22.278242 136316 caffe.cpp:526]      pool5	backward: 41.685 ms.
I1108 23:40:22.278481 136316 caffe.cpp:522]        fc6	forward: 39.301 ms.
I1108 23:40:22.278672 136316 caffe.cpp:526]        fc6	backward: 105.188 ms.
I1108 23:40:22.278867 136316 caffe.cpp:522]      relu6	forward: 17.211 ms.
I1108 23:40:22.279058 136316 caffe.cpp:526]      relu6	backward: 19.008 ms.
I1108 23:40:22.279249 136316 caffe.cpp:522]      drop6	forward: 35.747 ms.
I1108 23:40:22.279439 136316 caffe.cpp:526]      drop6	backward: 16.743 ms.
I1108 23:40:22.279630 136316 caffe.cpp:522]        fc7	forward: 12.424 ms.
I1108 23:40:22.279820 136316 caffe.cpp:526]        fc7	backward: 76.064 ms.
I1108 23:40:22.280011 136316 caffe.cpp:522]      relu7	forward: 17.254 ms.
I1108 23:40:22.280202 136316 caffe.cpp:526]      relu7	backward: 15.598 ms.
I1108 23:40:22.280426 136316 caffe.cpp:522]      drop7	forward: 32.438 ms.
I1108 23:40:22.280629 136316 caffe.cpp:526]      drop7	backward: 16.491 ms.
I1108 23:40:22.280943 136316 caffe.cpp:522]        fc8	forward: 12.113 ms.
I1108 23:40:22.281159 136316 caffe.cpp:526]        fc8	backward: 104.537 ms.
I1108 23:40:22.281450 136316 caffe.cpp:522]       loss	forward: 58.263 ms.
I1108 23:40:22.281642 136316 caffe.cpp:526]       loss	backward: 74.265 ms.
I1108 23:40:22.287050 136316 caffe.cpp:532] Average Forward pass: 1329.82 ms.
I1108 23:40:22.299872 136316 caffe.cpp:535] Average Backward pass: 1113.58 ms.
I1108 23:40:22.310422 136316 caffe.cpp:537] Average Forward-Backward: 2977 ms.
I1108 23:40:22.325048 136316 caffe.cpp:540] Total Time: 2977 ms.
I1108 23:40:22.337059 136316 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 25
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 778752
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 25
--->Total double-precision FLOPs = 1557504
--->Total FLOPs = 1557529
mem-read-1 = 25935
mem-read-2 = 35
mem-read-4 = 548776
mem-read-8 = 389445
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 2336273
mem-write-1 = 52
mem-write-2 = 17
mem-write-4 = 27655
mem-write-8 = 28343
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 1730561
--->Total Bytes read = 154858173
--->Total Bytes written = 111093386
--->Total Bytes = 265951559
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer9_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=9 -prof_forward_direction=1
I1108 23:43:54.867290 136435 caffe.cpp:444] Use CPU.
I1108 23:44:11.836814 136435 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:44:11.892706 136435 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:44:11.904680 136435 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:44:11.917291 136435 cpu_info.cpp:461] Total number of processors: 272
I1108 23:44:11.928534 136435 cpu_info.cpp:464] GPU is used: no
I1108 23:44:11.937661 136435 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:44:11.946566 136435 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:44:11.957720 136435 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:44:20.834631 136435 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:44:20.867380 136435 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:44:21.506429 136435 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:44:23.967208 136435 layer_factory.hpp:114] Creating layer data
I1108 23:44:24.114641 136435 net.cpp:160] Creating Layer data
I1108 23:44:24.162869 136435 net.cpp:570] data -> data
I1108 23:44:24.629201 136435 net.cpp:570] data -> label
I1108 23:44:31.705498 136435 net.cpp:210] Setting up data
I1108 23:44:31.785426 136435 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:44:31.890508 136435 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:44:31.897310 136435 net.cpp:225] Memory required for data: 19787264
I1108 23:44:31.964586 136435 layer_factory.hpp:114] Creating layer conv1
I1108 23:44:32.290649 136435 net.cpp:160] Creating Layer conv1
I1108 23:44:32.340246 136435 net.cpp:596] conv1 <- data
I1108 23:44:32.459537 136435 net.cpp:570] conv1 -> conv1
I1108 23:45:05.347260 136435 net.cpp:210] Setting up conv1
I1108 23:45:05.354508 136435 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:45:05.354858 136435 net.cpp:225] Memory required for data: 56958464
I1108 23:45:05.631489 136435 layer_factory.hpp:114] Creating layer relu1
I1108 23:45:05.751092 136435 net.cpp:160] Creating Layer relu1
I1108 23:45:05.755692 136435 net.cpp:596] relu1 <- conv1
I1108 23:45:05.787797 136435 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:45:05.978384 136435 net.cpp:210] Setting up relu1
I1108 23:45:05.980767 136435 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:45:05.981154 136435 net.cpp:225] Memory required for data: 94129664
I1108 23:45:05.981356 136435 layer_factory.hpp:114] Creating layer norm1
I1108 23:45:06.087208 136435 net.cpp:160] Creating Layer norm1
I1108 23:45:06.087514 136435 net.cpp:596] norm1 <- conv1
I1108 23:45:06.090128 136435 net.cpp:570] norm1 -> norm1
I1108 23:45:06.312741 136435 net.cpp:210] Setting up norm1
I1108 23:45:06.325583 136435 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:45:06.325958 136435 net.cpp:225] Memory required for data: 131300864
I1108 23:45:06.326259 136435 layer_factory.hpp:114] Creating layer pool1
I1108 23:45:06.419576 136435 net.cpp:160] Creating Layer pool1
I1108 23:45:06.419891 136435 net.cpp:596] pool1 <- norm1
I1108 23:45:06.434619 136435 net.cpp:570] pool1 -> pool1
I1108 23:45:06.734297 136435 net.cpp:210] Setting up pool1
I1108 23:45:06.736873 136435 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:45:06.737201 136435 net.cpp:225] Memory required for data: 140258816
I1108 23:45:06.737440 136435 layer_factory.hpp:114] Creating layer conv2
I1108 23:45:06.737803 136435 net.cpp:160] Creating Layer conv2
I1108 23:45:06.738065 136435 net.cpp:596] conv2 <- pool1
I1108 23:45:06.738292 136435 net.cpp:570] conv2 -> conv2
I1108 23:45:12.485321 136435 net.cpp:210] Setting up conv2
I1108 23:45:12.485653 136435 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:45:12.486039 136435 net.cpp:225] Memory required for data: 164146688
I1108 23:45:12.535929 136435 layer_factory.hpp:114] Creating layer relu2
I1108 23:45:12.536337 136435 net.cpp:160] Creating Layer relu2
I1108 23:45:12.536691 136435 net.cpp:596] relu2 <- conv2
I1108 23:45:12.536983 136435 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:45:12.537434 136435 net.cpp:210] Setting up relu2
I1108 23:45:12.537690 136435 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:45:12.537915 136435 net.cpp:225] Memory required for data: 188034560
I1108 23:45:12.538101 136435 layer_factory.hpp:114] Creating layer norm2
I1108 23:45:12.538339 136435 net.cpp:160] Creating Layer norm2
I1108 23:45:12.538528 136435 net.cpp:596] norm2 <- conv2
I1108 23:45:12.538786 136435 net.cpp:570] norm2 -> norm2
I1108 23:45:12.540881 136435 net.cpp:210] Setting up norm2
I1108 23:45:12.541188 136435 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:45:12.541414 136435 net.cpp:225] Memory required for data: 211922432
I1108 23:45:12.541597 136435 layer_factory.hpp:114] Creating layer pool2
I1108 23:45:12.542538 136435 net.cpp:160] Creating Layer pool2
I1108 23:45:12.542858 136435 net.cpp:596] pool2 <- norm2
I1108 23:45:12.543097 136435 net.cpp:570] pool2 -> pool2
I1108 23:45:12.543494 136435 net.cpp:210] Setting up pool2
I1108 23:45:12.543733 136435 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:45:12.543951 136435 net.cpp:225] Memory required for data: 217460224
I1108 23:45:12.544142 136435 layer_factory.hpp:114] Creating layer conv3
I1108 23:45:12.544466 136435 net.cpp:160] Creating Layer conv3
I1108 23:45:12.544680 136435 net.cpp:596] conv3 <- pool2
I1108 23:45:12.545014 136435 net.cpp:570] conv3 -> conv3
I1108 23:45:13.047400 136435 net.cpp:210] Setting up conv3
I1108 23:45:13.049768 136435 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:45:13.050101 136435 net.cpp:225] Memory required for data: 225766912
I1108 23:45:13.053163 136435 layer_factory.hpp:114] Creating layer relu3
I1108 23:45:13.053551 136435 net.cpp:160] Creating Layer relu3
I1108 23:45:13.053789 136435 net.cpp:596] relu3 <- conv3
I1108 23:45:13.054020 136435 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:45:13.058105 136435 net.cpp:210] Setting up relu3
I1108 23:45:13.058464 136435 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:45:13.058732 136435 net.cpp:225] Memory required for data: 234073600
I1108 23:45:13.059003 136435 layer_factory.hpp:114] Creating layer conv4
I1108 23:45:13.059468 136435 net.cpp:160] Creating Layer conv4
I1108 23:45:13.059727 136435 net.cpp:596] conv4 <- conv3
I1108 23:45:13.059975 136435 net.cpp:570] conv4 -> conv4
I1108 23:45:13.302170 136435 net.cpp:210] Setting up conv4
I1108 23:45:13.302551 136435 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:45:13.302932 136435 net.cpp:225] Memory required for data: 242380288
I1108 23:45:13.303273 136435 layer_factory.hpp:114] Creating layer relu4
I1108 23:45:13.303558 136435 net.cpp:160] Creating Layer relu4
I1108 23:45:13.303781 136435 net.cpp:596] relu4 <- conv4
I1108 23:45:13.304010 136435 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:45:13.315930 136435 net.cpp:210] Setting up relu4
I1108 23:45:13.316272 136435 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:45:13.316530 136435 net.cpp:225] Memory required for data: 250686976
I1108 23:45:13.316735 136435 layer_factory.hpp:114] Creating layer conv5
I1108 23:45:13.317183 136435 net.cpp:160] Creating Layer conv5
I1108 23:45:13.317423 136435 net.cpp:596] conv5 <- conv4
I1108 23:45:13.317662 136435 net.cpp:570] conv5 -> conv5
I1108 23:45:13.486524 136435 net.cpp:210] Setting up conv5
I1108 23:45:13.486908 136435 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:45:13.487303 136435 net.cpp:225] Memory required for data: 256224768
I1108 23:45:13.491919 136435 layer_factory.hpp:114] Creating layer relu5
I1108 23:45:13.492313 136435 net.cpp:160] Creating Layer relu5
I1108 23:45:13.492554 136435 net.cpp:596] relu5 <- conv5
I1108 23:45:13.492852 136435 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:45:13.493368 136435 net.cpp:210] Setting up relu5
I1108 23:45:13.493657 136435 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:45:13.493973 136435 net.cpp:225] Memory required for data: 261762560
I1108 23:45:13.494213 136435 layer_factory.hpp:114] Creating layer pool5
I1108 23:45:13.494472 136435 net.cpp:160] Creating Layer pool5
I1108 23:45:13.494683 136435 net.cpp:596] pool5 <- conv5
I1108 23:45:13.494904 136435 net.cpp:570] pool5 -> pool5
I1108 23:45:13.495301 136435 net.cpp:210] Setting up pool5
I1108 23:45:13.495548 136435 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:45:13.495767 136435 net.cpp:225] Memory required for data: 262942208
I1108 23:45:13.495949 136435 layer_factory.hpp:114] Creating layer fc6
I1108 23:45:13.550266 136435 net.cpp:160] Creating Layer fc6
I1108 23:45:13.550573 136435 net.cpp:596] fc6 <- pool5
I1108 23:45:13.550962 136435 net.cpp:570] fc6 -> fc6
I1108 23:45:17.638679 136435 net.cpp:210] Setting up fc6
I1108 23:45:17.638978 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:17.641038 136435 net.cpp:225] Memory required for data: 263466496
I1108 23:45:17.641353 136435 layer_factory.hpp:114] Creating layer relu6
I1108 23:45:17.643815 136435 net.cpp:160] Creating Layer relu6
I1108 23:45:17.644104 136435 net.cpp:596] relu6 <- fc6
I1108 23:45:17.644330 136435 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:45:17.644752 136435 net.cpp:210] Setting up relu6
I1108 23:45:17.645058 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:17.645284 136435 net.cpp:225] Memory required for data: 263990784
I1108 23:45:17.645467 136435 layer_factory.hpp:114] Creating layer drop6
I1108 23:45:17.665246 136435 net.cpp:160] Creating Layer drop6
I1108 23:45:17.665540 136435 net.cpp:596] drop6 <- fc6
I1108 23:45:17.665900 136435 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:45:17.770387 136435 net.cpp:210] Setting up drop6
I1108 23:45:17.770684 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:17.771013 136435 net.cpp:225] Memory required for data: 264515072
I1108 23:45:17.771255 136435 layer_factory.hpp:114] Creating layer fc7
I1108 23:45:17.771523 136435 net.cpp:160] Creating Layer fc7
I1108 23:45:17.771730 136435 net.cpp:596] fc7 <- fc6
I1108 23:45:17.772109 136435 net.cpp:570] fc7 -> fc7
I1108 23:45:19.482807 136435 net.cpp:210] Setting up fc7
I1108 23:45:19.483146 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:19.483520 136435 net.cpp:225] Memory required for data: 265039360
I1108 23:45:19.483865 136435 layer_factory.hpp:114] Creating layer relu7
I1108 23:45:19.484163 136435 net.cpp:160] Creating Layer relu7
I1108 23:45:19.484386 136435 net.cpp:596] relu7 <- fc7
I1108 23:45:19.484617 136435 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:45:19.485080 136435 net.cpp:210] Setting up relu7
I1108 23:45:19.485364 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:19.485597 136435 net.cpp:225] Memory required for data: 265563648
I1108 23:45:19.485785 136435 layer_factory.hpp:114] Creating layer drop7
I1108 23:45:19.486008 136435 net.cpp:160] Creating Layer drop7
I1108 23:45:19.486235 136435 net.cpp:596] drop7 <- fc7
I1108 23:45:19.486481 136435 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:45:19.486752 136435 net.cpp:210] Setting up drop7
I1108 23:45:19.486979 136435 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:45:19.487187 136435 net.cpp:225] Memory required for data: 266087936
I1108 23:45:19.487363 136435 layer_factory.hpp:114] Creating layer fc8
I1108 23:45:19.487604 136435 net.cpp:160] Creating Layer fc8
I1108 23:45:19.487797 136435 net.cpp:596] fc8 <- fc7
I1108 23:45:19.488055 136435 net.cpp:570] fc8 -> fc8
I1108 23:45:19.912904 136435 net.cpp:210] Setting up fc8
I1108 23:45:19.913267 136435 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:45:19.913669 136435 net.cpp:225] Memory required for data: 266215936
I1108 23:45:19.914016 136435 layer_factory.hpp:114] Creating layer loss
I1108 23:45:19.939103 136435 net.cpp:160] Creating Layer loss
I1108 23:45:19.939419 136435 net.cpp:596] loss <- fc8
I1108 23:45:19.940371 136435 net.cpp:596] loss <- label
I1108 23:45:19.968092 136435 net.cpp:570] loss -> loss
I1108 23:45:20.006402 136435 layer_factory.hpp:114] Creating layer loss
I1108 23:45:22.542821 136435 net.cpp:210] Setting up loss
I1108 23:45:22.591078 136435 net.cpp:217] Top shape: (1)
I1108 23:45:22.600673 136435 net.cpp:220]     with loss weight 1
I1108 23:45:22.732148 136435 net.cpp:225] Memory required for data: 266215940
I1108 23:45:22.776041 136435 net.cpp:287] loss needs backward computation.
I1108 23:45:22.862499 136435 net.cpp:287] fc8 needs backward computation.
I1108 23:45:22.869597 136435 net.cpp:287] drop7 needs backward computation.
I1108 23:45:22.880460 136435 net.cpp:287] relu7 needs backward computation.
I1108 23:45:22.880833 136435 net.cpp:287] fc7 needs backward computation.
I1108 23:45:22.883265 136435 net.cpp:287] drop6 needs backward computation.
I1108 23:45:22.883599 136435 net.cpp:287] relu6 needs backward computation.
I1108 23:45:22.883867 136435 net.cpp:287] fc6 needs backward computation.
I1108 23:45:22.884579 136435 net.cpp:287] pool5 needs backward computation.
I1108 23:45:22.885401 136435 net.cpp:287] relu5 needs backward computation.
I1108 23:45:22.885670 136435 net.cpp:287] conv5 needs backward computation.
I1108 23:45:22.885865 136435 net.cpp:287] relu4 needs backward computation.
I1108 23:45:22.886054 136435 net.cpp:287] conv4 needs backward computation.
I1108 23:45:22.886239 136435 net.cpp:287] relu3 needs backward computation.
I1108 23:45:22.886484 136435 net.cpp:287] conv3 needs backward computation.
I1108 23:45:22.898129 136435 net.cpp:287] pool2 needs backward computation.
I1108 23:45:22.898450 136435 net.cpp:287] norm2 needs backward computation.
I1108 23:45:22.898645 136435 net.cpp:287] relu2 needs backward computation.
I1108 23:45:22.898828 136435 net.cpp:287] conv2 needs backward computation.
I1108 23:45:22.899011 136435 net.cpp:287] pool1 needs backward computation.
I1108 23:45:22.899190 136435 net.cpp:287] norm1 needs backward computation.
I1108 23:45:22.899369 136435 net.cpp:287] relu1 needs backward computation.
I1108 23:45:22.899544 136435 net.cpp:287] conv1 needs backward computation.
I1108 23:45:22.910897 136435 net.cpp:289] data does not need backward computation.
I1108 23:45:22.935796 136435 net.cpp:331] This network produces output loss
I1108 23:45:23.010325 136435 net.cpp:345] Network initialization done.
I1108 23:45:23.178453 136435 caffe.cpp:452] Performing Forward
I1108 23:45:36.278079 136435 caffe.cpp:457] Initial loss: 6.88422
I1108 23:45:36.325312 136435 caffe.cpp:459] Performing Backward
I1108 23:45:40.859148 136435 caffe.cpp:468] *** Benchmark begins ***
I1108 23:45:40.871785 136435 caffe.cpp:469] Testing for 1 iterations.
I1108 23:45:41.016342 136435 caffe.cpp:482] Profiling Layer: conv3 forward
I1108 23:45:43.102015 136435 caffe.cpp:512] Iteration: 1 forward-backward time: 2079 ms.
I1108 23:45:43.261978 136435 caffe.cpp:519] Average time per layer: 
I1108 23:45:43.280539 136435 caffe.cpp:522]       data	forward: 546.274 ms.
I1108 23:45:43.351208 136435 caffe.cpp:526]       data	backward: 5.261 ms.
I1108 23:45:43.373522 136435 caffe.cpp:522]      conv1	forward: 128.79 ms.
I1108 23:45:43.382819 136435 caffe.cpp:526]      conv1	backward: 26.77 ms.
I1108 23:45:43.389219 136435 caffe.cpp:522]      relu1	forward: 14.591 ms.
I1108 23:45:43.399399 136435 caffe.cpp:526]      relu1	backward: 1.051 ms.
I1108 23:45:43.409361 136435 caffe.cpp:522]      norm1	forward: 21.683 ms.
I1108 23:45:43.416442 136435 caffe.cpp:526]      norm1	backward: 3.098 ms.
I1108 23:45:43.424244 136435 caffe.cpp:522]      pool1	forward: 21.606 ms.
I1108 23:45:43.433241 136435 caffe.cpp:526]      pool1	backward: 35.728 ms.
I1108 23:45:43.437124 136435 caffe.cpp:522]      conv2	forward: 68.063 ms.
I1108 23:45:43.444048 136435 caffe.cpp:526]      conv2	backward: 31.525 ms.
I1108 23:45:43.453447 136435 caffe.cpp:522]      relu2	forward: 19.066 ms.
I1108 23:45:43.462342 136435 caffe.cpp:526]      relu2	backward: 0.707 ms.
I1108 23:45:43.478564 136435 caffe.cpp:522]      norm2	forward: 11.632 ms.
I1108 23:45:43.480331 136435 caffe.cpp:526]      norm2	backward: 2.107 ms.
I1108 23:45:43.480711 136435 caffe.cpp:522]      pool2	forward: 18.624 ms.
I1108 23:45:43.480994 136435 caffe.cpp:526]      pool2	backward: 22.322 ms.
I1108 23:45:43.481187 136435 caffe.cpp:522]      conv3	forward: 49.047 ms.
I1108 23:45:43.481379 136435 caffe.cpp:526]      conv3	backward: 36.364 ms.
I1108 23:45:43.481569 136435 caffe.cpp:522]      relu3	forward: 12.197 ms.
I1108 23:45:43.481756 136435 caffe.cpp:526]      relu3	backward: 0.682 ms.
I1108 23:45:43.481943 136435 caffe.cpp:522]      conv4	forward: 26.047 ms.
I1108 23:45:43.482132 136435 caffe.cpp:526]      conv4	backward: 27.846 ms.
I1108 23:45:43.482321 136435 caffe.cpp:522]      relu4	forward: 14.436 ms.
I1108 23:45:43.482511 136435 caffe.cpp:526]      relu4	backward: 6.963 ms.
I1108 23:45:43.482694 136435 caffe.cpp:522]      conv5	forward: 28.042 ms.
I1108 23:45:43.482883 136435 caffe.cpp:526]      conv5	backward: 20.13 ms.
I1108 23:45:43.483113 136435 caffe.cpp:522]      relu5	forward: 18.972 ms.
I1108 23:45:43.483325 136435 caffe.cpp:526]      relu5	backward: 0.645 ms.
I1108 23:45:43.483553 136435 caffe.cpp:522]      pool5	forward: 18.038 ms.
I1108 23:45:43.483781 136435 caffe.cpp:526]      pool5	backward: 43.717 ms.
I1108 23:45:43.483971 136435 caffe.cpp:522]        fc6	forward: 40.071 ms.
I1108 23:45:43.484163 136435 caffe.cpp:526]        fc6	backward: 116.09 ms.
I1108 23:45:43.484354 136435 caffe.cpp:522]      relu6	forward: 15.325 ms.
I1108 23:45:43.484544 136435 caffe.cpp:526]      relu6	backward: 12.365 ms.
I1108 23:45:43.484732 136435 caffe.cpp:522]      drop6	forward: 33.134 ms.
I1108 23:45:43.484947 136435 caffe.cpp:526]      drop6	backward: 13.065 ms.
I1108 23:45:43.485136 136435 caffe.cpp:522]        fc7	forward: 11.262 ms.
I1108 23:45:43.485326 136435 caffe.cpp:526]        fc7	backward: 95.471 ms.
I1108 23:45:43.485514 136435 caffe.cpp:522]      relu7	forward: 18.521 ms.
I1108 23:45:43.485702 136435 caffe.cpp:526]      relu7	backward: 14.564 ms.
I1108 23:45:43.485891 136435 caffe.cpp:522]      drop7	forward: 29.121 ms.
I1108 23:45:43.486080 136435 caffe.cpp:526]      drop7	backward: 11.005 ms.
I1108 23:45:43.486310 136435 caffe.cpp:522]        fc8	forward: 12.161 ms.
I1108 23:45:43.486520 136435 caffe.cpp:526]        fc8	backward: 135.1 ms.
I1108 23:45:43.486807 136435 caffe.cpp:522]       loss	forward: 62.093 ms.
I1108 23:45:43.487040 136435 caffe.cpp:526]       loss	backward: 77.408 ms.
I1108 23:45:43.492240 136435 caffe.cpp:532] Average Forward pass: 1297.96 ms.
I1108 23:45:43.508168 136435 caffe.cpp:535] Average Backward pass: 750.789 ms.
I1108 23:45:43.519119 136435 caffe.cpp:537] Average Forward-Backward: 2577 ms.
I1108 23:45:43.534569 136435 caffe.cpp:540] Total Time: 2577 ms.
I1108 23:45:43.546958 136435 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 2
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 540389376
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 8646230018
--->Total double-precision FLOPs = 0
--->Total FLOPs = 8646230018
mem-read-1 = 48059
mem-read-2 = 75
mem-read-4 = 271515851
mem-read-8 = 6758489
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 56458501
mem-write-1 = 114
mem-write-2 = 34
mem-write-4 = 161137
mem-write-8 = 4161903
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 2321696
--->Total Bytes read = 4753523653
--->Total Bytes written = 182528562
--->Total Bytes = 4936052215
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer10_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=10 -prof_forward_direction=1
I1108 23:50:22.380071 136604 caffe.cpp:444] Use CPU.
I1108 23:50:39.319857 136604 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:50:39.375380 136604 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:50:39.387395 136604 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:50:39.399859 136604 cpu_info.cpp:461] Total number of processors: 272
I1108 23:50:39.411128 136604 cpu_info.cpp:464] GPU is used: no
I1108 23:50:39.420274 136604 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:50:39.429226 136604 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:50:39.440194 136604 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:50:48.222867 136604 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:50:48.255517 136604 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:50:48.886651 136604 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:50:51.330468 136604 layer_factory.hpp:114] Creating layer data
I1108 23:50:51.476652 136604 net.cpp:160] Creating Layer data
I1108 23:50:51.524634 136604 net.cpp:570] data -> data
I1108 23:50:51.994590 136604 net.cpp:570] data -> label
I1108 23:50:59.048962 136604 net.cpp:210] Setting up data
I1108 23:50:59.128847 136604 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:50:59.236322 136604 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:50:59.243794 136604 net.cpp:225] Memory required for data: 19787264
I1108 23:50:59.311806 136604 layer_factory.hpp:114] Creating layer conv1
I1108 23:50:59.640943 136604 net.cpp:160] Creating Layer conv1
I1108 23:50:59.690670 136604 net.cpp:596] conv1 <- data
I1108 23:50:59.809660 136604 net.cpp:570] conv1 -> conv1
I1108 23:51:32.546144 136604 net.cpp:210] Setting up conv1
I1108 23:51:32.553025 136604 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:51:32.553375 136604 net.cpp:225] Memory required for data: 56958464
I1108 23:51:32.830298 136604 layer_factory.hpp:114] Creating layer relu1
I1108 23:51:32.951207 136604 net.cpp:160] Creating Layer relu1
I1108 23:51:32.955689 136604 net.cpp:596] relu1 <- conv1
I1108 23:51:32.989070 136604 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:51:33.180397 136604 net.cpp:210] Setting up relu1
I1108 23:51:33.182862 136604 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:51:33.183220 136604 net.cpp:225] Memory required for data: 94129664
I1108 23:51:33.183431 136604 layer_factory.hpp:114] Creating layer norm1
I1108 23:51:33.288159 136604 net.cpp:160] Creating Layer norm1
I1108 23:51:33.288477 136604 net.cpp:596] norm1 <- conv1
I1108 23:51:33.291030 136604 net.cpp:570] norm1 -> norm1
I1108 23:51:33.515254 136604 net.cpp:210] Setting up norm1
I1108 23:51:33.528034 136604 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:51:33.528422 136604 net.cpp:225] Memory required for data: 131300864
I1108 23:51:33.528733 136604 layer_factory.hpp:114] Creating layer pool1
I1108 23:51:33.621963 136604 net.cpp:160] Creating Layer pool1
I1108 23:51:33.622282 136604 net.cpp:596] pool1 <- norm1
I1108 23:51:33.637034 136604 net.cpp:570] pool1 -> pool1
I1108 23:51:33.938552 136604 net.cpp:210] Setting up pool1
I1108 23:51:33.941056 136604 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:51:33.941388 136604 net.cpp:225] Memory required for data: 140258816
I1108 23:51:33.941606 136604 layer_factory.hpp:114] Creating layer conv2
I1108 23:51:33.941959 136604 net.cpp:160] Creating Layer conv2
I1108 23:51:33.942216 136604 net.cpp:596] conv2 <- pool1
I1108 23:51:33.942458 136604 net.cpp:570] conv2 -> conv2
I1108 23:51:39.695768 136604 net.cpp:210] Setting up conv2
I1108 23:51:39.696135 136604 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:51:39.696627 136604 net.cpp:225] Memory required for data: 164146688
I1108 23:51:39.748225 136604 layer_factory.hpp:114] Creating layer relu2
I1108 23:51:39.748646 136604 net.cpp:160] Creating Layer relu2
I1108 23:51:39.749061 136604 net.cpp:596] relu2 <- conv2
I1108 23:51:39.749325 136604 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:51:39.749785 136604 net.cpp:210] Setting up relu2
I1108 23:51:39.750056 136604 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:51:39.750290 136604 net.cpp:225] Memory required for data: 188034560
I1108 23:51:39.750480 136604 layer_factory.hpp:114] Creating layer norm2
I1108 23:51:39.750725 136604 net.cpp:160] Creating Layer norm2
I1108 23:51:39.750928 136604 net.cpp:596] norm2 <- conv2
I1108 23:51:39.751158 136604 net.cpp:570] norm2 -> norm2
I1108 23:51:39.753450 136604 net.cpp:210] Setting up norm2
I1108 23:51:39.753767 136604 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:51:39.754001 136604 net.cpp:225] Memory required for data: 211922432
I1108 23:51:39.754225 136604 layer_factory.hpp:114] Creating layer pool2
I1108 23:51:39.755199 136604 net.cpp:160] Creating Layer pool2
I1108 23:51:39.755498 136604 net.cpp:596] pool2 <- norm2
I1108 23:51:39.755743 136604 net.cpp:570] pool2 -> pool2
I1108 23:51:39.756150 136604 net.cpp:210] Setting up pool2
I1108 23:51:39.756398 136604 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:51:39.756618 136604 net.cpp:225] Memory required for data: 217460224
I1108 23:51:39.756891 136604 layer_factory.hpp:114] Creating layer conv3
I1108 23:51:39.757297 136604 net.cpp:160] Creating Layer conv3
I1108 23:51:39.757566 136604 net.cpp:596] conv3 <- pool2
I1108 23:51:39.757845 136604 net.cpp:570] conv3 -> conv3
I1108 23:51:40.260871 136604 net.cpp:210] Setting up conv3
I1108 23:51:40.263276 136604 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:51:40.263629 136604 net.cpp:225] Memory required for data: 225766912
I1108 23:51:40.266702 136604 layer_factory.hpp:114] Creating layer relu3
I1108 23:51:40.267102 136604 net.cpp:160] Creating Layer relu3
I1108 23:51:40.267354 136604 net.cpp:596] relu3 <- conv3
I1108 23:51:40.267633 136604 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:51:40.271729 136604 net.cpp:210] Setting up relu3
I1108 23:51:40.272037 136604 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:51:40.272282 136604 net.cpp:225] Memory required for data: 234073600
I1108 23:51:40.272476 136604 layer_factory.hpp:114] Creating layer conv4
I1108 23:51:40.272879 136604 net.cpp:160] Creating Layer conv4
I1108 23:51:40.273207 136604 net.cpp:596] conv4 <- conv3
I1108 23:51:40.273481 136604 net.cpp:570] conv4 -> conv4
I1108 23:51:40.514405 136604 net.cpp:210] Setting up conv4
I1108 23:51:40.514789 136604 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:51:40.515229 136604 net.cpp:225] Memory required for data: 242380288
I1108 23:51:40.515568 136604 layer_factory.hpp:114] Creating layer relu4
I1108 23:51:40.515861 136604 net.cpp:160] Creating Layer relu4
I1108 23:51:40.516080 136604 net.cpp:596] relu4 <- conv4
I1108 23:51:40.516309 136604 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:51:40.528748 136604 net.cpp:210] Setting up relu4
I1108 23:51:40.529135 136604 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:51:40.529569 136604 net.cpp:225] Memory required for data: 250686976
I1108 23:51:40.529814 136604 layer_factory.hpp:114] Creating layer conv5
I1108 23:51:40.530176 136604 net.cpp:160] Creating Layer conv5
I1108 23:51:40.530413 136604 net.cpp:596] conv5 <- conv4
I1108 23:51:40.530652 136604 net.cpp:570] conv5 -> conv5
I1108 23:51:40.699769 136604 net.cpp:210] Setting up conv5
I1108 23:51:40.700162 136604 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:51:40.700594 136604 net.cpp:225] Memory required for data: 256224768
I1108 23:51:40.705231 136604 layer_factory.hpp:114] Creating layer relu5
I1108 23:51:40.705636 136604 net.cpp:160] Creating Layer relu5
I1108 23:51:40.705924 136604 net.cpp:596] relu5 <- conv5
I1108 23:51:40.706209 136604 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:51:40.706707 136604 net.cpp:210] Setting up relu5
I1108 23:51:40.706997 136604 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:51:40.707238 136604 net.cpp:225] Memory required for data: 261762560
I1108 23:51:40.707450 136604 layer_factory.hpp:114] Creating layer pool5
I1108 23:51:40.707717 136604 net.cpp:160] Creating Layer pool5
I1108 23:51:40.707937 136604 net.cpp:596] pool5 <- conv5
I1108 23:51:40.708159 136604 net.cpp:570] pool5 -> pool5
I1108 23:51:40.708554 136604 net.cpp:210] Setting up pool5
I1108 23:51:40.708853 136604 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:51:40.709127 136604 net.cpp:225] Memory required for data: 262942208
I1108 23:51:40.709327 136604 layer_factory.hpp:114] Creating layer fc6
I1108 23:51:40.763509 136604 net.cpp:160] Creating Layer fc6
I1108 23:51:40.763819 136604 net.cpp:596] fc6 <- pool5
I1108 23:51:40.764188 136604 net.cpp:570] fc6 -> fc6
I1108 23:51:44.850349 136604 net.cpp:210] Setting up fc6
I1108 23:51:44.850654 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:44.852665 136604 net.cpp:225] Memory required for data: 263466496
I1108 23:51:44.853029 136604 layer_factory.hpp:114] Creating layer relu6
I1108 23:51:44.855484 136604 net.cpp:160] Creating Layer relu6
I1108 23:51:44.855779 136604 net.cpp:596] relu6 <- fc6
I1108 23:51:44.856005 136604 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:51:44.856422 136604 net.cpp:210] Setting up relu6
I1108 23:51:44.856678 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:44.856958 136604 net.cpp:225] Memory required for data: 263990784
I1108 23:51:44.857149 136604 layer_factory.hpp:114] Creating layer drop6
I1108 23:51:44.880175 136604 net.cpp:160] Creating Layer drop6
I1108 23:51:44.883359 136604 net.cpp:596] drop6 <- fc6
I1108 23:51:44.886121 136604 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:51:44.989552 136604 net.cpp:210] Setting up drop6
I1108 23:51:44.989845 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:44.990175 136604 net.cpp:225] Memory required for data: 264515072
I1108 23:51:44.990417 136604 layer_factory.hpp:114] Creating layer fc7
I1108 23:51:44.990682 136604 net.cpp:160] Creating Layer fc7
I1108 23:51:44.990881 136604 net.cpp:596] fc7 <- fc6
I1108 23:51:44.991255 136604 net.cpp:570] fc7 -> fc7
I1108 23:51:46.703902 136604 net.cpp:210] Setting up fc7
I1108 23:51:46.704273 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:46.704691 136604 net.cpp:225] Memory required for data: 265039360
I1108 23:51:46.705102 136604 layer_factory.hpp:114] Creating layer relu7
I1108 23:51:46.705431 136604 net.cpp:160] Creating Layer relu7
I1108 23:51:46.705672 136604 net.cpp:596] relu7 <- fc7
I1108 23:51:46.705924 136604 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:51:46.706368 136604 net.cpp:210] Setting up relu7
I1108 23:51:46.706660 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:46.706900 136604 net.cpp:225] Memory required for data: 265563648
I1108 23:51:46.707128 136604 layer_factory.hpp:114] Creating layer drop7
I1108 23:51:46.707381 136604 net.cpp:160] Creating Layer drop7
I1108 23:51:46.707600 136604 net.cpp:596] drop7 <- fc7
I1108 23:51:46.707883 136604 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:51:46.708156 136604 net.cpp:210] Setting up drop7
I1108 23:51:46.708359 136604 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:51:46.708569 136604 net.cpp:225] Memory required for data: 266087936
I1108 23:51:46.708750 136604 layer_factory.hpp:114] Creating layer fc8
I1108 23:51:46.709065 136604 net.cpp:160] Creating Layer fc8
I1108 23:51:46.709271 136604 net.cpp:596] fc8 <- fc7
I1108 23:51:46.709498 136604 net.cpp:570] fc8 -> fc8
I1108 23:51:47.132577 136604 net.cpp:210] Setting up fc8
I1108 23:51:47.133002 136604 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:51:47.133441 136604 net.cpp:225] Memory required for data: 266215936
I1108 23:51:47.133765 136604 layer_factory.hpp:114] Creating layer loss
I1108 23:51:47.158520 136604 net.cpp:160] Creating Layer loss
I1108 23:51:47.158843 136604 net.cpp:596] loss <- fc8
I1108 23:51:47.159878 136604 net.cpp:596] loss <- label
I1108 23:51:47.187173 136604 net.cpp:570] loss -> loss
I1108 23:51:47.225189 136604 layer_factory.hpp:114] Creating layer loss
I1108 23:51:49.771114 136604 net.cpp:210] Setting up loss
I1108 23:51:49.821096 136604 net.cpp:217] Top shape: (1)
I1108 23:51:49.830441 136604 net.cpp:220]     with loss weight 1
I1108 23:51:49.960149 136604 net.cpp:225] Memory required for data: 266215940
I1108 23:51:50.010949 136604 net.cpp:287] loss needs backward computation.
I1108 23:51:50.097688 136604 net.cpp:287] fc8 needs backward computation.
I1108 23:51:50.104943 136604 net.cpp:287] drop7 needs backward computation.
I1108 23:51:50.115834 136604 net.cpp:287] relu7 needs backward computation.
I1108 23:51:50.116156 136604 net.cpp:287] fc7 needs backward computation.
I1108 23:51:50.118582 136604 net.cpp:287] drop6 needs backward computation.
I1108 23:51:50.118890 136604 net.cpp:287] relu6 needs backward computation.
I1108 23:51:50.119115 136604 net.cpp:287] fc6 needs backward computation.
I1108 23:51:50.119927 136604 net.cpp:287] pool5 needs backward computation.
I1108 23:51:50.120687 136604 net.cpp:287] relu5 needs backward computation.
I1108 23:51:50.121014 136604 net.cpp:287] conv5 needs backward computation.
I1108 23:51:50.121212 136604 net.cpp:287] relu4 needs backward computation.
I1108 23:51:50.121399 136604 net.cpp:287] conv4 needs backward computation.
I1108 23:51:50.121582 136604 net.cpp:287] relu3 needs backward computation.
I1108 23:51:50.121762 136604 net.cpp:287] conv3 needs backward computation.
I1108 23:51:50.134063 136604 net.cpp:287] pool2 needs backward computation.
I1108 23:51:50.134419 136604 net.cpp:287] norm2 needs backward computation.
I1108 23:51:50.134783 136604 net.cpp:287] relu2 needs backward computation.
I1108 23:51:50.135021 136604 net.cpp:287] conv2 needs backward computation.
I1108 23:51:50.135208 136604 net.cpp:287] pool1 needs backward computation.
I1108 23:51:50.135390 136604 net.cpp:287] norm1 needs backward computation.
I1108 23:51:50.135567 136604 net.cpp:287] relu1 needs backward computation.
I1108 23:51:50.135740 136604 net.cpp:287] conv1 needs backward computation.
I1108 23:51:50.148237 136604 net.cpp:289] data does not need backward computation.
I1108 23:51:50.172992 136604 net.cpp:331] This network produces output loss
I1108 23:51:50.243615 136604 net.cpp:345] Network initialization done.
I1108 23:51:50.412299 136604 caffe.cpp:452] Performing Forward
I1108 23:52:03.433328 136604 caffe.cpp:457] Initial loss: 6.95284
I1108 23:52:03.492092 136604 caffe.cpp:459] Performing Backward
I1108 23:52:08.338235 136604 caffe.cpp:468] *** Benchmark begins ***
I1108 23:52:08.353289 136604 caffe.cpp:469] Testing for 1 iterations.
I1108 23:52:08.498728 136604 caffe.cpp:482] Profiling Layer: relu3 forward
I1108 23:52:10.666218 136604 caffe.cpp:512] Iteration: 1 forward-backward time: 2154 ms.
I1108 23:52:10.822667 136604 caffe.cpp:519] Average time per layer: 
I1108 23:52:10.838317 136604 caffe.cpp:522]       data	forward: 544.949 ms.
I1108 23:52:10.907183 136604 caffe.cpp:526]       data	backward: 7.25 ms.
I1108 23:52:10.933677 136604 caffe.cpp:522]      conv1	forward: 136.856 ms.
I1108 23:52:10.939343 136604 caffe.cpp:526]      conv1	backward: 48.61 ms.
I1108 23:52:10.945474 136604 caffe.cpp:522]      relu1	forward: 14.83 ms.
I1108 23:52:10.954380 136604 caffe.cpp:526]      relu1	backward: 22.374 ms.
I1108 23:52:10.964221 136604 caffe.cpp:522]      norm1	forward: 19.887 ms.
I1108 23:52:10.972079 136604 caffe.cpp:526]      norm1	backward: 13.309 ms.
I1108 23:52:10.981439 136604 caffe.cpp:522]      pool1	forward: 14.638 ms.
I1108 23:52:10.987134 136604 caffe.cpp:526]      pool1	backward: 81.539 ms.
I1108 23:52:10.999697 136604 caffe.cpp:522]      conv2	forward: 73.273 ms.
I1108 23:52:11.004463 136604 caffe.cpp:526]      conv2	backward: 79.469 ms.
I1108 23:52:11.009070 136604 caffe.cpp:522]      relu2	forward: 17.307 ms.
I1108 23:52:11.013269 136604 caffe.cpp:526]      relu2	backward: 15.628 ms.
I1108 23:52:11.025512 136604 caffe.cpp:522]      norm2	forward: 12.629 ms.
I1108 23:52:11.037096 136604 caffe.cpp:526]      norm2	backward: 14.893 ms.
I1108 23:52:11.039913 136604 caffe.cpp:522]      pool2	forward: 15.736 ms.
I1108 23:52:11.040211 136604 caffe.cpp:526]      pool2	backward: 62.702 ms.
I1108 23:52:11.040505 136604 caffe.cpp:522]      conv3	forward: 36.215 ms.
I1108 23:52:11.040745 136604 caffe.cpp:526]      conv3	backward: 87.682 ms.
I1108 23:52:11.040980 136604 caffe.cpp:522]      relu3	forward: 26.321 ms.
I1108 23:52:11.041172 136604 caffe.cpp:526]      relu3	backward: 35.498 ms.
I1108 23:52:11.041360 136604 caffe.cpp:522]      conv4	forward: 25.731 ms.
I1108 23:52:11.041549 136604 caffe.cpp:526]      conv4	backward: 48.475 ms.
I1108 23:52:11.041739 136604 caffe.cpp:522]      relu4	forward: 15.309 ms.
I1108 23:52:11.041929 136604 caffe.cpp:526]      relu4	backward: 7.31 ms.
I1108 23:52:11.042115 136604 caffe.cpp:522]      conv5	forward: 31.099 ms.
I1108 23:52:11.042917 136604 caffe.cpp:526]      conv5	backward: 18.552 ms.
I1108 23:52:11.043217 136604 caffe.cpp:522]      relu5	forward: 16.186 ms.
I1108 23:52:11.043484 136604 caffe.cpp:526]      relu5	backward: 0.225 ms.
I1108 23:52:11.043735 136604 caffe.cpp:522]      pool5	forward: 8.091 ms.
I1108 23:52:11.044499 136604 caffe.cpp:526]      pool5	backward: 9.156 ms.
I1108 23:52:11.044720 136604 caffe.cpp:522]        fc6	forward: 45.324 ms.
I1108 23:52:11.044963 136604 caffe.cpp:526]        fc6	backward: 27.138 ms.
I1108 23:52:11.045156 136604 caffe.cpp:522]      relu6	forward: 19.173 ms.
I1108 23:52:11.045346 136604 caffe.cpp:526]      relu6	backward: 0.085 ms.
I1108 23:52:11.047873 136604 caffe.cpp:522]      drop6	forward: 32.988 ms.
I1108 23:52:11.048125 136604 caffe.cpp:526]      drop6	backward: 0.079 ms.
I1108 23:52:11.048321 136604 caffe.cpp:522]        fc7	forward: 13.721 ms.
I1108 23:52:11.048517 136604 caffe.cpp:526]        fc7	backward: 16.707 ms.
I1108 23:52:11.048746 136604 caffe.cpp:522]      relu7	forward: 13.796 ms.
I1108 23:52:11.049021 136604 caffe.cpp:526]      relu7	backward: 0.086 ms.
I1108 23:52:11.049338 136604 caffe.cpp:522]      drop7	forward: 25.013 ms.
I1108 23:52:11.049615 136604 caffe.cpp:526]      drop7	backward: 0.099 ms.
I1108 23:52:11.049844 136604 caffe.cpp:522]        fc8	forward: 11.473 ms.
I1108 23:52:11.050035 136604 caffe.cpp:526]        fc8	backward: 185.864 ms.
I1108 23:52:11.050226 136604 caffe.cpp:522]       loss	forward: 47.594 ms.
I1108 23:52:11.050415 136604 caffe.cpp:526]       loss	backward: 60.01 ms.
I1108 23:52:11.055850 136604 caffe.cpp:532] Average Forward pass: 1273.68 ms.
I1108 23:52:11.070359 136604 caffe.cpp:535] Average Backward pass: 851.479 ms.
I1108 23:52:11.081420 136604 caffe.cpp:537] Average Forward-Backward: 2658 ms.
I1108 23:52:11.096065 136604 caffe.cpp:540] Total Time: 2658 ms.
I1108 23:52:11.108244 136604 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 129792
elements_fp_double_1 = 0
elements_fp_double_2 = 129792
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2076673
--->Total double-precision FLOPs = 259584
--->Total FLOPs = 2336257
mem-read-1 = 21836
mem-read-2 = 34
mem-read-4 = 175515
mem-read-8 = 244226
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 259601
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 564
mem-write-8 = 23920
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 129793
--->Total Bytes read = 19292268
--->Total Bytes written = 8500484
--->Total Bytes = 27792752
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer11_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=11 -prof_forward_direction=1
I1108 23:55:43.111143 136728 caffe.cpp:444] Use CPU.
I1108 23:56:00.037356 136728 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1108 23:56:00.094413 136728 cpu_info.cpp:455] Total number of sockets: 1
I1108 23:56:00.106581 136728 cpu_info.cpp:458] Total number of CPU cores: 68
I1108 23:56:00.119196 136728 cpu_info.cpp:461] Total number of processors: 272
I1108 23:56:00.130570 136728 cpu_info.cpp:464] GPU is used: no
I1108 23:56:00.139657 136728 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1108 23:56:00.148526 136728 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1108 23:56:00.159622 136728 cpu_info.cpp:473] Number of OpenMP threads: 16
I1108 23:56:08.916745 136728 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1108 23:56:08.947962 136728 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1108 23:56:09.586077 136728 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1108 23:56:12.036371 136728 layer_factory.hpp:114] Creating layer data
I1108 23:56:12.184502 136728 net.cpp:160] Creating Layer data
I1108 23:56:12.232973 136728 net.cpp:570] data -> data
I1108 23:56:12.699295 136728 net.cpp:570] data -> label
I1108 23:56:19.738359 136728 net.cpp:210] Setting up data
I1108 23:56:19.818007 136728 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1108 23:56:19.922945 136728 net.cpp:217] Top shape: 32 1 1 1 (32)
I1108 23:56:19.930179 136728 net.cpp:225] Memory required for data: 19787264
I1108 23:56:19.997617 136728 layer_factory.hpp:114] Creating layer conv1
I1108 23:56:20.324968 136728 net.cpp:160] Creating Layer conv1
I1108 23:56:20.374691 136728 net.cpp:596] conv1 <- data
I1108 23:56:20.493667 136728 net.cpp:570] conv1 -> conv1
I1108 23:56:53.316465 136728 net.cpp:210] Setting up conv1
I1108 23:56:53.323421 136728 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:56:53.323813 136728 net.cpp:225] Memory required for data: 56958464
I1108 23:56:53.609789 136728 layer_factory.hpp:114] Creating layer relu1
I1108 23:56:53.730339 136728 net.cpp:160] Creating Layer relu1
I1108 23:56:53.734925 136728 net.cpp:596] relu1 <- conv1
I1108 23:56:53.767302 136728 net.cpp:557] relu1 -> conv1 (in-place)
I1108 23:56:53.958384 136728 net.cpp:210] Setting up relu1
I1108 23:56:53.960819 136728 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:56:53.961205 136728 net.cpp:225] Memory required for data: 94129664
I1108 23:56:53.961418 136728 layer_factory.hpp:114] Creating layer norm1
I1108 23:56:54.066531 136728 net.cpp:160] Creating Layer norm1
I1108 23:56:54.066846 136728 net.cpp:596] norm1 <- conv1
I1108 23:56:54.069437 136728 net.cpp:570] norm1 -> norm1
I1108 23:56:54.294904 136728 net.cpp:210] Setting up norm1
I1108 23:56:54.307657 136728 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1108 23:56:54.308043 136728 net.cpp:225] Memory required for data: 131300864
I1108 23:56:54.308377 136728 layer_factory.hpp:114] Creating layer pool1
I1108 23:56:54.401734 136728 net.cpp:160] Creating Layer pool1
I1108 23:56:54.402050 136728 net.cpp:596] pool1 <- norm1
I1108 23:56:54.416860 136728 net.cpp:570] pool1 -> pool1
I1108 23:56:54.717972 136728 net.cpp:210] Setting up pool1
I1108 23:56:54.720505 136728 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1108 23:56:54.720914 136728 net.cpp:225] Memory required for data: 140258816
I1108 23:56:54.721143 136728 layer_factory.hpp:114] Creating layer conv2
I1108 23:56:54.721596 136728 net.cpp:160] Creating Layer conv2
I1108 23:56:54.721817 136728 net.cpp:596] conv2 <- pool1
I1108 23:56:54.722045 136728 net.cpp:570] conv2 -> conv2
I1108 23:57:00.510067 136728 net.cpp:210] Setting up conv2
I1108 23:57:00.510406 136728 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:57:00.510850 136728 net.cpp:225] Memory required for data: 164146688
I1108 23:57:00.563989 136728 layer_factory.hpp:114] Creating layer relu2
I1108 23:57:00.564406 136728 net.cpp:160] Creating Layer relu2
I1108 23:57:00.564812 136728 net.cpp:596] relu2 <- conv2
I1108 23:57:00.565093 136728 net.cpp:557] relu2 -> conv2 (in-place)
I1108 23:57:00.565559 136728 net.cpp:210] Setting up relu2
I1108 23:57:00.565834 136728 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:57:00.566067 136728 net.cpp:225] Memory required for data: 188034560
I1108 23:57:00.566256 136728 layer_factory.hpp:114] Creating layer norm2
I1108 23:57:00.566504 136728 net.cpp:160] Creating Layer norm2
I1108 23:57:00.566742 136728 net.cpp:596] norm2 <- conv2
I1108 23:57:00.566998 136728 net.cpp:570] norm2 -> norm2
I1108 23:57:00.569174 136728 net.cpp:210] Setting up norm2
I1108 23:57:00.569489 136728 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1108 23:57:00.569721 136728 net.cpp:225] Memory required for data: 211922432
I1108 23:57:00.569941 136728 layer_factory.hpp:114] Creating layer pool2
I1108 23:57:00.570919 136728 net.cpp:160] Creating Layer pool2
I1108 23:57:00.571215 136728 net.cpp:596] pool2 <- norm2
I1108 23:57:00.571452 136728 net.cpp:570] pool2 -> pool2
I1108 23:57:00.571851 136728 net.cpp:210] Setting up pool2
I1108 23:57:00.572100 136728 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:57:00.572320 136728 net.cpp:225] Memory required for data: 217460224
I1108 23:57:00.572553 136728 layer_factory.hpp:114] Creating layer conv3
I1108 23:57:00.572979 136728 net.cpp:160] Creating Layer conv3
I1108 23:57:00.573452 136728 net.cpp:596] conv3 <- pool2
I1108 23:57:00.573890 136728 net.cpp:570] conv3 -> conv3
I1108 23:57:01.055858 136728 net.cpp:210] Setting up conv3
I1108 23:57:01.058338 136728 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:57:01.058686 136728 net.cpp:225] Memory required for data: 225766912
I1108 23:57:01.061704 136728 layer_factory.hpp:114] Creating layer relu3
I1108 23:57:01.062099 136728 net.cpp:160] Creating Layer relu3
I1108 23:57:01.062340 136728 net.cpp:596] relu3 <- conv3
I1108 23:57:01.062582 136728 net.cpp:557] relu3 -> conv3 (in-place)
I1108 23:57:01.066792 136728 net.cpp:210] Setting up relu3
I1108 23:57:01.067119 136728 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:57:01.067379 136728 net.cpp:225] Memory required for data: 234073600
I1108 23:57:01.067594 136728 layer_factory.hpp:114] Creating layer conv4
I1108 23:57:01.067982 136728 net.cpp:160] Creating Layer conv4
I1108 23:57:01.068250 136728 net.cpp:596] conv4 <- conv3
I1108 23:57:01.068513 136728 net.cpp:570] conv4 -> conv4
I1108 23:57:01.335469 136728 net.cpp:210] Setting up conv4
I1108 23:57:01.335851 136728 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:57:01.336261 136728 net.cpp:225] Memory required for data: 242380288
I1108 23:57:01.336570 136728 layer_factory.hpp:114] Creating layer relu4
I1108 23:57:01.336901 136728 net.cpp:160] Creating Layer relu4
I1108 23:57:01.337144 136728 net.cpp:596] relu4 <- conv4
I1108 23:57:01.337383 136728 net.cpp:557] relu4 -> conv4 (in-place)
I1108 23:57:01.349632 136728 net.cpp:210] Setting up relu4
I1108 23:57:01.349970 136728 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1108 23:57:01.350368 136728 net.cpp:225] Memory required for data: 250686976
I1108 23:57:01.350582 136728 layer_factory.hpp:114] Creating layer conv5
I1108 23:57:01.350950 136728 net.cpp:160] Creating Layer conv5
I1108 23:57:01.351194 136728 net.cpp:596] conv5 <- conv4
I1108 23:57:01.351435 136728 net.cpp:570] conv5 -> conv5
I1108 23:57:01.521111 136728 net.cpp:210] Setting up conv5
I1108 23:57:01.521494 136728 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:57:01.521898 136728 net.cpp:225] Memory required for data: 256224768
I1108 23:57:01.526567 136728 layer_factory.hpp:114] Creating layer relu5
I1108 23:57:01.527009 136728 net.cpp:160] Creating Layer relu5
I1108 23:57:01.527269 136728 net.cpp:596] relu5 <- conv5
I1108 23:57:01.527561 136728 net.cpp:557] relu5 -> conv5 (in-place)
I1108 23:57:01.528013 136728 net.cpp:210] Setting up relu5
I1108 23:57:01.528302 136728 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1108 23:57:01.528543 136728 net.cpp:225] Memory required for data: 261762560
I1108 23:57:01.528753 136728 layer_factory.hpp:114] Creating layer pool5
I1108 23:57:01.529075 136728 net.cpp:160] Creating Layer pool5
I1108 23:57:01.529327 136728 net.cpp:596] pool5 <- conv5
I1108 23:57:01.529567 136728 net.cpp:570] pool5 -> pool5
I1108 23:57:01.530006 136728 net.cpp:210] Setting up pool5
I1108 23:57:01.530261 136728 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1108 23:57:01.530483 136728 net.cpp:225] Memory required for data: 262942208
I1108 23:57:01.530666 136728 layer_factory.hpp:114] Creating layer fc6
I1108 23:57:01.585503 136728 net.cpp:160] Creating Layer fc6
I1108 23:57:01.585814 136728 net.cpp:596] fc6 <- pool5
I1108 23:57:01.586182 136728 net.cpp:570] fc6 -> fc6
I1108 23:57:05.678997 136728 net.cpp:210] Setting up fc6
I1108 23:57:05.679303 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:05.681622 136728 net.cpp:225] Memory required for data: 263466496
I1108 23:57:05.681932 136728 layer_factory.hpp:114] Creating layer relu6
I1108 23:57:05.684442 136728 net.cpp:160] Creating Layer relu6
I1108 23:57:05.684739 136728 net.cpp:596] relu6 <- fc6
I1108 23:57:05.685060 136728 net.cpp:557] relu6 -> fc6 (in-place)
I1108 23:57:05.685515 136728 net.cpp:210] Setting up relu6
I1108 23:57:05.685771 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:05.685992 136728 net.cpp:225] Memory required for data: 263990784
I1108 23:57:05.686206 136728 layer_factory.hpp:114] Creating layer drop6
I1108 23:57:05.706398 136728 net.cpp:160] Creating Layer drop6
I1108 23:57:05.706701 136728 net.cpp:596] drop6 <- fc6
I1108 23:57:05.707077 136728 net.cpp:557] drop6 -> fc6 (in-place)
I1108 23:57:05.814265 136728 net.cpp:210] Setting up drop6
I1108 23:57:05.814631 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:05.814981 136728 net.cpp:225] Memory required for data: 264515072
I1108 23:57:05.815234 136728 layer_factory.hpp:114] Creating layer fc7
I1108 23:57:05.815510 136728 net.cpp:160] Creating Layer fc7
I1108 23:57:05.815732 136728 net.cpp:596] fc7 <- fc6
I1108 23:57:05.816114 136728 net.cpp:570] fc7 -> fc7
I1108 23:57:07.529161 136728 net.cpp:210] Setting up fc7
I1108 23:57:07.529575 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:07.530094 136728 net.cpp:225] Memory required for data: 265039360
I1108 23:57:07.530581 136728 layer_factory.hpp:114] Creating layer relu7
I1108 23:57:07.531057 136728 net.cpp:160] Creating Layer relu7
I1108 23:57:07.531394 136728 net.cpp:596] relu7 <- fc7
I1108 23:57:07.531699 136728 net.cpp:557] relu7 -> fc7 (in-place)
I1108 23:57:07.532217 136728 net.cpp:210] Setting up relu7
I1108 23:57:07.532539 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:07.532881 136728 net.cpp:225] Memory required for data: 265563648
I1108 23:57:07.533152 136728 layer_factory.hpp:114] Creating layer drop7
I1108 23:57:07.533406 136728 net.cpp:160] Creating Layer drop7
I1108 23:57:07.533620 136728 net.cpp:596] drop7 <- fc7
I1108 23:57:07.533874 136728 net.cpp:557] drop7 -> fc7 (in-place)
I1108 23:57:07.534158 136728 net.cpp:210] Setting up drop7
I1108 23:57:07.534378 136728 net.cpp:217] Top shape: 32 4096 (131072)
I1108 23:57:07.534601 136728 net.cpp:225] Memory required for data: 266087936
I1108 23:57:07.534790 136728 layer_factory.hpp:114] Creating layer fc8
I1108 23:57:07.535048 136728 net.cpp:160] Creating Layer fc8
I1108 23:57:07.535255 136728 net.cpp:596] fc8 <- fc7
I1108 23:57:07.535485 136728 net.cpp:570] fc8 -> fc8
I1108 23:57:07.958693 136728 net.cpp:210] Setting up fc8
I1108 23:57:07.959054 136728 net.cpp:217] Top shape: 32 1000 (32000)
I1108 23:57:07.959475 136728 net.cpp:225] Memory required for data: 266215936
I1108 23:57:07.959791 136728 layer_factory.hpp:114] Creating layer loss
I1108 23:57:07.984833 136728 net.cpp:160] Creating Layer loss
I1108 23:57:07.985157 136728 net.cpp:596] loss <- fc8
I1108 23:57:07.986060 136728 net.cpp:596] loss <- label
I1108 23:57:08.013883 136728 net.cpp:570] loss -> loss
I1108 23:57:08.052115 136728 layer_factory.hpp:114] Creating layer loss
I1108 23:57:10.635710 136728 net.cpp:210] Setting up loss
I1108 23:57:10.686105 136728 net.cpp:217] Top shape: (1)
I1108 23:57:10.700765 136728 net.cpp:220]     with loss weight 1
I1108 23:57:10.829967 136728 net.cpp:225] Memory required for data: 266215940
I1108 23:57:10.886589 136728 net.cpp:287] loss needs backward computation.
I1108 23:57:10.974699 136728 net.cpp:287] fc8 needs backward computation.
I1108 23:57:10.981989 136728 net.cpp:287] drop7 needs backward computation.
I1108 23:57:10.992866 136728 net.cpp:287] relu7 needs backward computation.
I1108 23:57:10.993186 136728 net.cpp:287] fc7 needs backward computation.
I1108 23:57:10.995625 136728 net.cpp:287] drop6 needs backward computation.
I1108 23:57:10.995991 136728 net.cpp:287] relu6 needs backward computation.
I1108 23:57:10.996290 136728 net.cpp:287] fc6 needs backward computation.
I1108 23:57:10.997052 136728 net.cpp:287] pool5 needs backward computation.
I1108 23:57:10.997809 136728 net.cpp:287] relu5 needs backward computation.
I1108 23:57:10.998080 136728 net.cpp:287] conv5 needs backward computation.
I1108 23:57:10.998282 136728 net.cpp:287] relu4 needs backward computation.
I1108 23:57:10.998471 136728 net.cpp:287] conv4 needs backward computation.
I1108 23:57:10.998656 136728 net.cpp:287] relu3 needs backward computation.
I1108 23:57:10.998872 136728 net.cpp:287] conv3 needs backward computation.
I1108 23:57:11.010885 136728 net.cpp:287] pool2 needs backward computation.
I1108 23:57:11.011236 136728 net.cpp:287] norm2 needs backward computation.
I1108 23:57:11.011548 136728 net.cpp:287] relu2 needs backward computation.
I1108 23:57:11.011787 136728 net.cpp:287] conv2 needs backward computation.
I1108 23:57:11.011978 136728 net.cpp:287] pool1 needs backward computation.
I1108 23:57:11.012158 136728 net.cpp:287] norm1 needs backward computation.
I1108 23:57:11.012337 136728 net.cpp:287] relu1 needs backward computation.
I1108 23:57:11.012513 136728 net.cpp:287] conv1 needs backward computation.
I1108 23:57:11.024894 136728 net.cpp:289] data does not need backward computation.
I1108 23:57:11.050492 136728 net.cpp:331] This network produces output loss
I1108 23:57:11.121706 136728 net.cpp:345] Network initialization done.
I1108 23:57:11.291113 136728 caffe.cpp:452] Performing Forward
I1108 23:57:24.191989 136728 caffe.cpp:457] Initial loss: 6.92554
I1108 23:57:24.245095 136728 caffe.cpp:459] Performing Backward
I1108 23:57:29.254866 136728 caffe.cpp:468] *** Benchmark begins ***
I1108 23:57:29.268383 136728 caffe.cpp:469] Testing for 1 iterations.
I1108 23:57:29.412539 136728 caffe.cpp:482] Profiling Layer: conv4 forward
I1108 23:57:31.561480 136728 caffe.cpp:512] Iteration: 1 forward-backward time: 2146 ms.
I1108 23:57:31.723387 136728 caffe.cpp:519] Average time per layer: 
I1108 23:57:31.745805 136728 caffe.cpp:522]       data	forward: 546.572 ms.
I1108 23:57:31.821377 136728 caffe.cpp:526]       data	backward: 5.397 ms.
I1108 23:57:31.847944 136728 caffe.cpp:522]      conv1	forward: 129.853 ms.
I1108 23:57:31.854326 136728 caffe.cpp:526]      conv1	backward: 56.562 ms.
I1108 23:57:31.861009 136728 caffe.cpp:522]      relu1	forward: 18.204 ms.
I1108 23:57:31.870975 136728 caffe.cpp:526]      relu1	backward: 15.974 ms.
I1108 23:57:31.874253 136728 caffe.cpp:522]      norm1	forward: 23.726 ms.
I1108 23:57:31.874578 136728 caffe.cpp:526]      norm1	backward: 18.204 ms.
I1108 23:57:31.874783 136728 caffe.cpp:522]      pool1	forward: 18.883 ms.
I1108 23:57:31.874995 136728 caffe.cpp:526]      pool1	backward: 77.041 ms.
I1108 23:57:31.877894 136728 caffe.cpp:522]      conv2	forward: 67.665 ms.
I1108 23:57:31.878144 136728 caffe.cpp:526]      conv2	backward: 75.822 ms.
I1108 23:57:31.878343 136728 caffe.cpp:522]      relu2	forward: 12.868 ms.
I1108 23:57:31.878535 136728 caffe.cpp:526]      relu2	backward: 17.688 ms.
I1108 23:57:31.878727 136728 caffe.cpp:522]      norm2	forward: 14.335 ms.
I1108 23:57:31.878978 136728 caffe.cpp:526]      norm2	backward: 17.749 ms.
I1108 23:57:31.879205 136728 caffe.cpp:522]      pool2	forward: 20.108 ms.
I1108 23:57:31.879523 136728 caffe.cpp:526]      pool2	backward: 22.379 ms.
I1108 23:57:31.879765 136728 caffe.cpp:522]      conv3	forward: 31.924 ms.
I1108 23:57:31.879958 136728 caffe.cpp:526]      conv3	backward: 36.421 ms.
I1108 23:57:31.880151 136728 caffe.cpp:522]      relu3	forward: 14.04 ms.
I1108 23:57:31.880342 136728 caffe.cpp:526]      relu3	backward: 0.823 ms.
I1108 23:57:31.880532 136728 caffe.cpp:522]      conv4	forward: 46.06 ms.
I1108 23:57:31.880723 136728 caffe.cpp:526]      conv4	backward: 27.964 ms.
I1108 23:57:31.880954 136728 caffe.cpp:522]      relu4	forward: 13.754 ms.
I1108 23:57:31.881148 136728 caffe.cpp:526]      relu4	backward: 7.772 ms.
I1108 23:57:31.881335 136728 caffe.cpp:522]      conv5	forward: 34.005 ms.
I1108 23:57:31.881537 136728 caffe.cpp:526]      conv5	backward: 18.907 ms.
I1108 23:57:31.881727 136728 caffe.cpp:522]      relu5	forward: 14.665 ms.
I1108 23:57:31.881955 136728 caffe.cpp:526]      relu5	backward: 0.259 ms.
I1108 23:57:31.882169 136728 caffe.cpp:522]      pool5	forward: 16.269 ms.
I1108 23:57:31.882417 136728 caffe.cpp:526]      pool5	backward: 9.274 ms.
I1108 23:57:31.883267 136728 caffe.cpp:522]        fc6	forward: 36.495 ms.
I1108 23:57:31.883499 136728 caffe.cpp:526]        fc6	backward: 57.505 ms.
I1108 23:57:31.883694 136728 caffe.cpp:522]      relu6	forward: 20.515 ms.
I1108 23:57:31.883896 136728 caffe.cpp:526]      relu6	backward: 0.117 ms.
I1108 23:57:31.884594 136728 caffe.cpp:522]      drop6	forward: 33.661 ms.
I1108 23:57:31.884917 136728 caffe.cpp:526]      drop6	backward: 0.114 ms.
I1108 23:57:31.885169 136728 caffe.cpp:522]        fc7	forward: 16.916 ms.
I1108 23:57:31.885390 136728 caffe.cpp:526]        fc7	backward: 69.886 ms.
I1108 23:57:31.885700 136728 caffe.cpp:522]      relu7	forward: 19.078 ms.
I1108 23:57:31.885939 136728 caffe.cpp:526]      relu7	backward: 15.064 ms.
I1108 23:57:31.886143 136728 caffe.cpp:522]      drop7	forward: 32.131 ms.
I1108 23:57:31.886337 136728 caffe.cpp:526]      drop7	backward: 26.95 ms.
I1108 23:57:31.886528 136728 caffe.cpp:522]        fc8	forward: 14.022 ms.
I1108 23:57:31.886723 136728 caffe.cpp:526]        fc8	backward: 131.683 ms.
I1108 23:57:31.890018 136728 caffe.cpp:522]       loss	forward: 67.269 ms.
I1108 23:57:31.890282 136728 caffe.cpp:526]       loss	backward: 78.552 ms.
I1108 23:57:31.895952 136728 caffe.cpp:532] Average Forward pass: 1319.05 ms.
I1108 23:57:31.910277 136728 caffe.cpp:535] Average Backward pass: 797.262 ms.
I1108 23:57:31.921226 136728 caffe.cpp:537] Average Forward-Backward: 2584 ms.
I1108 23:57:31.935931 136728 caffe.cpp:540] Total Time: 2584 ms.
I1108 23:57:31.948012 136728 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 2
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 405292032
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 6484672514
--->Total double-precision FLOPs = 0
--->Total FLOPs = 6484672514
mem-read-1 = 47276
mem-read-2 = 75
mem-read-4 = 203735150
mem-read-8 = 5293488
mem-read-16 = 0
mem-read-32 = 2
mem-read-64 = 42441221
mem-write-1 = 114
mem-write-2 = 34
mem-write-4 = 121201
mem-write-8 = 3142493
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 1860128
--->Total Bytes read = 3573574138
--->Total Bytes written = 144673186
--->Total Bytes = 3718247324
sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer12_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=12 -prof_forward_direction=1
I1109 00:01:25.873898 136895 caffe.cpp:444] Use CPU.
I1109 00:01:42.759281 136895 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 00:01:42.815124 136895 cpu_info.cpp:455] Total number of sockets: 1
I1109 00:01:42.828228 136895 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 00:01:42.840554 136895 cpu_info.cpp:461] Total number of processors: 272
I1109 00:01:42.851666 136895 cpu_info.cpp:464] GPU is used: no
I1109 00:01:42.860599 136895 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 00:01:42.869402 136895 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 00:01:42.880190 136895 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 00:01:51.624235 136895 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 00:01:51.657011 136895 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 00:01:52.286317 136895 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 00:01:54.729241 136895 layer_factory.hpp:114] Creating layer data
I1109 00:01:54.875516 136895 net.cpp:160] Creating Layer data
I1109 00:01:54.923535 136895 net.cpp:570] data -> data
I1109 00:01:55.392498 136895 net.cpp:570] data -> label
I1109 00:02:02.408234 136895 net.cpp:210] Setting up data
I1109 00:02:02.487479 136895 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 00:02:02.590634 136895 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 00:02:02.597940 136895 net.cpp:225] Memory required for data: 19787264
I1109 00:02:02.665189 136895 layer_factory.hpp:114] Creating layer conv1
I1109 00:02:02.988523 136895 net.cpp:160] Creating Layer conv1
I1109 00:02:03.042487 136895 net.cpp:596] conv1 <- data
I1109 00:02:03.162470 136895 net.cpp:570] conv1 -> conv1
I1109 00:02:35.782451 136895 net.cpp:210] Setting up conv1
I1109 00:02:35.789602 136895 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:02:35.789963 136895 net.cpp:225] Memory required for data: 56958464
I1109 00:02:36.066481 136895 layer_factory.hpp:114] Creating layer relu1
I1109 00:02:36.186270 136895 net.cpp:160] Creating Layer relu1
I1109 00:02:36.190907 136895 net.cpp:596] relu1 <- conv1
I1109 00:02:36.222731 136895 net.cpp:557] relu1 -> conv1 (in-place)
I1109 00:02:36.410918 136895 net.cpp:210] Setting up relu1
I1109 00:02:36.413408 136895 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:02:36.413789 136895 net.cpp:225] Memory required for data: 94129664
I1109 00:02:36.414013 136895 layer_factory.hpp:114] Creating layer norm1
I1109 00:02:36.518070 136895 net.cpp:160] Creating Layer norm1
I1109 00:02:36.518385 136895 net.cpp:596] norm1 <- conv1
I1109 00:02:36.520969 136895 net.cpp:570] norm1 -> norm1
I1109 00:02:36.748086 136895 net.cpp:210] Setting up norm1
I1109 00:02:36.761015 136895 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 00:02:36.761397 136895 net.cpp:225] Memory required for data: 131300864
I1109 00:02:36.761708 136895 layer_factory.hpp:114] Creating layer pool1
I1109 00:02:36.854616 136895 net.cpp:160] Creating Layer pool1
I1109 00:02:36.854933 136895 net.cpp:596] pool1 <- norm1
I1109 00:02:36.869698 136895 net.cpp:570] pool1 -> pool1
I1109 00:02:37.168161 136895 net.cpp:210] Setting up pool1
I1109 00:02:37.170675 136895 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 00:02:37.170999 136895 net.cpp:225] Memory required for data: 140258816
I1109 00:02:37.171248 136895 layer_factory.hpp:114] Creating layer conv2
I1109 00:02:37.171617 136895 net.cpp:160] Creating Layer conv2
I1109 00:02:37.171870 136895 net.cpp:596] conv2 <- pool1
I1109 00:02:37.172103 136895 net.cpp:570] conv2 -> conv2
I1109 00:02:42.900722 136895 net.cpp:210] Setting up conv2
I1109 00:02:42.901093 136895 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:02:42.901474 136895 net.cpp:225] Memory required for data: 164146688
I1109 00:02:42.951887 136895 layer_factory.hpp:114] Creating layer relu2
I1109 00:02:42.952276 136895 net.cpp:160] Creating Layer relu2
I1109 00:02:42.952611 136895 net.cpp:596] relu2 <- conv2
I1109 00:02:42.952947 136895 net.cpp:557] relu2 -> conv2 (in-place)
I1109 00:02:42.953397 136895 net.cpp:210] Setting up relu2
I1109 00:02:42.953657 136895 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:02:42.953888 136895 net.cpp:225] Memory required for data: 188034560
I1109 00:02:42.954077 136895 layer_factory.hpp:114] Creating layer norm2
I1109 00:02:42.954320 136895 net.cpp:160] Creating Layer norm2
I1109 00:02:42.954519 136895 net.cpp:596] norm2 <- conv2
I1109 00:02:42.954782 136895 net.cpp:570] norm2 -> norm2
I1109 00:02:42.956920 136895 net.cpp:210] Setting up norm2
I1109 00:02:42.957237 136895 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 00:02:42.957479 136895 net.cpp:225] Memory required for data: 211922432
I1109 00:02:42.957708 136895 layer_factory.hpp:114] Creating layer pool2
I1109 00:02:42.958679 136895 net.cpp:160] Creating Layer pool2
I1109 00:02:42.959002 136895 net.cpp:596] pool2 <- norm2
I1109 00:02:42.959285 136895 net.cpp:570] pool2 -> pool2
I1109 00:02:42.959692 136895 net.cpp:210] Setting up pool2
I1109 00:02:42.959940 136895 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:02:42.960165 136895 net.cpp:225] Memory required for data: 217460224
I1109 00:02:42.960362 136895 layer_factory.hpp:114] Creating layer conv3
I1109 00:02:42.960747 136895 net.cpp:160] Creating Layer conv3
I1109 00:02:42.961097 136895 net.cpp:596] conv3 <- pool2
I1109 00:02:42.961400 136895 net.cpp:570] conv3 -> conv3
I1109 00:02:43.413372 136895 net.cpp:210] Setting up conv3
I1109 00:02:43.415794 136895 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:02:43.416146 136895 net.cpp:225] Memory required for data: 225766912
I1109 00:02:43.419682 136895 layer_factory.hpp:114] Creating layer relu3
I1109 00:02:43.420162 136895 net.cpp:160] Creating Layer relu3
I1109 00:02:43.420490 136895 net.cpp:596] relu3 <- conv3
I1109 00:02:43.420860 136895 net.cpp:557] relu3 -> conv3 (in-place)
I1109 00:02:43.425292 136895 net.cpp:210] Setting up relu3
I1109 00:02:43.425637 136895 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:02:43.425935 136895 net.cpp:225] Memory required for data: 234073600
I1109 00:02:43.426167 136895 layer_factory.hpp:114] Creating layer conv4
I1109 00:02:43.426573 136895 net.cpp:160] Creating Layer conv4
I1109 00:02:43.426883 136895 net.cpp:596] conv4 <- conv3
I1109 00:02:43.427153 136895 net.cpp:570] conv4 -> conv4
I1109 00:02:43.695583 136895 net.cpp:210] Setting up conv4
I1109 00:02:43.695973 136895 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:02:43.696398 136895 net.cpp:225] Memory required for data: 242380288
I1109 00:02:43.696730 136895 layer_factory.hpp:114] Creating layer relu4
I1109 00:02:43.697088 136895 net.cpp:160] Creating Layer relu4
I1109 00:02:43.697329 136895 net.cpp:596] relu4 <- conv4
I1109 00:02:43.697582 136895 net.cpp:557] relu4 -> conv4 (in-place)
I1109 00:02:43.709882 136895 net.cpp:210] Setting up relu4
I1109 00:02:43.710232 136895 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 00:02:43.710609 136895 net.cpp:225] Memory required for data: 250686976
I1109 00:02:43.710959 136895 layer_factory.hpp:114] Creating layer conv5
I1109 00:02:43.711349 136895 net.cpp:160] Creating Layer conv5
I1109 00:02:43.711606 136895 net.cpp:596] conv5 <- conv4
I1109 00:02:43.711872 136895 net.cpp:570] conv5 -> conv5
I1109 00:02:43.881796 136895 net.cpp:210] Setting up conv5
I1109 00:02:43.882195 136895 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:02:43.882644 136895 net.cpp:225] Memory required for data: 256224768
I1109 00:02:43.887377 136895 layer_factory.hpp:114] Creating layer relu5
I1109 00:02:43.887830 136895 net.cpp:160] Creating Layer relu5
I1109 00:02:43.888120 136895 net.cpp:596] relu5 <- conv5
I1109 00:02:43.888450 136895 net.cpp:557] relu5 -> conv5 (in-place)
I1109 00:02:43.889545 136895 net.cpp:210] Setting up relu5
I1109 00:02:43.889922 136895 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 00:02:43.890197 136895 net.cpp:225] Memory required for data: 261762560
I1109 00:02:43.890425 136895 layer_factory.hpp:114] Creating layer pool5
I1109 00:02:43.890748 136895 net.cpp:160] Creating Layer pool5
I1109 00:02:43.890995 136895 net.cpp:596] pool5 <- conv5
I1109 00:02:43.891335 136895 net.cpp:570] pool5 -> pool5
I1109 00:02:43.891757 136895 net.cpp:210] Setting up pool5
I1109 00:02:43.892026 136895 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 00:02:43.892262 136895 net.cpp:225] Memory required for data: 262942208
I1109 00:02:43.892453 136895 layer_factory.hpp:114] Creating layer fc6
I1109 00:02:43.947399 136895 net.cpp:160] Creating Layer fc6
I1109 00:02:43.947708 136895 net.cpp:596] fc6 <- pool5
I1109 00:02:43.948083 136895 net.cpp:570] fc6 -> fc6
I1109 00:02:48.033962 136895 net.cpp:210] Setting up fc6
I1109 00:02:48.034268 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:48.036392 136895 net.cpp:225] Memory required for data: 263466496
I1109 00:02:48.036708 136895 layer_factory.hpp:114] Creating layer relu6
I1109 00:02:48.039242 136895 net.cpp:160] Creating Layer relu6
I1109 00:02:48.039541 136895 net.cpp:596] relu6 <- fc6
I1109 00:02:48.039777 136895 net.cpp:557] relu6 -> fc6 (in-place)
I1109 00:02:48.040205 136895 net.cpp:210] Setting up relu6
I1109 00:02:48.040458 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:48.040693 136895 net.cpp:225] Memory required for data: 263990784
I1109 00:02:48.040937 136895 layer_factory.hpp:114] Creating layer drop6
I1109 00:02:48.060927 136895 net.cpp:160] Creating Layer drop6
I1109 00:02:48.061238 136895 net.cpp:596] drop6 <- fc6
I1109 00:02:48.061673 136895 net.cpp:557] drop6 -> fc6 (in-place)
I1109 00:02:48.165031 136895 net.cpp:210] Setting up drop6
I1109 00:02:48.165328 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:48.165693 136895 net.cpp:225] Memory required for data: 264515072
I1109 00:02:48.165911 136895 layer_factory.hpp:114] Creating layer fc7
I1109 00:02:48.166194 136895 net.cpp:160] Creating Layer fc7
I1109 00:02:48.166412 136895 net.cpp:596] fc7 <- fc6
I1109 00:02:48.166800 136895 net.cpp:570] fc7 -> fc7
I1109 00:02:49.877483 136895 net.cpp:210] Setting up fc7
I1109 00:02:49.877820 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:49.878213 136895 net.cpp:225] Memory required for data: 265039360
I1109 00:02:49.878525 136895 layer_factory.hpp:114] Creating layer relu7
I1109 00:02:49.878829 136895 net.cpp:160] Creating Layer relu7
I1109 00:02:49.879055 136895 net.cpp:596] relu7 <- fc7
I1109 00:02:49.879286 136895 net.cpp:557] relu7 -> fc7 (in-place)
I1109 00:02:49.879721 136895 net.cpp:210] Setting up relu7
I1109 00:02:49.879983 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:49.880216 136895 net.cpp:225] Memory required for data: 265563648
I1109 00:02:49.880403 136895 layer_factory.hpp:114] Creating layer drop7
I1109 00:02:49.880661 136895 net.cpp:160] Creating Layer drop7
I1109 00:02:49.880919 136895 net.cpp:596] drop7 <- fc7
I1109 00:02:49.881181 136895 net.cpp:557] drop7 -> fc7 (in-place)
I1109 00:02:49.881515 136895 net.cpp:210] Setting up drop7
I1109 00:02:49.881723 136895 net.cpp:217] Top shape: 32 4096 (131072)
I1109 00:02:49.881963 136895 net.cpp:225] Memory required for data: 266087936
I1109 00:02:49.882143 136895 layer_factory.hpp:114] Creating layer fc8
I1109 00:02:49.882385 136895 net.cpp:160] Creating Layer fc8
I1109 00:02:49.882575 136895 net.cpp:596] fc8 <- fc7
I1109 00:02:49.882796 136895 net.cpp:570] fc8 -> fc8
I1109 00:02:50.306287 136895 net.cpp:210] Setting up fc8
I1109 00:02:50.306632 136895 net.cpp:217] Top shape: 32 1000 (32000)
I1109 00:02:50.307003 136895 net.cpp:225] Memory required for data: 266215936
I1109 00:02:50.307334 136895 layer_factory.hpp:114] Creating layer loss
I1109 00:02:50.331733 136895 net.cpp:160] Creating Layer loss
I1109 00:02:50.332051 136895 net.cpp:596] loss <- fc8
I1109 00:02:50.333113 136895 net.cpp:596] loss <- label
I1109 00:02:50.360318 136895 net.cpp:570] loss -> loss
I1109 00:02:50.398067 136895 layer_factory.hpp:114] Creating layer loss
I1109 00:02:53.033283 136895 net.cpp:210] Setting up loss
I1109 00:02:53.082173 136895 net.cpp:217] Top shape: (1)
I1109 00:02:53.098341 136895 net.cpp:220]     with loss weight 1
I1109 00:02:53.225569 136895 net.cpp:225] Memory required for data: 266215940
I1109 00:02:53.275832 136895 net.cpp:287] loss needs backward computation.
I1109 00:02:53.363631 136895 net.cpp:287] fc8 needs backward computation.
I1109 00:02:53.370910 136895 net.cpp:287] drop7 needs backward computation.
I1109 00:02:53.381989 136895 net.cpp:287] relu7 needs backward computation.
I1109 00:02:53.382302 136895 net.cpp:287] fc7 needs backward computation.
I1109 00:02:53.384673 136895 net.cpp:287] drop6 needs backward computation.
I1109 00:02:53.385074 136895 net.cpp:287] relu6 needs backward computation.
I1109 00:02:53.385401 136895 net.cpp:287] fc6 needs backward computation.
I1109 00:02:53.386122 136895 net.cpp:287] pool5 needs backward computation.
I1109 00:02:53.386870 136895 net.cpp:287] relu5 needs backward computation.
I1109 00:02:53.387126 136895 net.cpp:287] conv5 needs backward computation.
I1109 00:02:53.387320 136895 net.cpp:287] relu4 needs backward computation.
I1109 00:02:53.387534 136895 net.cpp:287] conv4 needs backward computation.
I1109 00:02:53.387732 136895 net.cpp:287] relu3 needs backward computation.
I1109 00:02:53.387980 136895 net.cpp:287] conv3 needs backward computation.
I1109 00:02:53.400593 136895 net.cpp:287] pool2 needs backward computation.
I1109 00:02:53.400969 136895 net.cpp:287] norm2 needs backward computation.
I1109 00:02:53.401280 136895 net.cpp:287] relu2 needs backward computation.
I1109 00:02:53.401515 136895 net.cpp:287] conv2 needs backward computation.
I1109 00:02:53.401705 136895 net.cpp:287] pool1 needs backward computation.
I1109 00:02:53.401892 136895 net.cpp:287] norm1 needs backward computation.
I1109 00:02:53.402077 136895 net.cpp:287] relu1 needs backward computation.
I1109 00:02:53.402258 136895 net.cpp:287] conv1 needs backward computation.
I1109 00:02:53.414908 136895 net.cpp:289] data does not need backward computation.
I1109 00:02:53.439216 136895 net.cpp:331] This network produces output loss
I1109 00:02:53.511035 136895 net.cpp:345] Network initialization done.
I1109 00:02:53.679455 136895 caffe.cpp:452] Performing Forward
I1109 00:03:06.537922 136895 caffe.cpp:457] Initial loss: 7.03598
I1109 00:03:06.602771 136895 caffe.cpp:459] Performing Backward
I1109 00:03:11.268951 136895 caffe.cpp:468] *** Benchmark begins ***
I1109 00:03:11.281040 136895 caffe.cpp:469] Testing for 1 iterations.
I1109 00:03:11.425668 136895 caffe.cpp:482] Profiling Layer: relu4 forward
I1109 00:03:13.534762 136895 caffe.cpp:512] Iteration: 1 forward-backward time: 2101 ms.
I1109 00:03:13.692646 136895 caffe.cpp:519] Average time per layer: 
I1109 00:03:13.710026 136895 caffe.cpp:522]       data	forward: 551.052 ms.
I1109 00:03:13.785702 136895 caffe.cpp:526]       data	backward: 4.731 ms.
I1109 00:03:13.810840 136895 caffe.cpp:522]      conv1	forward: 123.602 ms.
I1109 00:03:13.817708 136895 caffe.cpp:526]      conv1	backward: 47.149 ms.
I1109 00:03:13.825284 136895 caffe.cpp:522]      relu1	forward: 22.253 ms.
I1109 00:03:13.835780 136895 caffe.cpp:526]      relu1	backward: 14.457 ms.
I1109 00:03:13.839853 136895 caffe.cpp:522]      norm1	forward: 18.412 ms.
I1109 00:03:13.844305 136895 caffe.cpp:526]      norm1	backward: 17.297 ms.
I1109 00:03:13.853561 136895 caffe.cpp:522]      pool1	forward: 19.068 ms.
I1109 00:03:13.862855 136895 caffe.cpp:526]      pool1	backward: 80.666 ms.
I1109 00:03:13.872855 136895 caffe.cpp:522]      conv2	forward: 70.144 ms.
I1109 00:03:13.873255 136895 caffe.cpp:526]      conv2	backward: 74.168 ms.
I1109 00:03:13.881186 136895 caffe.cpp:522]      relu2	forward: 12.17 ms.
I1109 00:03:13.887127 136895 caffe.cpp:526]      relu2	backward: 16.197 ms.
I1109 00:03:13.892590 136895 caffe.cpp:522]      norm2	forward: 13.431 ms.
I1109 00:03:13.900419 136895 caffe.cpp:526]      norm2	backward: 16.116 ms.
I1109 00:03:13.903148 136895 caffe.cpp:522]      pool2	forward: 15.142 ms.
I1109 00:03:13.903375 136895 caffe.cpp:526]      pool2	backward: 55.97 ms.
I1109 00:03:13.903583 136895 caffe.cpp:522]      conv3	forward: 43.881 ms.
I1109 00:03:13.903789 136895 caffe.cpp:526]      conv3	backward: 83.816 ms.
I1109 00:03:13.903992 136895 caffe.cpp:522]      relu3	forward: 12.256 ms.
I1109 00:03:13.904196 136895 caffe.cpp:526]      relu3	backward: 30.047 ms.
I1109 00:03:13.904398 136895 caffe.cpp:522]      conv4	forward: 33.916 ms.
I1109 00:03:13.904602 136895 caffe.cpp:526]      conv4	backward: 27.949 ms.
I1109 00:03:13.904850 136895 caffe.cpp:522]      relu4	forward: 27.222 ms.
I1109 00:03:13.905107 136895 caffe.cpp:526]      relu4	backward: 7.45 ms.
I1109 00:03:13.905323 136895 caffe.cpp:522]      conv5	forward: 29.991 ms.
I1109 00:03:13.905531 136895 caffe.cpp:526]      conv5	backward: 18.682 ms.
I1109 00:03:13.905737 136895 caffe.cpp:522]      relu5	forward: 14.077 ms.
I1109 00:03:13.905941 136895 caffe.cpp:526]      relu5	backward: 0.231 ms.
I1109 00:03:13.906142 136895 caffe.cpp:522]      pool5	forward: 19.371 ms.
I1109 00:03:13.906347 136895 caffe.cpp:526]      pool5	backward: 9.2 ms.
I1109 00:03:13.907196 136895 caffe.cpp:522]        fc6	forward: 38.221 ms.
I1109 00:03:13.907436 136895 caffe.cpp:526]        fc6	backward: 46.508 ms.
I1109 00:03:13.907665 136895 caffe.cpp:522]      relu6	forward: 18.661 ms.
I1109 00:03:13.907910 136895 caffe.cpp:526]      relu6	backward: 0.087 ms.
I1109 00:03:13.910519 136895 caffe.cpp:522]      drop6	forward: 40.4 ms.
I1109 00:03:13.910907 136895 caffe.cpp:526]      drop6	backward: 0.088 ms.
I1109 00:03:13.911154 136895 caffe.cpp:522]        fc7	forward: 16.857 ms.
I1109 00:03:13.911352 136895 caffe.cpp:526]        fc7	backward: 22.076 ms.
I1109 00:03:13.911548 136895 caffe.cpp:522]      relu7	forward: 17.24 ms.
I1109 00:03:13.911741 136895 caffe.cpp:526]      relu7	backward: 0.094 ms.
I1109 00:03:13.911931 136895 caffe.cpp:522]      drop7	forward: 36.873 ms.
I1109 00:03:13.912123 136895 caffe.cpp:526]      drop7	backward: 0.141 ms.
I1109 00:03:13.912312 136895 caffe.cpp:522]        fc8	forward: 14.096 ms.
I1109 00:03:13.912504 136895 caffe.cpp:526]        fc8	backward: 94.17 ms.
I1109 00:03:13.912694 136895 caffe.cpp:522]       loss	forward: 56.397 ms.
I1109 00:03:13.912930 136895 caffe.cpp:526]       loss	backward: 79.216 ms.
I1109 00:03:13.918524 136895 caffe.cpp:532] Average Forward pass: 1319.6 ms.
I1109 00:03:13.931404 136895 caffe.cpp:535] Average Backward pass: 755.354 ms.
I1109 00:03:13.942144 136895 caffe.cpp:537] Average Forward-Backward: 2592 ms.
I1109 00:03:13.956671 136895 caffe.cpp:540] Total Time: 2592 ms.
I1109 00:03:13.968924 136895 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 129792
elements_fp_double_1 = 0
elements_fp_double_2 = 129792
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2076673
--->Total double-precision FLOPs = 259584
--->Total FLOPs = 2336257
mem-read-1 = 23116
mem-read-2 = 34
mem-read-4 = 185756
mem-read-8 = 258319
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 259601
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 560
mem-write-8 = 25203
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 129793
--->Total Bytes read = 19447256
--->Total Bytes written = 8510732
--->Total Bytes = 27957988

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer18_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=src/models/mkl2017_alexnet/train_val.prototxt -iterations=1 -prof_layer=18 -prof_forward_direction=0
I1109 03:14:04.084122 144581 caffe.cpp:444] Use CPU.
I1109 03:14:21.004227 144581 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1109 03:14:21.063742 144581 cpu_info.cpp:455] Total number of sockets: 1
I1109 03:14:21.075625 144581 cpu_info.cpp:458] Total number of CPU cores: 68
I1109 03:14:21.088093 144581 cpu_info.cpp:461] Total number of processors: 272
I1109 03:14:21.099210 144581 cpu_info.cpp:464] GPU is used: no
I1109 03:14:21.108333 144581 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1109 03:14:21.117219 144581 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1109 03:14:21.128131 144581 cpu_info.cpp:473] Number of OpenMP threads: 16
I1109 03:14:29.839851 144581 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 03:14:29.872262 144581 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 03:14:30.501627 144581 net.cpp:120] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 227
      dim: 227
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
    engine: MKL2017
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: MKL2017
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    engine: MKL2017
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    engine: MKL2017
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    engine: MKL2017
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1109 03:14:32.941654 144581 layer_factory.hpp:114] Creating layer data
I1109 03:14:33.087769 144581 net.cpp:160] Creating Layer data
I1109 03:14:33.135494 144581 net.cpp:570] data -> data
I1109 03:14:33.595055 144581 net.cpp:570] data -> label
I1109 03:14:40.600122 144581 net.cpp:210] Setting up data
I1109 03:14:40.678738 144581 net.cpp:217] Top shape: 32 3 227 227 (4946784)
I1109 03:14:40.784673 144581 net.cpp:217] Top shape: 32 1 1 1 (32)
I1109 03:14:40.792402 144581 net.cpp:225] Memory required for data: 19787264
I1109 03:14:40.861258 144581 layer_factory.hpp:114] Creating layer conv1
I1109 03:14:41.191707 144581 net.cpp:160] Creating Layer conv1
I1109 03:14:41.241616 144581 net.cpp:596] conv1 <- data
I1109 03:14:41.360249 144581 net.cpp:570] conv1 -> conv1
I1109 03:15:14.062727 144581 net.cpp:210] Setting up conv1
I1109 03:15:14.069875 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:14.070231 144581 net.cpp:225] Memory required for data: 56958464
I1109 03:15:14.355648 144581 layer_factory.hpp:114] Creating layer relu1
I1109 03:15:14.477143 144581 net.cpp:160] Creating Layer relu1
I1109 03:15:14.481747 144581 net.cpp:596] relu1 <- conv1
I1109 03:15:14.515318 144581 net.cpp:557] relu1 -> conv1 (in-place)
I1109 03:15:14.705950 144581 net.cpp:210] Setting up relu1
I1109 03:15:14.708364 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:14.708714 144581 net.cpp:225] Memory required for data: 94129664
I1109 03:15:14.709010 144581 layer_factory.hpp:114] Creating layer norm1
I1109 03:15:14.814208 144581 net.cpp:160] Creating Layer norm1
I1109 03:15:14.814529 144581 net.cpp:596] norm1 <- conv1
I1109 03:15:14.817121 144581 net.cpp:570] norm1 -> norm1
I1109 03:15:15.040161 144581 net.cpp:210] Setting up norm1
I1109 03:15:15.053037 144581 net.cpp:217] Top shape: 32 96 55 55 (9292800)
I1109 03:15:15.053426 144581 net.cpp:225] Memory required for data: 131300864
I1109 03:15:15.053735 144581 layer_factory.hpp:114] Creating layer pool1
I1109 03:15:15.149006 144581 net.cpp:160] Creating Layer pool1
I1109 03:15:15.149328 144581 net.cpp:596] pool1 <- norm1
I1109 03:15:15.164095 144581 net.cpp:570] pool1 -> pool1
I1109 03:15:15.465466 144581 net.cpp:210] Setting up pool1
I1109 03:15:15.467936 144581 net.cpp:217] Top shape: 32 96 27 27 (2239488)
I1109 03:15:15.468272 144581 net.cpp:225] Memory required for data: 140258816
I1109 03:15:15.468536 144581 layer_factory.hpp:114] Creating layer conv2
I1109 03:15:15.468977 144581 net.cpp:160] Creating Layer conv2
I1109 03:15:15.469216 144581 net.cpp:596] conv2 <- pool1
I1109 03:15:15.469460 144581 net.cpp:570] conv2 -> conv2
I1109 03:15:21.276048 144581 net.cpp:210] Setting up conv2
I1109 03:15:21.276376 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.276768 144581 net.cpp:225] Memory required for data: 164146688
I1109 03:15:21.327150 144581 layer_factory.hpp:114] Creating layer relu2
I1109 03:15:21.327558 144581 net.cpp:160] Creating Layer relu2
I1109 03:15:21.327924 144581 net.cpp:596] relu2 <- conv2
I1109 03:15:21.328197 144581 net.cpp:557] relu2 -> conv2 (in-place)
I1109 03:15:21.328644 144581 net.cpp:210] Setting up relu2
I1109 03:15:21.328964 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.329210 144581 net.cpp:225] Memory required for data: 188034560
I1109 03:15:21.329404 144581 layer_factory.hpp:114] Creating layer norm2
I1109 03:15:21.329653 144581 net.cpp:160] Creating Layer norm2
I1109 03:15:21.329854 144581 net.cpp:596] norm2 <- conv2
I1109 03:15:21.330119 144581 net.cpp:570] norm2 -> norm2
I1109 03:15:21.332142 144581 net.cpp:210] Setting up norm2
I1109 03:15:21.332458 144581 net.cpp:217] Top shape: 32 256 27 27 (5971968)
I1109 03:15:21.332700 144581 net.cpp:225] Memory required for data: 211922432
I1109 03:15:21.332975 144581 layer_factory.hpp:114] Creating layer pool2
I1109 03:15:21.333947 144581 net.cpp:160] Creating Layer pool2
I1109 03:15:21.334246 144581 net.cpp:596] pool2 <- norm2
I1109 03:15:21.334499 144581 net.cpp:570] pool2 -> pool2
I1109 03:15:21.334908 144581 net.cpp:210] Setting up pool2
I1109 03:15:21.335162 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:21.335389 144581 net.cpp:225] Memory required for data: 217460224
I1109 03:15:21.335633 144581 layer_factory.hpp:114] Creating layer conv3
I1109 03:15:21.336079 144581 net.cpp:160] Creating Layer conv3
I1109 03:15:21.336403 144581 net.cpp:596] conv3 <- pool2
I1109 03:15:21.336671 144581 net.cpp:570] conv3 -> conv3
I1109 03:15:21.817616 144581 net.cpp:210] Setting up conv3
I1109 03:15:21.820060 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:21.820446 144581 net.cpp:225] Memory required for data: 225766912
I1109 03:15:21.823689 144581 layer_factory.hpp:114] Creating layer relu3
I1109 03:15:21.824156 144581 net.cpp:160] Creating Layer relu3
I1109 03:15:21.824422 144581 net.cpp:596] relu3 <- conv3
I1109 03:15:21.824683 144581 net.cpp:557] relu3 -> conv3 (in-place)
I1109 03:15:21.828848 144581 net.cpp:210] Setting up relu3
I1109 03:15:21.829203 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:21.829604 144581 net.cpp:225] Memory required for data: 234073600
I1109 03:15:21.829846 144581 layer_factory.hpp:114] Creating layer conv4
I1109 03:15:21.830211 144581 net.cpp:160] Creating Layer conv4
I1109 03:15:21.830477 144581 net.cpp:596] conv4 <- conv3
I1109 03:15:21.830737 144581 net.cpp:570] conv4 -> conv4
I1109 03:15:22.073447 144581 net.cpp:210] Setting up conv4
I1109 03:15:22.073849 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:22.074249 144581 net.cpp:225] Memory required for data: 242380288
I1109 03:15:22.074604 144581 layer_factory.hpp:114] Creating layer relu4
I1109 03:15:22.074910 144581 net.cpp:160] Creating Layer relu4
I1109 03:15:22.075150 144581 net.cpp:596] relu4 <- conv4
I1109 03:15:22.075400 144581 net.cpp:557] relu4 -> conv4 (in-place)
I1109 03:15:22.087805 144581 net.cpp:210] Setting up relu4
I1109 03:15:22.088160 144581 net.cpp:217] Top shape: 32 384 13 13 (2076672)
I1109 03:15:22.088543 144581 net.cpp:225] Memory required for data: 250686976
I1109 03:15:22.088830 144581 layer_factory.hpp:114] Creating layer conv5
I1109 03:15:22.089231 144581 net.cpp:160] Creating Layer conv5
I1109 03:15:22.089486 144581 net.cpp:596] conv5 <- conv4
I1109 03:15:22.089745 144581 net.cpp:570] conv5 -> conv5
I1109 03:15:22.259388 144581 net.cpp:210] Setting up conv5
I1109 03:15:22.259801 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:22.260256 144581 net.cpp:225] Memory required for data: 256224768
I1109 03:15:22.265054 144581 layer_factory.hpp:114] Creating layer relu5
I1109 03:15:22.265481 144581 net.cpp:160] Creating Layer relu5
I1109 03:15:22.265782 144581 net.cpp:596] relu5 <- conv5
I1109 03:15:22.266064 144581 net.cpp:557] relu5 -> conv5 (in-place)
I1109 03:15:22.266538 144581 net.cpp:210] Setting up relu5
I1109 03:15:22.266834 144581 net.cpp:217] Top shape: 32 256 13 13 (1384448)
I1109 03:15:22.267094 144581 net.cpp:225] Memory required for data: 261762560
I1109 03:15:22.267344 144581 layer_factory.hpp:114] Creating layer pool5
I1109 03:15:22.267627 144581 net.cpp:160] Creating Layer pool5
I1109 03:15:22.267868 144581 net.cpp:596] pool5 <- conv5
I1109 03:15:22.268136 144581 net.cpp:570] pool5 -> pool5
I1109 03:15:22.268546 144581 net.cpp:210] Setting up pool5
I1109 03:15:22.268851 144581 net.cpp:217] Top shape: 32 256 6 6 (294912)
I1109 03:15:22.269109 144581 net.cpp:225] Memory required for data: 262942208
I1109 03:15:22.269302 144581 layer_factory.hpp:114] Creating layer fc6
I1109 03:15:22.324019 144581 net.cpp:160] Creating Layer fc6
I1109 03:15:22.324338 144581 net.cpp:596] fc6 <- pool5
I1109 03:15:22.324717 144581 net.cpp:570] fc6 -> fc6
I1109 03:15:26.415623 144581 net.cpp:210] Setting up fc6
I1109 03:15:26.415938 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.418057 144581 net.cpp:225] Memory required for data: 263466496
I1109 03:15:26.418380 144581 layer_factory.hpp:114] Creating layer relu6
I1109 03:15:26.420892 144581 net.cpp:160] Creating Layer relu6
I1109 03:15:26.421201 144581 net.cpp:596] relu6 <- fc6
I1109 03:15:26.421439 144581 net.cpp:557] relu6 -> fc6 (in-place)
I1109 03:15:26.421866 144581 net.cpp:210] Setting up relu6
I1109 03:15:26.422158 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.422401 144581 net.cpp:225] Memory required for data: 263990784
I1109 03:15:26.422611 144581 layer_factory.hpp:114] Creating layer drop6
I1109 03:15:26.442781 144581 net.cpp:160] Creating Layer drop6
I1109 03:15:26.443097 144581 net.cpp:596] drop6 <- fc6
I1109 03:15:26.443503 144581 net.cpp:557] drop6 -> fc6 (in-place)
I1109 03:15:26.547603 144581 net.cpp:210] Setting up drop6
I1109 03:15:26.547911 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:26.548259 144581 net.cpp:225] Memory required for data: 264515072
I1109 03:15:26.548511 144581 layer_factory.hpp:114] Creating layer fc7
I1109 03:15:26.548828 144581 net.cpp:160] Creating Layer fc7
I1109 03:15:26.549067 144581 net.cpp:596] fc7 <- fc6
I1109 03:15:26.549469 144581 net.cpp:570] fc7 -> fc7
I1109 03:15:28.261710 144581 net.cpp:210] Setting up fc7
I1109 03:15:28.262084 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.262529 144581 net.cpp:225] Memory required for data: 265039360
I1109 03:15:28.262866 144581 layer_factory.hpp:114] Creating layer relu7
I1109 03:15:28.263205 144581 net.cpp:160] Creating Layer relu7
I1109 03:15:28.263458 144581 net.cpp:596] relu7 <- fc7
I1109 03:15:28.263726 144581 net.cpp:557] relu7 -> fc7 (in-place)
I1109 03:15:28.264189 144581 net.cpp:210] Setting up relu7
I1109 03:15:28.264478 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.264731 144581 net.cpp:225] Memory required for data: 265563648
I1109 03:15:28.265034 144581 layer_factory.hpp:114] Creating layer drop7
I1109 03:15:28.265300 144581 net.cpp:160] Creating Layer drop7
I1109 03:15:28.265527 144581 net.cpp:596] drop7 <- fc7
I1109 03:15:28.265823 144581 net.cpp:557] drop7 -> fc7 (in-place)
I1109 03:15:28.266103 144581 net.cpp:210] Setting up drop7
I1109 03:15:28.266314 144581 net.cpp:217] Top shape: 32 4096 (131072)
I1109 03:15:28.266536 144581 net.cpp:225] Memory required for data: 266087936
I1109 03:15:28.266726 144581 layer_factory.hpp:114] Creating layer fc8
I1109 03:15:28.266983 144581 net.cpp:160] Creating Layer fc8
I1109 03:15:28.267184 144581 net.cpp:596] fc8 <- fc7
I1109 03:15:28.267413 144581 net.cpp:570] fc8 -> fc8
I1109 03:15:28.691860 144581 net.cpp:210] Setting up fc8
I1109 03:15:28.692224 144581 net.cpp:217] Top shape: 32 1000 (32000)
I1109 03:15:28.692641 144581 net.cpp:225] Memory required for data: 266215936
I1109 03:15:28.693003 144581 layer_factory.hpp:114] Creating layer loss
I1109 03:15:28.717963 144581 net.cpp:160] Creating Layer loss
I1109 03:15:28.718291 144581 net.cpp:596] loss <- fc8
I1109 03:15:28.719297 144581 net.cpp:596] loss <- label
I1109 03:15:28.747107 144581 net.cpp:570] loss -> loss
I1109 03:15:28.785631 144581 layer_factory.hpp:114] Creating layer loss
I1109 03:15:31.272161 144581 net.cpp:210] Setting up loss
I1109 03:15:31.317008 144581 net.cpp:217] Top shape: (1)
I1109 03:15:31.331240 144581 net.cpp:220]     with loss weight 1
I1109 03:15:31.461827 144581 net.cpp:225] Memory required for data: 266215940
I1109 03:15:31.512262 144581 net.cpp:287] loss needs backward computation.
I1109 03:15:31.610437 144581 net.cpp:287] fc8 needs backward computation.
I1109 03:15:31.622076 144581 net.cpp:287] drop7 needs backward computation.
I1109 03:15:31.632908 144581 net.cpp:287] relu7 needs backward computation.
I1109 03:15:31.633218 144581 net.cpp:287] fc7 needs backward computation.
I1109 03:15:31.635547 144581 net.cpp:287] drop6 needs backward computation.
I1109 03:15:31.635888 144581 net.cpp:287] relu6 needs backward computation.
I1109 03:15:31.636193 144581 net.cpp:287] fc6 needs backward computation.
I1109 03:15:31.636963 144581 net.cpp:287] pool5 needs backward computation.
I1109 03:15:31.637696 144581 net.cpp:287] relu5 needs backward computation.
I1109 03:15:31.637949 144581 net.cpp:287] conv5 needs backward computation.
I1109 03:15:31.638139 144581 net.cpp:287] relu4 needs backward computation.
I1109 03:15:31.638316 144581 net.cpp:287] conv4 needs backward computation.
I1109 03:15:31.638536 144581 net.cpp:287] relu3 needs backward computation.
I1109 03:15:31.638731 144581 net.cpp:287] conv3 needs backward computation.
I1109 03:15:31.651257 144581 net.cpp:287] pool2 needs backward computation.
I1109 03:15:31.651594 144581 net.cpp:287] norm2 needs backward computation.
I1109 03:15:31.651895 144581 net.cpp:287] relu2 needs backward computation.
I1109 03:15:31.652127 144581 net.cpp:287] conv2 needs backward computation.
I1109 03:15:31.652315 144581 net.cpp:287] pool1 needs backward computation.
I1109 03:15:31.652500 144581 net.cpp:287] norm1 needs backward computation.
I1109 03:15:31.652683 144581 net.cpp:287] relu1 needs backward computation.
I1109 03:15:31.652905 144581 net.cpp:287] conv1 needs backward computation.
I1109 03:15:31.665381 144581 net.cpp:289] data does not need backward computation.
I1109 03:15:31.689586 144581 net.cpp:331] This network produces output loss
I1109 03:15:31.763322 144581 net.cpp:345] Network initialization done.
I1109 03:15:31.931301 144581 caffe.cpp:452] Performing Forward
I1109 03:15:45.224436 144581 caffe.cpp:457] Initial loss: 6.90134
I1109 03:15:45.279042 144581 caffe.cpp:459] Performing Backward
I1109 03:15:50.090430 144581 caffe.cpp:468] *** Benchmark begins ***
I1109 03:15:50.102063 144581 caffe.cpp:469] Testing for 1 iterations.
I1109 03:15:50.249383 144581 caffe.cpp:485] Profiling Layer: drop6 backward
I1109 03:15:52.421960 144581 caffe.cpp:512] Iteration: 1 forward-backward time: 2165 ms.
I1109 03:15:52.581023 144581 caffe.cpp:519] Average time per layer: 
I1109 03:15:52.600108 144581 caffe.cpp:522]       data	forward: 546.999 ms.
I1109 03:15:52.673866 144581 caffe.cpp:526]       data	backward: 5.247 ms.
I1109 03:15:52.697134 144581 caffe.cpp:522]      conv1	forward: 123.725 ms.
I1109 03:15:52.714140 144581 caffe.cpp:526]      conv1	backward: 41.744 ms.
I1109 03:15:52.721014 144581 caffe.cpp:522]      relu1	forward: 25.406 ms.
I1109 03:15:52.729439 144581 caffe.cpp:526]      relu1	backward: 15.369 ms.
I1109 03:15:52.742593 144581 caffe.cpp:522]      norm1	forward: 16.396 ms.
I1109 03:15:52.749006 144581 caffe.cpp:526]      norm1	backward: 15.137 ms.
I1109 03:15:52.757910 144581 caffe.cpp:522]      pool1	forward: 27.193 ms.
I1109 03:15:52.761970 144581 caffe.cpp:526]      pool1	backward: 68.123 ms.
I1109 03:15:52.766660 144581 caffe.cpp:522]      conv2	forward: 61.741 ms.
I1109 03:15:52.769222 144581 caffe.cpp:526]      conv2	backward: 75.727 ms.
I1109 03:15:52.781787 144581 caffe.cpp:522]      relu2	forward: 11.522 ms.
I1109 03:15:52.785727 144581 caffe.cpp:526]      relu2	backward: 18.036 ms.
I1109 03:15:52.787376 144581 caffe.cpp:522]      norm2	forward: 12.794 ms.
I1109 03:15:52.787585 144581 caffe.cpp:526]      norm2	backward: 17.428 ms.
I1109 03:15:52.787780 144581 caffe.cpp:522]      pool2	forward: 13.854 ms.
I1109 03:15:52.788007 144581 caffe.cpp:526]      pool2	backward: 56.419 ms.
I1109 03:15:52.788210 144581 caffe.cpp:522]      conv3	forward: 32.112 ms.
I1109 03:15:52.788499 144581 caffe.cpp:526]      conv3	backward: 88.098 ms.
I1109 03:15:52.788754 144581 caffe.cpp:522]      relu3	forward: 12.181 ms.
I1109 03:15:52.788995 144581 caffe.cpp:526]      relu3	backward: 23.283 ms.
I1109 03:15:52.789189 144581 caffe.cpp:522]      conv4	forward: 35.451 ms.
I1109 03:15:52.789382 144581 caffe.cpp:526]      conv4	backward: 77.82 ms.
I1109 03:15:52.789575 144581 caffe.cpp:522]      relu4	forward: 20.514 ms.
I1109 03:15:52.789767 144581 caffe.cpp:526]      relu4	backward: 43.933 ms.
I1109 03:15:52.789958 144581 caffe.cpp:522]      conv5	forward: 24.782 ms.
I1109 03:15:52.790148 144581 caffe.cpp:526]      conv5	backward: 66.974 ms.
I1109 03:15:52.790339 144581 caffe.cpp:522]      relu5	forward: 0.203 ms.
I1109 03:15:52.790562 144581 caffe.cpp:526]      relu5	backward: 10.174 ms.
I1109 03:15:52.793202 144581 caffe.cpp:522]      pool5	forward: 0.328 ms.
I1109 03:15:52.793560 144581 caffe.cpp:526]      pool5	backward: 54.84 ms.
I1109 03:15:52.793833 144581 caffe.cpp:522]        fc6	forward: 16.882 ms.
I1109 03:15:52.794075 144581 caffe.cpp:526]        fc6	backward: 120.944 ms.
I1109 03:15:52.794275 144581 caffe.cpp:522]      relu6	forward: 0.812 ms.
I1109 03:15:52.794466 144581 caffe.cpp:526]      relu6	backward: 17.794 ms.
I1109 03:15:52.794659 144581 caffe.cpp:522]      drop6	forward: 1.545 ms.
I1109 03:15:52.794847 144581 caffe.cpp:526]      drop6	backward: 30.746 ms.
I1109 03:15:52.795038 144581 caffe.cpp:522]        fc7	forward: 4.653 ms.
I1109 03:15:52.795225 144581 caffe.cpp:526]        fc7	backward: 81.488 ms.
I1109 03:15:52.795418 144581 caffe.cpp:522]      relu7	forward: 0.125 ms.
I1109 03:15:52.795605 144581 caffe.cpp:526]      relu7	backward: 0.091 ms.
I1109 03:15:52.798229 144581 caffe.cpp:522]      drop7	forward: 0.298 ms.
I1109 03:15:52.798501 144581 caffe.cpp:526]      drop7	backward: 0.092 ms.
I1109 03:15:52.798831 144581 caffe.cpp:522]        fc8	forward: 1.928 ms.
I1109 03:15:52.799087 144581 caffe.cpp:526]        fc8	backward: 75.153 ms.
I1109 03:15:52.799294 144581 caffe.cpp:522]       loss	forward: 33.758 ms.
I1109 03:15:52.799491 144581 caffe.cpp:526]       loss	backward: 39.701 ms.
I1109 03:15:52.805058 144581 caffe.cpp:532] Average Forward pass: 1079.78 ms.
I1109 03:15:52.819470 144581 caffe.cpp:535] Average Backward pass: 1054.3 ms.
I1109 03:15:52.830391 144581 caffe.cpp:537] Average Forward-Backward: 2657 ms.
I1109 03:15:52.845538 144581 caffe.cpp:540] Total Time: 2657 ms.
I1109 03:15:52.857942 144581 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 16384
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 262144
--->Total double-precision FLOPs = 0
--->Total FLOPs = 262144
mem-read-1 = 27985
mem-read-2 = 37
mem-read-4 = 224941
mem-read-8 = 311478
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 16384
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 749
mem-write-8 = 30021
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 8192
--->Total Bytes read = 4468223
--->Total Bytes written = 767542
--->Total Bytes = 5235765

srun -n 1 -c 32 --cpu_bind=socket -m block:cyclic /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-hsw/bin//caffe time -model=subst_train_val.prototxt -iterations=10
I1013 15:25:09.102068 56971 caffe.cpp:437] Use CPU.
I1013 15:25:09.108644 56971 cpu_info.cpp:452] Processor speed [MHz]: 2300
I1013 15:25:09.108654 56971 cpu_info.cpp:455] Total number of sockets: 2
I1013 15:25:09.108656 56971 cpu_info.cpp:458] Total number of CPU cores: 32
I1013 15:25:09.108659 56971 cpu_info.cpp:461] Total number of processors: 64
I1013 15:25:09.108660 56971 cpu_info.cpp:464] GPU is used: no
I1013 15:25:09.108662 56971 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1013 15:25:09.108664 56971 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1013 15:25:09.108666 56971 cpu_info.cpp:473] Number of OpenMP threads: 16
I1013 15:25:09.111047 56971 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1013 15:25:09.111137 56971 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 16
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 16
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1013 15:25:09.111261 56971 layer_factory.hpp:114] Creating layer data
I1013 15:25:09.111271 56971 net.cpp:160] Creating Layer data
I1013 15:25:09.111274 56971 net.cpp:570] data -> data
I1013 15:25:09.111285 56971 net.cpp:570] data -> label
I1013 15:25:09.111506 56971 net.cpp:210] Setting up data
I1013 15:25:09.111515 56971 net.cpp:217] Top shape: 16 3 124 124 (738048)
I1013 15:25:09.111524 56971 net.cpp:217] Top shape: 16 1 1 1 (16)
I1013 15:25:09.111527 56971 net.cpp:225] Memory required for data: 2952256
I1013 15:25:09.111531 56971 layer_factory.hpp:114] Creating layer conv1
I1013 15:25:09.111544 56971 net.cpp:160] Creating Layer conv1
I1013 15:25:09.111548 56971 net.cpp:596] conv1 <- data
I1013 15:25:09.111554 56971 net.cpp:570] conv1 -> conv1
I1013 15:25:09.140023 56971 net.cpp:210] Setting up conv1
I1013 15:25:09.140041 56971 net.cpp:217] Top shape: 16 128 122 122 (30482432)
I1013 15:25:09.140049 56971 net.cpp:225] Memory required for data: 124881984
I1013 15:25:09.140071 56971 layer_factory.hpp:114] Creating layer relu1
I1013 15:25:09.140103 56971 net.cpp:160] Creating Layer relu1
I1013 15:25:09.140116 56971 net.cpp:596] relu1 <- conv1
I1013 15:25:09.140126 56971 net.cpp:557] relu1 -> conv1 (in-place)
I1013 15:25:09.140161 56971 net.cpp:210] Setting up relu1
I1013 15:25:09.140172 56971 net.cpp:217] Top shape: 16 128 122 122 (30482432)
I1013 15:25:09.140189 56971 net.cpp:225] Memory required for data: 246811712
I1013 15:25:09.140195 56971 layer_factory.hpp:114] Creating layer dropout1
I1013 15:25:09.140203 56971 net.cpp:160] Creating Layer dropout1
I1013 15:25:09.140208 56971 net.cpp:596] dropout1 <- conv1
I1013 15:25:09.140215 56971 net.cpp:570] dropout1 -> drop1
I1013 15:25:09.140228 56971 net.cpp:210] Setting up dropout1
I1013 15:25:09.140239 56971 net.cpp:217] Top shape: 16 128 122 122 (30482432)
I1013 15:25:09.140245 56971 net.cpp:225] Memory required for data: 368741440
I1013 15:25:09.140249 56971 layer_factory.hpp:114] Creating layer pool1
I1013 15:25:09.140264 56971 net.cpp:160] Creating Layer pool1
I1013 15:25:09.140269 56971 net.cpp:596] pool1 <- drop1
I1013 15:25:09.140280 56971 net.cpp:570] pool1 -> pool1
I1013 15:25:09.140305 56971 net.cpp:210] Setting up pool1
I1013 15:25:09.140311 56971 net.cpp:217] Top shape: 16 128 61 61 (7620608)
I1013 15:25:09.140316 56971 net.cpp:225] Memory required for data: 399223872
I1013 15:25:09.140321 56971 layer_factory.hpp:114] Creating layer conv2
I1013 15:25:09.140342 56971 net.cpp:160] Creating Layer conv2
I1013 15:25:09.140347 56971 net.cpp:596] conv2 <- pool1
I1013 15:25:09.140354 56971 net.cpp:570] conv2 -> conv2
I1013 15:25:09.263372 56971 net.cpp:210] Setting up conv2
I1013 15:25:09.263411 56971 net.cpp:217] Top shape: 16 128 59 59 (7129088)
I1013 15:25:09.263423 56971 net.cpp:225] Memory required for data: 427740224
I1013 15:25:09.263447 56971 layer_factory.hpp:114] Creating layer relu2
I1013 15:25:09.263470 56971 net.cpp:160] Creating Layer relu2
I1013 15:25:09.263476 56971 net.cpp:596] relu2 <- conv2
I1013 15:25:09.263485 56971 net.cpp:557] relu2 -> conv2 (in-place)
I1013 15:25:09.263514 56971 net.cpp:210] Setting up relu2
I1013 15:25:09.263557 56971 net.cpp:217] Top shape: 16 128 59 59 (7129088)
I1013 15:25:09.263609 56971 net.cpp:225] Memory required for data: 456256576
I1013 15:25:09.263662 56971 layer_factory.hpp:114] Creating layer dropout2
I1013 15:25:09.263679 56971 net.cpp:160] Creating Layer dropout2
I1013 15:25:09.263684 56971 net.cpp:596] dropout2 <- conv2
I1013 15:25:09.263691 56971 net.cpp:570] dropout2 -> drop2
I1013 15:25:09.263705 56971 net.cpp:210] Setting up dropout2
I1013 15:25:09.263710 56971 net.cpp:217] Top shape: 16 128 59 59 (7129088)
I1013 15:25:09.263717 56971 net.cpp:225] Memory required for data: 484772928
I1013 15:25:09.263722 56971 layer_factory.hpp:114] Creating layer pool2
I1013 15:25:09.263746 56971 net.cpp:160] Creating Layer pool2
I1013 15:25:09.263751 56971 net.cpp:596] pool2 <- drop2
I1013 15:25:09.263761 56971 net.cpp:570] pool2 -> pool2
I1013 15:25:09.263788 56971 net.cpp:210] Setting up pool2
I1013 15:25:09.263829 56971 net.cpp:217] Top shape: 16 128 30 30 (1843200)
I1013 15:25:09.263893 56971 net.cpp:225] Memory required for data: 492145728
I1013 15:25:09.263901 56971 layer_factory.hpp:114] Creating layer conv3
I1013 15:25:09.263932 56971 net.cpp:160] Creating Layer conv3
I1013 15:25:09.263958 56971 net.cpp:596] conv3 <- pool2
I1013 15:25:09.264000 56971 net.cpp:570] conv3 -> conv3
I1013 15:25:09.298557 56971 net.cpp:210] Setting up conv3
I1013 15:25:09.298588 56971 net.cpp:217] Top shape: 16 128 28 28 (1605632)
I1013 15:25:09.298600 56971 net.cpp:225] Memory required for data: 498568256
I1013 15:25:09.298622 56971 layer_factory.hpp:114] Creating layer relu3
I1013 15:25:09.298645 56971 net.cpp:160] Creating Layer relu3
I1013 15:25:09.298650 56971 net.cpp:596] relu3 <- conv3
I1013 15:25:09.298660 56971 net.cpp:557] relu3 -> conv3 (in-place)
I1013 15:25:09.298689 56971 net.cpp:210] Setting up relu3
I1013 15:25:09.298698 56971 net.cpp:217] Top shape: 16 128 28 28 (1605632)
I1013 15:25:09.298704 56971 net.cpp:225] Memory required for data: 504990784
I1013 15:25:09.298708 56971 layer_factory.hpp:114] Creating layer dropout3
I1013 15:25:09.298723 56971 net.cpp:160] Creating Layer dropout3
I1013 15:25:09.298739 56971 net.cpp:596] dropout3 <- conv3
I1013 15:25:09.298750 56971 net.cpp:570] dropout3 -> drop3
I1013 15:25:09.298764 56971 net.cpp:210] Setting up dropout3
I1013 15:25:09.298770 56971 net.cpp:217] Top shape: 16 128 28 28 (1605632)
I1013 15:25:09.298776 56971 net.cpp:225] Memory required for data: 511413312
I1013 15:25:09.298781 56971 layer_factory.hpp:114] Creating layer pool3
I1013 15:25:09.298796 56971 net.cpp:160] Creating Layer pool3
I1013 15:25:09.298802 56971 net.cpp:596] pool3 <- drop3
I1013 15:25:09.298811 56971 net.cpp:570] pool3 -> pool3
I1013 15:25:09.298836 56971 net.cpp:210] Setting up pool3
I1013 15:25:09.298844 56971 net.cpp:217] Top shape: 16 128 14 14 (401408)
I1013 15:25:09.298851 56971 net.cpp:225] Memory required for data: 513018944
I1013 15:25:09.298856 56971 layer_factory.hpp:114] Creating layer conv4
I1013 15:25:09.298880 56971 net.cpp:160] Creating Layer conv4
I1013 15:25:09.298888 56971 net.cpp:596] conv4 <- pool3
I1013 15:25:09.298902 56971 net.cpp:570] conv4 -> conv4
I1013 15:25:09.312695 56971 net.cpp:210] Setting up conv4
I1013 15:25:09.312713 56971 net.cpp:217] Top shape: 16 128 12 12 (294912)
I1013 15:25:09.312721 56971 net.cpp:225] Memory required for data: 514198592
I1013 15:25:09.312731 56971 layer_factory.hpp:114] Creating layer relu4
I1013 15:25:09.312746 56971 net.cpp:160] Creating Layer relu4
I1013 15:25:09.312750 56971 net.cpp:596] relu4 <- conv4
I1013 15:25:09.312757 56971 net.cpp:557] relu4 -> conv4 (in-place)
I1013 15:25:09.312778 56971 net.cpp:210] Setting up relu4
I1013 15:25:09.312786 56971 net.cpp:217] Top shape: 16 128 12 12 (294912)
I1013 15:25:09.312793 56971 net.cpp:225] Memory required for data: 515378240
I1013 15:25:09.312798 56971 layer_factory.hpp:114] Creating layer dropout4
I1013 15:25:09.312805 56971 net.cpp:160] Creating Layer dropout4
I1013 15:25:09.312810 56971 net.cpp:596] dropout4 <- conv4
I1013 15:25:09.312818 56971 net.cpp:570] dropout4 -> drop4
I1013 15:25:09.312827 56971 net.cpp:210] Setting up dropout4
I1013 15:25:09.312831 56971 net.cpp:217] Top shape: 16 128 12 12 (294912)
I1013 15:25:09.312839 56971 net.cpp:225] Memory required for data: 516557888
I1013 15:25:09.312842 56971 layer_factory.hpp:114] Creating layer pool4
I1013 15:25:09.312860 56971 net.cpp:160] Creating Layer pool4
I1013 15:25:09.312871 56971 net.cpp:596] pool4 <- drop4
I1013 15:25:09.312880 56971 net.cpp:570] pool4 -> pool4
I1013 15:25:09.312901 56971 net.cpp:210] Setting up pool4
I1013 15:25:09.312907 56971 net.cpp:217] Top shape: 16 128 6 6 (73728)
I1013 15:25:09.312914 56971 net.cpp:225] Memory required for data: 516852800
I1013 15:25:09.312924 56971 layer_factory.hpp:114] Creating layer fc1
I1013 15:25:09.312943 56971 net.cpp:160] Creating Layer fc1
I1013 15:25:09.312952 56971 net.cpp:596] fc1 <- pool4
I1013 15:25:09.312959 56971 net.cpp:570] fc1 -> fc1
I1013 15:25:09.383113 56971 net.cpp:210] Setting up fc1
I1013 15:25:09.383124 56971 net.cpp:217] Top shape: 16 1024 (16384)
I1013 15:25:09.383132 56971 net.cpp:225] Memory required for data: 516918336
I1013 15:25:09.383148 56971 layer_factory.hpp:114] Creating layer dropout5
I1013 15:25:09.383157 56971 net.cpp:160] Creating Layer dropout5
I1013 15:25:09.383162 56971 net.cpp:596] dropout5 <- fc1
I1013 15:25:09.383170 56971 net.cpp:570] dropout5 -> drop5
I1013 15:25:09.383183 56971 net.cpp:210] Setting up dropout5
I1013 15:25:09.383191 56971 net.cpp:217] Top shape: 16 1024 (16384)
I1013 15:25:09.383203 56971 net.cpp:225] Memory required for data: 516983872
I1013 15:25:09.383208 56971 layer_factory.hpp:114] Creating layer fc2
I1013 15:25:09.383219 56971 net.cpp:160] Creating Layer fc2
I1013 15:25:09.383226 56971 net.cpp:596] fc2 <- drop5
I1013 15:25:09.383239 56971 net.cpp:570] fc2 -> fc2
I1013 15:25:09.383314 56971 net.cpp:210] Setting up fc2
I1013 15:25:09.383325 56971 net.cpp:217] Top shape: 16 2 (32)
I1013 15:25:09.383337 56971 net.cpp:225] Memory required for data: 516984000
I1013 15:25:09.383347 56971 layer_factory.hpp:114] Creating layer loss
I1013 15:25:09.383359 56971 net.cpp:160] Creating Layer loss
I1013 15:25:09.383365 56971 net.cpp:596] loss <- fc2
I1013 15:25:09.383371 56971 net.cpp:596] loss <- label
I1013 15:25:09.383383 56971 net.cpp:570] loss -> (automatic)
I1013 15:25:09.383395 56971 layer_factory.hpp:114] Creating layer loss
I1013 15:25:09.383429 56971 net.cpp:210] Setting up loss
I1013 15:25:09.383437 56971 net.cpp:217] Top shape: (1)
I1013 15:25:09.383445 56971 net.cpp:220]     with loss weight 1
I1013 15:25:09.383493 56971 net.cpp:225] Memory required for data: 516984004
I1013 15:25:09.383502 56971 net.cpp:287] loss needs backward computation.
I1013 15:25:09.383507 56971 net.cpp:287] fc2 needs backward computation.
I1013 15:25:09.383512 56971 net.cpp:287] dropout5 needs backward computation.
I1013 15:25:09.383517 56971 net.cpp:287] fc1 needs backward computation.
I1013 15:25:09.383520 56971 net.cpp:287] pool4 needs backward computation.
I1013 15:25:09.383525 56971 net.cpp:287] dropout4 needs backward computation.
I1013 15:25:09.383529 56971 net.cpp:287] relu4 needs backward computation.
I1013 15:25:09.383534 56971 net.cpp:287] conv4 needs backward computation.
I1013 15:25:09.383539 56971 net.cpp:287] pool3 needs backward computation.
I1013 15:25:09.383543 56971 net.cpp:287] dropout3 needs backward computation.
I1013 15:25:09.383548 56971 net.cpp:287] relu3 needs backward computation.
I1013 15:25:09.383553 56971 net.cpp:287] conv3 needs backward computation.
I1013 15:25:09.383558 56971 net.cpp:287] pool2 needs backward computation.
I1013 15:25:09.383563 56971 net.cpp:287] dropout2 needs backward computation.
I1013 15:25:09.383568 56971 net.cpp:287] relu2 needs backward computation.
I1013 15:25:09.383571 56971 net.cpp:287] conv2 needs backward computation.
I1013 15:25:09.383577 56971 net.cpp:287] pool1 needs backward computation.
I1013 15:25:09.383581 56971 net.cpp:287] dropout1 needs backward computation.
I1013 15:25:09.383586 56971 net.cpp:287] relu1 needs backward computation.
I1013 15:25:09.383591 56971 net.cpp:287] conv1 needs backward computation.
I1013 15:25:09.383596 56971 net.cpp:289] data does not need backward computation.
I1013 15:25:09.383616 56971 net.cpp:345] Network initialization done.
I1013 15:25:09.383738 56971 caffe.cpp:445] Performing Forward
I1013 15:25:09.693107 56971 caffe.cpp:450] Initial loss: 51.3099
I1013 15:25:09.693150 56971 caffe.cpp:452] Performing Backward
I1013 15:25:10.002481 56971 caffe.cpp:461] *** Benchmark begins ***
I1013 15:25:10.002509 56971 caffe.cpp:462] Testing for 10 iterations.
I1013 15:25:10.249241 56971 caffe.cpp:491] Iteration: 1 forward-backward time: 246 ms.
I1013 15:25:10.495584 56971 caffe.cpp:491] Iteration: 2 forward-backward time: 246 ms.
I1013 15:25:10.739586 56971 caffe.cpp:491] Iteration: 3 forward-backward time: 243 ms.
I1013 15:25:10.983201 56971 caffe.cpp:491] Iteration: 4 forward-backward time: 243 ms.
I1013 15:25:11.227613 56971 caffe.cpp:491] Iteration: 5 forward-backward time: 244 ms.
I1013 15:25:11.472014 56971 caffe.cpp:491] Iteration: 6 forward-backward time: 244 ms.
I1013 15:25:11.718202 56971 caffe.cpp:491] Iteration: 7 forward-backward time: 246 ms.
I1013 15:25:11.964714 56971 caffe.cpp:491] Iteration: 8 forward-backward time: 246 ms.
I1013 15:25:12.210871 56971 caffe.cpp:491] Iteration: 9 forward-backward time: 246 ms.
I1013 15:25:12.457615 56971 caffe.cpp:491] Iteration: 10 forward-backward time: 246 ms.
I1013 15:25:12.457653 56971 caffe.cpp:498] Average time per layer: 
I1013 15:25:12.457656 56971 caffe.cpp:501]       data	forward: 10.0256 ms.
I1013 15:25:12.457664 56971 caffe.cpp:505]       data	backward: 0.0017 ms.
I1013 15:25:12.457669 56971 caffe.cpp:501]      conv1	forward: 6.0989 ms.
I1013 15:25:12.457672 56971 caffe.cpp:505]      conv1	backward: 7.6378 ms.
I1013 15:25:12.457676 56971 caffe.cpp:501]      relu1	forward: 4.7694 ms.
I1013 15:25:12.457680 56971 caffe.cpp:505]      relu1	backward: 13.5918 ms.
I1013 15:25:12.457685 56971 caffe.cpp:501]   dropout1	forward: 24.8335 ms.
I1013 15:25:12.457691 56971 caffe.cpp:505]   dropout1	backward: 15.3574 ms.
I1013 15:25:12.457695 56971 caffe.cpp:501]      pool1	forward: 11.3823 ms.
I1013 15:25:12.457700 56971 caffe.cpp:505]      pool1	backward: 10.4191 ms.
I1013 15:25:12.457703 56971 caffe.cpp:501]      conv2	forward: 17.7817 ms.
I1013 15:25:12.457707 56971 caffe.cpp:505]      conv2	backward: 84.9095 ms.
I1013 15:25:12.457712 56971 caffe.cpp:501]      relu2	forward: 0.5134 ms.
I1013 15:25:12.457716 56971 caffe.cpp:505]      relu2	backward: 2.6852 ms.
I1013 15:25:12.457720 56971 caffe.cpp:501]   dropout2	forward: 4.5295 ms.
I1013 15:25:12.457725 56971 caffe.cpp:505]   dropout2	backward: 3.6533 ms.
I1013 15:25:12.457728 56971 caffe.cpp:501]      pool2	forward: 2.9469 ms.
I1013 15:25:12.457733 56971 caffe.cpp:505]      pool2	backward: 1.9875 ms.
I1013 15:25:12.457736 56971 caffe.cpp:501]      conv3	forward: 3.7735 ms.
I1013 15:25:12.457741 56971 caffe.cpp:505]      conv3	backward: 10.4318 ms.
I1013 15:25:12.457746 56971 caffe.cpp:501]      relu3	forward: 0.0335 ms.
I1013 15:25:12.457751 56971 caffe.cpp:505]      relu3	backward: 0.2435 ms.
I1013 15:25:12.457756 56971 caffe.cpp:501]   dropout3	forward: 0.6418 ms.
I1013 15:25:12.457762 56971 caffe.cpp:505]   dropout3	backward: 0.443 ms.
I1013 15:25:12.457767 56971 caffe.cpp:501]      pool3	forward: 0.7 ms.
I1013 15:25:12.457772 56971 caffe.cpp:505]      pool3	backward: 0.4326 ms.
I1013 15:25:12.457777 56971 caffe.cpp:501]      conv4	forward: 0.7505 ms.
I1013 15:25:12.457780 56971 caffe.cpp:505]      conv4	backward: 2.0108 ms.
I1013 15:25:12.457785 56971 caffe.cpp:501]      relu4	forward: 0.0071 ms.
I1013 15:25:12.457790 56971 caffe.cpp:505]      relu4	backward: 0.0653 ms.
I1013 15:25:12.457795 56971 caffe.cpp:501]   dropout4	forward: 0.1624 ms.
I1013 15:25:12.457800 56971 caffe.cpp:505]   dropout4	backward: 0.1462 ms.
I1013 15:25:12.457805 56971 caffe.cpp:501]      pool4	forward: 0.1401 ms.
I1013 15:25:12.457809 56971 caffe.cpp:505]      pool4	backward: 0.0808 ms.
I1013 15:25:12.457815 56971 caffe.cpp:501]        fc1	forward: 0.7466 ms.
I1013 15:25:12.457820 56971 caffe.cpp:505]        fc1	backward: 1.3399 ms.
I1013 15:25:12.457824 56971 caffe.cpp:501]   dropout5	forward: 0.016 ms.
I1013 15:25:12.457830 56971 caffe.cpp:505]   dropout5	backward: 0.0096 ms.
I1013 15:25:12.457835 56971 caffe.cpp:501]        fc2	forward: 0.0134 ms.
I1013 15:25:12.457840 56971 caffe.cpp:505]        fc2	backward: 0.0367 ms.
I1013 15:25:12.457845 56971 caffe.cpp:501]       loss	forward: 0.0454 ms.
I1013 15:25:12.457850 56971 caffe.cpp:505]       loss	backward: 0.0038 ms.
I1013 15:25:12.457857 56971 caffe.cpp:511] Average Forward pass: 89.9414 ms.
I1013 15:25:12.457864 56971 caffe.cpp:514] Average Backward pass: 155.519 ms.
I1013 15:25:12.457868 56971 caffe.cpp:516] Average Forward-Backward: 245.5 ms.
I1013 15:25:12.457890 56971 caffe.cpp:519] Total Time: 2455 ms.
I1013 15:25:12.457896 56971 caffe.cpp:520] *** Benchmark ends ***

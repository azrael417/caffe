srun -n 1 -c 32 --cpu_bind=socket -m block:cyclic /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-hsw/bin//caffe time -model=subst_train_val.prototxt -iterations=10
I1013 15:25:35.061365 57122 caffe.cpp:437] Use CPU.
I1013 15:25:35.068580 57122 cpu_info.cpp:452] Processor speed [MHz]: 2300
I1013 15:25:35.068590 57122 cpu_info.cpp:455] Total number of sockets: 2
I1013 15:25:35.068593 57122 cpu_info.cpp:458] Total number of CPU cores: 32
I1013 15:25:35.068595 57122 cpu_info.cpp:461] Total number of processors: 64
I1013 15:25:35.068598 57122 cpu_info.cpp:464] GPU is used: no
I1013 15:25:35.068598 57122 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1013 15:25:35.068600 57122 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1013 15:25:35.068603 57122 cpu_info.cpp:473] Number of OpenMP threads: 16
I1013 15:25:35.070767 57122 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1013 15:25:35.070863 57122 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 128
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 128
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1013 15:25:35.070993 57122 layer_factory.hpp:114] Creating layer data
I1013 15:25:35.071003 57122 net.cpp:160] Creating Layer data
I1013 15:25:35.071007 57122 net.cpp:570] data -> data
I1013 15:25:35.071018 57122 net.cpp:570] data -> label
I1013 15:25:35.071210 57122 net.cpp:210] Setting up data
I1013 15:25:35.071218 57122 net.cpp:217] Top shape: 128 3 124 124 (5904384)
I1013 15:25:35.071228 57122 net.cpp:217] Top shape: 128 1 1 1 (128)
I1013 15:25:35.071231 57122 net.cpp:225] Memory required for data: 23618048
I1013 15:25:35.071234 57122 layer_factory.hpp:114] Creating layer conv1
I1013 15:25:35.071249 57122 net.cpp:160] Creating Layer conv1
I1013 15:25:35.071252 57122 net.cpp:596] conv1 <- data
I1013 15:25:35.071259 57122 net.cpp:570] conv1 -> conv1
I1013 15:25:35.092700 57122 net.cpp:210] Setting up conv1
I1013 15:25:35.092717 57122 net.cpp:217] Top shape: 128 128 122 122 (243859456)
I1013 15:25:35.092726 57122 net.cpp:225] Memory required for data: 999055872
I1013 15:25:35.092747 57122 layer_factory.hpp:114] Creating layer relu1
I1013 15:25:35.092780 57122 net.cpp:160] Creating Layer relu1
I1013 15:25:35.092794 57122 net.cpp:596] relu1 <- conv1
I1013 15:25:35.092805 57122 net.cpp:557] relu1 -> conv1 (in-place)
I1013 15:25:35.092839 57122 net.cpp:210] Setting up relu1
I1013 15:25:35.092851 57122 net.cpp:217] Top shape: 128 128 122 122 (243859456)
I1013 15:25:35.092859 57122 net.cpp:225] Memory required for data: 1974493696
I1013 15:25:35.092864 57122 layer_factory.hpp:114] Creating layer dropout1
I1013 15:25:35.092871 57122 net.cpp:160] Creating Layer dropout1
I1013 15:25:35.092875 57122 net.cpp:596] dropout1 <- conv1
I1013 15:25:35.092882 57122 net.cpp:570] dropout1 -> drop1
I1013 15:25:35.092895 57122 net.cpp:210] Setting up dropout1
I1013 15:25:35.092905 57122 net.cpp:217] Top shape: 128 128 122 122 (243859456)
I1013 15:25:35.092916 57122 net.cpp:225] Memory required for data: 2949931520
I1013 15:25:35.092919 57122 layer_factory.hpp:114] Creating layer pool1
I1013 15:25:35.092932 57122 net.cpp:160] Creating Layer pool1
I1013 15:25:35.092942 57122 net.cpp:596] pool1 <- drop1
I1013 15:25:35.092949 57122 net.cpp:570] pool1 -> pool1
I1013 15:25:35.092975 57122 net.cpp:210] Setting up pool1
I1013 15:25:35.092980 57122 net.cpp:217] Top shape: 128 128 61 61 (60964864)
I1013 15:25:35.092988 57122 net.cpp:225] Memory required for data: 3193790976
I1013 15:25:35.092991 57122 layer_factory.hpp:114] Creating layer conv2
I1013 15:25:35.093014 57122 net.cpp:160] Creating Layer conv2
I1013 15:25:35.093019 57122 net.cpp:596] conv2 <- pool1
I1013 15:25:35.093025 57122 net.cpp:570] conv2 -> conv2
I1013 15:25:35.216112 57122 net.cpp:210] Setting up conv2
I1013 15:25:35.216147 57122 net.cpp:217] Top shape: 128 128 59 59 (57032704)
I1013 15:25:35.216161 57122 net.cpp:225] Memory required for data: 3421921792
I1013 15:25:35.216184 57122 layer_factory.hpp:114] Creating layer relu2
I1013 15:25:35.216207 57122 net.cpp:160] Creating Layer relu2
I1013 15:25:35.216213 57122 net.cpp:596] relu2 <- conv2
I1013 15:25:35.216224 57122 net.cpp:557] relu2 -> conv2 (in-place)
I1013 15:25:35.216255 57122 net.cpp:210] Setting up relu2
I1013 15:25:35.216296 57122 net.cpp:217] Top shape: 128 128 59 59 (57032704)
I1013 15:25:35.216348 57122 net.cpp:225] Memory required for data: 3650052608
I1013 15:25:35.216408 57122 layer_factory.hpp:114] Creating layer dropout2
I1013 15:25:35.216420 57122 net.cpp:160] Creating Layer dropout2
I1013 15:25:35.216425 57122 net.cpp:596] dropout2 <- conv2
I1013 15:25:35.216433 57122 net.cpp:570] dropout2 -> drop2
I1013 15:25:35.216447 57122 net.cpp:210] Setting up dropout2
I1013 15:25:35.216451 57122 net.cpp:217] Top shape: 128 128 59 59 (57032704)
I1013 15:25:35.216459 57122 net.cpp:225] Memory required for data: 3878183424
I1013 15:25:35.216464 57122 layer_factory.hpp:114] Creating layer pool2
I1013 15:25:35.216490 57122 net.cpp:160] Creating Layer pool2
I1013 15:25:35.216521 57122 net.cpp:596] pool2 <- drop2
I1013 15:25:35.216529 57122 net.cpp:570] pool2 -> pool2
I1013 15:25:35.216557 57122 net.cpp:210] Setting up pool2
I1013 15:25:35.216562 57122 net.cpp:217] Top shape: 128 128 30 30 (14745600)
I1013 15:25:35.216572 57122 net.cpp:225] Memory required for data: 3937165824
I1013 15:25:35.216576 57122 layer_factory.hpp:114] Creating layer conv3
I1013 15:25:35.216617 57122 net.cpp:160] Creating Layer conv3
I1013 15:25:35.216624 57122 net.cpp:596] conv3 <- pool2
I1013 15:25:35.216631 57122 net.cpp:570] conv3 -> conv3
I1013 15:25:35.251179 57122 net.cpp:210] Setting up conv3
I1013 15:25:35.251207 57122 net.cpp:217] Top shape: 128 128 28 28 (12845056)
I1013 15:25:35.251219 57122 net.cpp:225] Memory required for data: 3988546048
I1013 15:25:35.251242 57122 layer_factory.hpp:114] Creating layer relu3
I1013 15:25:35.251265 57122 net.cpp:160] Creating Layer relu3
I1013 15:25:35.251271 57122 net.cpp:596] relu3 <- conv3
I1013 15:25:35.251279 57122 net.cpp:557] relu3 -> conv3 (in-place)
I1013 15:25:35.251308 57122 net.cpp:210] Setting up relu3
I1013 15:25:35.251363 57122 net.cpp:217] Top shape: 128 128 28 28 (12845056)
I1013 15:25:35.251400 57122 net.cpp:225] Memory required for data: 4039926272
I1013 15:25:35.251408 57122 layer_factory.hpp:114] Creating layer dropout3
I1013 15:25:35.251426 57122 net.cpp:160] Creating Layer dropout3
I1013 15:25:35.251441 57122 net.cpp:596] dropout3 <- conv3
I1013 15:25:35.251449 57122 net.cpp:570] dropout3 -> drop3
I1013 15:25:35.251462 57122 net.cpp:210] Setting up dropout3
I1013 15:25:35.251467 57122 net.cpp:217] Top shape: 128 128 28 28 (12845056)
I1013 15:25:35.251474 57122 net.cpp:225] Memory required for data: 4091306496
I1013 15:25:35.251482 57122 layer_factory.hpp:114] Creating layer pool3
I1013 15:25:35.251497 57122 net.cpp:160] Creating Layer pool3
I1013 15:25:35.251502 57122 net.cpp:596] pool3 <- drop3
I1013 15:25:35.251512 57122 net.cpp:570] pool3 -> pool3
I1013 15:25:35.251538 57122 net.cpp:210] Setting up pool3
I1013 15:25:35.251585 57122 net.cpp:217] Top shape: 128 128 14 14 (3211264)
I1013 15:25:35.251601 57122 net.cpp:225] Memory required for data: 4104151552
I1013 15:25:35.251606 57122 layer_factory.hpp:114] Creating layer conv4
I1013 15:25:35.251633 57122 net.cpp:160] Creating Layer conv4
I1013 15:25:35.251639 57122 net.cpp:596] conv4 <- pool3
I1013 15:25:35.251652 57122 net.cpp:570] conv4 -> conv4
I1013 15:25:35.265432 57122 net.cpp:210] Setting up conv4
I1013 15:25:35.265444 57122 net.cpp:217] Top shape: 128 128 12 12 (2359296)
I1013 15:25:35.265451 57122 net.cpp:225] Memory required for data: 4113588736
I1013 15:25:35.265465 57122 layer_factory.hpp:114] Creating layer relu4
I1013 15:25:35.265476 57122 net.cpp:160] Creating Layer relu4
I1013 15:25:35.265481 57122 net.cpp:596] relu4 <- conv4
I1013 15:25:35.265491 57122 net.cpp:557] relu4 -> conv4 (in-place)
I1013 15:25:35.265511 57122 net.cpp:210] Setting up relu4
I1013 15:25:35.265524 57122 net.cpp:217] Top shape: 128 128 12 12 (2359296)
I1013 15:25:35.265530 57122 net.cpp:225] Memory required for data: 4123025920
I1013 15:25:35.265535 57122 layer_factory.hpp:114] Creating layer dropout4
I1013 15:25:35.265547 57122 net.cpp:160] Creating Layer dropout4
I1013 15:25:35.265552 57122 net.cpp:596] dropout4 <- conv4
I1013 15:25:35.265561 57122 net.cpp:570] dropout4 -> drop4
I1013 15:25:35.265573 57122 net.cpp:210] Setting up dropout4
I1013 15:25:35.265576 57122 net.cpp:217] Top shape: 128 128 12 12 (2359296)
I1013 15:25:35.265583 57122 net.cpp:225] Memory required for data: 4132463104
I1013 15:25:35.265588 57122 layer_factory.hpp:114] Creating layer pool4
I1013 15:25:35.265602 57122 net.cpp:160] Creating Layer pool4
I1013 15:25:35.265606 57122 net.cpp:596] pool4 <- drop4
I1013 15:25:35.265614 57122 net.cpp:570] pool4 -> pool4
I1013 15:25:35.265635 57122 net.cpp:210] Setting up pool4
I1013 15:25:35.265652 57122 net.cpp:217] Top shape: 128 128 6 6 (589824)
I1013 15:25:35.265661 57122 net.cpp:225] Memory required for data: 4134822400
I1013 15:25:35.265668 57122 layer_factory.hpp:114] Creating layer fc1
I1013 15:25:35.265687 57122 net.cpp:160] Creating Layer fc1
I1013 15:25:35.265696 57122 net.cpp:596] fc1 <- pool4
I1013 15:25:35.265705 57122 net.cpp:570] fc1 -> fc1
I1013 15:25:35.335150 57122 net.cpp:210] Setting up fc1
I1013 15:25:35.335161 57122 net.cpp:217] Top shape: 128 1024 (131072)
I1013 15:25:35.335168 57122 net.cpp:225] Memory required for data: 4135346688
I1013 15:25:35.335182 57122 layer_factory.hpp:114] Creating layer dropout5
I1013 15:25:35.335192 57122 net.cpp:160] Creating Layer dropout5
I1013 15:25:35.335196 57122 net.cpp:596] dropout5 <- fc1
I1013 15:25:35.335207 57122 net.cpp:570] dropout5 -> drop5
I1013 15:25:35.335221 57122 net.cpp:210] Setting up dropout5
I1013 15:25:35.335230 57122 net.cpp:217] Top shape: 128 1024 (131072)
I1013 15:25:35.335237 57122 net.cpp:225] Memory required for data: 4135870976
I1013 15:25:35.335242 57122 layer_factory.hpp:114] Creating layer fc2
I1013 15:25:35.335254 57122 net.cpp:160] Creating Layer fc2
I1013 15:25:35.335259 57122 net.cpp:596] fc2 <- drop5
I1013 15:25:35.335268 57122 net.cpp:570] fc2 -> fc2
I1013 15:25:35.335341 57122 net.cpp:210] Setting up fc2
I1013 15:25:35.335352 57122 net.cpp:217] Top shape: 128 2 (256)
I1013 15:25:35.335361 57122 net.cpp:225] Memory required for data: 4135872000
I1013 15:25:35.335371 57122 layer_factory.hpp:114] Creating layer loss
I1013 15:25:35.335384 57122 net.cpp:160] Creating Layer loss
I1013 15:25:35.335392 57122 net.cpp:596] loss <- fc2
I1013 15:25:35.335397 57122 net.cpp:596] loss <- label
I1013 15:25:35.335407 57122 net.cpp:570] loss -> (automatic)
I1013 15:25:35.335418 57122 layer_factory.hpp:114] Creating layer loss
I1013 15:25:35.335449 57122 net.cpp:210] Setting up loss
I1013 15:25:35.335458 57122 net.cpp:217] Top shape: (1)
I1013 15:25:35.335465 57122 net.cpp:220]     with loss weight 1
I1013 15:25:35.335512 57122 net.cpp:225] Memory required for data: 4135872004
I1013 15:25:35.335520 57122 net.cpp:287] loss needs backward computation.
I1013 15:25:35.335525 57122 net.cpp:287] fc2 needs backward computation.
I1013 15:25:35.335530 57122 net.cpp:287] dropout5 needs backward computation.
I1013 15:25:35.335535 57122 net.cpp:287] fc1 needs backward computation.
I1013 15:25:35.335538 57122 net.cpp:287] pool4 needs backward computation.
I1013 15:25:35.335543 57122 net.cpp:287] dropout4 needs backward computation.
I1013 15:25:35.335547 57122 net.cpp:287] relu4 needs backward computation.
I1013 15:25:35.335552 57122 net.cpp:287] conv4 needs backward computation.
I1013 15:25:35.335557 57122 net.cpp:287] pool3 needs backward computation.
I1013 15:25:35.335562 57122 net.cpp:287] dropout3 needs backward computation.
I1013 15:25:35.335566 57122 net.cpp:287] relu3 needs backward computation.
I1013 15:25:35.335572 57122 net.cpp:287] conv3 needs backward computation.
I1013 15:25:35.335577 57122 net.cpp:287] pool2 needs backward computation.
I1013 15:25:35.335582 57122 net.cpp:287] dropout2 needs backward computation.
I1013 15:25:35.335585 57122 net.cpp:287] relu2 needs backward computation.
I1013 15:25:35.335590 57122 net.cpp:287] conv2 needs backward computation.
I1013 15:25:35.335595 57122 net.cpp:287] pool1 needs backward computation.
I1013 15:25:35.335599 57122 net.cpp:287] dropout1 needs backward computation.
I1013 15:25:35.335604 57122 net.cpp:287] relu1 needs backward computation.
I1013 15:25:35.335609 57122 net.cpp:287] conv1 needs backward computation.
I1013 15:25:35.335614 57122 net.cpp:289] data does not need backward computation.
I1013 15:25:35.335634 57122 net.cpp:345] Network initialization done.
I1013 15:25:35.335753 57122 caffe.cpp:445] Performing Forward
I1013 15:25:37.636663 57122 caffe.cpp:450] Initial loss: 23.2064
I1013 15:25:37.636706 57122 caffe.cpp:452] Performing Backward
I1013 15:25:40.002324 57122 caffe.cpp:461] *** Benchmark begins ***
I1013 15:25:40.002351 57122 caffe.cpp:462] Testing for 10 iterations.
I1013 15:25:41.979218 57122 caffe.cpp:491] Iteration: 1 forward-backward time: 1976 ms.
I1013 15:25:43.964026 57122 caffe.cpp:491] Iteration: 2 forward-backward time: 1984 ms.
I1013 15:25:45.949985 57122 caffe.cpp:491] Iteration: 3 forward-backward time: 1985 ms.
I1013 15:25:47.936270 57122 caffe.cpp:491] Iteration: 4 forward-backward time: 1986 ms.
I1013 15:25:49.924607 57122 caffe.cpp:491] Iteration: 5 forward-backward time: 1988 ms.
I1013 15:25:51.925611 57122 caffe.cpp:491] Iteration: 6 forward-backward time: 2000 ms.
I1013 15:25:53.913430 57122 caffe.cpp:491] Iteration: 7 forward-backward time: 1987 ms.
I1013 15:25:55.904336 57122 caffe.cpp:491] Iteration: 8 forward-backward time: 1990 ms.
I1013 15:25:57.891753 57122 caffe.cpp:491] Iteration: 9 forward-backward time: 1987 ms.
I1013 15:25:59.881100 57122 caffe.cpp:491] Iteration: 10 forward-backward time: 1989 ms.
I1013 15:25:59.881140 57122 caffe.cpp:498] Average time per layer: 
I1013 15:25:59.881145 57122 caffe.cpp:501]       data	forward: 77.135 ms.
I1013 15:25:59.881151 57122 caffe.cpp:505]       data	backward: 0.0015 ms.
I1013 15:25:59.881156 57122 caffe.cpp:501]      conv1	forward: 48.1579 ms.
I1013 15:25:59.881160 57122 caffe.cpp:505]      conv1	backward: 61.0057 ms.
I1013 15:25:59.881165 57122 caffe.cpp:501]      relu1	forward: 36.5745 ms.
I1013 15:25:59.881170 57122 caffe.cpp:505]      relu1	backward: 105.444 ms.
I1013 15:25:59.881175 57122 caffe.cpp:501]   dropout1	forward: 192.426 ms.
I1013 15:25:59.881181 57122 caffe.cpp:505]   dropout1	backward: 120.668 ms.
I1013 15:25:59.881184 57122 caffe.cpp:501]      pool1	forward: 95.0066 ms.
I1013 15:25:59.881189 57122 caffe.cpp:505]      pool1	backward: 86.6248 ms.
I1013 15:25:59.881193 57122 caffe.cpp:501]      conv2	forward: 149.798 ms.
I1013 15:25:59.881197 57122 caffe.cpp:505]      conv2	backward: 686.275 ms.
I1013 15:25:59.881201 57122 caffe.cpp:501]      relu2	forward: 7.9168 ms.
I1013 15:25:59.881206 57122 caffe.cpp:505]      relu2	backward: 23.3355 ms.
I1013 15:25:59.881211 57122 caffe.cpp:501]   dropout2	forward: 44.9468 ms.
I1013 15:25:59.881216 57122 caffe.cpp:505]   dropout2	backward: 27.3613 ms.
I1013 15:25:59.881220 57122 caffe.cpp:501]      pool2	forward: 21.3503 ms.
I1013 15:25:59.881224 57122 caffe.cpp:505]      pool2	backward: 19.6017 ms.
I1013 15:25:59.881229 57122 caffe.cpp:501]      conv3	forward: 32.0944 ms.
I1013 15:25:59.881234 57122 caffe.cpp:505]      conv3	backward: 86.3365 ms.
I1013 15:25:59.881239 57122 caffe.cpp:501]      relu3	forward: 1.3774 ms.
I1013 15:25:59.881244 57122 caffe.cpp:505]      relu3	backward: 5.2751 ms.
I1013 15:25:59.881249 57122 caffe.cpp:501]   dropout3	forward: 10.2585 ms.
I1013 15:25:59.881254 57122 caffe.cpp:505]   dropout3	backward: 6.465 ms.
I1013 15:25:59.881259 57122 caffe.cpp:501]      pool3	forward: 5.1507 ms.
I1013 15:25:59.881264 57122 caffe.cpp:505]      pool3	backward: 4.4377 ms.
I1013 15:25:59.881269 57122 caffe.cpp:501]      conv4	forward: 5.6041 ms.
I1013 15:25:59.881273 57122 caffe.cpp:505]      conv4	backward: 15.6995 ms.
I1013 15:25:59.881279 57122 caffe.cpp:501]      relu4	forward: 0.0474 ms.
I1013 15:25:59.881284 57122 caffe.cpp:505]      relu4	backward: 0.4836 ms.
I1013 15:25:59.881289 57122 caffe.cpp:501]   dropout4	forward: 1.1465 ms.
I1013 15:25:59.881294 57122 caffe.cpp:505]   dropout4	backward: 0.8373 ms.
I1013 15:25:59.881299 57122 caffe.cpp:501]      pool4	forward: 1.0979 ms.
I1013 15:25:59.881304 57122 caffe.cpp:505]      pool4	backward: 0.6045 ms.
I1013 15:25:59.881309 57122 caffe.cpp:501]        fc1	forward: 2.1058 ms.
I1013 15:25:59.881314 57122 caffe.cpp:505]        fc1	backward: 3.5584 ms.
I1013 15:25:59.881319 57122 caffe.cpp:501]   dropout5	forward: 0.0984 ms.
I1013 15:25:59.881325 57122 caffe.cpp:505]   dropout5	backward: 0.0225 ms.
I1013 15:25:59.881330 57122 caffe.cpp:501]        fc2	forward: 1.2157 ms.
I1013 15:25:59.881335 57122 caffe.cpp:505]        fc2	backward: 0.0452 ms.
I1013 15:25:59.881338 57122 caffe.cpp:501]       loss	forward: 0.1386 ms.
I1013 15:25:59.881343 57122 caffe.cpp:505]       loss	backward: 0.0049 ms.
I1013 15:25:59.881350 57122 caffe.cpp:511] Average Forward pass: 733.692 ms.
I1013 15:25:59.881376 57122 caffe.cpp:514] Average Backward pass: 1254.13 ms.
I1013 15:25:59.881382 57122 caffe.cpp:516] Average Forward-Backward: 1987.8 ms.
I1013 15:25:59.881388 57122 caffe.cpp:519] Total Time: 19878 ms.
I1013 15:25:59.881394 57122 caffe.cpp:520] *** Benchmark ends ***

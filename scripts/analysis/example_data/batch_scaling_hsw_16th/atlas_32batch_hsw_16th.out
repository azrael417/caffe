srun -n 1 -c 32 --cpu_bind=socket -m block:cyclic /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-hsw/bin//caffe time -model=subst_train_val.prototxt -iterations=10
I1013 15:25:13.385496 57022 caffe.cpp:437] Use CPU.
I1013 15:25:13.507756 57022 cpu_info.cpp:452] Processor speed [MHz]: 2300
I1013 15:25:13.507766 57022 cpu_info.cpp:455] Total number of sockets: 2
I1013 15:25:13.507767 57022 cpu_info.cpp:458] Total number of CPU cores: 32
I1013 15:25:13.507768 57022 cpu_info.cpp:461] Total number of processors: 64
I1013 15:25:13.507782 57022 cpu_info.cpp:464] GPU is used: no
I1013 15:25:13.507783 57022 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1013 15:25:13.507786 57022 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1013 15:25:13.507787 57022 cpu_info.cpp:473] Number of OpenMP threads: 16
I1013 15:25:13.510128 57022 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1013 15:25:13.510221 57022 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1013 15:25:13.510344 57022 layer_factory.hpp:114] Creating layer data
I1013 15:25:13.510354 57022 net.cpp:160] Creating Layer data
I1013 15:25:13.510356 57022 net.cpp:570] data -> data
I1013 15:25:13.510367 57022 net.cpp:570] data -> label
I1013 15:25:13.510612 57022 net.cpp:210] Setting up data
I1013 15:25:13.510618 57022 net.cpp:217] Top shape: 32 3 124 124 (1476096)
I1013 15:25:13.510629 57022 net.cpp:217] Top shape: 32 1 1 1 (32)
I1013 15:25:13.510632 57022 net.cpp:225] Memory required for data: 5904512
I1013 15:25:13.510635 57022 layer_factory.hpp:114] Creating layer conv1
I1013 15:25:13.510650 57022 net.cpp:160] Creating Layer conv1
I1013 15:25:13.510653 57022 net.cpp:596] conv1 <- data
I1013 15:25:13.510659 57022 net.cpp:570] conv1 -> conv1
I1013 15:25:13.532189 57022 net.cpp:210] Setting up conv1
I1013 15:25:13.532207 57022 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:25:13.532217 57022 net.cpp:225] Memory required for data: 249763968
I1013 15:25:13.532238 57022 layer_factory.hpp:114] Creating layer relu1
I1013 15:25:13.532256 57022 net.cpp:160] Creating Layer relu1
I1013 15:25:13.532268 57022 net.cpp:596] relu1 <- conv1
I1013 15:25:13.532275 57022 net.cpp:557] relu1 -> conv1 (in-place)
I1013 15:25:13.532301 57022 net.cpp:210] Setting up relu1
I1013 15:25:13.532312 57022 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:25:13.532327 57022 net.cpp:225] Memory required for data: 493623424
I1013 15:25:13.532332 57022 layer_factory.hpp:114] Creating layer dropout1
I1013 15:25:13.532341 57022 net.cpp:160] Creating Layer dropout1
I1013 15:25:13.532344 57022 net.cpp:596] dropout1 <- conv1
I1013 15:25:13.532351 57022 net.cpp:570] dropout1 -> drop1
I1013 15:25:13.532366 57022 net.cpp:210] Setting up dropout1
I1013 15:25:13.532377 57022 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:25:13.532384 57022 net.cpp:225] Memory required for data: 737482880
I1013 15:25:13.532397 57022 layer_factory.hpp:114] Creating layer pool1
I1013 15:25:13.532412 57022 net.cpp:160] Creating Layer pool1
I1013 15:25:13.532423 57022 net.cpp:596] pool1 <- drop1
I1013 15:25:13.532433 57022 net.cpp:570] pool1 -> pool1
I1013 15:25:13.532465 57022 net.cpp:210] Setting up pool1
I1013 15:25:13.532474 57022 net.cpp:217] Top shape: 32 128 61 61 (15241216)
I1013 15:25:13.532480 57022 net.cpp:225] Memory required for data: 798447744
I1013 15:25:13.532485 57022 layer_factory.hpp:114] Creating layer conv2
I1013 15:25:13.532508 57022 net.cpp:160] Creating Layer conv2
I1013 15:25:13.532515 57022 net.cpp:596] conv2 <- pool1
I1013 15:25:13.532522 57022 net.cpp:570] conv2 -> conv2
I1013 15:25:13.655799 57022 net.cpp:210] Setting up conv2
I1013 15:25:13.655836 57022 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:25:13.655848 57022 net.cpp:225] Memory required for data: 855480448
I1013 15:25:13.655872 57022 layer_factory.hpp:114] Creating layer relu2
I1013 15:25:13.655895 57022 net.cpp:160] Creating Layer relu2
I1013 15:25:13.655901 57022 net.cpp:596] relu2 <- conv2
I1013 15:25:13.655910 57022 net.cpp:557] relu2 -> conv2 (in-place)
I1013 15:25:13.655941 57022 net.cpp:210] Setting up relu2
I1013 15:25:13.655985 57022 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:25:13.656036 57022 net.cpp:225] Memory required for data: 912513152
I1013 15:25:13.656086 57022 layer_factory.hpp:114] Creating layer dropout2
I1013 15:25:13.656103 57022 net.cpp:160] Creating Layer dropout2
I1013 15:25:13.656108 57022 net.cpp:596] dropout2 <- conv2
I1013 15:25:13.656116 57022 net.cpp:570] dropout2 -> drop2
I1013 15:25:13.656131 57022 net.cpp:210] Setting up dropout2
I1013 15:25:13.656136 57022 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:25:13.656142 57022 net.cpp:225] Memory required for data: 969545856
I1013 15:25:13.656147 57022 layer_factory.hpp:114] Creating layer pool2
I1013 15:25:13.656172 57022 net.cpp:160] Creating Layer pool2
I1013 15:25:13.656208 57022 net.cpp:596] pool2 <- drop2
I1013 15:25:13.656258 57022 net.cpp:570] pool2 -> pool2
I1013 15:25:13.656293 57022 net.cpp:210] Setting up pool2
I1013 15:25:13.656330 57022 net.cpp:217] Top shape: 32 128 30 30 (3686400)
I1013 15:25:13.656364 57022 net.cpp:225] Memory required for data: 984291456
I1013 15:25:13.656399 57022 layer_factory.hpp:114] Creating layer conv3
I1013 15:25:13.656458 57022 net.cpp:160] Creating Layer conv3
I1013 15:25:13.656469 57022 net.cpp:596] conv3 <- pool2
I1013 15:25:13.656483 57022 net.cpp:570] conv3 -> conv3
I1013 15:25:13.691083 57022 net.cpp:210] Setting up conv3
I1013 15:25:13.691113 57022 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:25:13.691125 57022 net.cpp:225] Memory required for data: 997136512
I1013 15:25:13.691146 57022 layer_factory.hpp:114] Creating layer relu3
I1013 15:25:13.691169 57022 net.cpp:160] Creating Layer relu3
I1013 15:25:13.691174 57022 net.cpp:596] relu3 <- conv3
I1013 15:25:13.691184 57022 net.cpp:557] relu3 -> conv3 (in-place)
I1013 15:25:13.691213 57022 net.cpp:210] Setting up relu3
I1013 15:25:13.691241 57022 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:25:13.691303 57022 net.cpp:225] Memory required for data: 1009981568
I1013 15:25:13.691352 57022 layer_factory.hpp:114] Creating layer dropout3
I1013 15:25:13.691377 57022 net.cpp:160] Creating Layer dropout3
I1013 15:25:13.691395 57022 net.cpp:596] dropout3 <- conv3
I1013 15:25:13.691404 57022 net.cpp:570] dropout3 -> drop3
I1013 15:25:13.691419 57022 net.cpp:210] Setting up dropout3
I1013 15:25:13.691448 57022 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:25:13.691488 57022 net.cpp:225] Memory required for data: 1022826624
I1013 15:25:13.691547 57022 layer_factory.hpp:114] Creating layer pool3
I1013 15:25:13.691567 57022 net.cpp:160] Creating Layer pool3
I1013 15:25:13.691572 57022 net.cpp:596] pool3 <- drop3
I1013 15:25:13.691582 57022 net.cpp:570] pool3 -> pool3
I1013 15:25:13.691615 57022 net.cpp:210] Setting up pool3
I1013 15:25:13.691658 57022 net.cpp:217] Top shape: 32 128 14 14 (802816)
I1013 15:25:13.691695 57022 net.cpp:225] Memory required for data: 1026037888
I1013 15:25:13.691751 57022 layer_factory.hpp:114] Creating layer conv4
I1013 15:25:13.691782 57022 net.cpp:160] Creating Layer conv4
I1013 15:25:13.691817 57022 net.cpp:596] conv4 <- pool3
I1013 15:25:13.691838 57022 net.cpp:570] conv4 -> conv4
I1013 15:25:13.705495 57022 net.cpp:210] Setting up conv4
I1013 15:25:13.705505 57022 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:25:13.705513 57022 net.cpp:225] Memory required for data: 1028397184
I1013 15:25:13.705524 57022 layer_factory.hpp:114] Creating layer relu4
I1013 15:25:13.705538 57022 net.cpp:160] Creating Layer relu4
I1013 15:25:13.705543 57022 net.cpp:596] relu4 <- conv4
I1013 15:25:13.705550 57022 net.cpp:557] relu4 -> conv4 (in-place)
I1013 15:25:13.705571 57022 net.cpp:210] Setting up relu4
I1013 15:25:13.705602 57022 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:25:13.705636 57022 net.cpp:225] Memory required for data: 1030756480
I1013 15:25:13.705689 57022 layer_factory.hpp:114] Creating layer dropout4
I1013 15:25:13.705700 57022 net.cpp:160] Creating Layer dropout4
I1013 15:25:13.705705 57022 net.cpp:596] dropout4 <- conv4
I1013 15:25:13.705713 57022 net.cpp:570] dropout4 -> drop4
I1013 15:25:13.705724 57022 net.cpp:210] Setting up dropout4
I1013 15:25:13.705732 57022 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:25:13.705739 57022 net.cpp:225] Memory required for data: 1033115776
I1013 15:25:13.705744 57022 layer_factory.hpp:114] Creating layer pool4
I1013 15:25:13.705765 57022 net.cpp:160] Creating Layer pool4
I1013 15:25:13.705802 57022 net.cpp:596] pool4 <- drop4
I1013 15:25:13.705857 57022 net.cpp:570] pool4 -> pool4
I1013 15:25:13.705907 57022 net.cpp:210] Setting up pool4
I1013 15:25:13.705917 57022 net.cpp:217] Top shape: 32 128 6 6 (147456)
I1013 15:25:13.705925 57022 net.cpp:225] Memory required for data: 1033705600
I1013 15:25:13.705934 57022 layer_factory.hpp:114] Creating layer fc1
I1013 15:25:13.705953 57022 net.cpp:160] Creating Layer fc1
I1013 15:25:13.705982 57022 net.cpp:596] fc1 <- pool4
I1013 15:25:13.706022 57022 net.cpp:570] fc1 -> fc1
I1013 15:25:13.775449 57022 net.cpp:210] Setting up fc1
I1013 15:25:13.775460 57022 net.cpp:217] Top shape: 32 1024 (32768)
I1013 15:25:13.775467 57022 net.cpp:225] Memory required for data: 1033836672
I1013 15:25:13.775481 57022 layer_factory.hpp:114] Creating layer dropout5
I1013 15:25:13.775491 57022 net.cpp:160] Creating Layer dropout5
I1013 15:25:13.775496 57022 net.cpp:596] dropout5 <- fc1
I1013 15:25:13.775503 57022 net.cpp:570] dropout5 -> drop5
I1013 15:25:13.775516 57022 net.cpp:210] Setting up dropout5
I1013 15:25:13.775519 57022 net.cpp:217] Top shape: 32 1024 (32768)
I1013 15:25:13.775530 57022 net.cpp:225] Memory required for data: 1033967744
I1013 15:25:13.775535 57022 layer_factory.hpp:114] Creating layer fc2
I1013 15:25:13.775547 57022 net.cpp:160] Creating Layer fc2
I1013 15:25:13.775552 57022 net.cpp:596] fc2 <- drop5
I1013 15:25:13.775563 57022 net.cpp:570] fc2 -> fc2
I1013 15:25:13.775640 57022 net.cpp:210] Setting up fc2
I1013 15:25:13.775651 57022 net.cpp:217] Top shape: 32 2 (64)
I1013 15:25:13.775658 57022 net.cpp:225] Memory required for data: 1033968000
I1013 15:25:13.775670 57022 layer_factory.hpp:114] Creating layer loss
I1013 15:25:13.775681 57022 net.cpp:160] Creating Layer loss
I1013 15:25:13.775686 57022 net.cpp:596] loss <- fc2
I1013 15:25:13.775693 57022 net.cpp:596] loss <- label
I1013 15:25:13.775705 57022 net.cpp:570] loss -> (automatic)
I1013 15:25:13.775718 57022 layer_factory.hpp:114] Creating layer loss
I1013 15:25:13.775750 57022 net.cpp:210] Setting up loss
I1013 15:25:13.775758 57022 net.cpp:217] Top shape: (1)
I1013 15:25:13.775765 57022 net.cpp:220]     with loss weight 1
I1013 15:25:13.775815 57022 net.cpp:225] Memory required for data: 1033968004
I1013 15:25:13.775821 57022 net.cpp:287] loss needs backward computation.
I1013 15:25:13.775827 57022 net.cpp:287] fc2 needs backward computation.
I1013 15:25:13.775831 57022 net.cpp:287] dropout5 needs backward computation.
I1013 15:25:13.775836 57022 net.cpp:287] fc1 needs backward computation.
I1013 15:25:13.775840 57022 net.cpp:287] pool4 needs backward computation.
I1013 15:25:13.775845 57022 net.cpp:287] dropout4 needs backward computation.
I1013 15:25:13.775849 57022 net.cpp:287] relu4 needs backward computation.
I1013 15:25:13.775853 57022 net.cpp:287] conv4 needs backward computation.
I1013 15:25:13.775858 57022 net.cpp:287] pool3 needs backward computation.
I1013 15:25:13.775863 57022 net.cpp:287] dropout3 needs backward computation.
I1013 15:25:13.775867 57022 net.cpp:287] relu3 needs backward computation.
I1013 15:25:13.775871 57022 net.cpp:287] conv3 needs backward computation.
I1013 15:25:13.775876 57022 net.cpp:287] pool2 needs backward computation.
I1013 15:25:13.775882 57022 net.cpp:287] dropout2 needs backward computation.
I1013 15:25:13.775887 57022 net.cpp:287] relu2 needs backward computation.
I1013 15:25:13.775890 57022 net.cpp:287] conv2 needs backward computation.
I1013 15:25:13.775895 57022 net.cpp:287] pool1 needs backward computation.
I1013 15:25:13.775900 57022 net.cpp:287] dropout1 needs backward computation.
I1013 15:25:13.775905 57022 net.cpp:287] relu1 needs backward computation.
I1013 15:25:13.775910 57022 net.cpp:287] conv1 needs backward computation.
I1013 15:25:13.775915 57022 net.cpp:289] data does not need backward computation.
I1013 15:25:13.775935 57022 net.cpp:345] Network initialization done.
I1013 15:25:13.776053 57022 caffe.cpp:445] Performing Forward
I1013 15:25:14.381496 57022 caffe.cpp:450] Initial loss: 23.9585
I1013 15:25:14.381536 57022 caffe.cpp:452] Performing Backward
I1013 15:25:14.986711 57022 caffe.cpp:461] *** Benchmark begins ***
I1013 15:25:14.986740 57022 caffe.cpp:462] Testing for 10 iterations.
I1013 15:25:15.475639 57022 caffe.cpp:491] Iteration: 1 forward-backward time: 488 ms.
I1013 15:25:15.965306 57022 caffe.cpp:491] Iteration: 2 forward-backward time: 489 ms.
I1013 15:25:16.459007 57022 caffe.cpp:491] Iteration: 3 forward-backward time: 493 ms.
I1013 15:25:16.954398 57022 caffe.cpp:491] Iteration: 4 forward-backward time: 495 ms.
I1013 15:25:17.449440 57022 caffe.cpp:491] Iteration: 5 forward-backward time: 495 ms.
I1013 15:25:17.943868 57022 caffe.cpp:491] Iteration: 6 forward-backward time: 494 ms.
I1013 15:25:18.440986 57022 caffe.cpp:491] Iteration: 7 forward-backward time: 497 ms.
I1013 15:25:18.935135 57022 caffe.cpp:491] Iteration: 8 forward-backward time: 494 ms.
I1013 15:25:19.429945 57022 caffe.cpp:491] Iteration: 9 forward-backward time: 494 ms.
I1013 15:25:19.924680 57022 caffe.cpp:491] Iteration: 10 forward-backward time: 494 ms.
I1013 15:25:19.924718 57022 caffe.cpp:498] Average time per layer: 
I1013 15:25:19.924723 57022 caffe.cpp:501]       data	forward: 19.5426 ms.
I1013 15:25:19.924731 57022 caffe.cpp:505]       data	backward: 0.0018 ms.
I1013 15:25:19.924736 57022 caffe.cpp:501]      conv1	forward: 12.5654 ms.
I1013 15:25:19.924741 57022 caffe.cpp:505]      conv1	backward: 15.0179 ms.
I1013 15:25:19.924744 57022 caffe.cpp:501]      relu1	forward: 9.3443 ms.
I1013 15:25:19.924749 57022 caffe.cpp:505]      relu1	backward: 26.7267 ms.
I1013 15:25:19.924756 57022 caffe.cpp:501]   dropout1	forward: 48.7092 ms.
I1013 15:25:19.924760 57022 caffe.cpp:505]   dropout1	backward: 30.1107 ms.
I1013 15:25:19.924764 57022 caffe.cpp:501]      pool1	forward: 22.6936 ms.
I1013 15:25:19.924768 57022 caffe.cpp:505]      pool1	backward: 20.7764 ms.
I1013 15:25:19.924772 57022 caffe.cpp:501]      conv2	forward: 36.8367 ms.
I1013 15:25:19.924777 57022 caffe.cpp:505]      conv2	backward: 171.113 ms.
I1013 15:25:19.924782 57022 caffe.cpp:501]      relu2	forward: 1.4852 ms.
I1013 15:25:19.924787 57022 caffe.cpp:505]      relu2	backward: 5.8421 ms.
I1013 15:25:19.924792 57022 caffe.cpp:501]   dropout2	forward: 11.5174 ms.
I1013 15:25:19.924796 57022 caffe.cpp:505]   dropout2	backward: 7.0394 ms.
I1013 15:25:19.924800 57022 caffe.cpp:501]      pool2	forward: 5.5692 ms.
I1013 15:25:19.924804 57022 caffe.cpp:505]      pool2	backward: 5.2223 ms.
I1013 15:25:19.924809 57022 caffe.cpp:501]      conv3	forward: 7.5859 ms.
I1013 15:25:19.924814 57022 caffe.cpp:505]      conv3	backward: 20.811 ms.
I1013 15:25:19.924820 57022 caffe.cpp:501]      relu3	forward: 0.0696 ms.
I1013 15:25:19.924825 57022 caffe.cpp:505]      relu3	backward: 0.656 ms.
I1013 15:25:19.924830 57022 caffe.cpp:501]   dropout3	forward: 1.6974 ms.
I1013 15:25:19.924836 57022 caffe.cpp:505]   dropout3	backward: 1.2743 ms.
I1013 15:25:19.924841 57022 caffe.cpp:501]      pool3	forward: 1.4111 ms.
I1013 15:25:19.924846 57022 caffe.cpp:505]      pool3	backward: 0.6468 ms.
I1013 15:25:19.924850 57022 caffe.cpp:501]      conv4	forward: 1.4742 ms.
I1013 15:25:19.924855 57022 caffe.cpp:505]      conv4	backward: 3.8842 ms.
I1013 15:25:19.924860 57022 caffe.cpp:501]      relu4	forward: 0.012 ms.
I1013 15:25:19.924866 57022 caffe.cpp:505]      relu4	backward: 0.1196 ms.
I1013 15:25:19.924871 57022 caffe.cpp:501]   dropout4	forward: 0.3167 ms.
I1013 15:25:19.924876 57022 caffe.cpp:505]   dropout4	backward: 0.2834 ms.
I1013 15:25:19.924882 57022 caffe.cpp:501]      pool4	forward: 0.2756 ms.
I1013 15:25:19.924887 57022 caffe.cpp:505]      pool4	backward: 0.1573 ms.
I1013 15:25:19.924892 57022 caffe.cpp:501]        fc1	forward: 0.7816 ms.
I1013 15:25:19.924897 57022 caffe.cpp:505]        fc1	backward: 1.9114 ms.
I1013 15:25:19.924902 57022 caffe.cpp:501]   dropout5	forward: 0.023 ms.
I1013 15:25:19.924907 57022 caffe.cpp:505]   dropout5	backward: 0.0153 ms.
I1013 15:25:19.924913 57022 caffe.cpp:501]        fc2	forward: 0.0253 ms.
I1013 15:25:19.924918 57022 caffe.cpp:505]        fc2	backward: 0.0624 ms.
I1013 15:25:19.924923 57022 caffe.cpp:501]       loss	forward: 0.0586 ms.
I1013 15:25:19.924928 57022 caffe.cpp:505]       loss	backward: 0.0043 ms.
I1013 15:25:19.924934 57022 caffe.cpp:511] Average Forward pass: 182.031 ms.
I1013 15:25:19.924940 57022 caffe.cpp:514] Average Backward pass: 311.713 ms.
I1013 15:25:19.924960 57022 caffe.cpp:516] Average Forward-Backward: 493.8 ms.
I1013 15:25:19.924968 57022 caffe.cpp:519] Total Time: 4938 ms.
I1013 15:25:19.924973 57022 caffe.cpp:520] *** Benchmark ends ***

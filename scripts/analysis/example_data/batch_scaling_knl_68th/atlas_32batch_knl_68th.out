srun -n 1 -c 272 --cpu_bind=cores /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-knl/bin/caffe time -model=subst_train_val.prototxt -iterations=10
I1013 15:24:28.872004 259298 caffe.cpp:437] Use CPU.
I1013 15:24:29.019098 259298 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1013 15:24:29.019181 259298 cpu_info.cpp:455] Total number of sockets: 1
I1013 15:24:29.019201 259298 cpu_info.cpp:458] Total number of CPU cores: 68
I1013 15:24:29.019217 259298 cpu_info.cpp:461] Total number of processors: 272
I1013 15:24:29.019232 259298 cpu_info.cpp:464] GPU is used: no
I1013 15:24:29.019248 259298 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1013 15:24:29.019261 259298 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1013 15:24:29.019276 259298 cpu_info.cpp:473] Number of OpenMP threads: 68
I1013 15:24:29.044711 259298 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1013 15:24:29.045509 259298 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 32
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 32
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1013 15:24:29.047216 259298 layer_factory.hpp:114] Creating layer data
I1013 15:24:29.047297 259298 net.cpp:160] Creating Layer data
I1013 15:24:29.047336 259298 net.cpp:570] data -> data
I1013 15:24:29.047412 259298 net.cpp:570] data -> label
I1013 15:24:29.070168 259298 net.cpp:210] Setting up data
I1013 15:24:29.070279 259298 net.cpp:217] Top shape: 32 3 124 124 (1476096)
I1013 15:24:29.070346 259298 net.cpp:217] Top shape: 32 1 1 1 (32)
I1013 15:24:29.070389 259298 net.cpp:225] Memory required for data: 5904512
I1013 15:24:29.070430 259298 layer_factory.hpp:114] Creating layer conv1
I1013 15:24:29.070557 259298 net.cpp:160] Creating Layer conv1
I1013 15:24:29.070612 259298 net.cpp:596] conv1 <- data
I1013 15:24:29.070704 259298 net.cpp:570] conv1 -> conv1
I1013 15:24:29.229317 259298 net.cpp:210] Setting up conv1
I1013 15:24:29.229415 259298 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:24:29.229526 259298 net.cpp:225] Memory required for data: 249763968
I1013 15:24:29.229750 259298 layer_factory.hpp:114] Creating layer relu1
I1013 15:24:29.229867 259298 net.cpp:160] Creating Layer relu1
I1013 15:24:29.229919 259298 net.cpp:596] relu1 <- conv1
I1013 15:24:29.230020 259298 net.cpp:557] relu1 -> conv1 (in-place)
I1013 15:24:29.235481 259298 net.cpp:210] Setting up relu1
I1013 15:24:29.235565 259298 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:24:29.235607 259298 net.cpp:225] Memory required for data: 493623424
I1013 15:24:29.235638 259298 layer_factory.hpp:114] Creating layer dropout1
I1013 15:24:29.235685 259298 net.cpp:160] Creating Layer dropout1
I1013 15:24:29.235712 259298 net.cpp:596] dropout1 <- conv1
I1013 15:24:29.235750 259298 net.cpp:570] dropout1 -> drop1
I1013 15:24:29.235817 259298 net.cpp:210] Setting up dropout1
I1013 15:24:29.235852 259298 net.cpp:217] Top shape: 32 128 122 122 (60964864)
I1013 15:24:29.235893 259298 net.cpp:225] Memory required for data: 737482880
I1013 15:24:29.235924 259298 layer_factory.hpp:114] Creating layer pool1
I1013 15:24:29.236032 259298 net.cpp:160] Creating Layer pool1
I1013 15:24:29.236250 259298 net.cpp:596] pool1 <- drop1
I1013 15:24:29.236318 259298 net.cpp:570] pool1 -> pool1
I1013 15:24:29.240948 259298 net.cpp:210] Setting up pool1
I1013 15:24:29.241036 259298 net.cpp:217] Top shape: 32 128 61 61 (15241216)
I1013 15:24:29.241082 259298 net.cpp:225] Memory required for data: 798447744
I1013 15:24:29.241114 259298 layer_factory.hpp:114] Creating layer conv2
I1013 15:24:29.241194 259298 net.cpp:160] Creating Layer conv2
I1013 15:24:29.241230 259298 net.cpp:596] conv2 <- pool1
I1013 15:24:29.241278 259298 net.cpp:570] conv2 -> conv2
I1013 15:24:29.796010 259298 net.cpp:210] Setting up conv2
I1013 15:24:29.796105 259298 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:24:29.796171 259298 net.cpp:225] Memory required for data: 855480448
I1013 15:24:29.796262 259298 layer_factory.hpp:114] Creating layer relu2
I1013 15:24:29.796356 259298 net.cpp:160] Creating Layer relu2
I1013 15:24:29.796411 259298 net.cpp:596] relu2 <- conv2
I1013 15:24:29.796478 259298 net.cpp:557] relu2 -> conv2 (in-place)
I1013 15:24:29.800990 259298 net.cpp:210] Setting up relu2
I1013 15:24:29.801077 259298 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:24:29.801125 259298 net.cpp:225] Memory required for data: 912513152
I1013 15:24:29.801156 259298 layer_factory.hpp:114] Creating layer dropout2
I1013 15:24:29.801210 259298 net.cpp:160] Creating Layer dropout2
I1013 15:24:29.801244 259298 net.cpp:596] dropout2 <- conv2
I1013 15:24:29.801292 259298 net.cpp:570] dropout2 -> drop2
I1013 15:24:29.801367 259298 net.cpp:210] Setting up dropout2
I1013 15:24:29.801409 259298 net.cpp:217] Top shape: 32 128 59 59 (14258176)
I1013 15:24:29.801457 259298 net.cpp:225] Memory required for data: 969545856
I1013 15:24:29.801602 259298 layer_factory.hpp:114] Creating layer pool2
I1013 15:24:29.801692 259298 net.cpp:160] Creating Layer pool2
I1013 15:24:29.801718 259298 net.cpp:596] pool2 <- drop2
I1013 15:24:29.801758 259298 net.cpp:570] pool2 -> pool2
I1013 15:24:29.805905 259298 net.cpp:210] Setting up pool2
I1013 15:24:29.805991 259298 net.cpp:217] Top shape: 32 128 30 30 (3686400)
I1013 15:24:29.806035 259298 net.cpp:225] Memory required for data: 984291456
I1013 15:24:29.806064 259298 layer_factory.hpp:114] Creating layer conv3
I1013 15:24:29.806171 259298 net.cpp:160] Creating Layer conv3
I1013 15:24:29.806219 259298 net.cpp:596] conv3 <- pool2
I1013 15:24:29.806293 259298 net.cpp:570] conv3 -> conv3
I1013 15:24:30.008227 259298 net.cpp:210] Setting up conv3
I1013 15:24:30.008332 259298 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:24:30.008396 259298 net.cpp:225] Memory required for data: 997136512
I1013 15:24:30.008482 259298 layer_factory.hpp:114] Creating layer relu3
I1013 15:24:30.008599 259298 net.cpp:160] Creating Layer relu3
I1013 15:24:30.008658 259298 net.cpp:596] relu3 <- conv3
I1013 15:24:30.008724 259298 net.cpp:557] relu3 -> conv3 (in-place)
I1013 15:24:30.013386 259298 net.cpp:210] Setting up relu3
I1013 15:24:30.013516 259298 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:24:30.013568 259298 net.cpp:225] Memory required for data: 1009981568
I1013 15:24:30.013599 259298 layer_factory.hpp:114] Creating layer dropout3
I1013 15:24:30.013662 259298 net.cpp:160] Creating Layer dropout3
I1013 15:24:30.013703 259298 net.cpp:596] dropout3 <- conv3
I1013 15:24:30.013753 259298 net.cpp:570] dropout3 -> drop3
I1013 15:24:30.013823 259298 net.cpp:210] Setting up dropout3
I1013 15:24:30.013856 259298 net.cpp:217] Top shape: 32 128 28 28 (3211264)
I1013 15:24:30.013891 259298 net.cpp:225] Memory required for data: 1022826624
I1013 15:24:30.013917 259298 layer_factory.hpp:114] Creating layer pool3
I1013 15:24:30.013994 259298 net.cpp:160] Creating Layer pool3
I1013 15:24:30.014032 259298 net.cpp:596] pool3 <- drop3
I1013 15:24:30.014092 259298 net.cpp:570] pool3 -> pool3
I1013 15:24:30.017901 259298 net.cpp:210] Setting up pool3
I1013 15:24:30.017982 259298 net.cpp:217] Top shape: 32 128 14 14 (802816)
I1013 15:24:30.018028 259298 net.cpp:225] Memory required for data: 1026037888
I1013 15:24:30.018059 259298 layer_factory.hpp:114] Creating layer conv4
I1013 15:24:30.018162 259298 net.cpp:160] Creating Layer conv4
I1013 15:24:30.018206 259298 net.cpp:596] conv4 <- pool3
I1013 15:24:30.018275 259298 net.cpp:570] conv4 -> conv4
I1013 15:24:30.132485 259298 net.cpp:210] Setting up conv4
I1013 15:24:30.132575 259298 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:24:30.132658 259298 net.cpp:225] Memory required for data: 1028397184
I1013 15:24:30.132725 259298 layer_factory.hpp:114] Creating layer relu4
I1013 15:24:30.132805 259298 net.cpp:160] Creating Layer relu4
I1013 15:24:30.132844 259298 net.cpp:596] relu4 <- conv4
I1013 15:24:30.132897 259298 net.cpp:557] relu4 -> conv4 (in-place)
I1013 15:24:30.137176 259298 net.cpp:210] Setting up relu4
I1013 15:24:30.137260 259298 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:24:30.137307 259298 net.cpp:225] Memory required for data: 1030756480
I1013 15:24:30.137339 259298 layer_factory.hpp:114] Creating layer dropout4
I1013 15:24:30.137414 259298 net.cpp:160] Creating Layer dropout4
I1013 15:24:30.137457 259298 net.cpp:596] dropout4 <- conv4
I1013 15:24:30.137544 259298 net.cpp:570] dropout4 -> drop4
I1013 15:24:30.137624 259298 net.cpp:210] Setting up dropout4
I1013 15:24:30.137660 259298 net.cpp:217] Top shape: 32 128 12 12 (589824)
I1013 15:24:30.137701 259298 net.cpp:225] Memory required for data: 1033115776
I1013 15:24:30.137735 259298 layer_factory.hpp:114] Creating layer pool4
I1013 15:24:30.137833 259298 net.cpp:160] Creating Layer pool4
I1013 15:24:30.137871 259298 net.cpp:596] pool4 <- drop4
I1013 15:24:30.137967 259298 net.cpp:570] pool4 -> pool4
I1013 15:24:30.142102 259298 net.cpp:210] Setting up pool4
I1013 15:24:30.142211 259298 net.cpp:217] Top shape: 32 128 6 6 (147456)
I1013 15:24:30.142256 259298 net.cpp:225] Memory required for data: 1033705600
I1013 15:24:30.142284 259298 layer_factory.hpp:114] Creating layer fc1
I1013 15:24:30.142359 259298 net.cpp:160] Creating Layer fc1
I1013 15:24:30.142398 259298 net.cpp:596] fc1 <- pool4
I1013 15:24:30.142446 259298 net.cpp:570] fc1 -> fc1
I1013 15:24:30.378187 259298 net.cpp:210] Setting up fc1
I1013 15:24:30.378273 259298 net.cpp:217] Top shape: 32 1024 (32768)
I1013 15:24:30.378340 259298 net.cpp:225] Memory required for data: 1033836672
I1013 15:24:30.378410 259298 layer_factory.hpp:114] Creating layer dropout5
I1013 15:24:30.378468 259298 net.cpp:160] Creating Layer dropout5
I1013 15:24:30.378499 259298 net.cpp:596] dropout5 <- fc1
I1013 15:24:30.378540 259298 net.cpp:570] dropout5 -> drop5
I1013 15:24:30.378607 259298 net.cpp:210] Setting up dropout5
I1013 15:24:30.378645 259298 net.cpp:217] Top shape: 32 1024 (32768)
I1013 15:24:30.378708 259298 net.cpp:225] Memory required for data: 1033967744
I1013 15:24:30.378736 259298 layer_factory.hpp:114] Creating layer fc2
I1013 15:24:30.378819 259298 net.cpp:160] Creating Layer fc2
I1013 15:24:30.378854 259298 net.cpp:596] fc2 <- drop5
I1013 15:24:30.378913 259298 net.cpp:570] fc2 -> fc2
I1013 15:24:30.382529 259298 net.cpp:210] Setting up fc2
I1013 15:24:30.382613 259298 net.cpp:217] Top shape: 32 2 (64)
I1013 15:24:30.382652 259298 net.cpp:225] Memory required for data: 1033968000
I1013 15:24:30.382709 259298 layer_factory.hpp:114] Creating layer loss
I1013 15:24:30.382771 259298 net.cpp:160] Creating Layer loss
I1013 15:24:30.382802 259298 net.cpp:596] loss <- fc2
I1013 15:24:30.382846 259298 net.cpp:596] loss <- label
I1013 15:24:30.382899 259298 net.cpp:570] loss -> (automatic)
I1013 15:24:30.382972 259298 layer_factory.hpp:114] Creating layer loss
I1013 15:24:30.386309 259298 net.cpp:210] Setting up loss
I1013 15:24:30.386394 259298 net.cpp:217] Top shape: (1)
I1013 15:24:30.386431 259298 net.cpp:220]     with loss weight 1
I1013 15:24:30.386555 259298 net.cpp:225] Memory required for data: 1033968004
I1013 15:24:30.386593 259298 net.cpp:287] loss needs backward computation.
I1013 15:24:30.386620 259298 net.cpp:287] fc2 needs backward computation.
I1013 15:24:30.386639 259298 net.cpp:287] dropout5 needs backward computation.
I1013 15:24:30.386659 259298 net.cpp:287] fc1 needs backward computation.
I1013 15:24:30.386679 259298 net.cpp:287] pool4 needs backward computation.
I1013 15:24:30.386698 259298 net.cpp:287] dropout4 needs backward computation.
I1013 15:24:30.386719 259298 net.cpp:287] relu4 needs backward computation.
I1013 15:24:30.386737 259298 net.cpp:287] conv4 needs backward computation.
I1013 15:24:30.386785 259298 net.cpp:287] pool3 needs backward computation.
I1013 15:24:30.386828 259298 net.cpp:287] dropout3 needs backward computation.
I1013 15:24:30.386852 259298 net.cpp:287] relu3 needs backward computation.
I1013 15:24:30.386870 259298 net.cpp:287] conv3 needs backward computation.
I1013 15:24:30.386890 259298 net.cpp:287] pool2 needs backward computation.
I1013 15:24:30.386909 259298 net.cpp:287] dropout2 needs backward computation.
I1013 15:24:30.386929 259298 net.cpp:287] relu2 needs backward computation.
I1013 15:24:30.386948 259298 net.cpp:287] conv2 needs backward computation.
I1013 15:24:30.386968 259298 net.cpp:287] pool1 needs backward computation.
I1013 15:24:30.386988 259298 net.cpp:287] dropout1 needs backward computation.
I1013 15:24:30.387014 259298 net.cpp:287] relu1 needs backward computation.
I1013 15:24:30.387035 259298 net.cpp:287] conv1 needs backward computation.
I1013 15:24:30.387056 259298 net.cpp:289] data does not need backward computation.
I1013 15:24:30.387145 259298 net.cpp:345] Network initialization done.
I1013 15:24:30.387439 259298 caffe.cpp:445] Performing Forward
I1013 15:24:31.352072 259298 caffe.cpp:450] Initial loss: 71.9611
I1013 15:24:31.352170 259298 caffe.cpp:452] Performing Backward
I1013 15:24:31.940677 259298 caffe.cpp:461] *** Benchmark begins ***
I1013 15:24:31.940780 259298 caffe.cpp:462] Testing for 10 iterations.
I1013 15:24:32.509522 259298 caffe.cpp:491] Iteration: 1 forward-backward time: 568 ms.
I1013 15:24:33.093812 259298 caffe.cpp:491] Iteration: 2 forward-backward time: 584 ms.
I1013 15:24:33.649533 259298 caffe.cpp:491] Iteration: 3 forward-backward time: 555 ms.
I1013 15:24:34.205258 259298 caffe.cpp:491] Iteration: 4 forward-backward time: 555 ms.
I1013 15:24:34.758347 259298 caffe.cpp:491] Iteration: 5 forward-backward time: 553 ms.
I1013 15:24:35.324041 259298 caffe.cpp:491] Iteration: 6 forward-backward time: 565 ms.
I1013 15:24:35.878237 259298 caffe.cpp:491] Iteration: 7 forward-backward time: 554 ms.
I1013 15:24:36.436666 259298 caffe.cpp:491] Iteration: 8 forward-backward time: 558 ms.
I1013 15:24:36.990877 259298 caffe.cpp:491] Iteration: 9 forward-backward time: 554 ms.
I1013 15:24:37.545220 259298 caffe.cpp:491] Iteration: 10 forward-backward time: 554 ms.
I1013 15:24:37.545315 259298 caffe.cpp:498] Average time per layer: 
I1013 15:24:37.545341 259298 caffe.cpp:501]       data	forward: 72.7593 ms.
I1013 15:24:37.545373 259298 caffe.cpp:505]       data	backward: 0.0031 ms.
I1013 15:24:37.545404 259298 caffe.cpp:501]      conv1	forward: 11.2372 ms.
I1013 15:24:37.545436 259298 caffe.cpp:505]      conv1	backward: 11.2059 ms.
I1013 15:24:37.545492 259298 caffe.cpp:501]      relu1	forward: 5.6116 ms.
I1013 15:24:37.545526 259298 caffe.cpp:505]      relu1	backward: 88.9843 ms.
I1013 15:24:37.545557 259298 caffe.cpp:501]   dropout1	forward: 68.8962 ms.
I1013 15:24:37.545589 259298 caffe.cpp:505]   dropout1	backward: 56.7208 ms.
I1013 15:24:37.545624 259298 caffe.cpp:501]      pool1	forward: 38.7962 ms.
I1013 15:24:37.545657 259298 caffe.cpp:505]      pool1	backward: 15.7862 ms.
I1013 15:24:37.545692 259298 caffe.cpp:501]      conv2	forward: 67.4239 ms.
I1013 15:24:37.545745 259298 caffe.cpp:505]      conv2	backward: 67.3147 ms.
I1013 15:24:37.545783 259298 caffe.cpp:501]      relu2	forward: 1.072 ms.
I1013 15:24:37.545814 259298 caffe.cpp:505]      relu2	backward: 4.4399 ms.
I1013 15:24:37.545846 259298 caffe.cpp:501]   dropout2	forward: 8.1917 ms.
I1013 15:24:37.545930 259298 caffe.cpp:505]   dropout2	backward: 4.9595 ms.
I1013 15:24:37.545965 259298 caffe.cpp:501]      pool2	forward: 9.335 ms.
I1013 15:24:37.546002 259298 caffe.cpp:505]      pool2	backward: 3.5694 ms.
I1013 15:24:37.546176 259298 caffe.cpp:501]      conv3	forward: 2.7364 ms.
I1013 15:24:37.546216 259298 caffe.cpp:505]      conv3	backward: 4.9668 ms.
I1013 15:24:37.546246 259298 caffe.cpp:501]      relu3	forward: 0.1653 ms.
I1013 15:24:37.546275 259298 caffe.cpp:505]      relu3	backward: 0.7476 ms.
I1013 15:24:37.546308 259298 caffe.cpp:501]   dropout3	forward: 1.1873 ms.
I1013 15:24:37.546339 259298 caffe.cpp:505]   dropout3	backward: 1.0006 ms.
I1013 15:24:37.546370 259298 caffe.cpp:501]      pool3	forward: 2.1194 ms.
I1013 15:24:37.546403 259298 caffe.cpp:505]      pool3	backward: 0.7396 ms.
I1013 15:24:37.546433 259298 caffe.cpp:501]      conv4	forward: 0.6872 ms.
I1013 15:24:37.546464 259298 caffe.cpp:505]      conv4	backward: 1.0572 ms.
I1013 15:24:37.546496 259298 caffe.cpp:501]      relu4	forward: 0.0407 ms.
I1013 15:24:37.546530 259298 caffe.cpp:505]      relu4	backward: 0.1591 ms.
I1013 15:24:37.546562 259298 caffe.cpp:501]   dropout4	forward: 0.2271 ms.
I1013 15:24:37.546591 259298 caffe.cpp:505]   dropout4	backward: 0.2007 ms.
I1013 15:24:37.546627 259298 caffe.cpp:501]      pool4	forward: 0.4317 ms.
I1013 15:24:37.546659 259298 caffe.cpp:505]      pool4	backward: 0.1876 ms.
I1013 15:24:37.546691 259298 caffe.cpp:501]        fc1	forward: 0.6694 ms.
I1013 15:24:37.546722 259298 caffe.cpp:505]        fc1	backward: 5.299 ms.
I1013 15:24:37.546751 259298 caffe.cpp:501]   dropout5	forward: 0.0961 ms.
I1013 15:24:37.546782 259298 caffe.cpp:505]   dropout5	backward: 0.0305 ms.
I1013 15:24:37.546823 259298 caffe.cpp:501]        fc2	forward: 0.1525 ms.
I1013 15:24:37.546958 259298 caffe.cpp:505]        fc2	backward: 0.1166 ms.
I1013 15:24:37.546991 259298 caffe.cpp:501]       loss	forward: 0.6221 ms.
I1013 15:24:37.547044 259298 caffe.cpp:505]       loss	backward: 0.0096 ms.
I1013 15:24:37.547086 259298 caffe.cpp:511] Average Forward pass: 292.636 ms.
I1013 15:24:37.547119 259298 caffe.cpp:514] Average Backward pass: 267.688 ms.
I1013 15:24:37.547153 259298 caffe.cpp:516] Average Forward-Backward: 560.6 ms.
I1013 15:24:37.547188 259298 caffe.cpp:519] Total Time: 5606 ms.
I1013 15:24:37.547231 259298 caffe.cpp:520] *** Benchmark ends ***

srun -n 1 -c 272 --cpu_bind=cores /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-knl/bin/caffe time -model=subst_train_val.prototxt -iterations=10
I1013 15:23:42.932986 258775 caffe.cpp:437] Use CPU.
I1013 15:23:42.972875 258775 cpu_info.cpp:452] Processor speed [MHz]: 1400
I1013 15:23:42.972941 258775 cpu_info.cpp:455] Total number of sockets: 1
I1013 15:23:42.972960 258775 cpu_info.cpp:458] Total number of CPU cores: 68
I1013 15:23:42.972976 258775 cpu_info.cpp:461] Total number of processors: 272
I1013 15:23:42.972992 258775 cpu_info.cpp:464] GPU is used: no
I1013 15:23:42.973009 258775 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1013 15:23:42.973024 258775 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1013 15:23:42.973042 258775 cpu_info.cpp:473] Number of OpenMP threads: 68
I1013 15:23:42.998280 258775 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1013 15:23:42.999322 258775 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1013 15:23:43.001402 258775 layer_factory.hpp:114] Creating layer data
I1013 15:23:43.001552 258775 net.cpp:160] Creating Layer data
I1013 15:23:43.001603 258775 net.cpp:570] data -> data
I1013 15:23:43.001689 258775 net.cpp:570] data -> label
I1013 15:23:43.024788 258775 net.cpp:210] Setting up data
I1013 15:23:43.024902 258775 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1013 15:23:43.024969 258775 net.cpp:217] Top shape: 1 1 1 1 (1)
I1013 15:23:43.025004 258775 net.cpp:225] Memory required for data: 184516
I1013 15:23:43.025040 258775 layer_factory.hpp:114] Creating layer conv1
I1013 15:23:43.025161 258775 net.cpp:160] Creating Layer conv1
I1013 15:23:43.025208 258775 net.cpp:596] conv1 <- data
I1013 15:23:43.025292 258775 net.cpp:570] conv1 -> conv1
I1013 15:23:43.150830 258775 net.cpp:210] Setting up conv1
I1013 15:23:43.150913 258775 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1013 15:23:43.150952 258775 net.cpp:225] Memory required for data: 7805124
I1013 15:23:43.151032 258775 layer_factory.hpp:114] Creating layer relu1
I1013 15:23:43.151099 258775 net.cpp:160] Creating Layer relu1
I1013 15:23:43.151126 258775 net.cpp:596] relu1 <- conv1
I1013 15:23:43.151160 258775 net.cpp:557] relu1 -> conv1 (in-place)
I1013 15:23:43.155789 258775 net.cpp:210] Setting up relu1
I1013 15:23:43.155874 258775 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1013 15:23:43.155915 258775 net.cpp:225] Memory required for data: 15425732
I1013 15:23:43.155944 258775 layer_factory.hpp:114] Creating layer dropout1
I1013 15:23:43.155990 258775 net.cpp:160] Creating Layer dropout1
I1013 15:23:43.156013 258775 net.cpp:596] dropout1 <- conv1
I1013 15:23:43.156047 258775 net.cpp:570] dropout1 -> drop1
I1013 15:23:43.156103 258775 net.cpp:210] Setting up dropout1
I1013 15:23:43.156128 258775 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1013 15:23:43.156157 258775 net.cpp:225] Memory required for data: 23046340
I1013 15:23:43.156182 258775 layer_factory.hpp:114] Creating layer pool1
I1013 15:23:43.156244 258775 net.cpp:160] Creating Layer pool1
I1013 15:23:43.156299 258775 net.cpp:596] pool1 <- drop1
I1013 15:23:43.156352 258775 net.cpp:570] pool1 -> pool1
I1013 15:23:43.160815 258775 net.cpp:210] Setting up pool1
I1013 15:23:43.160902 258775 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1013 15:23:43.160948 258775 net.cpp:225] Memory required for data: 24951492
I1013 15:23:43.160977 258775 layer_factory.hpp:114] Creating layer conv2
I1013 15:23:43.161051 258775 net.cpp:160] Creating Layer conv2
I1013 15:23:43.161082 258775 net.cpp:596] conv2 <- pool1
I1013 15:23:43.161123 258775 net.cpp:570] conv2 -> conv2
I1013 15:23:43.256424 258775 net.cpp:210] Setting up conv2
I1013 15:23:43.256520 258775 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1013 15:23:43.256582 258775 net.cpp:225] Memory required for data: 26733764
I1013 15:23:43.256669 258775 layer_factory.hpp:114] Creating layer relu2
I1013 15:23:43.256758 258775 net.cpp:160] Creating Layer relu2
I1013 15:23:43.256803 258775 net.cpp:596] relu2 <- conv2
I1013 15:23:43.256866 258775 net.cpp:557] relu2 -> conv2 (in-place)
I1013 15:23:43.261813 258775 net.cpp:210] Setting up relu2
I1013 15:23:43.261904 258775 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1013 15:23:43.261958 258775 net.cpp:225] Memory required for data: 28516036
I1013 15:23:43.261996 258775 layer_factory.hpp:114] Creating layer dropout2
I1013 15:23:43.262048 258775 net.cpp:160] Creating Layer dropout2
I1013 15:23:43.262082 258775 net.cpp:596] dropout2 <- conv2
I1013 15:23:43.262127 258775 net.cpp:570] dropout2 -> drop2
I1013 15:23:43.262202 258775 net.cpp:210] Setting up dropout2
I1013 15:23:43.262239 258775 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1013 15:23:43.262284 258775 net.cpp:225] Memory required for data: 30298308
I1013 15:23:43.262382 258775 layer_factory.hpp:114] Creating layer pool2
I1013 15:23:43.262614 258775 net.cpp:160] Creating Layer pool2
I1013 15:23:43.262892 258775 net.cpp:596] pool2 <- drop2
I1013 15:23:43.262996 258775 net.cpp:570] pool2 -> pool2
I1013 15:23:43.267624 258775 net.cpp:210] Setting up pool2
I1013 15:23:43.267712 258775 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1013 15:23:43.267755 258775 net.cpp:225] Memory required for data: 30759108
I1013 15:23:43.267781 258775 layer_factory.hpp:114] Creating layer conv3
I1013 15:23:43.267858 258775 net.cpp:160] Creating Layer conv3
I1013 15:23:43.267894 258775 net.cpp:596] conv3 <- pool2
I1013 15:23:43.267940 258775 net.cpp:570] conv3 -> conv3
I1013 15:23:43.355832 258775 net.cpp:210] Setting up conv3
I1013 15:23:43.355928 258775 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1013 15:23:43.355981 258775 net.cpp:225] Memory required for data: 31160516
I1013 15:23:43.356058 258775 layer_factory.hpp:114] Creating layer relu3
I1013 15:23:43.356138 258775 net.cpp:160] Creating Layer relu3
I1013 15:23:43.356178 258775 net.cpp:596] relu3 <- conv3
I1013 15:23:43.356228 258775 net.cpp:557] relu3 -> conv3 (in-place)
I1013 15:23:43.361107 258775 net.cpp:210] Setting up relu3
I1013 15:23:43.361196 258775 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1013 15:23:43.361243 258775 net.cpp:225] Memory required for data: 31561924
I1013 15:23:43.361275 258775 layer_factory.hpp:114] Creating layer dropout3
I1013 15:23:43.361323 258775 net.cpp:160] Creating Layer dropout3
I1013 15:23:43.361352 258775 net.cpp:596] dropout3 <- conv3
I1013 15:23:43.361397 258775 net.cpp:570] dropout3 -> drop3
I1013 15:23:43.361500 258775 net.cpp:210] Setting up dropout3
I1013 15:23:43.361551 258775 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1013 15:23:43.361594 258775 net.cpp:225] Memory required for data: 31963332
I1013 15:23:43.361629 258775 layer_factory.hpp:114] Creating layer pool3
I1013 15:23:43.361737 258775 net.cpp:160] Creating Layer pool3
I1013 15:23:43.361868 258775 net.cpp:596] pool3 <- drop3
I1013 15:23:43.361963 258775 net.cpp:570] pool3 -> pool3
I1013 15:23:43.366818 258775 net.cpp:210] Setting up pool3
I1013 15:23:43.366904 258775 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1013 15:23:43.366943 258775 net.cpp:225] Memory required for data: 32063684
I1013 15:23:43.366971 258775 layer_factory.hpp:114] Creating layer conv4
I1013 15:23:43.367046 258775 net.cpp:160] Creating Layer conv4
I1013 15:23:43.367076 258775 net.cpp:596] conv4 <- pool3
I1013 15:23:43.367116 258775 net.cpp:570] conv4 -> conv4
I1013 15:23:43.447240 258775 net.cpp:210] Setting up conv4
I1013 15:23:43.447327 258775 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1013 15:23:43.447371 258775 net.cpp:225] Memory required for data: 32137412
I1013 15:23:43.447429 258775 layer_factory.hpp:114] Creating layer relu4
I1013 15:23:43.447491 258775 net.cpp:160] Creating Layer relu4
I1013 15:23:43.447523 258775 net.cpp:596] relu4 <- conv4
I1013 15:23:43.447563 258775 net.cpp:557] relu4 -> conv4 (in-place)
I1013 15:23:43.452242 258775 net.cpp:210] Setting up relu4
I1013 15:23:43.452328 258775 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1013 15:23:43.452371 258775 net.cpp:225] Memory required for data: 32211140
I1013 15:23:43.452402 258775 layer_factory.hpp:114] Creating layer dropout4
I1013 15:23:43.452450 258775 net.cpp:160] Creating Layer dropout4
I1013 15:23:43.452477 258775 net.cpp:596] dropout4 <- conv4
I1013 15:23:43.452515 258775 net.cpp:570] dropout4 -> drop4
I1013 15:23:43.452579 258775 net.cpp:210] Setting up dropout4
I1013 15:23:43.452607 258775 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1013 15:23:43.452641 258775 net.cpp:225] Memory required for data: 32284868
I1013 15:23:43.452668 258775 layer_factory.hpp:114] Creating layer pool4
I1013 15:23:43.452729 258775 net.cpp:160] Creating Layer pool4
I1013 15:23:43.452800 258775 net.cpp:596] pool4 <- drop4
I1013 15:23:43.452981 258775 net.cpp:570] pool4 -> pool4
I1013 15:23:43.457531 258775 net.cpp:210] Setting up pool4
I1013 15:23:43.457614 258775 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1013 15:23:43.457687 258775 net.cpp:225] Memory required for data: 32303300
I1013 15:23:43.457720 258775 layer_factory.hpp:114] Creating layer fc1
I1013 15:23:43.457794 258775 net.cpp:160] Creating Layer fc1
I1013 15:23:43.457828 258775 net.cpp:596] fc1 <- pool4
I1013 15:23:43.457873 258775 net.cpp:570] fc1 -> fc1
I1013 15:23:43.694947 258775 net.cpp:210] Setting up fc1
I1013 15:23:43.695032 258775 net.cpp:217] Top shape: 1 1024 (1024)
I1013 15:23:43.695073 258775 net.cpp:225] Memory required for data: 32307396
I1013 15:23:43.695143 258775 layer_factory.hpp:114] Creating layer dropout5
I1013 15:23:43.695194 258775 net.cpp:160] Creating Layer dropout5
I1013 15:23:43.695219 258775 net.cpp:596] dropout5 <- fc1
I1013 15:23:43.695253 258775 net.cpp:570] dropout5 -> drop5
I1013 15:23:43.695309 258775 net.cpp:210] Setting up dropout5
I1013 15:23:43.695338 258775 net.cpp:217] Top shape: 1 1024 (1024)
I1013 15:23:43.695371 258775 net.cpp:225] Memory required for data: 32311492
I1013 15:23:43.695399 258775 layer_factory.hpp:114] Creating layer fc2
I1013 15:23:43.695475 258775 net.cpp:160] Creating Layer fc2
I1013 15:23:43.695508 258775 net.cpp:596] fc2 <- drop5
I1013 15:23:43.695649 258775 net.cpp:570] fc2 -> fc2
I1013 15:23:43.699023 258775 net.cpp:210] Setting up fc2
I1013 15:23:43.699112 258775 net.cpp:217] Top shape: 1 2 (2)
I1013 15:23:43.699151 258775 net.cpp:225] Memory required for data: 32311500
I1013 15:23:43.699206 258775 layer_factory.hpp:114] Creating layer loss
I1013 15:23:43.699275 258775 net.cpp:160] Creating Layer loss
I1013 15:23:43.699306 258775 net.cpp:596] loss <- fc2
I1013 15:23:43.699333 258775 net.cpp:596] loss <- label
I1013 15:23:43.699379 258775 net.cpp:570] loss -> (automatic)
I1013 15:23:43.699442 258775 layer_factory.hpp:114] Creating layer loss
I1013 15:23:43.702684 258775 net.cpp:210] Setting up loss
I1013 15:23:43.702769 258775 net.cpp:217] Top shape: (1)
I1013 15:23:43.702807 258775 net.cpp:220]     with loss weight 1
I1013 15:23:43.702932 258775 net.cpp:225] Memory required for data: 32311504
I1013 15:23:43.702967 258775 net.cpp:287] loss needs backward computation.
I1013 15:23:43.702997 258775 net.cpp:287] fc2 needs backward computation.
I1013 15:23:43.703018 258775 net.cpp:287] dropout5 needs backward computation.
I1013 15:23:43.703038 258775 net.cpp:287] fc1 needs backward computation.
I1013 15:23:43.703058 258775 net.cpp:287] pool4 needs backward computation.
I1013 15:23:43.703079 258775 net.cpp:287] dropout4 needs backward computation.
I1013 15:23:43.703101 258775 net.cpp:287] relu4 needs backward computation.
I1013 15:23:43.703143 258775 net.cpp:287] conv4 needs backward computation.
I1013 15:23:43.703179 258775 net.cpp:287] pool3 needs backward computation.
I1013 15:23:43.703200 258775 net.cpp:287] dropout3 needs backward computation.
I1013 15:23:43.703233 258775 net.cpp:287] relu3 needs backward computation.
I1013 15:23:43.703255 258775 net.cpp:287] conv3 needs backward computation.
I1013 15:23:43.703277 258775 net.cpp:287] pool2 needs backward computation.
I1013 15:23:43.703300 258775 net.cpp:287] dropout2 needs backward computation.
I1013 15:23:43.703348 258775 net.cpp:287] relu2 needs backward computation.
I1013 15:23:43.703387 258775 net.cpp:287] conv2 needs backward computation.
I1013 15:23:43.703419 258775 net.cpp:287] pool1 needs backward computation.
I1013 15:23:43.703441 258775 net.cpp:287] dropout1 needs backward computation.
I1013 15:23:43.703461 258775 net.cpp:287] relu1 needs backward computation.
I1013 15:23:43.703487 258775 net.cpp:287] conv1 needs backward computation.
I1013 15:23:43.703518 258775 net.cpp:289] data does not need backward computation.
I1013 15:23:43.703565 258775 net.cpp:345] Network initialization done.
I1013 15:23:43.703891 258775 caffe.cpp:445] Performing Forward
I1013 15:23:44.107785 258775 caffe.cpp:450] Initial loss: 87.3365
I1013 15:23:44.107894 258775 caffe.cpp:452] Performing Backward
I1013 15:23:44.200055 258775 caffe.cpp:461] *** Benchmark begins ***
I1013 15:23:44.200132 258775 caffe.cpp:462] Testing for 10 iterations.
I1013 15:23:44.279799 258775 caffe.cpp:491] Iteration: 1 forward-backward time: 79 ms.
I1013 15:23:44.361734 258775 caffe.cpp:491] Iteration: 2 forward-backward time: 81 ms.
I1013 15:23:44.443466 258775 caffe.cpp:491] Iteration: 3 forward-backward time: 81 ms.
I1013 15:23:44.525004 258775 caffe.cpp:491] Iteration: 4 forward-backward time: 81 ms.
I1013 15:23:44.603083 258775 caffe.cpp:491] Iteration: 5 forward-backward time: 78 ms.
I1013 15:23:44.683651 258775 caffe.cpp:491] Iteration: 6 forward-backward time: 80 ms.
I1013 15:23:44.764194 258775 caffe.cpp:491] Iteration: 7 forward-backward time: 80 ms.
I1013 15:23:44.845223 258775 caffe.cpp:491] Iteration: 8 forward-backward time: 80 ms.
I1013 15:23:44.924466 258775 caffe.cpp:491] Iteration: 9 forward-backward time: 79 ms.
I1013 15:23:45.003842 258775 caffe.cpp:491] Iteration: 10 forward-backward time: 79 ms.
I1013 15:23:45.003947 258775 caffe.cpp:498] Average time per layer: 
I1013 15:23:45.003973 258775 caffe.cpp:501]       data	forward: 2.8612 ms.
I1013 15:23:45.004004 258775 caffe.cpp:505]       data	backward: 0.0035 ms.
I1013 15:23:45.004037 258775 caffe.cpp:501]      conv1	forward: 0.442 ms.
I1013 15:23:45.004068 258775 caffe.cpp:505]      conv1	backward: 0.8478 ms.
I1013 15:23:45.004098 258775 caffe.cpp:501]      relu1	forward: 0.0562 ms.
I1013 15:23:45.004130 258775 caffe.cpp:505]      relu1	backward: 0.8306 ms.
I1013 15:23:45.004163 258775 caffe.cpp:501]   dropout1	forward: 0.9127 ms.
I1013 15:23:45.004196 258775 caffe.cpp:505]   dropout1	backward: 0.7437 ms.
I1013 15:23:45.004228 258775 caffe.cpp:501]      pool1	forward: 40.3242 ms.
I1013 15:23:45.004266 258775 caffe.cpp:505]      pool1	backward: 6.7973 ms.
I1013 15:23:45.004299 258775 caffe.cpp:501]      conv2	forward: 2.4376 ms.
I1013 15:23:45.004360 258775 caffe.cpp:505]      conv2	backward: 3.5187 ms.
I1013 15:23:45.004406 258775 caffe.cpp:501]      relu2	forward: 0.047 ms.
I1013 15:23:45.004580 258775 caffe.cpp:505]      relu2	backward: 0.3087 ms.
I1013 15:23:45.004631 258775 caffe.cpp:501]   dropout2	forward: 0.2562 ms.
I1013 15:23:45.004672 258775 caffe.cpp:505]   dropout2	backward: 0.1706 ms.
I1013 15:23:45.004709 258775 caffe.cpp:501]      pool2	forward: 9.82 ms.
I1013 15:23:45.004742 258775 caffe.cpp:505]      pool2	backward: 1.5402 ms.
I1013 15:23:45.004776 258775 caffe.cpp:501]      conv3	forward: 0.3383 ms.
I1013 15:23:45.004815 258775 caffe.cpp:505]      conv3	backward: 0.5111 ms.
I1013 15:23:45.005136 258775 caffe.cpp:501]      relu3	forward: 0.0264 ms.
I1013 15:23:45.005185 258775 caffe.cpp:505]      relu3	backward: 0.1455 ms.
I1013 15:23:45.005223 258775 caffe.cpp:501]   dropout3	forward: 0.098 ms.
I1013 15:23:45.005265 258775 caffe.cpp:505]   dropout3	backward: 0.0758 ms.
I1013 15:23:45.005316 258775 caffe.cpp:501]      pool3	forward: 2.2552 ms.
I1013 15:23:45.005357 258775 caffe.cpp:505]      pool3	backward: 0.4076 ms.
I1013 15:23:45.005396 258775 caffe.cpp:501]      conv4	forward: 0.189 ms.
I1013 15:23:45.005434 258775 caffe.cpp:505]      conv4	backward: 0.2128 ms.
I1013 15:23:45.005550 258775 caffe.cpp:501]      relu4	forward: 0.0201 ms.
I1013 15:23:45.005597 258775 caffe.cpp:505]      relu4	backward: 0.0831 ms.
I1013 15:23:45.005656 258775 caffe.cpp:501]   dropout4	forward: 0.19 ms.
I1013 15:23:45.005697 258775 caffe.cpp:505]   dropout4	backward: 0.0491 ms.
I1013 15:23:45.005736 258775 caffe.cpp:501]      pool4	forward: 0.4149 ms.
I1013 15:23:45.005774 258775 caffe.cpp:505]      pool4	backward: 0.1363 ms.
I1013 15:23:45.005808 258775 caffe.cpp:501]        fc1	forward: 0.3324 ms.
I1013 15:23:45.005858 258775 caffe.cpp:505]        fc1	backward: 2.2938 ms.
I1013 15:23:45.005905 258775 caffe.cpp:501]   dropout5	forward: 0.0685 ms.
I1013 15:23:45.005949 258775 caffe.cpp:505]   dropout5	backward: 0.0207 ms.
I1013 15:23:45.005988 258775 caffe.cpp:501]        fc2	forward: 0.0342 ms.
I1013 15:23:45.006263 258775 caffe.cpp:505]        fc2	backward: 0.0337 ms.
I1013 15:23:45.006306 258775 caffe.cpp:501]       loss	forward: 0.0646 ms.
I1013 15:23:45.006346 258775 caffe.cpp:505]       loss	backward: 0.0096 ms.
I1013 15:23:45.006408 258775 caffe.cpp:511] Average Forward pass: 61.3476 ms.
I1013 15:23:45.006456 258775 caffe.cpp:514] Average Backward pass: 18.8957 ms.
I1013 15:23:45.006492 258775 caffe.cpp:516] Average Forward-Backward: 80.6 ms.
I1013 15:23:45.006543 258775 caffe.cpp:519] Total Time: 806 ms.
I1013 15:23:45.006590 258775 caffe.cpp:520] *** Benchmark ends ***

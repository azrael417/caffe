srun -n 1 -c 32 --cpu_bind=cores -m block:cyclic /project/projectdirs/mpccc/tmalas/intelcaffe/install_cori-hsw/bin/caffe time -model=subst_train_val.prototxt -iterations=10
I1017 11:21:33.294351 28585 caffe.cpp:437] Use CPU.
I1017 11:21:33.304422 28585 cpu_info.cpp:452] Processor speed [MHz]: 2300
I1017 11:21:33.304430 28585 cpu_info.cpp:455] Total number of sockets: 2
I1017 11:21:33.304432 28585 cpu_info.cpp:458] Total number of CPU cores: 32
I1017 11:21:33.304435 28585 cpu_info.cpp:461] Total number of processors: 64
I1017 11:21:33.304447 28585 cpu_info.cpp:464] GPU is used: no
I1017 11:21:33.304450 28585 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1017 11:21:33.304451 28585 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1017 11:21:33.304452 28585 cpu_info.cpp:473] Number of OpenMP threads: 32
I1017 11:21:33.306835 28585 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1017 11:21:33.306917 28585 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 64
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 64
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1017 11:21:33.307044 28585 layer_factory.hpp:114] Creating layer data
I1017 11:21:33.307054 28585 net.cpp:160] Creating Layer data
I1017 11:21:33.307056 28585 net.cpp:570] data -> data
I1017 11:21:33.307067 28585 net.cpp:570] data -> label
I1017 11:21:33.307278 28585 net.cpp:210] Setting up data
I1017 11:21:33.307288 28585 net.cpp:217] Top shape: 64 3 124 124 (2952192)
I1017 11:21:33.307302 28585 net.cpp:217] Top shape: 64 1 1 1 (64)
I1017 11:21:33.307306 28585 net.cpp:225] Memory required for data: 11809024
I1017 11:21:33.307309 28585 layer_factory.hpp:114] Creating layer conv1
I1017 11:21:33.307327 28585 net.cpp:160] Creating Layer conv1
I1017 11:21:33.307332 28585 net.cpp:596] conv1 <- data
I1017 11:21:33.307338 28585 net.cpp:570] conv1 -> conv1
I1017 11:21:33.337576 28585 net.cpp:210] Setting up conv1
I1017 11:21:33.337599 28585 net.cpp:217] Top shape: 64 128 122 122 (121929728)
I1017 11:21:33.337607 28585 net.cpp:225] Memory required for data: 499527936
I1017 11:21:33.337625 28585 layer_factory.hpp:114] Creating layer relu1
I1017 11:21:33.337642 28585 net.cpp:160] Creating Layer relu1
I1017 11:21:33.337646 28585 net.cpp:596] relu1 <- conv1
I1017 11:21:33.337651 28585 net.cpp:557] relu1 -> conv1 (in-place)
I1017 11:21:33.337684 28585 net.cpp:210] Setting up relu1
I1017 11:21:33.337687 28585 net.cpp:217] Top shape: 64 128 122 122 (121929728)
I1017 11:21:33.337689 28585 net.cpp:225] Memory required for data: 987246848
I1017 11:21:33.337692 28585 layer_factory.hpp:114] Creating layer dropout1
I1017 11:21:33.337697 28585 net.cpp:160] Creating Layer dropout1
I1017 11:21:33.337698 28585 net.cpp:596] dropout1 <- conv1
I1017 11:21:33.337702 28585 net.cpp:570] dropout1 -> drop1
I1017 11:21:33.337709 28585 net.cpp:210] Setting up dropout1
I1017 11:21:33.337712 28585 net.cpp:217] Top shape: 64 128 122 122 (121929728)
I1017 11:21:33.337714 28585 net.cpp:225] Memory required for data: 1474965760
I1017 11:21:33.337716 28585 layer_factory.hpp:114] Creating layer pool1
I1017 11:21:33.337725 28585 net.cpp:160] Creating Layer pool1
I1017 11:21:33.337728 28585 net.cpp:596] pool1 <- drop1
I1017 11:21:33.337730 28585 net.cpp:570] pool1 -> pool1
I1017 11:21:33.337752 28585 net.cpp:210] Setting up pool1
I1017 11:21:33.337761 28585 net.cpp:217] Top shape: 64 128 61 61 (30482432)
I1017 11:21:33.337765 28585 net.cpp:225] Memory required for data: 1596895488
I1017 11:21:33.337767 28585 layer_factory.hpp:114] Creating layer conv2
I1017 11:21:33.337784 28585 net.cpp:160] Creating Layer conv2
I1017 11:21:33.337790 28585 net.cpp:596] conv2 <- pool1
I1017 11:21:33.337795 28585 net.cpp:570] conv2 -> conv2
I1017 11:21:33.550837 28585 net.cpp:210] Setting up conv2
I1017 11:21:33.550865 28585 net.cpp:217] Top shape: 64 128 59 59 (28516352)
I1017 11:21:33.550874 28585 net.cpp:225] Memory required for data: 1710960896
I1017 11:21:33.550890 28585 layer_factory.hpp:114] Creating layer relu2
I1017 11:21:33.550906 28585 net.cpp:160] Creating Layer relu2
I1017 11:21:33.550909 28585 net.cpp:596] relu2 <- conv2
I1017 11:21:33.550916 28585 net.cpp:557] relu2 -> conv2 (in-place)
I1017 11:21:33.550951 28585 net.cpp:210] Setting up relu2
I1017 11:21:33.550952 28585 net.cpp:217] Top shape: 64 128 59 59 (28516352)
I1017 11:21:33.550956 28585 net.cpp:225] Memory required for data: 1825026304
I1017 11:21:33.550957 28585 layer_factory.hpp:114] Creating layer dropout2
I1017 11:21:33.550963 28585 net.cpp:160] Creating Layer dropout2
I1017 11:21:33.550966 28585 net.cpp:596] dropout2 <- conv2
I1017 11:21:33.550971 28585 net.cpp:570] dropout2 -> drop2
I1017 11:21:33.550977 28585 net.cpp:210] Setting up dropout2
I1017 11:21:33.550979 28585 net.cpp:217] Top shape: 64 128 59 59 (28516352)
I1017 11:21:33.550981 28585 net.cpp:225] Memory required for data: 1939091712
I1017 11:21:33.550983 28585 layer_factory.hpp:114] Creating layer pool2
I1017 11:21:33.551007 28585 net.cpp:160] Creating Layer pool2
I1017 11:21:33.551008 28585 net.cpp:596] pool2 <- drop2
I1017 11:21:33.551012 28585 net.cpp:570] pool2 -> pool2
I1017 11:21:33.551026 28585 net.cpp:210] Setting up pool2
I1017 11:21:33.551033 28585 net.cpp:217] Top shape: 64 128 30 30 (7372800)
I1017 11:21:33.551038 28585 net.cpp:225] Memory required for data: 1968582912
I1017 11:21:33.551038 28585 layer_factory.hpp:114] Creating layer conv3
I1017 11:21:33.551072 28585 net.cpp:160] Creating Layer conv3
I1017 11:21:33.551076 28585 net.cpp:596] conv3 <- pool2
I1017 11:21:33.551082 28585 net.cpp:570] conv3 -> conv3
I1017 11:21:33.608256 28585 net.cpp:210] Setting up conv3
I1017 11:21:33.608280 28585 net.cpp:217] Top shape: 64 128 28 28 (6422528)
I1017 11:21:33.608290 28585 net.cpp:225] Memory required for data: 1994273024
I1017 11:21:33.608305 28585 layer_factory.hpp:114] Creating layer relu3
I1017 11:21:33.608321 28585 net.cpp:160] Creating Layer relu3
I1017 11:21:33.608325 28585 net.cpp:596] relu3 <- conv3
I1017 11:21:33.608331 28585 net.cpp:557] relu3 -> conv3 (in-place)
I1017 11:21:33.608355 28585 net.cpp:210] Setting up relu3
I1017 11:21:33.608374 28585 net.cpp:217] Top shape: 64 128 28 28 (6422528)
I1017 11:21:33.608386 28585 net.cpp:225] Memory required for data: 2019963136
I1017 11:21:33.608388 28585 layer_factory.hpp:114] Creating layer dropout3
I1017 11:21:33.608393 28585 net.cpp:160] Creating Layer dropout3
I1017 11:21:33.608395 28585 net.cpp:596] dropout3 <- conv3
I1017 11:21:33.608402 28585 net.cpp:570] dropout3 -> drop3
I1017 11:21:33.608408 28585 net.cpp:210] Setting up dropout3
I1017 11:21:33.608415 28585 net.cpp:217] Top shape: 64 128 28 28 (6422528)
I1017 11:21:33.608418 28585 net.cpp:225] Memory required for data: 2045653248
I1017 11:21:33.608420 28585 layer_factory.hpp:114] Creating layer pool3
I1017 11:21:33.608440 28585 net.cpp:160] Creating Layer pool3
I1017 11:21:33.608443 28585 net.cpp:596] pool3 <- drop3
I1017 11:21:33.608445 28585 net.cpp:570] pool3 -> pool3
I1017 11:21:33.608464 28585 net.cpp:210] Setting up pool3
I1017 11:21:33.608466 28585 net.cpp:217] Top shape: 64 128 14 14 (1605632)
I1017 11:21:33.608469 28585 net.cpp:225] Memory required for data: 2052075776
I1017 11:21:33.608471 28585 layer_factory.hpp:114] Creating layer conv4
I1017 11:21:33.608506 28585 net.cpp:160] Creating Layer conv4
I1017 11:21:33.608510 28585 net.cpp:596] conv4 <- pool3
I1017 11:21:33.608513 28585 net.cpp:570] conv4 -> conv4
I1017 11:21:33.628482 28585 net.cpp:210] Setting up conv4
I1017 11:21:33.628500 28585 net.cpp:217] Top shape: 64 128 12 12 (1179648)
I1017 11:21:33.628506 28585 net.cpp:225] Memory required for data: 2056794368
I1017 11:21:33.628515 28585 layer_factory.hpp:114] Creating layer relu4
I1017 11:21:33.628528 28585 net.cpp:160] Creating Layer relu4
I1017 11:21:33.628531 28585 net.cpp:596] relu4 <- conv4
I1017 11:21:33.628535 28585 net.cpp:557] relu4 -> conv4 (in-place)
I1017 11:21:33.628551 28585 net.cpp:210] Setting up relu4
I1017 11:21:33.628552 28585 net.cpp:217] Top shape: 64 128 12 12 (1179648)
I1017 11:21:33.628556 28585 net.cpp:225] Memory required for data: 2061512960
I1017 11:21:33.628557 28585 layer_factory.hpp:114] Creating layer dropout4
I1017 11:21:33.628563 28585 net.cpp:160] Creating Layer dropout4
I1017 11:21:33.628566 28585 net.cpp:596] dropout4 <- conv4
I1017 11:21:33.628569 28585 net.cpp:570] dropout4 -> drop4
I1017 11:21:33.628587 28585 net.cpp:210] Setting up dropout4
I1017 11:21:33.628588 28585 net.cpp:217] Top shape: 64 128 12 12 (1179648)
I1017 11:21:33.628592 28585 net.cpp:225] Memory required for data: 2066231552
I1017 11:21:33.628593 28585 layer_factory.hpp:114] Creating layer pool4
I1017 11:21:33.628603 28585 net.cpp:160] Creating Layer pool4
I1017 11:21:33.628614 28585 net.cpp:596] pool4 <- drop4
I1017 11:21:33.628620 28585 net.cpp:570] pool4 -> pool4
I1017 11:21:33.628654 28585 net.cpp:210] Setting up pool4
I1017 11:21:33.628657 28585 net.cpp:217] Top shape: 64 128 6 6 (294912)
I1017 11:21:33.628661 28585 net.cpp:225] Memory required for data: 2067411200
I1017 11:21:33.628665 28585 layer_factory.hpp:114] Creating layer fc1
I1017 11:21:33.628675 28585 net.cpp:160] Creating Layer fc1
I1017 11:21:33.628690 28585 net.cpp:596] fc1 <- pool4
I1017 11:21:33.628696 28585 net.cpp:570] fc1 -> fc1
I1017 11:21:33.682773 28585 net.cpp:210] Setting up fc1
I1017 11:21:33.682780 28585 net.cpp:217] Top shape: 64 1024 (65536)
I1017 11:21:33.682783 28585 net.cpp:225] Memory required for data: 2067673344
I1017 11:21:33.682790 28585 layer_factory.hpp:114] Creating layer dropout5
I1017 11:21:33.682796 28585 net.cpp:160] Creating Layer dropout5
I1017 11:21:33.682799 28585 net.cpp:596] dropout5 <- fc1
I1017 11:21:33.682802 28585 net.cpp:570] dropout5 -> drop5
I1017 11:21:33.682807 28585 net.cpp:210] Setting up dropout5
I1017 11:21:33.682811 28585 net.cpp:217] Top shape: 64 1024 (65536)
I1017 11:21:33.682812 28585 net.cpp:225] Memory required for data: 2067935488
I1017 11:21:33.682814 28585 layer_factory.hpp:114] Creating layer fc2
I1017 11:21:33.682819 28585 net.cpp:160] Creating Layer fc2
I1017 11:21:33.682821 28585 net.cpp:596] fc2 <- drop5
I1017 11:21:33.682826 28585 net.cpp:570] fc2 -> fc2
I1017 11:21:33.682870 28585 net.cpp:210] Setting up fc2
I1017 11:21:33.682875 28585 net.cpp:217] Top shape: 64 2 (128)
I1017 11:21:33.682890 28585 net.cpp:225] Memory required for data: 2067936000
I1017 11:21:33.682894 28585 layer_factory.hpp:114] Creating layer loss
I1017 11:21:33.682901 28585 net.cpp:160] Creating Layer loss
I1017 11:21:33.682904 28585 net.cpp:596] loss <- fc2
I1017 11:21:33.682905 28585 net.cpp:596] loss <- label
I1017 11:21:33.682910 28585 net.cpp:570] loss -> (automatic)
I1017 11:21:33.682930 28585 layer_factory.hpp:114] Creating layer loss
I1017 11:21:33.682952 28585 net.cpp:210] Setting up loss
I1017 11:21:33.682956 28585 net.cpp:217] Top shape: (1)
I1017 11:21:33.682960 28585 net.cpp:220]     with loss weight 1
I1017 11:21:33.682992 28585 net.cpp:225] Memory required for data: 2067936004
I1017 11:21:33.682996 28585 net.cpp:287] loss needs backward computation.
I1017 11:21:33.682999 28585 net.cpp:287] fc2 needs backward computation.
I1017 11:21:33.683001 28585 net.cpp:287] dropout5 needs backward computation.
I1017 11:21:33.683003 28585 net.cpp:287] fc1 needs backward computation.
I1017 11:21:33.683006 28585 net.cpp:287] pool4 needs backward computation.
I1017 11:21:33.683007 28585 net.cpp:287] dropout4 needs backward computation.
I1017 11:21:33.683009 28585 net.cpp:287] relu4 needs backward computation.
I1017 11:21:33.683012 28585 net.cpp:287] conv4 needs backward computation.
I1017 11:21:33.683014 28585 net.cpp:287] pool3 needs backward computation.
I1017 11:21:33.683017 28585 net.cpp:287] dropout3 needs backward computation.
I1017 11:21:33.683018 28585 net.cpp:287] relu3 needs backward computation.
I1017 11:21:33.683022 28585 net.cpp:287] conv3 needs backward computation.
I1017 11:21:33.683024 28585 net.cpp:287] pool2 needs backward computation.
I1017 11:21:33.683027 28585 net.cpp:287] dropout2 needs backward computation.
I1017 11:21:33.683028 28585 net.cpp:287] relu2 needs backward computation.
I1017 11:21:33.683032 28585 net.cpp:287] conv2 needs backward computation.
I1017 11:21:33.683033 28585 net.cpp:287] pool1 needs backward computation.
I1017 11:21:33.683037 28585 net.cpp:287] dropout1 needs backward computation.
I1017 11:21:33.683038 28585 net.cpp:287] relu1 needs backward computation.
I1017 11:21:33.683040 28585 net.cpp:287] conv1 needs backward computation.
I1017 11:21:33.683043 28585 net.cpp:289] data does not need backward computation.
I1017 11:21:33.683054 28585 net.cpp:345] Network initialization done.
I1017 11:21:33.683130 28585 caffe.cpp:445] Performing Forward
I1017 11:21:34.982854 28585 caffe.cpp:450] Initial loss: 2.14971
I1017 11:21:34.982908 28585 caffe.cpp:452] Performing Backward
I1017 11:21:36.247027 28585 caffe.cpp:461] *** Benchmark begins ***
I1017 11:21:36.247066 28585 caffe.cpp:462] Testing for 10 iterations.
I1017 11:21:37.198488 28585 caffe.cpp:491] Iteration: 1 forward-backward time: 951 ms.
I1017 11:21:38.156587 28585 caffe.cpp:491] Iteration: 2 forward-backward time: 958 ms.
I1017 11:21:39.114711 28585 caffe.cpp:491] Iteration: 3 forward-backward time: 958 ms.
I1017 11:21:40.074338 28585 caffe.cpp:491] Iteration: 4 forward-backward time: 959 ms.
I1017 11:21:41.081722 28585 caffe.cpp:491] Iteration: 5 forward-backward time: 1007 ms.
I1017 11:21:42.040868 28585 caffe.cpp:491] Iteration: 6 forward-backward time: 959 ms.
I1017 11:21:43.001770 28585 caffe.cpp:491] Iteration: 7 forward-backward time: 960 ms.
I1017 11:21:43.962815 28585 caffe.cpp:491] Iteration: 8 forward-backward time: 961 ms.
I1017 11:21:44.926023 28585 caffe.cpp:491] Iteration: 9 forward-backward time: 963 ms.
I1017 11:21:45.888634 28585 caffe.cpp:491] Iteration: 10 forward-backward time: 962 ms.
I1017 11:21:45.888689 28585 caffe.cpp:498] Average time per layer: 
I1017 11:21:45.888694 28585 caffe.cpp:501]       data	forward: 65.4 ms.
I1017 11:21:45.888701 28585 caffe.cpp:505]       data	backward: 0.0018 ms.
I1017 11:21:45.888708 28585 caffe.cpp:501]      conv1	forward: 28.6447 ms.
I1017 11:21:45.888713 28585 caffe.cpp:505]      conv1	backward: 27.0882 ms.
I1017 11:21:45.888720 28585 caffe.cpp:501]      relu1	forward: 18.2667 ms.
I1017 11:21:45.888725 28585 caffe.cpp:505]      relu1	backward: 52.9073 ms.
I1017 11:21:45.888731 28585 caffe.cpp:501]   dropout1	forward: 96.3162 ms.
I1017 11:21:45.888746 28585 caffe.cpp:505]   dropout1	backward: 59.3104 ms.
I1017 11:21:45.888751 28585 caffe.cpp:501]      pool1	forward: 35.3297 ms.
I1017 11:21:45.888756 28585 caffe.cpp:505]      pool1	backward: 42.1892 ms.
I1017 11:21:45.888761 28585 caffe.cpp:501]      conv2	forward: 75.7541 ms.
I1017 11:21:45.888767 28585 caffe.cpp:505]      conv2	backward: 301.813 ms.
I1017 11:21:45.888772 28585 caffe.cpp:501]      relu2	forward: 3.7863 ms.
I1017 11:21:45.888777 28585 caffe.cpp:505]      relu2	backward: 11.7979 ms.
I1017 11:21:45.888782 28585 caffe.cpp:501]   dropout2	forward: 22.9901 ms.
I1017 11:21:45.888787 28585 caffe.cpp:505]   dropout2	backward: 13.8419 ms.
I1017 11:21:45.888792 28585 caffe.cpp:501]      pool2	forward: 8.474 ms.
I1017 11:21:45.888797 28585 caffe.cpp:505]      pool2	backward: 10.0555 ms.
I1017 11:21:45.888802 28585 caffe.cpp:501]      conv3	forward: 15.9908 ms.
I1017 11:21:45.888806 28585 caffe.cpp:505]      conv3	backward: 39.228 ms.
I1017 11:21:45.888811 28585 caffe.cpp:501]      relu3	forward: 0.3163 ms.
I1017 11:21:45.888815 28585 caffe.cpp:505]      relu3	backward: 2.2123 ms.
I1017 11:21:45.888820 28585 caffe.cpp:501]   dropout3	forward: 4.0379 ms.
I1017 11:21:45.888825 28585 caffe.cpp:505]   dropout3	backward: 3.2606 ms.
I1017 11:21:45.888829 28585 caffe.cpp:501]      pool3	forward: 2.1815 ms.
I1017 11:21:45.888834 28585 caffe.cpp:505]      pool3	backward: 1.6241 ms.
I1017 11:21:45.888839 28585 caffe.cpp:501]      conv4	forward: 2.8139 ms.
I1017 11:21:45.888844 28585 caffe.cpp:505]      conv4	backward: 7.4301 ms.
I1017 11:21:45.888849 28585 caffe.cpp:501]      relu4	forward: 0.0243 ms.
I1017 11:21:45.888854 28585 caffe.cpp:505]      relu4	backward: 0.1887 ms.
I1017 11:21:45.888857 28585 caffe.cpp:501]   dropout4	forward: 0.4642 ms.
I1017 11:21:45.888862 28585 caffe.cpp:505]   dropout4	backward: 0.5313 ms.
I1017 11:21:45.888867 28585 caffe.cpp:501]      pool4	forward: 0.4438 ms.
I1017 11:21:45.888872 28585 caffe.cpp:505]      pool4	backward: 0.3019 ms.
I1017 11:21:45.888877 28585 caffe.cpp:501]        fc1	forward: 0.9858 ms.
I1017 11:21:45.888881 28585 caffe.cpp:505]        fc1	backward: 7.6792 ms.
I1017 11:21:45.888886 28585 caffe.cpp:501]   dropout5	forward: 0.0427 ms.
I1017 11:21:45.888890 28585 caffe.cpp:505]   dropout5	backward: 0.0188 ms.
I1017 11:21:45.888895 28585 caffe.cpp:501]        fc2	forward: 0.0349 ms.
I1017 11:21:45.888900 28585 caffe.cpp:505]        fc2	backward: 0.0563 ms.
I1017 11:21:45.888905 28585 caffe.cpp:501]       loss	forward: 0.114 ms.
I1017 11:21:45.888909 28585 caffe.cpp:505]       loss	backward: 0.0056 ms.
I1017 11:21:45.888914 28585 caffe.cpp:511] Average Forward pass: 382.477 ms.
I1017 11:21:45.888919 28585 caffe.cpp:514] Average Backward pass: 581.614 ms.
I1017 11:21:45.888936 28585 caffe.cpp:516] Average Forward-Backward: 964.1 ms.
I1017 11:21:45.888942 28585 caffe.cpp:519] Total Time: 9641 ms.
I1017 11:21:45.888947 28585 caffe.cpp:520] *** Benchmark ends ***

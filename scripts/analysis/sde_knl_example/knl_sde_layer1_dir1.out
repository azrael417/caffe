sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer1_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=1 -prof_forward_direction=1
I1031 11:09:12.769083 131275 caffe.cpp:444] Use CPU.
I1031 11:09:31.443907 131275 cpu_info.cpp:452] Processor speed [MHz]: 1300
I1031 11:09:31.506559 131275 cpu_info.cpp:455] Total number of sockets: 1
I1031 11:09:31.519522 131275 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 11:09:31.532027 131275 cpu_info.cpp:461] Total number of processors: 256
I1031 11:09:31.550143 131275 cpu_info.cpp:464] GPU is used: no
I1031 11:09:31.560012 131275 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 11:09:31.569705 131275 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 11:09:31.582829 131275 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 11:09:40.988529 131275 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 11:09:41.703269 131275 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 11:09:44.223995 131275 layer_factory.hpp:114] Creating layer data
I1031 11:09:44.387361 131275 net.cpp:160] Creating Layer data
I1031 11:09:44.440443 131275 net.cpp:570] data -> data
I1031 11:09:44.958973 131275 net.cpp:570] data -> label
I1031 11:09:52.765288 131275 net.cpp:210] Setting up data
I1031 11:09:52.852716 131275 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 11:09:52.964462 131275 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 11:09:52.972198 131275 net.cpp:225] Memory required for data: 184516
I1031 11:09:53.056843 131275 layer_factory.hpp:114] Creating layer conv1
I1031 11:09:53.423991 131275 net.cpp:160] Creating Layer conv1
I1031 11:09:53.479737 131275 net.cpp:596] conv1 <- data
I1031 11:09:53.612640 131275 net.cpp:570] conv1 -> conv1
I1031 11:10:31.762493 131275 net.cpp:210] Setting up conv1
I1031 11:10:31.832815 131275 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:10:31.839226 131275 net.cpp:225] Memory required for data: 7805124
I1031 11:10:32.177409 131275 layer_factory.hpp:114] Creating layer relu1
I1031 11:10:32.327021 131275 net.cpp:160] Creating Layer relu1
I1031 11:10:32.332507 131275 net.cpp:596] relu1 <- conv1
I1031 11:10:32.368980 131275 net.cpp:557] relu1 -> conv1 (in-place)
I1031 11:10:32.598450 131275 net.cpp:210] Setting up relu1
I1031 11:10:32.601867 131275 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:10:32.602216 131275 net.cpp:225] Memory required for data: 15425732
I1031 11:10:32.602468 131275 layer_factory.hpp:114] Creating layer dropout1
I1031 11:10:32.635680 131275 net.cpp:160] Creating Layer dropout1
I1031 11:10:32.636020 131275 net.cpp:596] dropout1 <- conv1
I1031 11:10:32.638903 131275 net.cpp:570] dropout1 -> drop1
I1031 11:10:32.754585 131275 net.cpp:210] Setting up dropout1
I1031 11:10:32.768548 131275 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:10:32.768956 131275 net.cpp:225] Memory required for data: 23046340
I1031 11:10:32.769302 131275 layer_factory.hpp:114] Creating layer pool1
I1031 11:10:32.881463 131275 net.cpp:160] Creating Layer pool1
I1031 11:10:32.881909 131275 net.cpp:596] pool1 <- drop1
I1031 11:10:32.882227 131275 net.cpp:570] pool1 -> pool1
I1031 11:10:33.310176 131275 net.cpp:210] Setting up pool1
I1031 11:10:33.319193 131275 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 11:10:33.319571 131275 net.cpp:225] Memory required for data: 24951492
I1031 11:10:33.319869 131275 layer_factory.hpp:114] Creating layer conv2
I1031 11:10:33.383970 131275 net.cpp:160] Creating Layer conv2
I1031 11:10:33.388548 131275 net.cpp:596] conv2 <- pool1
I1031 11:10:33.404461 131275 net.cpp:570] conv2 -> conv2
I1031 11:10:40.466708 131275 net.cpp:210] Setting up conv2
I1031 11:10:40.467160 131275 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:10:40.473016 131275 net.cpp:225] Memory required for data: 26733764
I1031 11:10:40.529722 131275 layer_factory.hpp:114] Creating layer relu2
I1031 11:10:40.530241 131275 net.cpp:160] Creating Layer relu2
I1031 11:10:40.530642 131275 net.cpp:596] relu2 <- conv2
I1031 11:10:40.530995 131275 net.cpp:557] relu2 -> conv2 (in-place)
I1031 11:10:40.531703 131275 net.cpp:210] Setting up relu2
I1031 11:10:40.531994 131275 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:10:40.532240 131275 net.cpp:225] Memory required for data: 28516036
I1031 11:10:40.532443 131275 layer_factory.hpp:114] Creating layer dropout2
I1031 11:10:40.532693 131275 net.cpp:160] Creating Layer dropout2
I1031 11:10:40.532893 131275 net.cpp:596] dropout2 <- conv2
I1031 11:10:40.533123 131275 net.cpp:570] dropout2 -> drop2
I1031 11:10:40.533430 131275 net.cpp:210] Setting up dropout2
I1031 11:10:40.533643 131275 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:10:40.533905 131275 net.cpp:225] Memory required for data: 30298308
I1031 11:10:40.534113 131275 layer_factory.hpp:114] Creating layer pool2
I1031 11:10:40.534564 131275 net.cpp:160] Creating Layer pool2
I1031 11:10:40.534873 131275 net.cpp:596] pool2 <- drop2
I1031 11:10:40.535145 131275 net.cpp:570] pool2 -> pool2
I1031 11:10:40.535615 131275 net.cpp:210] Setting up pool2
I1031 11:10:40.535883 131275 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 11:10:40.536134 131275 net.cpp:225] Memory required for data: 30759108
I1031 11:10:40.536339 131275 layer_factory.hpp:114] Creating layer conv3
I1031 11:10:40.536700 131275 net.cpp:160] Creating Layer conv3
I1031 11:10:40.536932 131275 net.cpp:596] conv3 <- pool2
I1031 11:10:40.537184 131275 net.cpp:570] conv3 -> conv3
I1031 11:10:41.119392 131275 net.cpp:210] Setting up conv3
I1031 11:10:41.121994 131275 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:10:41.122426 131275 net.cpp:225] Memory required for data: 31160516
I1031 11:10:41.131031 131275 layer_factory.hpp:114] Creating layer relu3
I1031 11:10:41.131510 131275 net.cpp:160] Creating Layer relu3
I1031 11:10:41.131880 131275 net.cpp:596] relu3 <- conv3
I1031 11:10:41.132197 131275 net.cpp:557] relu3 -> conv3 (in-place)
I1031 11:10:41.132858 131275 net.cpp:210] Setting up relu3
I1031 11:10:41.133178 131275 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:10:41.133443 131275 net.cpp:225] Memory required for data: 31561924
I1031 11:10:41.133651 131275 layer_factory.hpp:114] Creating layer dropout3
I1031 11:10:41.133914 131275 net.cpp:160] Creating Layer dropout3
I1031 11:10:41.134145 131275 net.cpp:596] dropout3 <- conv3
I1031 11:10:41.134435 131275 net.cpp:570] dropout3 -> drop3
I1031 11:10:41.134766 131275 net.cpp:210] Setting up dropout3
I1031 11:10:41.135032 131275 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:10:41.135304 131275 net.cpp:225] Memory required for data: 31963332
I1031 11:10:41.135664 131275 layer_factory.hpp:114] Creating layer pool3
I1031 11:10:41.136029 131275 net.cpp:160] Creating Layer pool3
I1031 11:10:41.136255 131275 net.cpp:596] pool3 <- drop3
I1031 11:10:41.136513 131275 net.cpp:570] pool3 -> pool3
I1031 11:10:41.136950 131275 net.cpp:210] Setting up pool3
I1031 11:10:41.137224 131275 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 11:10:41.137459 131275 net.cpp:225] Memory required for data: 32063684
I1031 11:10:41.137665 131275 layer_factory.hpp:114] Creating layer conv4
I1031 11:10:41.138010 131275 net.cpp:160] Creating Layer conv4
I1031 11:10:41.138249 131275 net.cpp:596] conv4 <- pool3
I1031 11:10:41.138550 131275 net.cpp:570] conv4 -> conv4
I1031 11:10:41.452074 131275 net.cpp:210] Setting up conv4
I1031 11:10:41.452436 131275 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:10:41.452903 131275 net.cpp:225] Memory required for data: 32137412
I1031 11:10:41.453306 131275 layer_factory.hpp:114] Creating layer relu4
I1031 11:10:41.453654 131275 net.cpp:160] Creating Layer relu4
I1031 11:10:41.453913 131275 net.cpp:596] relu4 <- conv4
I1031 11:10:41.454176 131275 net.cpp:557] relu4 -> conv4 (in-place)
I1031 11:10:41.454725 131275 net.cpp:210] Setting up relu4
I1031 11:10:41.455036 131275 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:10:41.455301 131275 net.cpp:225] Memory required for data: 32211140
I1031 11:10:41.455509 131275 layer_factory.hpp:114] Creating layer dropout4
I1031 11:10:41.455780 131275 net.cpp:160] Creating Layer dropout4
I1031 11:10:41.456008 131275 net.cpp:596] dropout4 <- conv4
I1031 11:10:41.456265 131275 net.cpp:570] dropout4 -> drop4
I1031 11:10:41.456609 131275 net.cpp:210] Setting up dropout4
I1031 11:10:41.456837 131275 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:10:41.457069 131275 net.cpp:225] Memory required for data: 32284868
I1031 11:10:41.457264 131275 layer_factory.hpp:114] Creating layer pool4
I1031 11:10:41.457563 131275 net.cpp:160] Creating Layer pool4
I1031 11:10:41.457787 131275 net.cpp:596] pool4 <- drop4
I1031 11:10:41.458019 131275 net.cpp:570] pool4 -> pool4
I1031 11:10:41.471534 131275 net.cpp:210] Setting up pool4
I1031 11:10:41.471902 131275 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 11:10:41.474352 131275 net.cpp:225] Memory required for data: 32303300
I1031 11:10:41.474622 131275 layer_factory.hpp:114] Creating layer fc1
I1031 11:10:41.535945 131275 net.cpp:160] Creating Layer fc1
I1031 11:10:41.536274 131275 net.cpp:596] fc1 <- pool4
I1031 11:10:41.536696 131275 net.cpp:570] fc1 -> fc1
I1031 11:10:42.366698 131275 net.cpp:210] Setting up fc1
I1031 11:10:42.367692 131275 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:10:42.368119 131275 net.cpp:225] Memory required for data: 32307396
I1031 11:10:42.372905 131275 layer_factory.hpp:114] Creating layer dropout5
I1031 11:10:42.373301 131275 net.cpp:160] Creating Layer dropout5
I1031 11:10:42.373530 131275 net.cpp:596] dropout5 <- fc1
I1031 11:10:42.373766 131275 net.cpp:570] dropout5 -> drop5
I1031 11:10:42.374115 131275 net.cpp:210] Setting up dropout5
I1031 11:10:42.374424 131275 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:10:42.374668 131275 net.cpp:225] Memory required for data: 32311492
I1031 11:10:42.374864 131275 layer_factory.hpp:114] Creating layer fc2
I1031 11:10:42.375136 131275 net.cpp:160] Creating Layer fc2
I1031 11:10:42.375516 131275 net.cpp:596] fc2 <- drop5
I1031 11:10:42.375780 131275 net.cpp:570] fc2 -> fc2
I1031 11:10:42.384040 131275 net.cpp:210] Setting up fc2
I1031 11:10:42.385277 131275 net.cpp:217] Top shape: 1 2 (2)
I1031 11:10:42.387575 131275 net.cpp:225] Memory required for data: 32311500
I1031 11:10:42.387905 131275 layer_factory.hpp:114] Creating layer loss
I1031 11:10:42.414399 131275 net.cpp:160] Creating Layer loss
I1031 11:10:42.414734 131275 net.cpp:596] loss <- fc2
I1031 11:10:42.415742 131275 net.cpp:596] loss <- label
I1031 11:10:42.466523 131275 net.cpp:570] loss -> (automatic)
I1031 11:10:42.502198 131275 layer_factory.hpp:114] Creating layer loss
I1031 11:10:42.836315 131275 net.cpp:210] Setting up loss
I1031 11:10:42.839238 131275 net.cpp:217] Top shape: (1)
I1031 11:10:42.845561 131275 net.cpp:220]     with loss weight 1
I1031 11:10:42.978478 131275 net.cpp:225] Memory required for data: 32311504
I1031 11:10:43.022455 131275 net.cpp:287] loss needs backward computation.
I1031 11:10:43.118484 131275 net.cpp:287] fc2 needs backward computation.
I1031 11:10:43.126065 131275 net.cpp:287] dropout5 needs backward computation.
I1031 11:10:43.128406 131275 net.cpp:287] fc1 needs backward computation.
I1031 11:10:43.129231 131275 net.cpp:287] pool4 needs backward computation.
I1031 11:10:43.129515 131275 net.cpp:287] dropout4 needs backward computation.
I1031 11:10:43.129745 131275 net.cpp:287] relu4 needs backward computation.
I1031 11:10:43.139830 131275 net.cpp:287] conv4 needs backward computation.
I1031 11:10:43.157699 131275 net.cpp:287] pool3 needs backward computation.
I1031 11:10:43.172037 131275 net.cpp:287] dropout3 needs backward computation.
I1031 11:10:43.177033 131275 net.cpp:287] relu3 needs backward computation.
I1031 11:10:43.177366 131275 net.cpp:287] conv3 needs backward computation.
I1031 11:10:43.177675 131275 net.cpp:287] pool2 needs backward computation.
I1031 11:10:43.177907 131275 net.cpp:287] dropout2 needs backward computation.
I1031 11:10:43.178131 131275 net.cpp:287] relu2 needs backward computation.
I1031 11:10:43.178349 131275 net.cpp:287] conv2 needs backward computation.
I1031 11:10:43.178550 131275 net.cpp:287] pool1 needs backward computation.
I1031 11:10:43.178738 131275 net.cpp:287] dropout1 needs backward computation.
I1031 11:10:43.178926 131275 net.cpp:287] relu1 needs backward computation.
I1031 11:10:43.179111 131275 net.cpp:287] conv1 needs backward computation.
I1031 11:10:43.199873 131275 net.cpp:289] data does not need backward computation.
I1031 11:10:43.260293 131275 net.cpp:345] Network initialization done.
I1031 11:10:43.443505 131275 caffe.cpp:452] Performing Forward
I1031 11:10:55.570294 131275 caffe.cpp:457] Initial loss: 87.3365
I1031 11:10:55.698735 131275 caffe.cpp:459] Performing Backward
I1031 11:10:58.768939 131275 caffe.cpp:468] *** Benchmark begins ***
I1031 11:10:58.783535 131275 caffe.cpp:469] Testing for 1 iterations.
I1031 11:10:58.947918 131275 caffe.cpp:482] Profiling Layer: conv1 forward
I1031 11:11:00.516108 131275 caffe.cpp:512] Iteration: 1 forward-backward time: 1561 ms.
I1031 11:11:00.622506 131275 caffe.cpp:519] Average time per layer: 
I1031 11:11:00.641023 131275 caffe.cpp:522]       data	forward: 55.326 ms.
I1031 11:11:00.704289 131275 caffe.cpp:526]       data	backward: 5.869 ms.
I1031 11:11:00.747575 131275 caffe.cpp:522]      conv1	forward: 74.613 ms.
I1031 11:11:00.757732 131275 caffe.cpp:526]      conv1	backward: 32.52 ms.
I1031 11:11:00.770261 131275 caffe.cpp:522]      relu1	forward: 13.496 ms.
I1031 11:11:00.778767 131275 caffe.cpp:526]      relu1	backward: 63.51 ms.
I1031 11:11:00.793699 131275 caffe.cpp:522]   dropout1	forward: 85.132 ms.
I1031 11:11:00.795668 131275 caffe.cpp:526]   dropout1	backward: 56.489 ms.
I1031 11:11:00.795920 131275 caffe.cpp:522]      pool1	forward: 132.129 ms.
I1031 11:11:00.799165 131275 caffe.cpp:526]      pool1	backward: 108.275 ms.
I1031 11:11:00.799437 131275 caffe.cpp:522]      conv2	forward: 47.014 ms.
I1031 11:11:00.799645 131275 caffe.cpp:526]      conv2	backward: 14.096 ms.
I1031 11:11:00.799850 131275 caffe.cpp:522]      relu2	forward: 14.534 ms.
I1031 11:11:00.800207 131275 caffe.cpp:526]      relu2	backward: 6.818 ms.
I1031 11:11:00.800456 131275 caffe.cpp:522]   dropout2	forward: 57.434 ms.
I1031 11:11:00.800683 131275 caffe.cpp:526]   dropout2	backward: 7.763 ms.
I1031 11:11:00.801035 131275 caffe.cpp:522]      pool2	forward: 34.809 ms.
I1031 11:11:00.801328 131275 caffe.cpp:526]      pool2	backward: 25.469 ms.
I1031 11:11:00.801538 131275 caffe.cpp:522]      conv3	forward: 34.456 ms.
I1031 11:11:00.801743 131275 caffe.cpp:526]      conv3	backward: 5.298 ms.
I1031 11:11:00.801940 131275 caffe.cpp:522]      relu3	forward: 25.407 ms.
I1031 11:11:00.802144 131275 caffe.cpp:526]      relu3	backward: 1.366 ms.
I1031 11:11:00.802381 131275 caffe.cpp:522]   dropout3	forward: 51.893 ms.
I1031 11:11:00.802589 131275 caffe.cpp:526]   dropout3	backward: 1.897 ms.
I1031 11:11:00.802788 131275 caffe.cpp:522]      pool3	forward: 15.703 ms.
I1031 11:11:00.802990 131275 caffe.cpp:526]      pool3	backward: 5.908 ms.
I1031 11:11:00.803189 131275 caffe.cpp:522]      conv4	forward: 26.449 ms.
I1031 11:11:00.803390 131275 caffe.cpp:526]      conv4	backward: 44.804 ms.
I1031 11:11:00.803592 131275 caffe.cpp:522]      relu4	forward: 13.766 ms.
I1031 11:11:00.803838 131275 caffe.cpp:526]      relu4	backward: 46.326 ms.
I1031 11:11:00.804102 131275 caffe.cpp:522]   dropout4	forward: 58.321 ms.
I1031 11:11:00.804432 131275 caffe.cpp:526]   dropout4	backward: 54.218 ms.
I1031 11:11:00.804692 131275 caffe.cpp:522]      pool4	forward: 12.895 ms.
I1031 11:11:00.804898 131275 caffe.cpp:526]      pool4	backward: 27.897 ms.
I1031 11:11:00.805100 131275 caffe.cpp:522]        fc1	forward: 16.467 ms.
I1031 11:11:00.805304 131275 caffe.cpp:526]        fc1	backward: 46.709 ms.
I1031 11:11:00.805506 131275 caffe.cpp:522]   dropout5	forward: 13.626 ms.
I1031 11:11:00.805708 131275 caffe.cpp:526]   dropout5	backward: 14.367 ms.
I1031 11:11:00.805912 131275 caffe.cpp:522]        fc2	forward: 0.117 ms.
I1031 11:11:00.806813 131275 caffe.cpp:526]        fc2	backward: 0.217 ms.
I1031 11:11:00.807052 131275 caffe.cpp:522]       loss	forward: 66.388 ms.
I1031 11:11:00.807263 131275 caffe.cpp:526]       loss	backward: 33.319 ms.
I1031 11:11:00.813383 131275 caffe.cpp:532] Average Forward pass: 912.246 ms.
I1031 11:11:00.827469 131275 caffe.cpp:535] Average Backward pass: 616.263 ms.
I1031 11:11:00.839429 131275 caffe.cpp:537] Average Forward-Backward: 1978 ms.
I1031 11:11:00.857190 131275 caffe.cpp:540] Total Time: 1978 ms.
I1031 11:11:00.870594 131275 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 6429888
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 102878209
--->Total double-precision FLOPs = 0
--->Total FLOPs = 102878209
mem-read-1 = 70391
mem-read-2 = 127
mem-read-4 = 3963322
mem-read-8 = 1040960
mem-read-16 = 1
mem-read-32 = 1490
mem-read-64 = 3342471
mem-write-1 = 166
mem-write-2 = 51
mem-write-4 = 123692
mem-write-8 = 141031
mem-write-16 = 1
mem-write-32 = 5954
mem-write-64 = 239080
--->Total Bytes read = 238217453
--->Total Bytes written = 17114948
--->Total Bytes = 255332401

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer11_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=11 -prof_forward_direction=0
I1031 14:45:04.038323 100944 caffe.cpp:444] Use CPU.
I1031 14:45:22.113493 100944 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:45:22.175186 100944 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:45:22.187608 100944 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:45:22.199584 100944 cpu_info.cpp:461] Total number of processors: 256
I1031 14:45:22.217443 100944 cpu_info.cpp:464] GPU is used: no
I1031 14:45:22.226850 100944 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:45:22.235872 100944 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:45:22.248520 100944 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:45:31.403273 100944 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:45:32.096184 100944 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:45:34.528348 100944 layer_factory.hpp:114] Creating layer data
I1031 14:45:34.688205 100944 net.cpp:160] Creating Layer data
I1031 14:45:34.739194 100944 net.cpp:570] data -> data
I1031 14:45:35.232197 100944 net.cpp:570] data -> label
I1031 14:45:42.789419 100944 net.cpp:210] Setting up data
I1031 14:45:42.873978 100944 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:45:42.980371 100944 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:45:42.987725 100944 net.cpp:225] Memory required for data: 184516
I1031 14:45:43.066563 100944 layer_factory.hpp:114] Creating layer conv1
I1031 14:45:43.422183 100944 net.cpp:160] Creating Layer conv1
I1031 14:45:43.475546 100944 net.cpp:596] conv1 <- data
I1031 14:45:43.605568 100944 net.cpp:570] conv1 -> conv1
I1031 14:46:20.995733 100944 net.cpp:210] Setting up conv1
I1031 14:46:21.078783 100944 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:46:21.087338 100944 net.cpp:225] Memory required for data: 7805124
I1031 14:46:21.403771 100944 layer_factory.hpp:114] Creating layer relu1
I1031 14:46:21.535866 100944 net.cpp:160] Creating Layer relu1
I1031 14:46:21.540930 100944 net.cpp:596] relu1 <- conv1
I1031 14:46:21.575779 100944 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:46:21.792666 100944 net.cpp:210] Setting up relu1
I1031 14:46:21.795341 100944 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:46:21.795758 100944 net.cpp:225] Memory required for data: 15425732
I1031 14:46:21.795980 100944 layer_factory.hpp:114] Creating layer dropout1
I1031 14:46:21.828763 100944 net.cpp:160] Creating Layer dropout1
I1031 14:46:21.829125 100944 net.cpp:596] dropout1 <- conv1
I1031 14:46:21.831889 100944 net.cpp:570] dropout1 -> drop1
I1031 14:46:21.959684 100944 net.cpp:210] Setting up dropout1
I1031 14:46:21.975075 100944 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:46:21.975586 100944 net.cpp:225] Memory required for data: 23046340
I1031 14:46:21.975989 100944 layer_factory.hpp:114] Creating layer pool1
I1031 14:46:22.080598 100944 net.cpp:160] Creating Layer pool1
I1031 14:46:22.081465 100944 net.cpp:596] pool1 <- drop1
I1031 14:46:22.081893 100944 net.cpp:570] pool1 -> pool1
I1031 14:46:22.500810 100944 net.cpp:210] Setting up pool1
I1031 14:46:22.509887 100944 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:46:22.510272 100944 net.cpp:225] Memory required for data: 24951492
I1031 14:46:22.510633 100944 layer_factory.hpp:114] Creating layer conv2
I1031 14:46:22.576185 100944 net.cpp:160] Creating Layer conv2
I1031 14:46:22.580875 100944 net.cpp:596] conv2 <- pool1
I1031 14:46:22.597177 100944 net.cpp:570] conv2 -> conv2
I1031 14:46:29.468035 100944 net.cpp:210] Setting up conv2
I1031 14:46:29.476343 100944 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:46:29.485529 100944 net.cpp:225] Memory required for data: 26733764
I1031 14:46:29.561502 100944 layer_factory.hpp:114] Creating layer relu2
I1031 14:46:29.574226 100944 net.cpp:160] Creating Layer relu2
I1031 14:46:29.582990 100944 net.cpp:596] relu2 <- conv2
I1031 14:46:29.585482 100944 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:46:29.594466 100944 net.cpp:210] Setting up relu2
I1031 14:46:29.605355 100944 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:46:29.608150 100944 net.cpp:225] Memory required for data: 28516036
I1031 14:46:29.617285 100944 layer_factory.hpp:114] Creating layer dropout2
I1031 14:46:29.617776 100944 net.cpp:160] Creating Layer dropout2
I1031 14:46:29.627815 100944 net.cpp:596] dropout2 <- conv2
I1031 14:46:29.638701 100944 net.cpp:570] dropout2 -> drop2
I1031 14:46:29.647110 100944 net.cpp:210] Setting up dropout2
I1031 14:46:29.651638 100944 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:46:29.653693 100944 net.cpp:225] Memory required for data: 30298308
I1031 14:46:29.658928 100944 layer_factory.hpp:114] Creating layer pool2
I1031 14:46:29.663486 100944 net.cpp:160] Creating Layer pool2
I1031 14:46:29.666072 100944 net.cpp:596] pool2 <- drop2
I1031 14:46:29.676553 100944 net.cpp:570] pool2 -> pool2
I1031 14:46:29.682677 100944 net.cpp:210] Setting up pool2
I1031 14:46:29.685691 100944 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:46:29.695708 100944 net.cpp:225] Memory required for data: 30759108
I1031 14:46:29.696142 100944 layer_factory.hpp:114] Creating layer conv3
I1031 14:46:29.710805 100944 net.cpp:160] Creating Layer conv3
I1031 14:46:29.723326 100944 net.cpp:596] conv3 <- pool2
I1031 14:46:29.723889 100944 net.cpp:570] conv3 -> conv3
I1031 14:46:30.318856 100944 net.cpp:210] Setting up conv3
I1031 14:46:30.327873 100944 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:46:30.333664 100944 net.cpp:225] Memory required for data: 31160516
I1031 14:46:30.352665 100944 layer_factory.hpp:114] Creating layer relu3
I1031 14:46:30.354588 100944 net.cpp:160] Creating Layer relu3
I1031 14:46:30.371101 100944 net.cpp:596] relu3 <- conv3
I1031 14:46:30.379525 100944 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:46:30.390184 100944 net.cpp:210] Setting up relu3
I1031 14:46:30.398056 100944 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:46:30.404440 100944 net.cpp:225] Memory required for data: 31561924
I1031 14:46:30.410384 100944 layer_factory.hpp:114] Creating layer dropout3
I1031 14:46:30.417353 100944 net.cpp:160] Creating Layer dropout3
I1031 14:46:30.422998 100944 net.cpp:596] dropout3 <- conv3
I1031 14:46:30.423497 100944 net.cpp:570] dropout3 -> drop3
I1031 14:46:30.423894 100944 net.cpp:210] Setting up dropout3
I1031 14:46:30.428344 100944 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:46:30.430579 100944 net.cpp:225] Memory required for data: 31963332
I1031 14:46:30.435348 100944 layer_factory.hpp:114] Creating layer pool3
I1031 14:46:30.437659 100944 net.cpp:160] Creating Layer pool3
I1031 14:46:30.437978 100944 net.cpp:596] pool3 <- drop3
I1031 14:46:30.438256 100944 net.cpp:570] pool3 -> pool3
I1031 14:46:30.447017 100944 net.cpp:210] Setting up pool3
I1031 14:46:30.451071 100944 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:46:30.453268 100944 net.cpp:225] Memory required for data: 32063684
I1031 14:46:30.455760 100944 layer_factory.hpp:114] Creating layer conv4
I1031 14:46:30.468601 100944 net.cpp:160] Creating Layer conv4
I1031 14:46:30.479538 100944 net.cpp:596] conv4 <- pool3
I1031 14:46:30.482287 100944 net.cpp:570] conv4 -> conv4
I1031 14:46:30.851214 100944 net.cpp:210] Setting up conv4
I1031 14:46:30.859671 100944 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:46:30.861876 100944 net.cpp:225] Memory required for data: 32137412
I1031 14:46:30.866756 100944 layer_factory.hpp:114] Creating layer relu4
I1031 14:46:30.867137 100944 net.cpp:160] Creating Layer relu4
I1031 14:46:30.871702 100944 net.cpp:596] relu4 <- conv4
I1031 14:46:30.878149 100944 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:46:30.880825 100944 net.cpp:210] Setting up relu4
I1031 14:46:30.889456 100944 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:46:30.900096 100944 net.cpp:225] Memory required for data: 32211140
I1031 14:46:30.900533 100944 layer_factory.hpp:114] Creating layer dropout4
I1031 14:46:30.910995 100944 net.cpp:160] Creating Layer dropout4
I1031 14:46:30.921193 100944 net.cpp:596] dropout4 <- conv4
I1031 14:46:30.929770 100944 net.cpp:570] dropout4 -> drop4
I1031 14:46:30.930279 100944 net.cpp:210] Setting up dropout4
I1031 14:46:30.934487 100944 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:46:30.942746 100944 net.cpp:225] Memory required for data: 32284868
I1031 14:46:30.943181 100944 layer_factory.hpp:114] Creating layer pool4
I1031 14:46:30.949501 100944 net.cpp:160] Creating Layer pool4
I1031 14:46:30.949921 100944 net.cpp:596] pool4 <- drop4
I1031 14:46:30.954268 100944 net.cpp:570] pool4 -> pool4
I1031 14:46:30.973201 100944 net.cpp:210] Setting up pool4
I1031 14:46:30.981672 100944 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:46:30.986232 100944 net.cpp:225] Memory required for data: 32303300
I1031 14:46:30.994688 100944 layer_factory.hpp:114] Creating layer fc1
I1031 14:46:31.066777 100944 net.cpp:160] Creating Layer fc1
I1031 14:46:31.067580 100944 net.cpp:596] fc1 <- pool4
I1031 14:46:31.068048 100944 net.cpp:570] fc1 -> fc1
I1031 14:46:31.943053 100944 net.cpp:210] Setting up fc1
I1031 14:46:31.947679 100944 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:46:31.952342 100944 net.cpp:225] Memory required for data: 32307396
I1031 14:46:31.959230 100944 layer_factory.hpp:114] Creating layer dropout5
I1031 14:46:31.967221 100944 net.cpp:160] Creating Layer dropout5
I1031 14:46:31.970118 100944 net.cpp:596] dropout5 <- fc1
I1031 14:46:31.976537 100944 net.cpp:570] dropout5 -> drop5
I1031 14:46:31.983220 100944 net.cpp:210] Setting up dropout5
I1031 14:46:31.989684 100944 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:46:31.991701 100944 net.cpp:225] Memory required for data: 32311492
I1031 14:46:32.001934 100944 layer_factory.hpp:114] Creating layer fc2
I1031 14:46:32.011255 100944 net.cpp:160] Creating Layer fc2
I1031 14:46:32.016446 100944 net.cpp:596] fc2 <- drop5
I1031 14:46:32.027081 100944 net.cpp:570] fc2 -> fc2
I1031 14:46:32.063577 100944 net.cpp:210] Setting up fc2
I1031 14:46:32.072885 100944 net.cpp:217] Top shape: 1 2 (2)
I1031 14:46:32.085247 100944 net.cpp:225] Memory required for data: 32311500
I1031 14:46:32.091814 100944 layer_factory.hpp:114] Creating layer loss
I1031 14:46:32.129360 100944 net.cpp:160] Creating Layer loss
I1031 14:46:32.134168 100944 net.cpp:596] loss <- fc2
I1031 14:46:32.137451 100944 net.cpp:596] loss <- label
I1031 14:46:32.203773 100944 net.cpp:570] loss -> (automatic)
I1031 14:46:32.261092 100944 layer_factory.hpp:114] Creating layer loss
I1031 14:46:32.702778 100944 net.cpp:210] Setting up loss
I1031 14:46:32.712121 100944 net.cpp:217] Top shape: (1)
I1031 14:46:32.734495 100944 net.cpp:220]     with loss weight 1
I1031 14:46:32.869282 100944 net.cpp:225] Memory required for data: 32311504
I1031 14:46:32.928509 100944 net.cpp:287] loss needs backward computation.
I1031 14:46:33.031749 100944 net.cpp:287] fc2 needs backward computation.
I1031 14:46:33.050684 100944 net.cpp:287] dropout5 needs backward computation.
I1031 14:46:33.058754 100944 net.cpp:287] fc1 needs backward computation.
I1031 14:46:33.068480 100944 net.cpp:287] pool4 needs backward computation.
I1031 14:46:33.075439 100944 net.cpp:287] dropout4 needs backward computation.
I1031 14:46:33.082240 100944 net.cpp:287] relu4 needs backward computation.
I1031 14:46:33.093863 100944 net.cpp:287] conv4 needs backward computation.
I1031 14:46:33.110780 100944 net.cpp:287] pool3 needs backward computation.
I1031 14:46:33.124737 100944 net.cpp:287] dropout3 needs backward computation.
I1031 14:46:33.129636 100944 net.cpp:287] relu3 needs backward computation.
I1031 14:46:33.129971 100944 net.cpp:287] conv3 needs backward computation.
I1031 14:46:33.130390 100944 net.cpp:287] pool2 needs backward computation.
I1031 14:46:33.130760 100944 net.cpp:287] dropout2 needs backward computation.
I1031 14:46:33.131003 100944 net.cpp:287] relu2 needs backward computation.
I1031 14:46:33.131202 100944 net.cpp:287] conv2 needs backward computation.
I1031 14:46:33.131443 100944 net.cpp:287] pool1 needs backward computation.
I1031 14:46:33.131647 100944 net.cpp:287] dropout1 needs backward computation.
I1031 14:46:33.131846 100944 net.cpp:287] relu1 needs backward computation.
I1031 14:46:33.132037 100944 net.cpp:287] conv1 needs backward computation.
I1031 14:46:33.152145 100944 net.cpp:289] data does not need backward computation.
I1031 14:46:33.209313 100944 net.cpp:345] Network initialization done.
I1031 14:46:33.396551 100944 caffe.cpp:452] Performing Forward
I1031 14:46:45.344120 100944 caffe.cpp:457] Initial loss: 87.3365
I1031 14:46:45.471972 100944 caffe.cpp:459] Performing Backward
I1031 14:46:48.931967 100944 caffe.cpp:468] *** Benchmark begins ***
I1031 14:46:48.947523 100944 caffe.cpp:469] Testing for 1 iterations.
I1031 14:46:49.107156 100944 caffe.cpp:485] Profiling Layer: dropout3 backward
I1031 14:46:50.473407 100944 caffe.cpp:512] Iteration: 1 forward-backward time: 1360 ms.
I1031 14:46:50.565024 100944 caffe.cpp:519] Average time per layer: 
I1031 14:46:50.581212 100944 caffe.cpp:522]       data	forward: 49.129 ms.
I1031 14:46:50.662356 100944 caffe.cpp:526]       data	backward: 9.92 ms.
I1031 14:46:50.688971 100944 caffe.cpp:522]      conv1	forward: 75.278 ms.
I1031 14:46:50.698011 100944 caffe.cpp:526]      conv1	backward: 29.022 ms.
I1031 14:46:50.700619 100944 caffe.cpp:522]      relu1	forward: 25.027 ms.
I1031 14:46:50.702911 100944 caffe.cpp:526]      relu1	backward: 54.602 ms.
I1031 14:46:50.705510 100944 caffe.cpp:522]   dropout1	forward: 90.517 ms.
I1031 14:46:50.713845 100944 caffe.cpp:526]   dropout1	backward: 57.901 ms.
I1031 14:46:50.722367 100944 caffe.cpp:522]      pool1	forward: 125.378 ms.
I1031 14:46:50.730425 100944 caffe.cpp:526]      pool1	backward: 132.345 ms.
I1031 14:46:50.738802 100944 caffe.cpp:522]      conv2	forward: 73.718 ms.
I1031 14:46:50.741817 100944 caffe.cpp:526]      conv2	backward: 75.273 ms.
I1031 14:46:50.750622 100944 caffe.cpp:522]      relu2	forward: 21.258 ms.
I1031 14:46:50.756844 100944 caffe.cpp:526]      relu2	backward: 31.997 ms.
I1031 14:46:50.761404 100944 caffe.cpp:522]   dropout2	forward: 8.318 ms.
I1031 14:46:50.766295 100944 caffe.cpp:526]   dropout2	backward: 40.703 ms.
I1031 14:46:50.770349 100944 caffe.cpp:522]      pool2	forward: 29.426 ms.
I1031 14:46:50.773679 100944 caffe.cpp:526]      pool2	backward: 66.103 ms.
I1031 14:46:50.774749 100944 caffe.cpp:522]      conv3	forward: 8.401 ms.
I1031 14:46:50.774982 100944 caffe.cpp:526]      conv3	backward: 84.776 ms.
I1031 14:46:50.775205 100944 caffe.cpp:522]      relu3	forward: 0.093 ms.
I1031 14:46:50.793970 100944 caffe.cpp:526]      relu3	backward: 30.417 ms.
I1031 14:46:50.794450 100944 caffe.cpp:522]   dropout3	forward: 2.139 ms.
I1031 14:46:50.794791 100944 caffe.cpp:526]   dropout3	backward: 13.087 ms.
I1031 14:46:50.795017 100944 caffe.cpp:522]      pool3	forward: 6.643 ms.
I1031 14:46:50.795228 100944 caffe.cpp:526]      pool3	backward: 5.866 ms.
I1031 14:46:50.795477 100944 caffe.cpp:522]      conv4	forward: 0.759 ms.
I1031 14:46:50.795689 100944 caffe.cpp:526]      conv4	backward: 12.293 ms.
I1031 14:46:50.795900 100944 caffe.cpp:522]      relu4	forward: 0.064 ms.
I1031 14:46:50.798858 100944 caffe.cpp:526]      relu4	backward: 5.583 ms.
I1031 14:46:50.799126 100944 caffe.cpp:522]   dropout4	forward: 0.516 ms.
I1031 14:46:50.799347 100944 caffe.cpp:526]   dropout4	backward: 12.71 ms.
I1031 14:46:50.799633 100944 caffe.cpp:522]      pool4	forward: 1.295 ms.
I1031 14:46:50.799842 100944 caffe.cpp:526]      pool4	backward: 1.143 ms.
I1031 14:46:50.800047 100944 caffe.cpp:522]        fc1	forward: 1.07 ms.
I1031 14:46:50.800289 100944 caffe.cpp:526]        fc1	backward: 11.6 ms.
I1031 14:46:50.800530 100944 caffe.cpp:522]   dropout5	forward: 0.173 ms.
I1031 14:46:50.800973 100944 caffe.cpp:526]   dropout5	backward: 0.064 ms.
I1031 14:46:50.801317 100944 caffe.cpp:522]        fc2	forward: 0.116 ms.
I1031 14:46:50.802199 100944 caffe.cpp:526]        fc2	backward: 0.206 ms.
I1031 14:46:50.802459 100944 caffe.cpp:522]       loss	forward: 33.037 ms.
I1031 14:46:50.802690 100944 caffe.cpp:526]       loss	backward: 34.792 ms.
I1031 14:46:50.808652 100944 caffe.cpp:532] Average Forward pass: 612.251 ms.
I1031 14:46:50.822358 100944 caffe.cpp:535] Average Backward pass: 720.333 ms.
I1031 14:46:50.834452 100944 caffe.cpp:537] Average Forward-Backward: 1811 ms.
I1031 14:46:50.850109 100944 caffe.cpp:540] Total Time: 1811 ms.
I1031 14:46:50.862974 100944 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 12544
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 200704
--->Total double-precision FLOPs = 0
--->Total FLOPs = 200704
mem-read-1 = 53860
mem-read-2 = 71
mem-read-4 = 439918
mem-read-8 = 644786
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 23937
mem-write-1 = 106
mem-write-2 = 34
mem-write-4 = 1264
mem-write-8 = 62896
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 13441
--->Total Bytes read = 8503962
--->Total Bytes written = 1368654
--->Total Bytes = 9872616

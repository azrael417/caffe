sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer15_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=15 -prof_forward_direction=1
I1031 12:59:47.743890 97134 caffe.cpp:444] Use CPU.
I1031 13:00:05.676482 97134 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 13:00:05.763643 97134 cpu_info.cpp:455] Total number of sockets: 1
I1031 13:00:05.776469 97134 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 13:00:05.788478 97134 cpu_info.cpp:461] Total number of processors: 256
I1031 13:00:05.805526 97134 cpu_info.cpp:464] GPU is used: no
I1031 13:00:05.814806 97134 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 13:00:05.823837 97134 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 13:00:05.836733 97134 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 13:00:14.969795 97134 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 13:00:15.650409 97134 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 13:00:18.169028 97134 layer_factory.hpp:114] Creating layer data
I1031 13:00:18.334173 97134 net.cpp:160] Creating Layer data
I1031 13:00:18.387444 97134 net.cpp:570] data -> data
I1031 13:00:18.915944 97134 net.cpp:570] data -> label
I1031 13:00:26.396193 97134 net.cpp:210] Setting up data
I1031 13:00:26.480182 97134 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 13:00:26.586573 97134 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 13:00:26.593914 97134 net.cpp:225] Memory required for data: 184516
I1031 13:00:26.672786 97134 layer_factory.hpp:114] Creating layer conv1
I1031 13:00:27.021975 97134 net.cpp:160] Creating Layer conv1
I1031 13:00:27.075564 97134 net.cpp:596] conv1 <- data
I1031 13:00:27.202342 97134 net.cpp:570] conv1 -> conv1
I1031 13:01:04.583268 97134 net.cpp:210] Setting up conv1
I1031 13:01:04.684129 97134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:01:04.690271 97134 net.cpp:225] Memory required for data: 7805124
I1031 13:01:05.040987 97134 layer_factory.hpp:114] Creating layer relu1
I1031 13:01:05.170999 97134 net.cpp:160] Creating Layer relu1
I1031 13:01:05.176148 97134 net.cpp:596] relu1 <- conv1
I1031 13:01:05.210880 97134 net.cpp:557] relu1 -> conv1 (in-place)
I1031 13:01:05.425597 97134 net.cpp:210] Setting up relu1
I1031 13:01:05.428267 97134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:01:05.428643 97134 net.cpp:225] Memory required for data: 15425732
I1031 13:01:05.428860 97134 layer_factory.hpp:114] Creating layer dropout1
I1031 13:01:05.462944 97134 net.cpp:160] Creating Layer dropout1
I1031 13:01:05.463744 97134 net.cpp:596] dropout1 <- conv1
I1031 13:01:05.466495 97134 net.cpp:570] dropout1 -> drop1
I1031 13:01:05.577915 97134 net.cpp:210] Setting up dropout1
I1031 13:01:05.591466 97134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:01:05.591876 97134 net.cpp:225] Memory required for data: 23046340
I1031 13:01:05.592226 97134 layer_factory.hpp:114] Creating layer pool1
I1031 13:01:05.693858 97134 net.cpp:160] Creating Layer pool1
I1031 13:01:05.698370 97134 net.cpp:596] pool1 <- drop1
I1031 13:01:05.698729 97134 net.cpp:570] pool1 -> pool1
I1031 13:01:06.115577 97134 net.cpp:210] Setting up pool1
I1031 13:01:06.120719 97134 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 13:01:06.121129 97134 net.cpp:225] Memory required for data: 24951492
I1031 13:01:06.121444 97134 layer_factory.hpp:114] Creating layer conv2
I1031 13:01:06.184046 97134 net.cpp:160] Creating Layer conv2
I1031 13:01:06.188437 97134 net.cpp:596] conv2 <- pool1
I1031 13:01:06.203824 97134 net.cpp:570] conv2 -> conv2
I1031 13:01:12.956945 97134 net.cpp:210] Setting up conv2
I1031 13:01:12.957429 97134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:01:12.971695 97134 net.cpp:225] Memory required for data: 26733764
I1031 13:01:13.045397 97134 layer_factory.hpp:114] Creating layer relu2
I1031 13:01:13.058434 97134 net.cpp:160] Creating Layer relu2
I1031 13:01:13.065304 97134 net.cpp:596] relu2 <- conv2
I1031 13:01:13.070992 97134 net.cpp:557] relu2 -> conv2 (in-place)
I1031 13:01:13.074563 97134 net.cpp:210] Setting up relu2
I1031 13:01:13.078872 97134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:01:13.085397 97134 net.cpp:225] Memory required for data: 28516036
I1031 13:01:13.093441 97134 layer_factory.hpp:114] Creating layer dropout2
I1031 13:01:13.100461 97134 net.cpp:160] Creating Layer dropout2
I1031 13:01:13.112965 97134 net.cpp:596] dropout2 <- conv2
I1031 13:01:13.119465 97134 net.cpp:570] dropout2 -> drop2
I1031 13:01:13.125267 97134 net.cpp:210] Setting up dropout2
I1031 13:01:13.129771 97134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:01:13.134637 97134 net.cpp:225] Memory required for data: 30298308
I1031 13:01:13.136819 97134 layer_factory.hpp:114] Creating layer pool2
I1031 13:01:13.145473 97134 net.cpp:160] Creating Layer pool2
I1031 13:01:13.147785 97134 net.cpp:596] pool2 <- drop2
I1031 13:01:13.153200 97134 net.cpp:570] pool2 -> pool2
I1031 13:01:13.160070 97134 net.cpp:210] Setting up pool2
I1031 13:01:13.164624 97134 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 13:01:13.174964 97134 net.cpp:225] Memory required for data: 30759108
I1031 13:01:13.176856 97134 layer_factory.hpp:114] Creating layer conv3
I1031 13:01:13.187973 97134 net.cpp:160] Creating Layer conv3
I1031 13:01:13.192365 97134 net.cpp:596] conv3 <- pool2
I1031 13:01:13.196797 97134 net.cpp:570] conv3 -> conv3
I1031 13:01:13.809350 97134 net.cpp:210] Setting up conv3
I1031 13:01:13.814483 97134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:01:13.822206 97134 net.cpp:225] Memory required for data: 31160516
I1031 13:01:13.846282 97134 layer_factory.hpp:114] Creating layer relu3
I1031 13:01:13.851018 97134 net.cpp:160] Creating Layer relu3
I1031 13:01:13.857718 97134 net.cpp:596] relu3 <- conv3
I1031 13:01:13.859622 97134 net.cpp:557] relu3 -> conv3 (in-place)
I1031 13:01:13.870906 97134 net.cpp:210] Setting up relu3
I1031 13:01:13.877617 97134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:01:13.888108 97134 net.cpp:225] Memory required for data: 31561924
I1031 13:01:13.890476 97134 layer_factory.hpp:114] Creating layer dropout3
I1031 13:01:13.897217 97134 net.cpp:160] Creating Layer dropout3
I1031 13:01:13.903513 97134 net.cpp:596] dropout3 <- conv3
I1031 13:01:13.912047 97134 net.cpp:570] dropout3 -> drop3
I1031 13:01:13.913966 97134 net.cpp:210] Setting up dropout3
I1031 13:01:13.914249 97134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:01:13.917186 97134 net.cpp:225] Memory required for data: 31963332
I1031 13:01:13.925431 97134 layer_factory.hpp:114] Creating layer pool3
I1031 13:01:13.929978 97134 net.cpp:160] Creating Layer pool3
I1031 13:01:13.934463 97134 net.cpp:596] pool3 <- drop3
I1031 13:01:13.943073 97134 net.cpp:570] pool3 -> pool3
I1031 13:01:13.951953 97134 net.cpp:210] Setting up pool3
I1031 13:01:13.964546 97134 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 13:01:13.970613 97134 net.cpp:225] Memory required for data: 32063684
I1031 13:01:13.975515 97134 layer_factory.hpp:114] Creating layer conv4
I1031 13:01:13.980481 97134 net.cpp:160] Creating Layer conv4
I1031 13:01:13.990769 97134 net.cpp:596] conv4 <- pool3
I1031 13:01:13.992874 97134 net.cpp:570] conv4 -> conv4
I1031 13:01:14.355118 97134 net.cpp:210] Setting up conv4
I1031 13:01:14.355448 97134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:01:14.355811 97134 net.cpp:225] Memory required for data: 32137412
I1031 13:01:14.356133 97134 layer_factory.hpp:114] Creating layer relu4
I1031 13:01:14.356413 97134 net.cpp:160] Creating Layer relu4
I1031 13:01:14.356626 97134 net.cpp:596] relu4 <- conv4
I1031 13:01:14.356880 97134 net.cpp:557] relu4 -> conv4 (in-place)
I1031 13:01:14.357338 97134 net.cpp:210] Setting up relu4
I1031 13:01:14.357599 97134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:01:14.357842 97134 net.cpp:225] Memory required for data: 32211140
I1031 13:01:14.358045 97134 layer_factory.hpp:114] Creating layer dropout4
I1031 13:01:14.358279 97134 net.cpp:160] Creating Layer dropout4
I1031 13:01:14.358479 97134 net.cpp:596] dropout4 <- conv4
I1031 13:01:14.358728 97134 net.cpp:570] dropout4 -> drop4
I1031 13:01:14.359081 97134 net.cpp:210] Setting up dropout4
I1031 13:01:14.359498 97134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:01:14.361320 97134 net.cpp:225] Memory required for data: 32284868
I1031 13:01:14.368098 97134 layer_factory.hpp:114] Creating layer pool4
I1031 13:01:14.383105 97134 net.cpp:160] Creating Layer pool4
I1031 13:01:14.383530 97134 net.cpp:596] pool4 <- drop4
I1031 13:01:14.389567 97134 net.cpp:570] pool4 -> pool4
I1031 13:01:14.414124 97134 net.cpp:210] Setting up pool4
I1031 13:01:14.418874 97134 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 13:01:14.434603 97134 net.cpp:225] Memory required for data: 32303300
I1031 13:01:14.444941 97134 layer_factory.hpp:114] Creating layer fc1
I1031 13:01:14.511039 97134 net.cpp:160] Creating Layer fc1
I1031 13:01:14.515578 97134 net.cpp:596] fc1 <- pool4
I1031 13:01:14.522382 97134 net.cpp:570] fc1 -> fc1
I1031 13:01:15.381659 97134 net.cpp:210] Setting up fc1
I1031 13:01:15.385992 97134 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:01:15.390499 97134 net.cpp:225] Memory required for data: 32307396
I1031 13:01:15.399989 97134 layer_factory.hpp:114] Creating layer dropout5
I1031 13:01:15.407331 97134 net.cpp:160] Creating Layer dropout5
I1031 13:01:15.413894 97134 net.cpp:596] dropout5 <- fc1
I1031 13:01:15.426295 97134 net.cpp:570] dropout5 -> drop5
I1031 13:01:15.433647 97134 net.cpp:210] Setting up dropout5
I1031 13:01:15.437530 97134 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:01:15.444880 97134 net.cpp:225] Memory required for data: 32311492
I1031 13:01:15.455605 97134 layer_factory.hpp:114] Creating layer fc2
I1031 13:01:15.462323 97134 net.cpp:160] Creating Layer fc2
I1031 13:01:15.466748 97134 net.cpp:596] fc2 <- drop5
I1031 13:01:15.479586 97134 net.cpp:570] fc2 -> fc2
I1031 13:01:15.511032 97134 net.cpp:210] Setting up fc2
I1031 13:01:15.521811 97134 net.cpp:217] Top shape: 1 2 (2)
I1031 13:01:15.530711 97134 net.cpp:225] Memory required for data: 32311500
I1031 13:01:15.540487 97134 layer_factory.hpp:114] Creating layer loss
I1031 13:01:15.570385 97134 net.cpp:160] Creating Layer loss
I1031 13:01:15.575358 97134 net.cpp:596] loss <- fc2
I1031 13:01:15.582558 97134 net.cpp:596] loss <- label
I1031 13:01:15.646381 97134 net.cpp:570] loss -> (automatic)
I1031 13:01:15.694519 97134 layer_factory.hpp:114] Creating layer loss
I1031 13:01:16.142570 97134 net.cpp:210] Setting up loss
I1031 13:01:16.153584 97134 net.cpp:217] Top shape: (1)
I1031 13:01:16.170925 97134 net.cpp:220]     with loss weight 1
I1031 13:01:16.308670 97134 net.cpp:225] Memory required for data: 32311504
I1031 13:01:16.360018 97134 net.cpp:287] loss needs backward computation.
I1031 13:01:16.467100 97134 net.cpp:287] fc2 needs backward computation.
I1031 13:01:16.475112 97134 net.cpp:287] dropout5 needs backward computation.
I1031 13:01:16.477439 97134 net.cpp:287] fc1 needs backward computation.
I1031 13:01:16.478258 97134 net.cpp:287] pool4 needs backward computation.
I1031 13:01:16.478588 97134 net.cpp:287] dropout4 needs backward computation.
I1031 13:01:16.478863 97134 net.cpp:287] relu4 needs backward computation.
I1031 13:01:16.489125 97134 net.cpp:287] conv4 needs backward computation.
I1031 13:01:16.506299 97134 net.cpp:287] pool3 needs backward computation.
I1031 13:01:16.520170 97134 net.cpp:287] dropout3 needs backward computation.
I1031 13:01:16.524977 97134 net.cpp:287] relu3 needs backward computation.
I1031 13:01:16.525313 97134 net.cpp:287] conv3 needs backward computation.
I1031 13:01:16.525656 97134 net.cpp:287] pool2 needs backward computation.
I1031 13:01:16.525930 97134 net.cpp:287] dropout2 needs backward computation.
I1031 13:01:16.526129 97134 net.cpp:287] relu2 needs backward computation.
I1031 13:01:16.526315 97134 net.cpp:287] conv2 needs backward computation.
I1031 13:01:16.526507 97134 net.cpp:287] pool1 needs backward computation.
I1031 13:01:16.526698 97134 net.cpp:287] dropout1 needs backward computation.
I1031 13:01:16.526888 97134 net.cpp:287] relu1 needs backward computation.
I1031 13:01:16.527072 97134 net.cpp:287] conv1 needs backward computation.
I1031 13:01:16.547168 97134 net.cpp:289] data does not need backward computation.
I1031 13:01:16.609557 97134 net.cpp:345] Network initialization done.
I1031 13:01:16.790737 97134 caffe.cpp:452] Performing Forward
I1031 13:01:28.290769 97134 caffe.cpp:457] Initial loss: 87.3365
I1031 13:01:28.416908 97134 caffe.cpp:459] Performing Backward
I1031 13:01:31.825682 97134 caffe.cpp:468] *** Benchmark begins ***
I1031 13:01:31.847972 97134 caffe.cpp:469] Testing for 1 iterations.
I1031 13:01:32.004679 97134 caffe.cpp:482] Profiling Layer: dropout4 forward
I1031 13:01:34.019870 97134 caffe.cpp:512] Iteration: 1 forward-backward time: 2007 ms.
I1031 13:01:34.125584 97134 caffe.cpp:519] Average time per layer: 
I1031 13:01:34.158288 97134 caffe.cpp:522]       data	forward: 54.413 ms.
I1031 13:01:34.232537 97134 caffe.cpp:526]       data	backward: 5.681 ms.
I1031 13:01:34.259021 97134 caffe.cpp:522]      conv1	forward: 46.418 ms.
I1031 13:01:34.263823 97134 caffe.cpp:526]      conv1	backward: 29.066 ms.
I1031 13:01:34.274857 97134 caffe.cpp:522]      relu1	forward: 17.166 ms.
I1031 13:01:34.290410 97134 caffe.cpp:526]      relu1	backward: 64.604 ms.
I1031 13:01:34.291877 97134 caffe.cpp:522]   dropout1	forward: 36.691 ms.
I1031 13:01:34.292151 97134 caffe.cpp:526]   dropout1	backward: 60.851 ms.
I1031 13:01:34.292357 97134 caffe.cpp:522]      pool1	forward: 126.226 ms.
I1031 13:01:34.295495 97134 caffe.cpp:526]      pool1	backward: 142.366 ms.
I1031 13:01:34.295804 97134 caffe.cpp:522]      conv2	forward: 27.417 ms.
I1031 13:01:34.296011 97134 caffe.cpp:526]      conv2	backward: 65.566 ms.
I1031 13:01:34.296214 97134 caffe.cpp:522]      relu2	forward: 0.133 ms.
I1031 13:01:34.296416 97134 caffe.cpp:526]      relu2	backward: 37.419 ms.
I1031 13:01:34.296617 97134 caffe.cpp:522]   dropout2	forward: 8.196 ms.
I1031 13:01:34.297631 97134 caffe.cpp:526]   dropout2	backward: 41.48 ms.
I1031 13:01:34.298060 97134 caffe.cpp:522]      pool2	forward: 30.005 ms.
I1031 13:01:34.298349 97134 caffe.cpp:526]      pool2	backward: 62.292 ms.
I1031 13:01:34.298584 97134 caffe.cpp:522]      conv3	forward: 60.842 ms.
I1031 13:01:34.298786 97134 caffe.cpp:526]      conv3	backward: 58.652 ms.
I1031 13:01:34.298990 97134 caffe.cpp:522]      relu3	forward: 15.932 ms.
I1031 13:01:34.299191 97134 caffe.cpp:526]      relu3	backward: 44.53 ms.
I1031 13:01:34.299468 97134 caffe.cpp:522]   dropout3	forward: 59.56 ms.
I1031 13:01:34.299705 97134 caffe.cpp:526]   dropout3	backward: 39.567 ms.
I1031 13:01:34.299906 97134 caffe.cpp:522]      pool3	forward: 18.032 ms.
I1031 13:01:34.300107 97134 caffe.cpp:526]      pool3	backward: 69.301 ms.
I1031 13:01:34.300308 97134 caffe.cpp:522]      conv4	forward: 52.536 ms.
I1031 13:01:34.300510 97134 caffe.cpp:526]      conv4	backward: 82.651 ms.
I1031 13:01:34.300712 97134 caffe.cpp:522]      relu4	forward: 20.052 ms.
I1031 13:01:34.300956 97134 caffe.cpp:526]      relu4	backward: 39.539 ms.
I1031 13:01:34.301185 97134 caffe.cpp:522]   dropout4	forward: 68.658 ms.
I1031 13:01:34.301535 97134 caffe.cpp:526]   dropout4	backward: 49.1 ms.
I1031 13:01:34.301805 97134 caffe.cpp:522]      pool4	forward: 26.481 ms.
I1031 13:01:34.302011 97134 caffe.cpp:526]      pool4	backward: 50.376 ms.
I1031 13:01:34.302213 97134 caffe.cpp:522]        fc1	forward: 41.761 ms.
I1031 13:01:34.302415 97134 caffe.cpp:526]        fc1	backward: 59.617 ms.
I1031 13:01:34.302618 97134 caffe.cpp:522]   dropout5	forward: 43.089 ms.
I1031 13:01:34.302820 97134 caffe.cpp:526]   dropout5	backward: 15.431 ms.
I1031 13:01:34.303021 97134 caffe.cpp:522]        fc2	forward: 18.162 ms.
I1031 13:01:34.303222 97134 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 13:01:34.303498 97134 caffe.cpp:522]       loss	forward: 74.468 ms.
I1031 13:01:34.303732 97134 caffe.cpp:526]       loss	backward: 44.222 ms.
I1031 13:01:34.309666 97134 caffe.cpp:532] Average Forward pass: 905.424 ms.
I1031 13:01:34.323424 97134 caffe.cpp:535] Average Backward pass: 1071.91 ms.
I1031 13:01:34.335464 97134 caffe.cpp:537] Average Forward-Backward: 2414 ms.
I1031 13:01:34.351047 97134 caffe.cpp:540] Total Time: 2414 ms.
I1031 13:01:34.363920 97134 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 2304
elements_fp_double_1 = 33
elements_fp_double_2 = 27872
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 36867
--->Total double-precision FLOPs = 55777
--->Total FLOPs = 92644
mem-read-1 = 75543
mem-read-2 = 105
mem-read-4 = 611461
mem-read-8 = 860111
mem-read-16 = 92176
mem-read-32 = 1
mem-read-64 = 7185
mem-write-1 = 188
mem-write-2 = 67
mem-write-4 = 2460
mem-write-8 = 95519
mem-write-16 = 32
mem-write-32 = 1
mem-write-64 = 3841
--->Total Bytes read = 11337173
--->Total Bytes written = 1020682
--->Total Bytes = 12357855

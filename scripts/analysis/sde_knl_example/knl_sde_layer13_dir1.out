sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer13_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=13 -prof_forward_direction=1
I1031 12:47:52.263934 96737 caffe.cpp:444] Use CPU.
I1031 12:48:10.223951 96737 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 12:48:10.287132 96737 cpu_info.cpp:455] Total number of sockets: 1
I1031 12:48:10.300153 96737 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 12:48:10.312095 96737 cpu_info.cpp:461] Total number of processors: 256
I1031 12:48:10.329149 96737 cpu_info.cpp:464] GPU is used: no
I1031 12:48:10.338572 96737 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 12:48:10.347555 96737 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 12:48:10.360185 96737 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 12:48:19.546514 96737 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 12:48:20.237949 96737 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 12:48:22.667536 96737 layer_factory.hpp:114] Creating layer data
I1031 12:48:22.826613 96737 net.cpp:160] Creating Layer data
I1031 12:48:22.877629 96737 net.cpp:570] data -> data
I1031 12:48:23.374233 96737 net.cpp:570] data -> label
I1031 12:48:30.858105 96737 net.cpp:210] Setting up data
I1031 12:48:30.945024 96737 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 12:48:31.054127 96737 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 12:48:31.080577 96737 net.cpp:225] Memory required for data: 184516
I1031 12:48:31.163172 96737 layer_factory.hpp:114] Creating layer conv1
I1031 12:48:31.509795 96737 net.cpp:160] Creating Layer conv1
I1031 12:48:31.563139 96737 net.cpp:596] conv1 <- data
I1031 12:48:31.690320 96737 net.cpp:570] conv1 -> conv1
I1031 12:49:09.176236 96737 net.cpp:210] Setting up conv1
I1031 12:49:09.248643 96737 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:49:09.268928 96737 net.cpp:225] Memory required for data: 7805124
I1031 12:49:09.605296 96737 layer_factory.hpp:114] Creating layer relu1
I1031 12:49:09.750958 96737 net.cpp:160] Creating Layer relu1
I1031 12:49:09.756639 96737 net.cpp:596] relu1 <- conv1
I1031 12:49:09.793102 96737 net.cpp:557] relu1 -> conv1 (in-place)
I1031 12:49:10.010257 96737 net.cpp:210] Setting up relu1
I1031 12:49:10.018944 96737 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:49:10.019630 96737 net.cpp:225] Memory required for data: 15425732
I1031 12:49:10.020077 96737 layer_factory.hpp:114] Creating layer dropout1
I1031 12:49:10.055724 96737 net.cpp:160] Creating Layer dropout1
I1031 12:49:10.057132 96737 net.cpp:596] dropout1 <- conv1
I1031 12:49:10.060092 96737 net.cpp:570] dropout1 -> drop1
I1031 12:49:10.174007 96737 net.cpp:210] Setting up dropout1
I1031 12:49:10.188019 96737 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:49:10.188413 96737 net.cpp:225] Memory required for data: 23046340
I1031 12:49:10.188765 96737 layer_factory.hpp:114] Creating layer pool1
I1031 12:49:10.292611 96737 net.cpp:160] Creating Layer pool1
I1031 12:49:10.293308 96737 net.cpp:596] pool1 <- drop1
I1031 12:49:10.293720 96737 net.cpp:570] pool1 -> pool1
I1031 12:49:10.710822 96737 net.cpp:210] Setting up pool1
I1031 12:49:10.719815 96737 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 12:49:10.720194 96737 net.cpp:225] Memory required for data: 24951492
I1031 12:49:10.720520 96737 layer_factory.hpp:114] Creating layer conv2
I1031 12:49:10.783920 96737 net.cpp:160] Creating Layer conv2
I1031 12:49:10.788414 96737 net.cpp:596] conv2 <- pool1
I1031 12:49:10.804097 96737 net.cpp:570] conv2 -> conv2
I1031 12:49:17.618276 96737 net.cpp:210] Setting up conv2
I1031 12:49:17.620622 96737 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:49:17.630056 96737 net.cpp:225] Memory required for data: 26733764
I1031 12:49:17.696701 96737 layer_factory.hpp:114] Creating layer relu2
I1031 12:49:17.709836 96737 net.cpp:160] Creating Layer relu2
I1031 12:49:17.716321 96737 net.cpp:596] relu2 <- conv2
I1031 12:49:17.731257 96737 net.cpp:557] relu2 -> conv2 (in-place)
I1031 12:49:17.748302 96737 net.cpp:210] Setting up relu2
I1031 12:49:17.754647 96737 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:49:17.766759 96737 net.cpp:225] Memory required for data: 28516036
I1031 12:49:17.773687 96737 layer_factory.hpp:114] Creating layer dropout2
I1031 12:49:17.777797 96737 net.cpp:160] Creating Layer dropout2
I1031 12:49:17.784345 96737 net.cpp:596] dropout2 <- conv2
I1031 12:49:17.795110 96737 net.cpp:570] dropout2 -> drop2
I1031 12:49:17.799607 96737 net.cpp:210] Setting up dropout2
I1031 12:49:17.804018 96737 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:49:17.804424 96737 net.cpp:225] Memory required for data: 30298308
I1031 12:49:17.810467 96737 layer_factory.hpp:114] Creating layer pool2
I1031 12:49:17.817337 96737 net.cpp:160] Creating Layer pool2
I1031 12:49:17.819803 96737 net.cpp:596] pool2 <- drop2
I1031 12:49:17.828533 96737 net.cpp:570] pool2 -> pool2
I1031 12:49:17.832881 96737 net.cpp:210] Setting up pool2
I1031 12:49:17.839095 96737 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 12:49:17.847798 96737 net.cpp:225] Memory required for data: 30759108
I1031 12:49:17.856305 96737 layer_factory.hpp:114] Creating layer conv3
I1031 12:49:17.876912 96737 net.cpp:160] Creating Layer conv3
I1031 12:49:17.877238 96737 net.cpp:596] conv3 <- pool2
I1031 12:49:17.877496 96737 net.cpp:570] conv3 -> conv3
I1031 12:49:18.469763 96737 net.cpp:210] Setting up conv3
I1031 12:49:18.478205 96737 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:49:18.486703 96737 net.cpp:225] Memory required for data: 31160516
I1031 12:49:18.502882 96737 layer_factory.hpp:114] Creating layer relu3
I1031 12:49:18.512154 96737 net.cpp:160] Creating Layer relu3
I1031 12:49:18.522083 96737 net.cpp:596] relu3 <- conv3
I1031 12:49:18.529139 96737 net.cpp:557] relu3 -> conv3 (in-place)
I1031 12:49:18.548297 96737 net.cpp:210] Setting up relu3
I1031 12:49:18.557126 96737 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:49:18.563684 96737 net.cpp:225] Memory required for data: 31561924
I1031 12:49:18.572185 96737 layer_factory.hpp:114] Creating layer dropout3
I1031 12:49:18.578397 96737 net.cpp:160] Creating Layer dropout3
I1031 12:49:18.580713 96737 net.cpp:596] dropout3 <- conv3
I1031 12:49:18.585108 96737 net.cpp:570] dropout3 -> drop3
I1031 12:49:18.589537 96737 net.cpp:210] Setting up dropout3
I1031 12:49:18.591933 96737 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:49:18.596560 96737 net.cpp:225] Memory required for data: 31963332
I1031 12:49:18.606410 96737 layer_factory.hpp:114] Creating layer pool3
I1031 12:49:18.609002 96737 net.cpp:160] Creating Layer pool3
I1031 12:49:18.613713 96737 net.cpp:596] pool3 <- drop3
I1031 12:49:18.623843 96737 net.cpp:570] pool3 -> pool3
I1031 12:49:18.632360 96737 net.cpp:210] Setting up pool3
I1031 12:49:18.644765 96737 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 12:49:18.650918 96737 net.cpp:225] Memory required for data: 32063684
I1031 12:49:18.653734 96737 layer_factory.hpp:114] Creating layer conv4
I1031 12:49:18.656182 96737 net.cpp:160] Creating Layer conv4
I1031 12:49:18.658313 96737 net.cpp:596] conv4 <- pool3
I1031 12:49:18.660954 96737 net.cpp:570] conv4 -> conv4
I1031 12:49:19.049219 96737 net.cpp:210] Setting up conv4
I1031 12:49:19.053798 96737 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:49:19.056417 96737 net.cpp:225] Memory required for data: 32137412
I1031 12:49:19.060976 96737 layer_factory.hpp:114] Creating layer relu4
I1031 12:49:19.070766 96737 net.cpp:160] Creating Layer relu4
I1031 12:49:19.073303 96737 net.cpp:596] relu4 <- conv4
I1031 12:49:19.089067 96737 net.cpp:557] relu4 -> conv4 (in-place)
I1031 12:49:19.095484 96737 net.cpp:210] Setting up relu4
I1031 12:49:19.100208 96737 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:49:19.108587 96737 net.cpp:225] Memory required for data: 32211140
I1031 12:49:19.124989 96737 layer_factory.hpp:114] Creating layer dropout4
I1031 12:49:19.131342 96737 net.cpp:160] Creating Layer dropout4
I1031 12:49:19.135220 96737 net.cpp:596] dropout4 <- conv4
I1031 12:49:19.138617 96737 net.cpp:570] dropout4 -> drop4
I1031 12:49:19.147238 96737 net.cpp:210] Setting up dropout4
I1031 12:49:19.151696 96737 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:49:19.156148 96737 net.cpp:225] Memory required for data: 32284868
I1031 12:49:19.162752 96737 layer_factory.hpp:114] Creating layer pool4
I1031 12:49:19.166846 96737 net.cpp:160] Creating Layer pool4
I1031 12:49:19.175720 96737 net.cpp:596] pool4 <- drop4
I1031 12:49:19.181874 96737 net.cpp:570] pool4 -> pool4
I1031 12:49:19.196982 96737 net.cpp:210] Setting up pool4
I1031 12:49:19.197338 96737 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 12:49:19.199877 96737 net.cpp:225] Memory required for data: 32303300
I1031 12:49:19.200131 96737 layer_factory.hpp:114] Creating layer fc1
I1031 12:49:19.264669 96737 net.cpp:160] Creating Layer fc1
I1031 12:49:19.265010 96737 net.cpp:596] fc1 <- pool4
I1031 12:49:19.265440 96737 net.cpp:570] fc1 -> fc1
I1031 12:49:20.145213 96737 net.cpp:210] Setting up fc1
I1031 12:49:20.149667 96737 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:49:20.160195 96737 net.cpp:225] Memory required for data: 32307396
I1031 12:49:20.173254 96737 layer_factory.hpp:114] Creating layer dropout5
I1031 12:49:20.181704 96737 net.cpp:160] Creating Layer dropout5
I1031 12:49:20.199020 96737 net.cpp:596] dropout5 <- fc1
I1031 12:49:20.203183 96737 net.cpp:570] dropout5 -> drop5
I1031 12:49:20.209303 96737 net.cpp:210] Setting up dropout5
I1031 12:49:20.218225 96737 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:49:20.230319 96737 net.cpp:225] Memory required for data: 32311492
I1031 12:49:20.233335 96737 layer_factory.hpp:114] Creating layer fc2
I1031 12:49:20.245246 96737 net.cpp:160] Creating Layer fc2
I1031 12:49:20.250524 96737 net.cpp:596] fc2 <- drop5
I1031 12:49:20.258329 96737 net.cpp:570] fc2 -> fc2
I1031 12:49:20.300209 96737 net.cpp:210] Setting up fc2
I1031 12:49:20.313684 96737 net.cpp:217] Top shape: 1 2 (2)
I1031 12:49:20.324369 96737 net.cpp:225] Memory required for data: 32311500
I1031 12:49:20.332991 96737 layer_factory.hpp:114] Creating layer loss
I1031 12:49:20.362964 96737 net.cpp:160] Creating Layer loss
I1031 12:49:20.371789 96737 net.cpp:596] loss <- fc2
I1031 12:49:20.382026 96737 net.cpp:596] loss <- label
I1031 12:49:20.448015 96737 net.cpp:570] loss -> (automatic)
I1031 12:49:20.509526 96737 layer_factory.hpp:114] Creating layer loss
I1031 12:49:20.933102 96737 net.cpp:210] Setting up loss
I1031 12:49:20.942283 96737 net.cpp:217] Top shape: (1)
I1031 12:49:20.956807 96737 net.cpp:220]     with loss weight 1
I1031 12:49:21.102421 96737 net.cpp:225] Memory required for data: 32311504
I1031 12:49:21.155910 96737 net.cpp:287] loss needs backward computation.
I1031 12:49:21.262583 96737 net.cpp:287] fc2 needs backward computation.
I1031 12:49:21.270776 96737 net.cpp:287] dropout5 needs backward computation.
I1031 12:49:21.273026 96737 net.cpp:287] fc1 needs backward computation.
I1031 12:49:21.273821 96737 net.cpp:287] pool4 needs backward computation.
I1031 12:49:21.274096 96737 net.cpp:287] dropout4 needs backward computation.
I1031 12:49:21.274293 96737 net.cpp:287] relu4 needs backward computation.
I1031 12:49:21.284013 96737 net.cpp:287] conv4 needs backward computation.
I1031 12:49:21.301164 96737 net.cpp:287] pool3 needs backward computation.
I1031 12:49:21.314990 96737 net.cpp:287] dropout3 needs backward computation.
I1031 12:49:21.319941 96737 net.cpp:287] relu3 needs backward computation.
I1031 12:49:21.320268 96737 net.cpp:287] conv3 needs backward computation.
I1031 12:49:21.320591 96737 net.cpp:287] pool2 needs backward computation.
I1031 12:49:21.320864 96737 net.cpp:287] dropout2 needs backward computation.
I1031 12:49:21.321063 96737 net.cpp:287] relu2 needs backward computation.
I1031 12:49:21.321250 96737 net.cpp:287] conv2 needs backward computation.
I1031 12:49:21.321444 96737 net.cpp:287] pool1 needs backward computation.
I1031 12:49:21.321632 96737 net.cpp:287] dropout1 needs backward computation.
I1031 12:49:21.321821 96737 net.cpp:287] relu1 needs backward computation.
I1031 12:49:21.322006 96737 net.cpp:287] conv1 needs backward computation.
I1031 12:49:21.342373 96737 net.cpp:289] data does not need backward computation.
I1031 12:49:21.402501 96737 net.cpp:345] Network initialization done.
I1031 12:49:21.583933 96737 caffe.cpp:452] Performing Forward
I1031 12:49:33.444658 96737 caffe.cpp:457] Initial loss: 0
I1031 12:49:33.476399 96737 caffe.cpp:459] Performing Backward
I1031 12:49:36.684281 96737 caffe.cpp:468] *** Benchmark begins ***
I1031 12:49:36.701752 96737 caffe.cpp:469] Testing for 1 iterations.
I1031 12:49:36.859972 96737 caffe.cpp:482] Profiling Layer: conv4 forward
I1031 12:49:38.399591 96737 caffe.cpp:512] Iteration: 1 forward-backward time: 1535 ms.
I1031 12:49:38.580886 96737 caffe.cpp:519] Average time per layer: 
I1031 12:49:38.600662 96737 caffe.cpp:522]       data	forward: 48.64 ms.
I1031 12:49:38.684646 96737 caffe.cpp:526]       data	backward: 7.592 ms.
I1031 12:49:38.723242 96737 caffe.cpp:522]      conv1	forward: 80.887 ms.
I1031 12:49:38.744587 96737 caffe.cpp:526]      conv1	backward: 35.52 ms.
I1031 12:49:38.749119 96737 caffe.cpp:522]      relu1	forward: 24.876 ms.
I1031 12:49:38.753454 96737 caffe.cpp:526]      relu1	backward: 96.904 ms.
I1031 12:49:38.761309 96737 caffe.cpp:522]   dropout1	forward: 94.024 ms.
I1031 12:49:38.770016 96737 caffe.cpp:526]   dropout1	backward: 56.301 ms.
I1031 12:49:38.772501 96737 caffe.cpp:522]      pool1	forward: 131.783 ms.
I1031 12:49:38.778412 96737 caffe.cpp:526]      pool1	backward: 132.855 ms.
I1031 12:49:38.779001 96737 caffe.cpp:522]      conv2	forward: 72.866 ms.
I1031 12:49:38.779351 96737 caffe.cpp:526]      conv2	backward: 55.688 ms.
I1031 12:49:38.779659 96737 caffe.cpp:522]      relu2	forward: 23.397 ms.
I1031 12:49:38.779912 96737 caffe.cpp:526]      relu2	backward: 14.063 ms.
I1031 12:49:38.780228 96737 caffe.cpp:522]   dropout2	forward: 54.923 ms.
I1031 12:49:38.781643 96737 caffe.cpp:526]   dropout2	backward: 16.143 ms.
I1031 12:49:38.782024 96737 caffe.cpp:522]      pool2	forward: 30.302 ms.
I1031 12:49:38.782479 96737 caffe.cpp:526]      pool2	backward: 28.237 ms.
I1031 12:49:38.782927 96737 caffe.cpp:522]      conv3	forward: 70.264 ms.
I1031 12:49:38.783396 96737 caffe.cpp:526]      conv3	backward: 2.514 ms.
I1031 12:49:38.783779 96737 caffe.cpp:522]      relu3	forward: 17.824 ms.
I1031 12:49:38.784049 96737 caffe.cpp:526]      relu3	backward: 1.359 ms.
I1031 12:49:38.784281 96737 caffe.cpp:522]   dropout3	forward: 43.825 ms.
I1031 12:49:38.784517 96737 caffe.cpp:526]   dropout3	backward: 1.873 ms.
I1031 12:49:38.784745 96737 caffe.cpp:522]      pool3	forward: 12.64 ms.
I1031 12:49:38.785122 96737 caffe.cpp:526]      pool3	backward: 5.972 ms.
I1031 12:49:38.785495 96737 caffe.cpp:522]      conv4	forward: 71.363 ms.
I1031 12:49:38.785979 96737 caffe.cpp:526]      conv4	backward: 9.768 ms.
I1031 12:49:38.787180 96737 caffe.cpp:522]      relu4	forward: 15.872 ms.
I1031 12:49:38.787720 96737 caffe.cpp:526]      relu4	backward: 5.421 ms.
I1031 12:49:38.788175 96737 caffe.cpp:522]   dropout4	forward: 47.475 ms.
I1031 12:49:38.788583 96737 caffe.cpp:526]   dropout4	backward: 12.763 ms.
I1031 12:49:38.788867 96737 caffe.cpp:522]      pool4	forward: 18.644 ms.
I1031 12:49:38.789207 96737 caffe.cpp:526]      pool4	backward: 1.153 ms.
I1031 12:49:38.789726 96737 caffe.cpp:522]        fc1	forward: 13.495 ms.
I1031 12:49:38.790174 96737 caffe.cpp:526]        fc1	backward: 11.305 ms.
I1031 12:49:38.790556 96737 caffe.cpp:522]   dropout5	forward: 0.206 ms.
I1031 12:49:38.790825 96737 caffe.cpp:526]   dropout5	backward: 0.065 ms.
I1031 12:49:38.810314 96737 caffe.cpp:522]        fc2	forward: 0.112 ms.
I1031 12:49:38.811300 96737 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 12:49:38.811625 96737 caffe.cpp:522]       loss	forward: 30.99 ms.
I1031 12:49:38.811862 96737 caffe.cpp:526]       loss	backward: 33.722 ms.
I1031 12:49:38.817904 96737 caffe.cpp:532] Average Forward pass: 965.71 ms.
I1031 12:49:38.832054 96737 caffe.cpp:535] Average Backward pass: 539.25 ms.
I1031 12:49:38.844167 96737 caffe.cpp:537] Average Forward-Backward: 2068 ms.
I1031 12:49:38.861444 96737 caffe.cpp:540] Total Time: 2068 ms.
I1031 12:49:38.875277 96737 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 2663424
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 42614785
--->Total double-precision FLOPs = 0
--->Total FLOPs = 42614785
mem-read-1 = 75511
mem-read-2 = 110
mem-read-4 = 1943894
mem-read-8 = 907143
mem-read-16 = 0
mem-read-32 = 5378
mem-read-64 = 287684
mem-write-1 = 166
mem-write-2 = 51
mem-write-4 = 27981
mem-write-8 = 107616
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 10404
--->Total Bytes read = 33692323
--->Total Bytes written = 1639040
--->Total Bytes = 35331363

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer3_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=3 -prof_forward_direction=0
I1031 13:56:41.820960 99233 caffe.cpp:444] Use CPU.
I1031 13:56:59.623965 99233 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 13:56:59.687033 99233 cpu_info.cpp:455] Total number of sockets: 1
I1031 13:56:59.700093 99233 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 13:56:59.712190 99233 cpu_info.cpp:461] Total number of processors: 256
I1031 13:56:59.729574 99233 cpu_info.cpp:464] GPU is used: no
I1031 13:56:59.738956 99233 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 13:56:59.747951 99233 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 13:56:59.760504 99233 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 13:57:08.871001 99233 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 13:57:09.571837 99233 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 13:57:11.985975 99233 layer_factory.hpp:114] Creating layer data
I1031 13:57:12.143029 99233 net.cpp:160] Creating Layer data
I1031 13:57:12.193861 99233 net.cpp:570] data -> data
I1031 13:57:12.712703 99233 net.cpp:570] data -> label
I1031 13:57:20.188910 99233 net.cpp:210] Setting up data
I1031 13:57:20.272805 99233 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 13:57:20.381474 99233 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 13:57:20.389163 99233 net.cpp:225] Memory required for data: 184516
I1031 13:57:20.471516 99233 layer_factory.hpp:114] Creating layer conv1
I1031 13:57:20.820133 99233 net.cpp:160] Creating Layer conv1
I1031 13:57:20.873421 99233 net.cpp:596] conv1 <- data
I1031 13:57:21.000046 99233 net.cpp:570] conv1 -> conv1
I1031 13:57:58.209913 99233 net.cpp:210] Setting up conv1
I1031 13:57:58.280748 99233 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:57:58.308287 99233 net.cpp:225] Memory required for data: 7805124
I1031 13:57:58.625082 99233 layer_factory.hpp:114] Creating layer relu1
I1031 13:57:58.766584 99233 net.cpp:160] Creating Layer relu1
I1031 13:57:58.771831 99233 net.cpp:596] relu1 <- conv1
I1031 13:57:58.806788 99233 net.cpp:557] relu1 -> conv1 (in-place)
I1031 13:57:59.019496 99233 net.cpp:210] Setting up relu1
I1031 13:57:59.022104 99233 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:57:59.022464 99233 net.cpp:225] Memory required for data: 15425732
I1031 13:57:59.022680 99233 layer_factory.hpp:114] Creating layer dropout1
I1031 13:57:59.054901 99233 net.cpp:160] Creating Layer dropout1
I1031 13:57:59.055238 99233 net.cpp:596] dropout1 <- conv1
I1031 13:57:59.058085 99233 net.cpp:570] dropout1 -> drop1
I1031 13:57:59.168824 99233 net.cpp:210] Setting up dropout1
I1031 13:57:59.182209 99233 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:57:59.182602 99233 net.cpp:225] Memory required for data: 23046340
I1031 13:57:59.182936 99233 layer_factory.hpp:114] Creating layer pool1
I1031 13:57:59.282743 99233 net.cpp:160] Creating Layer pool1
I1031 13:57:59.283550 99233 net.cpp:596] pool1 <- drop1
I1031 13:57:59.283984 99233 net.cpp:570] pool1 -> pool1
I1031 13:57:59.694721 99233 net.cpp:210] Setting up pool1
I1031 13:57:59.703583 99233 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 13:57:59.704105 99233 net.cpp:225] Memory required for data: 24951492
I1031 13:57:59.704433 99233 layer_factory.hpp:114] Creating layer conv2
I1031 13:57:59.766788 99233 net.cpp:160] Creating Layer conv2
I1031 13:57:59.771226 99233 net.cpp:596] conv2 <- pool1
I1031 13:57:59.786653 99233 net.cpp:570] conv2 -> conv2
I1031 13:58:06.538249 99233 net.cpp:210] Setting up conv2
I1031 13:58:06.551107 99233 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:58:06.560472 99233 net.cpp:225] Memory required for data: 26733764
I1031 13:58:06.621793 99233 layer_factory.hpp:114] Creating layer relu2
I1031 13:58:06.634021 99233 net.cpp:160] Creating Layer relu2
I1031 13:58:06.636690 99233 net.cpp:596] relu2 <- conv2
I1031 13:58:06.641541 99233 net.cpp:557] relu2 -> conv2 (in-place)
I1031 13:58:06.651084 99233 net.cpp:210] Setting up relu2
I1031 13:58:06.657454 99233 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:58:06.669987 99233 net.cpp:225] Memory required for data: 28516036
I1031 13:58:06.678416 99233 layer_factory.hpp:114] Creating layer dropout2
I1031 13:58:06.685437 99233 net.cpp:160] Creating Layer dropout2
I1031 13:58:06.691851 99233 net.cpp:596] dropout2 <- conv2
I1031 13:58:06.698366 99233 net.cpp:570] dropout2 -> drop2
I1031 13:58:06.706786 99233 net.cpp:210] Setting up dropout2
I1031 13:58:06.709282 99233 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:58:06.725581 99233 net.cpp:225] Memory required for data: 30298308
I1031 13:58:06.733906 99233 layer_factory.hpp:114] Creating layer pool2
I1031 13:58:06.735819 99233 net.cpp:160] Creating Layer pool2
I1031 13:58:06.740998 99233 net.cpp:596] pool2 <- drop2
I1031 13:58:06.753157 99233 net.cpp:570] pool2 -> pool2
I1031 13:58:06.757655 99233 net.cpp:210] Setting up pool2
I1031 13:58:06.770148 99233 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 13:58:06.778131 99233 net.cpp:225] Memory required for data: 30759108
I1031 13:58:06.787154 99233 layer_factory.hpp:114] Creating layer conv3
I1031 13:58:06.793824 99233 net.cpp:160] Creating Layer conv3
I1031 13:58:06.798185 99233 net.cpp:596] conv3 <- pool2
I1031 13:58:06.806520 99233 net.cpp:570] conv3 -> conv3
I1031 13:58:07.380928 99233 net.cpp:210] Setting up conv3
I1031 13:58:07.393244 99233 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:58:07.396121 99233 net.cpp:225] Memory required for data: 31160516
I1031 13:58:07.421741 99233 layer_factory.hpp:114] Creating layer relu3
I1031 13:58:07.432166 99233 net.cpp:160] Creating Layer relu3
I1031 13:58:07.436550 99233 net.cpp:596] relu3 <- conv3
I1031 13:58:07.444676 99233 net.cpp:557] relu3 -> conv3 (in-place)
I1031 13:58:07.447327 99233 net.cpp:210] Setting up relu3
I1031 13:58:07.460239 99233 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:58:07.464691 99233 net.cpp:225] Memory required for data: 31561924
I1031 13:58:07.469377 99233 layer_factory.hpp:114] Creating layer dropout3
I1031 13:58:07.476016 99233 net.cpp:160] Creating Layer dropout3
I1031 13:58:07.484220 99233 net.cpp:596] dropout3 <- conv3
I1031 13:58:07.490794 99233 net.cpp:570] dropout3 -> drop3
I1031 13:58:07.501353 99233 net.cpp:210] Setting up dropout3
I1031 13:58:07.501718 99233 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:58:07.512339 99233 net.cpp:225] Memory required for data: 31963332
I1031 13:58:07.520414 99233 layer_factory.hpp:114] Creating layer pool3
I1031 13:58:07.534765 99233 net.cpp:160] Creating Layer pool3
I1031 13:58:07.535140 99233 net.cpp:596] pool3 <- drop3
I1031 13:58:07.545662 99233 net.cpp:570] pool3 -> pool3
I1031 13:58:07.552552 99233 net.cpp:210] Setting up pool3
I1031 13:58:07.558954 99233 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 13:58:07.561544 99233 net.cpp:225] Memory required for data: 32063684
I1031 13:58:07.566051 99233 layer_factory.hpp:114] Creating layer conv4
I1031 13:58:07.570339 99233 net.cpp:160] Creating Layer conv4
I1031 13:58:07.582294 99233 net.cpp:596] conv4 <- pool3
I1031 13:58:07.586977 99233 net.cpp:570] conv4 -> conv4
I1031 13:58:07.927636 99233 net.cpp:210] Setting up conv4
I1031 13:58:07.927928 99233 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:58:07.928290 99233 net.cpp:225] Memory required for data: 32137412
I1031 13:58:07.928611 99233 layer_factory.hpp:114] Creating layer relu4
I1031 13:58:07.928894 99233 net.cpp:160] Creating Layer relu4
I1031 13:58:07.929110 99233 net.cpp:596] relu4 <- conv4
I1031 13:58:07.929363 99233 net.cpp:557] relu4 -> conv4 (in-place)
I1031 13:58:07.929816 99233 net.cpp:210] Setting up relu4
I1031 13:58:07.930085 99233 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:58:07.930331 99233 net.cpp:225] Memory required for data: 32211140
I1031 13:58:07.930536 99233 layer_factory.hpp:114] Creating layer dropout4
I1031 13:58:07.930773 99233 net.cpp:160] Creating Layer dropout4
I1031 13:58:07.930975 99233 net.cpp:596] dropout4 <- conv4
I1031 13:58:07.931263 99233 net.cpp:570] dropout4 -> drop4
I1031 13:58:07.931715 99233 net.cpp:210] Setting up dropout4
I1031 13:58:07.931957 99233 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:58:07.940431 99233 net.cpp:225] Memory required for data: 32284868
I1031 13:58:07.946997 99233 layer_factory.hpp:114] Creating layer pool4
I1031 13:58:07.951496 99233 net.cpp:160] Creating Layer pool4
I1031 13:58:07.955695 99233 net.cpp:596] pool4 <- drop4
I1031 13:58:07.960115 99233 net.cpp:570] pool4 -> pool4
I1031 13:58:07.986196 99233 net.cpp:210] Setting up pool4
I1031 13:58:07.994966 99233 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 13:58:08.003624 99233 net.cpp:225] Memory required for data: 32303300
I1031 13:58:08.008038 99233 layer_factory.hpp:114] Creating layer fc1
I1031 13:58:08.073714 99233 net.cpp:160] Creating Layer fc1
I1031 13:58:08.081795 99233 net.cpp:596] fc1 <- pool4
I1031 13:58:08.086621 99233 net.cpp:570] fc1 -> fc1
I1031 13:58:08.997041 99233 net.cpp:210] Setting up fc1
I1031 13:58:09.005662 99233 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:58:09.007695 99233 net.cpp:225] Memory required for data: 32307396
I1031 13:58:09.019647 99233 layer_factory.hpp:114] Creating layer dropout5
I1031 13:58:09.024158 99233 net.cpp:160] Creating Layer dropout5
I1031 13:58:09.024510 99233 net.cpp:596] dropout5 <- fc1
I1031 13:58:09.029050 99233 net.cpp:570] dropout5 -> drop5
I1031 13:58:09.033316 99233 net.cpp:210] Setting up dropout5
I1031 13:58:09.035620 99233 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:58:09.039871 99233 net.cpp:225] Memory required for data: 32311492
I1031 13:58:09.042307 99233 layer_factory.hpp:114] Creating layer fc2
I1031 13:58:09.050612 99233 net.cpp:160] Creating Layer fc2
I1031 13:58:09.052989 99233 net.cpp:596] fc2 <- drop5
I1031 13:58:09.055850 99233 net.cpp:570] fc2 -> fc2
I1031 13:58:09.095029 99233 net.cpp:210] Setting up fc2
I1031 13:58:09.108947 99233 net.cpp:217] Top shape: 1 2 (2)
I1031 13:58:09.119258 99233 net.cpp:225] Memory required for data: 32311500
I1031 13:58:09.123667 99233 layer_factory.hpp:114] Creating layer loss
I1031 13:58:09.154767 99233 net.cpp:160] Creating Layer loss
I1031 13:58:09.157333 99233 net.cpp:596] loss <- fc2
I1031 13:58:09.179443 99233 net.cpp:596] loss <- label
I1031 13:58:09.239850 99233 net.cpp:570] loss -> (automatic)
I1031 13:58:09.290808 99233 layer_factory.hpp:114] Creating layer loss
I1031 13:58:09.707228 99233 net.cpp:210] Setting up loss
I1031 13:58:09.715924 99233 net.cpp:217] Top shape: (1)
I1031 13:58:09.731835 99233 net.cpp:220]     with loss weight 1
I1031 13:58:09.864311 99233 net.cpp:225] Memory required for data: 32311504
I1031 13:58:09.919185 99233 net.cpp:287] loss needs backward computation.
I1031 13:58:10.023984 99233 net.cpp:287] fc2 needs backward computation.
I1031 13:58:10.037801 99233 net.cpp:287] dropout5 needs backward computation.
I1031 13:58:10.050591 99233 net.cpp:287] fc1 needs backward computation.
I1031 13:58:10.065822 99233 net.cpp:287] pool4 needs backward computation.
I1031 13:58:10.068573 99233 net.cpp:287] dropout4 needs backward computation.
I1031 13:58:10.068933 99233 net.cpp:287] relu4 needs backward computation.
I1031 13:58:10.078748 99233 net.cpp:287] conv4 needs backward computation.
I1031 13:58:10.095648 99233 net.cpp:287] pool3 needs backward computation.
I1031 13:58:10.109246 99233 net.cpp:287] dropout3 needs backward computation.
I1031 13:58:10.114076 99233 net.cpp:287] relu3 needs backward computation.
I1031 13:58:10.114401 99233 net.cpp:287] conv3 needs backward computation.
I1031 13:58:10.114738 99233 net.cpp:287] pool2 needs backward computation.
I1031 13:58:10.115001 99233 net.cpp:287] dropout2 needs backward computation.
I1031 13:58:10.115200 99233 net.cpp:287] relu2 needs backward computation.
I1031 13:58:10.115459 99233 net.cpp:287] conv2 needs backward computation.
I1031 13:58:10.115697 99233 net.cpp:287] pool1 needs backward computation.
I1031 13:58:10.115887 99233 net.cpp:287] dropout1 needs backward computation.
I1031 13:58:10.116077 99233 net.cpp:287] relu1 needs backward computation.
I1031 13:58:10.116264 99233 net.cpp:287] conv1 needs backward computation.
I1031 13:58:10.138890 99233 net.cpp:289] data does not need backward computation.
I1031 13:58:10.197340 99233 net.cpp:345] Network initialization done.
I1031 13:58:10.379904 99233 caffe.cpp:452] Performing Forward
I1031 13:58:22.184013 99233 caffe.cpp:457] Initial loss: 0
I1031 13:58:22.216436 99233 caffe.cpp:459] Performing Backward
I1031 13:58:25.594830 99233 caffe.cpp:468] *** Benchmark begins ***
I1031 13:58:25.617070 99233 caffe.cpp:469] Testing for 1 iterations.
I1031 13:58:25.775133 99233 caffe.cpp:485] Profiling Layer: dropout1 backward
I1031 13:58:27.913810 99233 caffe.cpp:512] Iteration: 1 forward-backward time: 2134 ms.
I1031 13:58:28.081574 99233 caffe.cpp:519] Average time per layer: 
I1031 13:58:28.098325 99233 caffe.cpp:522]       data	forward: 47.426 ms.
I1031 13:58:28.178275 99233 caffe.cpp:526]       data	backward: 7.63 ms.
I1031 13:58:28.233394 99233 caffe.cpp:522]      conv1	forward: 70.091 ms.
I1031 13:58:28.246515 99233 caffe.cpp:526]      conv1	backward: 45.862 ms.
I1031 13:58:28.253113 99233 caffe.cpp:522]      relu1	forward: 15.524 ms.
I1031 13:58:28.265702 99233 caffe.cpp:526]      relu1	backward: 63.121 ms.
I1031 13:58:28.277953 99233 caffe.cpp:522]   dropout1	forward: 48.799 ms.
I1031 13:58:28.278733 99233 caffe.cpp:526]   dropout1	backward: 79.74 ms.
I1031 13:58:28.278950 99233 caffe.cpp:522]      pool1	forward: 124.084 ms.
I1031 13:58:28.281867 99233 caffe.cpp:526]      pool1	backward: 132.744 ms.
I1031 13:58:28.284404 99233 caffe.cpp:522]      conv2	forward: 27.43 ms.
I1031 13:58:28.284806 99233 caffe.cpp:526]      conv2	backward: 81.793 ms.
I1031 13:58:28.285025 99233 caffe.cpp:522]      relu2	forward: 0.142 ms.
I1031 13:58:28.285233 99233 caffe.cpp:526]      relu2	backward: 33.204 ms.
I1031 13:58:28.285439 99233 caffe.cpp:522]   dropout2	forward: 8.213 ms.
I1031 13:58:28.286272 99233 caffe.cpp:526]   dropout2	backward: 29.096 ms.
I1031 13:58:28.286514 99233 caffe.cpp:522]      pool2	forward: 29.356 ms.
I1031 13:58:28.286720 99233 caffe.cpp:526]      pool2	backward: 69.224 ms.
I1031 13:58:28.286926 99233 caffe.cpp:522]      conv3	forward: 69.252 ms.
I1031 13:58:28.287129 99233 caffe.cpp:526]      conv3	backward: 65.028 ms.
I1031 13:58:28.287333 99233 caffe.cpp:522]      relu3	forward: 15.807 ms.
I1031 13:58:28.287633 99233 caffe.cpp:526]      relu3	backward: 38.508 ms.
I1031 13:58:28.287854 99233 caffe.cpp:522]   dropout3	forward: 47.615 ms.
I1031 13:58:28.288203 99233 caffe.cpp:526]   dropout3	backward: 25.12 ms.
I1031 13:58:28.288554 99233 caffe.cpp:522]      pool3	forward: 25.769 ms.
I1031 13:58:28.288864 99233 caffe.cpp:526]      pool3	backward: 49.482 ms.
I1031 13:58:28.289068 99233 caffe.cpp:522]      conv4	forward: 52.832 ms.
I1031 13:58:28.289273 99233 caffe.cpp:526]      conv4	backward: 83.782 ms.
I1031 13:58:28.289479 99233 caffe.cpp:522]      relu4	forward: 26.42 ms.
I1031 13:58:28.289687 99233 caffe.cpp:526]      relu4	backward: 41.547 ms.
I1031 13:58:28.289894 99233 caffe.cpp:522]   dropout4	forward: 71.148 ms.
I1031 13:58:28.290098 99233 caffe.cpp:526]   dropout4	backward: 53.909 ms.
I1031 13:58:28.290302 99233 caffe.cpp:522]      pool4	forward: 14.482 ms.
I1031 13:58:28.290503 99233 caffe.cpp:526]      pool4	backward: 33.07 ms.
I1031 13:58:28.290705 99233 caffe.cpp:522]        fc1	forward: 52.662 ms.
I1031 13:58:28.290907 99233 caffe.cpp:526]        fc1	backward: 50.303 ms.
I1031 13:58:28.291113 99233 caffe.cpp:522]   dropout5	forward: 44.566 ms.
I1031 13:58:28.291359 99233 caffe.cpp:526]   dropout5	backward: 17.458 ms.
I1031 13:58:28.291683 99233 caffe.cpp:522]        fc2	forward: 15.351 ms.
I1031 13:58:28.292014 99233 caffe.cpp:526]        fc2	backward: 0.209 ms.
I1031 13:58:28.292276 99233 caffe.cpp:522]       loss	forward: 173.144 ms.
I1031 13:58:28.292490 99233 caffe.cpp:526]       loss	backward: 55.259 ms.
I1031 13:58:28.298246 99233 caffe.cpp:532] Average Forward pass: 1040.01 ms.
I1031 13:58:28.312237 99233 caffe.cpp:535] Average Backward pass: 1065.58 ms.
I1031 13:58:28.324311 99233 caffe.cpp:537] Average Forward-Backward: 2632 ms.
I1031 13:58:28.339923 99233 caffe.cpp:540] Total Time: 2632 ms.
I1031 13:58:28.352661 99233 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 238144
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 3810304
--->Total double-precision FLOPs = 0
--->Total FLOPs = 3810304
mem-read-1 = 54246
mem-read-2 = 71
mem-read-4 = 576395
mem-read-8 = 980923
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 394945
mem-write-1 = 106
mem-write-2 = 34
mem-write-4 = 1277
mem-write-8 = 153366
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 244001
--->Total Bytes read = 35483864
--->Total Bytes written = 16848306
--->Total Bytes = 52332170

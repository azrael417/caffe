sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer14_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=14 -prof_forward_direction=0
I1031 15:03:08.141037 101619 caffe.cpp:444] Use CPU.
I1031 15:03:26.055652 101619 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 15:03:26.117506 101619 cpu_info.cpp:455] Total number of sockets: 1
I1031 15:03:26.130139 101619 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 15:03:26.142277 101619 cpu_info.cpp:461] Total number of processors: 256
I1031 15:03:26.160548 101619 cpu_info.cpp:464] GPU is used: no
I1031 15:03:26.169992 101619 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 15:03:26.179282 101619 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 15:03:26.191925 101619 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 15:03:35.323668 101619 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 15:03:36.017943 101619 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 15:03:38.436087 101619 layer_factory.hpp:114] Creating layer data
I1031 15:03:38.593327 101619 net.cpp:160] Creating Layer data
I1031 15:03:38.644356 101619 net.cpp:570] data -> data
I1031 15:03:39.143137 101619 net.cpp:570] data -> label
I1031 15:03:46.637063 101619 net.cpp:210] Setting up data
I1031 15:03:46.727967 101619 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 15:03:46.843325 101619 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 15:03:46.850899 101619 net.cpp:225] Memory required for data: 184516
I1031 15:03:46.931957 101619 layer_factory.hpp:114] Creating layer conv1
I1031 15:03:47.305878 101619 net.cpp:160] Creating Layer conv1
I1031 15:03:47.366374 101619 net.cpp:596] conv1 <- data
I1031 15:03:47.504042 101619 net.cpp:570] conv1 -> conv1
I1031 15:04:24.942029 101619 net.cpp:210] Setting up conv1
I1031 15:04:25.015314 101619 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:04:25.026873 101619 net.cpp:225] Memory required for data: 7805124
I1031 15:04:25.360343 101619 layer_factory.hpp:114] Creating layer relu1
I1031 15:04:25.502516 101619 net.cpp:160] Creating Layer relu1
I1031 15:04:25.507745 101619 net.cpp:596] relu1 <- conv1
I1031 15:04:25.542762 101619 net.cpp:557] relu1 -> conv1 (in-place)
I1031 15:04:25.761360 101619 net.cpp:210] Setting up relu1
I1031 15:04:25.764035 101619 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:04:25.764394 101619 net.cpp:225] Memory required for data: 15425732
I1031 15:04:25.764601 101619 layer_factory.hpp:114] Creating layer dropout1
I1031 15:04:25.796891 101619 net.cpp:160] Creating Layer dropout1
I1031 15:04:25.797229 101619 net.cpp:596] dropout1 <- conv1
I1031 15:04:25.800108 101619 net.cpp:570] dropout1 -> drop1
I1031 15:04:25.927625 101619 net.cpp:210] Setting up dropout1
I1031 15:04:25.942433 101619 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:04:25.942944 101619 net.cpp:225] Memory required for data: 23046340
I1031 15:04:25.943316 101619 layer_factory.hpp:114] Creating layer pool1
I1031 15:04:26.050595 101619 net.cpp:160] Creating Layer pool1
I1031 15:04:26.050956 101619 net.cpp:596] pool1 <- drop1
I1031 15:04:26.051443 101619 net.cpp:570] pool1 -> pool1
I1031 15:04:26.476229 101619 net.cpp:210] Setting up pool1
I1031 15:04:26.481505 101619 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 15:04:26.481889 101619 net.cpp:225] Memory required for data: 24951492
I1031 15:04:26.482208 101619 layer_factory.hpp:114] Creating layer conv2
I1031 15:04:26.544960 101619 net.cpp:160] Creating Layer conv2
I1031 15:04:26.549439 101619 net.cpp:596] conv2 <- pool1
I1031 15:04:26.564859 101619 net.cpp:570] conv2 -> conv2
I1031 15:04:33.398581 101619 net.cpp:210] Setting up conv2
I1031 15:04:33.409281 101619 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:04:33.422494 101619 net.cpp:225] Memory required for data: 26733764
I1031 15:04:33.493263 101619 layer_factory.hpp:114] Creating layer relu2
I1031 15:04:33.508375 101619 net.cpp:160] Creating Layer relu2
I1031 15:04:33.510195 101619 net.cpp:596] relu2 <- conv2
I1031 15:04:33.513284 101619 net.cpp:557] relu2 -> conv2 (in-place)
I1031 15:04:33.518774 101619 net.cpp:210] Setting up relu2
I1031 15:04:33.523397 101619 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:04:33.534188 101619 net.cpp:225] Memory required for data: 28516036
I1031 15:04:33.542655 101619 layer_factory.hpp:114] Creating layer dropout2
I1031 15:04:33.544761 101619 net.cpp:160] Creating Layer dropout2
I1031 15:04:33.549474 101619 net.cpp:596] dropout2 <- conv2
I1031 15:04:33.556306 101619 net.cpp:570] dropout2 -> drop2
I1031 15:04:33.560449 101619 net.cpp:210] Setting up dropout2
I1031 15:04:33.565110 101619 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:04:33.573714 101619 net.cpp:225] Memory required for data: 30298308
I1031 15:04:33.580067 101619 layer_factory.hpp:114] Creating layer pool2
I1031 15:04:33.584576 101619 net.cpp:160] Creating Layer pool2
I1031 15:04:33.590914 101619 net.cpp:596] pool2 <- drop2
I1031 15:04:33.599594 101619 net.cpp:570] pool2 -> pool2
I1031 15:04:33.612257 101619 net.cpp:210] Setting up pool2
I1031 15:04:33.616654 101619 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 15:04:33.620949 101619 net.cpp:225] Memory required for data: 30759108
I1031 15:04:33.623489 101619 layer_factory.hpp:114] Creating layer conv3
I1031 15:04:33.626060 101619 net.cpp:160] Creating Layer conv3
I1031 15:04:33.634495 101619 net.cpp:596] conv3 <- pool2
I1031 15:04:33.642906 101619 net.cpp:570] conv3 -> conv3
I1031 15:04:34.254600 101619 net.cpp:210] Setting up conv3
I1031 15:04:34.261070 101619 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:04:34.269510 101619 net.cpp:225] Memory required for data: 31160516
I1031 15:04:34.291404 101619 layer_factory.hpp:114] Creating layer relu3
I1031 15:04:34.296063 101619 net.cpp:160] Creating Layer relu3
I1031 15:04:34.308423 101619 net.cpp:596] relu3 <- conv3
I1031 15:04:34.318840 101619 net.cpp:557] relu3 -> conv3 (in-place)
I1031 15:04:34.329545 101619 net.cpp:210] Setting up relu3
I1031 15:04:34.338145 101619 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:04:34.344406 101619 net.cpp:225] Memory required for data: 31561924
I1031 15:04:34.350754 101619 layer_factory.hpp:114] Creating layer dropout3
I1031 15:04:34.355214 101619 net.cpp:160] Creating Layer dropout3
I1031 15:04:34.357571 101619 net.cpp:596] dropout3 <- conv3
I1031 15:04:34.364198 101619 net.cpp:570] dropout3 -> drop3
I1031 15:04:34.370565 101619 net.cpp:210] Setting up dropout3
I1031 15:04:34.373072 101619 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:04:34.381517 101619 net.cpp:225] Memory required for data: 31963332
I1031 15:04:34.384011 101619 layer_factory.hpp:114] Creating layer pool3
I1031 15:04:34.386539 101619 net.cpp:160] Creating Layer pool3
I1031 15:04:34.386831 101619 net.cpp:596] pool3 <- drop3
I1031 15:04:34.387105 101619 net.cpp:570] pool3 -> pool3
I1031 15:04:34.399852 101619 net.cpp:210] Setting up pool3
I1031 15:04:34.413075 101619 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 15:04:34.420064 101619 net.cpp:225] Memory required for data: 32063684
I1031 15:04:34.421795 101619 layer_factory.hpp:114] Creating layer conv4
I1031 15:04:34.426046 101619 net.cpp:160] Creating Layer conv4
I1031 15:04:34.429450 101619 net.cpp:596] conv4 <- pool3
I1031 15:04:34.494555 101619 net.cpp:570] conv4 -> conv4
I1031 15:04:34.838142 101619 net.cpp:210] Setting up conv4
I1031 15:04:34.848609 101619 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:04:34.855317 101619 net.cpp:225] Memory required for data: 32137412
I1031 15:04:34.867977 101619 layer_factory.hpp:114] Creating layer relu4
I1031 15:04:34.872608 101619 net.cpp:160] Creating Layer relu4
I1031 15:04:34.881238 101619 net.cpp:596] relu4 <- conv4
I1031 15:04:34.887778 101619 net.cpp:557] relu4 -> conv4 (in-place)
I1031 15:04:34.896368 101619 net.cpp:210] Setting up relu4
I1031 15:04:34.906639 101619 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:04:34.915102 101619 net.cpp:225] Memory required for data: 32211140
I1031 15:04:34.919411 101619 layer_factory.hpp:114] Creating layer dropout4
I1031 15:04:34.928036 101619 net.cpp:160] Creating Layer dropout4
I1031 15:04:34.934216 101619 net.cpp:596] dropout4 <- conv4
I1031 15:04:34.942694 101619 net.cpp:570] dropout4 -> drop4
I1031 15:04:34.951632 101619 net.cpp:210] Setting up dropout4
I1031 15:04:34.955868 101619 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:04:34.962505 101619 net.cpp:225] Memory required for data: 32284868
I1031 15:04:34.973254 101619 layer_factory.hpp:114] Creating layer pool4
I1031 15:04:34.977591 101619 net.cpp:160] Creating Layer pool4
I1031 15:04:34.986621 101619 net.cpp:596] pool4 <- drop4
I1031 15:04:34.995031 101619 net.cpp:570] pool4 -> pool4
I1031 15:04:35.021700 101619 net.cpp:210] Setting up pool4
I1031 15:04:35.026381 101619 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 15:04:35.038478 101619 net.cpp:225] Memory required for data: 32303300
I1031 15:04:35.038818 101619 layer_factory.hpp:114] Creating layer fc1
I1031 15:04:35.103257 101619 net.cpp:160] Creating Layer fc1
I1031 15:04:35.103639 101619 net.cpp:596] fc1 <- pool4
I1031 15:04:35.104051 101619 net.cpp:570] fc1 -> fc1
I1031 15:04:35.999966 101619 net.cpp:210] Setting up fc1
I1031 15:04:36.004346 101619 net.cpp:217] Top shape: 1 1024 (1024)
I1031 15:04:36.011965 101619 net.cpp:225] Memory required for data: 32307396
I1031 15:04:36.028435 101619 layer_factory.hpp:114] Creating layer dropout5
I1031 15:04:36.039113 101619 net.cpp:160] Creating Layer dropout5
I1031 15:04:36.043892 101619 net.cpp:596] dropout5 <- fc1
I1031 15:04:36.045786 101619 net.cpp:570] dropout5 -> drop5
I1031 15:04:36.057232 101619 net.cpp:210] Setting up dropout5
I1031 15:04:36.059489 101619 net.cpp:217] Top shape: 1 1024 (1024)
I1031 15:04:36.059866 101619 net.cpp:225] Memory required for data: 32311492
I1031 15:04:36.074471 101619 layer_factory.hpp:114] Creating layer fc2
I1031 15:04:36.080945 101619 net.cpp:160] Creating Layer fc2
I1031 15:04:36.085578 101619 net.cpp:596] fc2 <- drop5
I1031 15:04:36.090601 101619 net.cpp:570] fc2 -> fc2
I1031 15:04:36.117471 101619 net.cpp:210] Setting up fc2
I1031 15:04:36.124397 101619 net.cpp:217] Top shape: 1 2 (2)
I1031 15:04:36.134982 101619 net.cpp:225] Memory required for data: 32311500
I1031 15:04:36.139683 101619 layer_factory.hpp:114] Creating layer loss
I1031 15:04:36.174217 101619 net.cpp:160] Creating Layer loss
I1031 15:04:36.182652 101619 net.cpp:596] loss <- fc2
I1031 15:04:36.197398 101619 net.cpp:596] loss <- label
I1031 15:04:36.259197 101619 net.cpp:570] loss -> (automatic)
I1031 15:04:36.316144 101619 layer_factory.hpp:114] Creating layer loss
I1031 15:04:36.739158 101619 net.cpp:210] Setting up loss
I1031 15:04:36.748411 101619 net.cpp:217] Top shape: (1)
I1031 15:04:36.762567 101619 net.cpp:220]     with loss weight 1
I1031 15:04:36.899852 101619 net.cpp:225] Memory required for data: 32311504
I1031 15:04:36.949337 101619 net.cpp:287] loss needs backward computation.
I1031 15:04:37.053491 101619 net.cpp:287] fc2 needs backward computation.
I1031 15:04:37.072331 101619 net.cpp:287] dropout5 needs backward computation.
I1031 15:04:37.084406 101619 net.cpp:287] fc1 needs backward computation.
I1031 15:04:37.092175 101619 net.cpp:287] pool4 needs backward computation.
I1031 15:04:37.096753 101619 net.cpp:287] dropout4 needs backward computation.
I1031 15:04:37.101490 101619 net.cpp:287] relu4 needs backward computation.
I1031 15:04:37.116063 101619 net.cpp:287] conv4 needs backward computation.
I1031 15:04:37.136044 101619 net.cpp:287] pool3 needs backward computation.
I1031 15:04:37.150002 101619 net.cpp:287] dropout3 needs backward computation.
I1031 15:04:37.154918 101619 net.cpp:287] relu3 needs backward computation.
I1031 15:04:37.155254 101619 net.cpp:287] conv3 needs backward computation.
I1031 15:04:37.155644 101619 net.cpp:287] pool2 needs backward computation.
I1031 15:04:37.155900 101619 net.cpp:287] dropout2 needs backward computation.
I1031 15:04:37.156114 101619 net.cpp:287] relu2 needs backward computation.
I1031 15:04:37.156321 101619 net.cpp:287] conv2 needs backward computation.
I1031 15:04:37.156529 101619 net.cpp:287] pool1 needs backward computation.
I1031 15:04:37.156738 101619 net.cpp:287] dropout1 needs backward computation.
I1031 15:04:37.156946 101619 net.cpp:287] relu1 needs backward computation.
I1031 15:04:37.157147 101619 net.cpp:287] conv1 needs backward computation.
I1031 15:04:37.177470 101619 net.cpp:289] data does not need backward computation.
I1031 15:04:37.234910 101619 net.cpp:345] Network initialization done.
I1031 15:04:37.419942 101619 caffe.cpp:452] Performing Forward
I1031 15:04:49.487633 101619 caffe.cpp:457] Initial loss: 87.3365
I1031 15:04:49.618033 101619 caffe.cpp:459] Performing Backward
I1031 15:04:53.032162 101619 caffe.cpp:468] *** Benchmark begins ***
I1031 15:04:53.049643 101619 caffe.cpp:469] Testing for 1 iterations.
I1031 15:04:53.212653 101619 caffe.cpp:485] Profiling Layer: relu4 backward
I1031 15:04:54.888263 101619 caffe.cpp:512] Iteration: 1 forward-backward time: 1672 ms.
I1031 15:04:54.981201 101619 caffe.cpp:519] Average time per layer: 
I1031 15:04:54.999281 101619 caffe.cpp:522]       data	forward: 47.049 ms.
I1031 15:04:55.080147 101619 caffe.cpp:526]       data	backward: 8.142 ms.
I1031 15:04:55.113912 101619 caffe.cpp:522]      conv1	forward: 66.821 ms.
I1031 15:04:55.116935 101619 caffe.cpp:526]      conv1	backward: 49.807 ms.
I1031 15:04:55.119297 101619 caffe.cpp:522]      relu1	forward: 35.361 ms.
I1031 15:04:55.119660 101619 caffe.cpp:526]      relu1	backward: 57.867 ms.
I1031 15:04:55.119889 101619 caffe.cpp:522]   dropout1	forward: 96.269 ms.
I1031 15:04:55.120208 101619 caffe.cpp:526]   dropout1	backward: 56.349 ms.
I1031 15:04:55.120524 101619 caffe.cpp:522]      pool1	forward: 127.493 ms.
I1031 15:04:55.125097 101619 caffe.cpp:526]      pool1	backward: 137.843 ms.
I1031 15:04:55.125363 101619 caffe.cpp:522]      conv2	forward: 27.447 ms.
I1031 15:04:55.125572 101619 caffe.cpp:526]      conv2	backward: 67.621 ms.
I1031 15:04:55.125780 101619 caffe.cpp:522]      relu2	forward: 0.135 ms.
I1031 15:04:55.125982 101619 caffe.cpp:526]      relu2	backward: 42.675 ms.
I1031 15:04:55.126185 101619 caffe.cpp:522]   dropout2	forward: 10.842 ms.
I1031 15:04:55.129039 101619 caffe.cpp:526]   dropout2	backward: 54.559 ms.
I1031 15:04:55.129300 101619 caffe.cpp:522]      pool2	forward: 29.7 ms.
I1031 15:04:55.129509 101619 caffe.cpp:526]      pool2	backward: 62.608 ms.
I1031 15:04:55.129719 101619 caffe.cpp:522]      conv3	forward: 2.211 ms.
I1031 15:04:55.129920 101619 caffe.cpp:526]      conv3	backward: 76.102 ms.
I1031 15:04:55.130122 101619 caffe.cpp:522]      relu3	forward: 0.084 ms.
I1031 15:04:55.149161 101619 caffe.cpp:526]      relu3	backward: 45.658 ms.
I1031 15:04:55.149580 101619 caffe.cpp:522]   dropout3	forward: 4.649 ms.
I1031 15:04:55.149953 101619 caffe.cpp:526]   dropout3	backward: 51.56 ms.
I1031 15:04:55.150197 101619 caffe.cpp:522]      pool3	forward: 6.675 ms.
I1031 15:04:55.150398 101619 caffe.cpp:526]      pool3	backward: 61.113 ms.
I1031 15:04:55.150604 101619 caffe.cpp:522]      conv4	forward: 0.734 ms.
I1031 15:04:55.150805 101619 caffe.cpp:526]      conv4	backward: 92.307 ms.
I1031 15:04:55.151010 101619 caffe.cpp:522]      relu4	forward: 0.054 ms.
I1031 15:04:55.153882 101619 caffe.cpp:526]      relu4	backward: 60.38 ms.
I1031 15:04:55.154152 101619 caffe.cpp:522]   dropout4	forward: 0.508 ms.
I1031 15:04:55.154362 101619 caffe.cpp:526]   dropout4	backward: 56.273 ms.
I1031 15:04:55.154568 101619 caffe.cpp:522]      pool4	forward: 1.3 ms.
I1031 15:04:55.154767 101619 caffe.cpp:526]      pool4	backward: 28.569 ms.
I1031 15:04:55.155009 101619 caffe.cpp:522]        fc1	forward: 1.022 ms.
I1031 15:04:55.155230 101619 caffe.cpp:526]        fc1	backward: 22.545 ms.
I1031 15:04:55.155669 101619 caffe.cpp:522]   dropout5	forward: 0.173 ms.
I1031 15:04:55.155946 101619 caffe.cpp:526]   dropout5	backward: 0.067 ms.
I1031 15:04:55.156168 101619 caffe.cpp:522]        fc2	forward: 0.103 ms.
I1031 15:04:55.157032 101619 caffe.cpp:526]        fc2	backward: 0.204 ms.
I1031 15:04:55.157289 101619 caffe.cpp:522]       loss	forward: 47.722 ms.
I1031 15:04:55.157513 101619 caffe.cpp:526]       loss	backward: 34.564 ms.
I1031 15:04:55.163444 101619 caffe.cpp:532] Average Forward pass: 566.557 ms.
I1031 15:04:55.177172 101619 caffe.cpp:535] Average Backward pass: 1076.79 ms.
I1031 15:04:55.188874 101619 caffe.cpp:537] Average Forward-Backward: 2060 ms.
I1031 15:04:55.204483 101619 caffe.cpp:540] Total Time: 2060 ms.
I1031 15:04:55.217437 101619 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 1152
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 2304
--->Total FLOPs = 2304
mem-read-1 = 54279
mem-read-2 = 69
mem-read-4 = 435926
mem-read-8 = 635140
mem-read-16 = 0
mem-read-32 = 4610
mem-read-64 = 6946
mem-write-1 = 102
mem-write-2 = 34
mem-write-4 = 19528
mem-write-8 = 63220
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 1154
--->Total Bytes read = 7471305
--->Total Bytes written = 657962
--->Total Bytes = 8129267

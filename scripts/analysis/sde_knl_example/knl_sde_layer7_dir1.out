sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer7_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=7 -prof_forward_direction=1
I1031 12:09:50.621989 95375 caffe.cpp:444] Use CPU.
I1031 12:10:08.527504 95375 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 12:10:08.590339 95375 cpu_info.cpp:455] Total number of sockets: 1
I1031 12:10:08.603332 95375 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 12:10:08.615267 95375 cpu_info.cpp:461] Total number of processors: 256
I1031 12:10:08.632377 95375 cpu_info.cpp:464] GPU is used: no
I1031 12:10:08.641706 95375 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 12:10:08.650586 95375 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 12:10:08.662374 95375 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 12:10:17.943680 95375 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 12:10:18.665990 95375 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 12:10:21.170925 95375 layer_factory.hpp:114] Creating layer data
I1031 12:10:21.328143 95375 net.cpp:160] Creating Layer data
I1031 12:10:21.379201 95375 net.cpp:570] data -> data
I1031 12:10:21.872341 95375 net.cpp:570] data -> label
I1031 12:10:29.319589 95375 net.cpp:210] Setting up data
I1031 12:10:29.403743 95375 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 12:10:29.509615 95375 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 12:10:29.516985 95375 net.cpp:225] Memory required for data: 184516
I1031 12:10:29.599524 95375 layer_factory.hpp:114] Creating layer conv1
I1031 12:10:29.946676 95375 net.cpp:160] Creating Layer conv1
I1031 12:10:30.000669 95375 net.cpp:596] conv1 <- data
I1031 12:10:30.135278 95375 net.cpp:570] conv1 -> conv1
I1031 12:11:07.371266 95375 net.cpp:210] Setting up conv1
I1031 12:11:07.522253 95375 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:11:07.527758 95375 net.cpp:225] Memory required for data: 7805124
I1031 12:11:07.833598 95375 layer_factory.hpp:114] Creating layer relu1
I1031 12:11:07.968868 95375 net.cpp:160] Creating Layer relu1
I1031 12:11:07.973906 95375 net.cpp:596] relu1 <- conv1
I1031 12:11:08.010540 95375 net.cpp:557] relu1 -> conv1 (in-place)
I1031 12:11:08.228759 95375 net.cpp:210] Setting up relu1
I1031 12:11:08.231667 95375 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:11:08.232045 95375 net.cpp:225] Memory required for data: 15425732
I1031 12:11:08.232264 95375 layer_factory.hpp:114] Creating layer dropout1
I1031 12:11:08.264837 95375 net.cpp:160] Creating Layer dropout1
I1031 12:11:08.265171 95375 net.cpp:596] dropout1 <- conv1
I1031 12:11:08.268054 95375 net.cpp:570] dropout1 -> drop1
I1031 12:11:08.380890 95375 net.cpp:210] Setting up dropout1
I1031 12:11:08.394459 95375 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:11:08.394860 95375 net.cpp:225] Memory required for data: 23046340
I1031 12:11:08.395212 95375 layer_factory.hpp:114] Creating layer pool1
I1031 12:11:08.504957 95375 net.cpp:160] Creating Layer pool1
I1031 12:11:08.507643 95375 net.cpp:596] pool1 <- drop1
I1031 12:11:08.507994 95375 net.cpp:570] pool1 -> pool1
I1031 12:11:08.938026 95375 net.cpp:210] Setting up pool1
I1031 12:11:08.943285 95375 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 12:11:08.943876 95375 net.cpp:225] Memory required for data: 24951492
I1031 12:11:08.944291 95375 layer_factory.hpp:114] Creating layer conv2
I1031 12:11:09.010166 95375 net.cpp:160] Creating Layer conv2
I1031 12:11:09.014817 95375 net.cpp:596] conv2 <- pool1
I1031 12:11:09.031455 95375 net.cpp:570] conv2 -> conv2
I1031 12:11:15.990473 95375 net.cpp:210] Setting up conv2
I1031 12:11:15.997189 95375 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:11:16.008605 95375 net.cpp:225] Memory required for data: 26733764
I1031 12:11:16.076119 95375 layer_factory.hpp:114] Creating layer relu2
I1031 12:11:16.086948 95375 net.cpp:160] Creating Layer relu2
I1031 12:11:16.092092 95375 net.cpp:596] relu2 <- conv2
I1031 12:11:16.100656 95375 net.cpp:557] relu2 -> conv2 (in-place)
I1031 12:11:16.108079 95375 net.cpp:210] Setting up relu2
I1031 12:11:16.116438 95375 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:11:16.123253 95375 net.cpp:225] Memory required for data: 28516036
I1031 12:11:16.133231 95375 layer_factory.hpp:114] Creating layer dropout2
I1031 12:11:16.137689 95375 net.cpp:160] Creating Layer dropout2
I1031 12:11:16.145490 95375 net.cpp:596] dropout2 <- conv2
I1031 12:11:16.150817 95375 net.cpp:570] dropout2 -> drop2
I1031 12:11:16.153460 95375 net.cpp:210] Setting up dropout2
I1031 12:11:16.155720 95375 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:11:16.164510 95375 net.cpp:225] Memory required for data: 30298308
I1031 12:11:16.168931 95375 layer_factory.hpp:114] Creating layer pool2
I1031 12:11:16.177384 95375 net.cpp:160] Creating Layer pool2
I1031 12:11:16.187499 95375 net.cpp:596] pool2 <- drop2
I1031 12:11:16.194264 95375 net.cpp:570] pool2 -> pool2
I1031 12:11:16.202852 95375 net.cpp:210] Setting up pool2
I1031 12:11:16.204876 95375 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 12:11:16.211611 95375 net.cpp:225] Memory required for data: 30759108
I1031 12:11:16.220108 95375 layer_factory.hpp:114] Creating layer conv3
I1031 12:11:16.228312 95375 net.cpp:160] Creating Layer conv3
I1031 12:11:16.232704 95375 net.cpp:596] conv3 <- pool2
I1031 12:11:16.241581 95375 net.cpp:570] conv3 -> conv3
I1031 12:11:16.820039 95375 net.cpp:210] Setting up conv3
I1031 12:11:16.828796 95375 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:11:16.839334 95375 net.cpp:225] Memory required for data: 31160516
I1031 12:11:16.861789 95375 layer_factory.hpp:114] Creating layer relu3
I1031 12:11:16.868342 95375 net.cpp:160] Creating Layer relu3
I1031 12:11:16.876921 95375 net.cpp:596] relu3 <- conv3
I1031 12:11:16.881263 95375 net.cpp:557] relu3 -> conv3 (in-place)
I1031 12:11:16.883777 95375 net.cpp:210] Setting up relu3
I1031 12:11:16.892388 95375 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:11:16.900823 95375 net.cpp:225] Memory required for data: 31561924
I1031 12:11:16.909513 95375 layer_factory.hpp:114] Creating layer dropout3
I1031 12:11:16.917964 95375 net.cpp:160] Creating Layer dropout3
I1031 12:11:16.924387 95375 net.cpp:596] dropout3 <- conv3
I1031 12:11:16.932760 95375 net.cpp:570] dropout3 -> drop3
I1031 12:11:16.943647 95375 net.cpp:210] Setting up dropout3
I1031 12:11:16.945930 95375 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:11:16.950264 95375 net.cpp:225] Memory required for data: 31963332
I1031 12:11:16.958784 95375 layer_factory.hpp:114] Creating layer pool3
I1031 12:11:16.964632 95375 net.cpp:160] Creating Layer pool3
I1031 12:11:16.969471 95375 net.cpp:596] pool3 <- drop3
I1031 12:11:16.978245 95375 net.cpp:570] pool3 -> pool3
I1031 12:11:16.987054 95375 net.cpp:210] Setting up pool3
I1031 12:11:16.991624 95375 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 12:11:16.997740 95375 net.cpp:225] Memory required for data: 32063684
I1031 12:11:17.006569 95375 layer_factory.hpp:114] Creating layer conv4
I1031 12:11:17.013028 95375 net.cpp:160] Creating Layer conv4
I1031 12:11:17.017560 95375 net.cpp:596] conv4 <- pool3
I1031 12:11:17.019186 95375 net.cpp:570] conv4 -> conv4
I1031 12:11:17.399021 95375 net.cpp:210] Setting up conv4
I1031 12:11:17.399305 95375 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:11:17.399705 95375 net.cpp:225] Memory required for data: 32137412
I1031 12:11:17.400019 95375 layer_factory.hpp:114] Creating layer relu4
I1031 12:11:17.400298 95375 net.cpp:160] Creating Layer relu4
I1031 12:11:17.400507 95375 net.cpp:596] relu4 <- conv4
I1031 12:11:17.400760 95375 net.cpp:557] relu4 -> conv4 (in-place)
I1031 12:11:17.401212 95375 net.cpp:210] Setting up relu4
I1031 12:11:17.401475 95375 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:11:17.401718 95375 net.cpp:225] Memory required for data: 32211140
I1031 12:11:17.401921 95375 layer_factory.hpp:114] Creating layer dropout4
I1031 12:11:17.402160 95375 net.cpp:160] Creating Layer dropout4
I1031 12:11:17.402364 95375 net.cpp:596] dropout4 <- conv4
I1031 12:11:17.402674 95375 net.cpp:570] dropout4 -> drop4
I1031 12:11:17.403053 95375 net.cpp:210] Setting up dropout4
I1031 12:11:17.403272 95375 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:11:17.403568 95375 net.cpp:225] Memory required for data: 32284868
I1031 12:11:17.403774 95375 layer_factory.hpp:114] Creating layer pool4
I1031 12:11:17.404069 95375 net.cpp:160] Creating Layer pool4
I1031 12:11:17.404283 95375 net.cpp:596] pool4 <- drop4
I1031 12:11:17.404521 95375 net.cpp:570] pool4 -> pool4
I1031 12:11:17.418473 95375 net.cpp:210] Setting up pool4
I1031 12:11:17.418834 95375 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 12:11:17.421393 95375 net.cpp:225] Memory required for data: 32303300
I1031 12:11:17.421653 95375 layer_factory.hpp:114] Creating layer fc1
I1031 12:11:17.484184 95375 net.cpp:160] Creating Layer fc1
I1031 12:11:17.492754 95375 net.cpp:596] fc1 <- pool4
I1031 12:11:17.499207 95375 net.cpp:570] fc1 -> fc1
I1031 12:11:18.371253 95375 net.cpp:210] Setting up fc1
I1031 12:11:18.377781 95375 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:11:18.384488 95375 net.cpp:225] Memory required for data: 32307396
I1031 12:11:18.395774 95375 layer_factory.hpp:114] Creating layer dropout5
I1031 12:11:18.406270 95375 net.cpp:160] Creating Layer dropout5
I1031 12:11:18.414636 95375 net.cpp:596] dropout5 <- fc1
I1031 12:11:18.422763 95375 net.cpp:570] dropout5 -> drop5
I1031 12:11:18.428007 95375 net.cpp:210] Setting up dropout5
I1031 12:11:18.432586 95375 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:11:18.443298 95375 net.cpp:225] Memory required for data: 32311492
I1031 12:11:18.455312 95375 layer_factory.hpp:114] Creating layer fc2
I1031 12:11:18.457213 95375 net.cpp:160] Creating Layer fc2
I1031 12:11:18.464153 95375 net.cpp:596] fc2 <- drop5
I1031 12:11:18.471882 95375 net.cpp:570] fc2 -> fc2
I1031 12:11:18.506788 95375 net.cpp:210] Setting up fc2
I1031 12:11:18.516894 95375 net.cpp:217] Top shape: 1 2 (2)
I1031 12:11:18.529384 95375 net.cpp:225] Memory required for data: 32311500
I1031 12:11:18.536195 95375 layer_factory.hpp:114] Creating layer loss
I1031 12:11:18.569003 95375 net.cpp:160] Creating Layer loss
I1031 12:11:18.577436 95375 net.cpp:596] loss <- fc2
I1031 12:11:18.590982 95375 net.cpp:596] loss <- label
I1031 12:11:18.655278 95375 net.cpp:570] loss -> (automatic)
I1031 12:11:18.709656 95375 layer_factory.hpp:114] Creating layer loss
I1031 12:11:19.136817 95375 net.cpp:210] Setting up loss
I1031 12:11:19.147148 95375 net.cpp:217] Top shape: (1)
I1031 12:11:19.160305 95375 net.cpp:220]     with loss weight 1
I1031 12:11:19.296664 95375 net.cpp:225] Memory required for data: 32311504
I1031 12:11:19.347785 95375 net.cpp:287] loss needs backward computation.
I1031 12:11:19.454684 95375 net.cpp:287] fc2 needs backward computation.
I1031 12:11:19.471019 95375 net.cpp:287] dropout5 needs backward computation.
I1031 12:11:19.481511 95375 net.cpp:287] fc1 needs backward computation.
I1031 12:11:19.498498 95375 net.cpp:287] pool4 needs backward computation.
I1031 12:11:19.500629 95375 net.cpp:287] dropout4 needs backward computation.
I1031 12:11:19.500962 95375 net.cpp:287] relu4 needs backward computation.
I1031 12:11:19.510908 95375 net.cpp:287] conv4 needs backward computation.
I1031 12:11:19.528151 95375 net.cpp:287] pool3 needs backward computation.
I1031 12:11:19.541882 95375 net.cpp:287] dropout3 needs backward computation.
I1031 12:11:19.546664 95375 net.cpp:287] relu3 needs backward computation.
I1031 12:11:19.547001 95375 net.cpp:287] conv3 needs backward computation.
I1031 12:11:19.547339 95375 net.cpp:287] pool2 needs backward computation.
I1031 12:11:19.547650 95375 net.cpp:287] dropout2 needs backward computation.
I1031 12:11:19.547853 95375 net.cpp:287] relu2 needs backward computation.
I1031 12:11:19.548043 95375 net.cpp:287] conv2 needs backward computation.
I1031 12:11:19.548238 95375 net.cpp:287] pool1 needs backward computation.
I1031 12:11:19.548430 95375 net.cpp:287] dropout1 needs backward computation.
I1031 12:11:19.548621 95375 net.cpp:287] relu1 needs backward computation.
I1031 12:11:19.548807 95375 net.cpp:287] conv1 needs backward computation.
I1031 12:11:19.568979 95375 net.cpp:289] data does not need backward computation.
I1031 12:11:19.626097 95375 net.cpp:345] Network initialization done.
I1031 12:11:19.810097 95375 caffe.cpp:452] Performing Forward
I1031 12:11:31.614948 95375 caffe.cpp:457] Initial loss: 0
I1031 12:11:31.655246 95375 caffe.cpp:459] Performing Backward
I1031 12:11:35.041811 95375 caffe.cpp:468] *** Benchmark begins ***
I1031 12:11:35.061626 95375 caffe.cpp:469] Testing for 1 iterations.
I1031 12:11:35.222224 95375 caffe.cpp:482] Profiling Layer: dropout2 forward
I1031 12:11:36.871325 95375 caffe.cpp:512] Iteration: 1 forward-backward time: 1646 ms.
I1031 12:11:37.041990 95375 caffe.cpp:519] Average time per layer: 
I1031 12:11:37.058403 95375 caffe.cpp:522]       data	forward: 53.918 ms.
I1031 12:11:37.147300 95375 caffe.cpp:526]       data	backward: 7.627 ms.
I1031 12:11:37.176709 95375 caffe.cpp:522]      conv1	forward: 55.155 ms.
I1031 12:11:37.189576 95375 caffe.cpp:526]      conv1	backward: 32.121 ms.
I1031 12:11:37.195920 95375 caffe.cpp:522]      relu1	forward: 29.018 ms.
I1031 12:11:37.200826 95375 caffe.cpp:526]      relu1	backward: 70.079 ms.
I1031 12:11:37.206347 95375 caffe.cpp:522]   dropout1	forward: 76.775 ms.
I1031 12:11:37.211313 95375 caffe.cpp:526]   dropout1	backward: 64.636 ms.
I1031 12:11:37.214779 95375 caffe.cpp:522]      pool1	forward: 128.494 ms.
I1031 12:11:37.222666 95375 caffe.cpp:526]      pool1	backward: 152.211 ms.
I1031 12:11:37.228993 95375 caffe.cpp:522]      conv2	forward: 27.549 ms.
I1031 12:11:37.232899 95375 caffe.cpp:526]      conv2	backward: 79.993 ms.
I1031 12:11:37.236773 95375 caffe.cpp:522]      relu2	forward: 0.132 ms.
I1031 12:11:37.240094 95375 caffe.cpp:526]      relu2	backward: 28.004 ms.
I1031 12:11:37.240492 95375 caffe.cpp:522]   dropout2	forward: 19.49 ms.
I1031 12:11:37.247088 95375 caffe.cpp:526]   dropout2	backward: 36.304 ms.
I1031 12:11:37.248714 95375 caffe.cpp:522]      pool2	forward: 30.199 ms.
I1031 12:11:37.255831 95375 caffe.cpp:526]      pool2	backward: 63.993 ms.
I1031 12:11:37.262092 95375 caffe.cpp:522]      conv3	forward: 2.207 ms.
I1031 12:11:37.265636 95375 caffe.cpp:526]      conv3	backward: 77.685 ms.
I1031 12:11:37.272202 95375 caffe.cpp:522]      relu3	forward: 0.095 ms.
I1031 12:11:37.296003 95375 caffe.cpp:526]      relu3	backward: 26.288 ms.
I1031 12:11:37.300631 95375 caffe.cpp:522]   dropout3	forward: 4.765 ms.
I1031 12:11:37.310067 95375 caffe.cpp:526]   dropout3	backward: 44.764 ms.
I1031 12:11:37.315079 95375 caffe.cpp:522]      pool3	forward: 6.798 ms.
I1031 12:11:37.319881 95375 caffe.cpp:526]      pool3	backward: 67.351 ms.
I1031 12:11:37.326256 95375 caffe.cpp:522]      conv4	forward: 0.733 ms.
I1031 12:11:37.332824 95375 caffe.cpp:526]      conv4	backward: 74.294 ms.
I1031 12:11:37.336905 95375 caffe.cpp:522]      relu4	forward: 0.069 ms.
I1031 12:11:37.348865 95375 caffe.cpp:526]      relu4	backward: 50.106 ms.
I1031 12:11:37.349614 95375 caffe.cpp:522]   dropout4	forward: 0.572 ms.
I1031 12:11:37.349843 95375 caffe.cpp:526]   dropout4	backward: 52.773 ms.
I1031 12:11:37.350061 95375 caffe.cpp:522]      pool4	forward: 1.327 ms.
I1031 12:11:37.350272 95375 caffe.cpp:526]      pool4	backward: 48.66 ms.
I1031 12:11:37.350488 95375 caffe.cpp:522]        fc1	forward: 1.128 ms.
I1031 12:11:37.350699 95375 caffe.cpp:526]        fc1	backward: 58.825 ms.
I1031 12:11:37.350914 95375 caffe.cpp:522]   dropout5	forward: 0.18 ms.
I1031 12:11:37.351127 95375 caffe.cpp:526]   dropout5	backward: 0.065 ms.
I1031 12:11:37.351342 95375 caffe.cpp:522]        fc2	forward: 0.12 ms.
I1031 12:11:37.352339 95375 caffe.cpp:526]        fc2	backward: 0.209 ms.
I1031 12:11:37.352676 95375 caffe.cpp:522]       loss	forward: 34.44 ms.
I1031 12:11:37.352883 95375 caffe.cpp:526]       loss	backward: 35.364 ms.
I1031 12:11:37.358638 95375 caffe.cpp:532] Average Forward pass: 532.819 ms.
I1031 12:11:37.372005 95375 caffe.cpp:535] Average Backward pass: 1081.51 ms.
I1031 12:11:37.383533 95375 caffe.cpp:537] Average Forward-Backward: 2246 ms.
I1031 12:11:37.398888 95375 caffe.cpp:540] Total Time: 2246 ms.
I1031 12:11:37.411907 95375 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 55712
elements_fp_double_1 = 33
elements_fp_double_2 = 668576
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 891395
--->Total double-precision FLOPs = 1337185
--->Total FLOPs = 2228580
mem-read-1 = 381014
mem-read-2 = 105
mem-read-4 = 3147115
mem-read-8 = 4390962
mem-read-16 = 2227856
mem-read-32 = 1
mem-read-64 = 129617
mem-write-1 = 188
mem-write-2 = 67
mem-write-4 = 2412
mem-write-8 = 659503
mem-write-16 = 32
mem-write-32 = 1
mem-write-64 = 85937
--->Total Bytes read = 92038596
--->Total Bytes written = 10786506
--->Total Bytes = 102825102

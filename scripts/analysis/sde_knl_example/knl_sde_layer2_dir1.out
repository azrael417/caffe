sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer2_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=2 -prof_forward_direction=1
I1031 11:15:31.224786 131454 caffe.cpp:444] Use CPU.
I1031 11:15:49.888099 131454 cpu_info.cpp:452] Processor speed [MHz]: 1300
I1031 11:15:49.951056 131454 cpu_info.cpp:455] Total number of sockets: 1
I1031 11:15:49.964364 131454 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 11:15:49.976884 131454 cpu_info.cpp:461] Total number of processors: 256
I1031 11:15:49.995074 131454 cpu_info.cpp:464] GPU is used: no
I1031 11:15:50.006780 131454 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 11:15:50.037816 131454 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 11:15:50.054435 131454 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 11:15:59.503223 131454 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 11:16:00.222721 131454 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 11:16:02.742120 131454 layer_factory.hpp:114] Creating layer data
I1031 11:16:02.910852 131454 net.cpp:160] Creating Layer data
I1031 11:16:02.964289 131454 net.cpp:570] data -> data
I1031 11:16:03.478469 131454 net.cpp:570] data -> label
I1031 11:16:11.244119 131454 net.cpp:210] Setting up data
I1031 11:16:11.332126 131454 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 11:16:11.445453 131454 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 11:16:11.453528 131454 net.cpp:225] Memory required for data: 184516
I1031 11:16:11.538060 131454 layer_factory.hpp:114] Creating layer conv1
I1031 11:16:11.905061 131454 net.cpp:160] Creating Layer conv1
I1031 11:16:11.960958 131454 net.cpp:596] conv1 <- data
I1031 11:16:12.094172 131454 net.cpp:570] conv1 -> conv1
I1031 11:16:50.448325 131454 net.cpp:210] Setting up conv1
I1031 11:16:50.527915 131454 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:16:50.539227 131454 net.cpp:225] Memory required for data: 7805124
I1031 11:16:50.883532 131454 layer_factory.hpp:114] Creating layer relu1
I1031 11:16:51.024461 131454 net.cpp:160] Creating Layer relu1
I1031 11:16:51.029669 131454 net.cpp:596] relu1 <- conv1
I1031 11:16:51.066203 131454 net.cpp:557] relu1 -> conv1 (in-place)
I1031 11:16:51.305830 131454 net.cpp:210] Setting up relu1
I1031 11:16:51.309481 131454 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:16:51.309957 131454 net.cpp:225] Memory required for data: 15425732
I1031 11:16:51.310226 131454 layer_factory.hpp:114] Creating layer dropout1
I1031 11:16:51.345964 131454 net.cpp:160] Creating Layer dropout1
I1031 11:16:51.346390 131454 net.cpp:596] dropout1 <- conv1
I1031 11:16:51.349666 131454 net.cpp:570] dropout1 -> drop1
I1031 11:16:51.469604 131454 net.cpp:210] Setting up dropout1
I1031 11:16:51.484086 131454 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:16:51.484503 131454 net.cpp:225] Memory required for data: 23046340
I1031 11:16:51.484884 131454 layer_factory.hpp:114] Creating layer pool1
I1031 11:16:51.597946 131454 net.cpp:160] Creating Layer pool1
I1031 11:16:51.598681 131454 net.cpp:596] pool1 <- drop1
I1031 11:16:51.599081 131454 net.cpp:570] pool1 -> pool1
I1031 11:16:52.035254 131454 net.cpp:210] Setting up pool1
I1031 11:16:52.040515 131454 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 11:16:52.040921 131454 net.cpp:225] Memory required for data: 24951492
I1031 11:16:52.041265 131454 layer_factory.hpp:114] Creating layer conv2
I1031 11:16:52.106695 131454 net.cpp:160] Creating Layer conv2
I1031 11:16:52.111284 131454 net.cpp:596] conv2 <- pool1
I1031 11:16:52.127347 131454 net.cpp:570] conv2 -> conv2
I1031 11:16:59.053531 131454 net.cpp:210] Setting up conv2
I1031 11:16:59.053910 131454 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:16:59.059995 131454 net.cpp:225] Memory required for data: 26733764
I1031 11:16:59.118554 131454 layer_factory.hpp:114] Creating layer relu2
I1031 11:16:59.119029 131454 net.cpp:160] Creating Layer relu2
I1031 11:16:59.119371 131454 net.cpp:596] relu2 <- conv2
I1031 11:16:59.119745 131454 net.cpp:557] relu2 -> conv2 (in-place)
I1031 11:16:59.120236 131454 net.cpp:210] Setting up relu2
I1031 11:16:59.120522 131454 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:16:59.120782 131454 net.cpp:225] Memory required for data: 28516036
I1031 11:16:59.120990 131454 layer_factory.hpp:114] Creating layer dropout2
I1031 11:16:59.121237 131454 net.cpp:160] Creating Layer dropout2
I1031 11:16:59.121450 131454 net.cpp:596] dropout2 <- conv2
I1031 11:16:59.121808 131454 net.cpp:570] dropout2 -> drop2
I1031 11:16:59.122124 131454 net.cpp:210] Setting up dropout2
I1031 11:16:59.122540 131454 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:16:59.122884 131454 net.cpp:225] Memory required for data: 30298308
I1031 11:16:59.123136 131454 layer_factory.hpp:114] Creating layer pool2
I1031 11:16:59.123453 131454 net.cpp:160] Creating Layer pool2
I1031 11:16:59.123693 131454 net.cpp:596] pool2 <- drop2
I1031 11:16:59.123960 131454 net.cpp:570] pool2 -> pool2
I1031 11:16:59.124413 131454 net.cpp:210] Setting up pool2
I1031 11:16:59.124696 131454 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 11:16:59.124938 131454 net.cpp:225] Memory required for data: 30759108
I1031 11:16:59.125167 131454 layer_factory.hpp:114] Creating layer conv3
I1031 11:16:59.125576 131454 net.cpp:160] Creating Layer conv3
I1031 11:16:59.125941 131454 net.cpp:596] conv3 <- pool2
I1031 11:16:59.126250 131454 net.cpp:570] conv3 -> conv3
I1031 11:16:59.668112 131454 net.cpp:210] Setting up conv3
I1031 11:16:59.670691 131454 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:16:59.671077 131454 net.cpp:225] Memory required for data: 31160516
I1031 11:16:59.679618 131454 layer_factory.hpp:114] Creating layer relu3
I1031 11:16:59.680088 131454 net.cpp:160] Creating Layer relu3
I1031 11:16:59.680452 131454 net.cpp:596] relu3 <- conv3
I1031 11:16:59.680779 131454 net.cpp:557] relu3 -> conv3 (in-place)
I1031 11:16:59.681442 131454 net.cpp:210] Setting up relu3
I1031 11:16:59.681757 131454 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:16:59.682036 131454 net.cpp:225] Memory required for data: 31561924
I1031 11:16:59.682255 131454 layer_factory.hpp:114] Creating layer dropout3
I1031 11:16:59.682615 131454 net.cpp:160] Creating Layer dropout3
I1031 11:16:59.682870 131454 net.cpp:596] dropout3 <- conv3
I1031 11:16:59.683291 131454 net.cpp:570] dropout3 -> drop3
I1031 11:16:59.683696 131454 net.cpp:210] Setting up dropout3
I1031 11:16:59.683931 131454 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:16:59.684175 131454 net.cpp:225] Memory required for data: 31963332
I1031 11:16:59.684375 131454 layer_factory.hpp:114] Creating layer pool3
I1031 11:16:59.684656 131454 net.cpp:160] Creating Layer pool3
I1031 11:16:59.684876 131454 net.cpp:596] pool3 <- drop3
I1031 11:16:59.685129 131454 net.cpp:570] pool3 -> pool3
I1031 11:16:59.685557 131454 net.cpp:210] Setting up pool3
I1031 11:16:59.685864 131454 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 11:16:59.686240 131454 net.cpp:225] Memory required for data: 32063684
I1031 11:16:59.686560 131454 layer_factory.hpp:114] Creating layer conv4
I1031 11:16:59.686980 131454 net.cpp:160] Creating Layer conv4
I1031 11:16:59.687218 131454 net.cpp:596] conv4 <- pool3
I1031 11:16:59.687466 131454 net.cpp:570] conv4 -> conv4
I1031 11:17:00.041957 131454 net.cpp:210] Setting up conv4
I1031 11:17:00.042279 131454 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:17:00.042781 131454 net.cpp:225] Memory required for data: 32137412
I1031 11:17:00.043151 131454 layer_factory.hpp:114] Creating layer relu4
I1031 11:17:00.043503 131454 net.cpp:160] Creating Layer relu4
I1031 11:17:00.043774 131454 net.cpp:596] relu4 <- conv4
I1031 11:17:00.044049 131454 net.cpp:557] relu4 -> conv4 (in-place)
I1031 11:17:00.044577 131454 net.cpp:210] Setting up relu4
I1031 11:17:00.044881 131454 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:17:00.045153 131454 net.cpp:225] Memory required for data: 32211140
I1031 11:17:00.045372 131454 layer_factory.hpp:114] Creating layer dropout4
I1031 11:17:00.045624 131454 net.cpp:160] Creating Layer dropout4
I1031 11:17:00.045882 131454 net.cpp:596] dropout4 <- conv4
I1031 11:17:00.046144 131454 net.cpp:570] dropout4 -> drop4
I1031 11:17:00.046509 131454 net.cpp:210] Setting up dropout4
I1031 11:17:00.046779 131454 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:17:00.047034 131454 net.cpp:225] Memory required for data: 32284868
I1031 11:17:00.047233 131454 layer_factory.hpp:114] Creating layer pool4
I1031 11:17:00.047530 131454 net.cpp:160] Creating Layer pool4
I1031 11:17:00.047754 131454 net.cpp:596] pool4 <- drop4
I1031 11:17:00.047992 131454 net.cpp:570] pool4 -> pool4
I1031 11:17:00.061499 131454 net.cpp:210] Setting up pool4
I1031 11:17:00.062124 131454 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 11:17:00.064621 131454 net.cpp:225] Memory required for data: 32303300
I1031 11:17:00.064877 131454 layer_factory.hpp:114] Creating layer fc1
I1031 11:17:00.125026 131454 net.cpp:160] Creating Layer fc1
I1031 11:17:00.125371 131454 net.cpp:596] fc1 <- pool4
I1031 11:17:00.125805 131454 net.cpp:570] fc1 -> fc1
I1031 11:17:00.981212 131454 net.cpp:210] Setting up fc1
I1031 11:17:00.981915 131454 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:17:00.982358 131454 net.cpp:225] Memory required for data: 32307396
I1031 11:17:00.987308 131454 layer_factory.hpp:114] Creating layer dropout5
I1031 11:17:00.987732 131454 net.cpp:160] Creating Layer dropout5
I1031 11:17:00.987983 131454 net.cpp:596] dropout5 <- fc1
I1031 11:17:00.988250 131454 net.cpp:570] dropout5 -> drop5
I1031 11:17:00.988562 131454 net.cpp:210] Setting up dropout5
I1031 11:17:00.988796 131454 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:17:00.989059 131454 net.cpp:225] Memory required for data: 32311492
I1031 11:17:00.989277 131454 layer_factory.hpp:114] Creating layer fc2
I1031 11:17:00.989573 131454 net.cpp:160] Creating Layer fc2
I1031 11:17:00.989975 131454 net.cpp:596] fc2 <- drop5
I1031 11:17:00.990270 131454 net.cpp:570] fc2 -> fc2
I1031 11:17:00.998653 131454 net.cpp:210] Setting up fc2
I1031 11:17:01.000083 131454 net.cpp:217] Top shape: 1 2 (2)
I1031 11:17:01.004775 131454 net.cpp:225] Memory required for data: 32311500
I1031 11:17:01.005254 131454 layer_factory.hpp:114] Creating layer loss
I1031 11:17:01.032004 131454 net.cpp:160] Creating Layer loss
I1031 11:17:01.032346 131454 net.cpp:596] loss <- fc2
I1031 11:17:01.033330 131454 net.cpp:596] loss <- label
I1031 11:17:01.083520 131454 net.cpp:570] loss -> (automatic)
I1031 11:17:01.118752 131454 layer_factory.hpp:114] Creating layer loss
I1031 11:17:01.449878 131454 net.cpp:210] Setting up loss
I1031 11:17:01.452960 131454 net.cpp:217] Top shape: (1)
I1031 11:17:01.459439 131454 net.cpp:220]     with loss weight 1
I1031 11:17:01.593127 131454 net.cpp:225] Memory required for data: 32311504
I1031 11:17:01.636622 131454 net.cpp:287] loss needs backward computation.
I1031 11:17:01.738376 131454 net.cpp:287] fc2 needs backward computation.
I1031 11:17:01.746553 131454 net.cpp:287] dropout5 needs backward computation.
I1031 11:17:01.748873 131454 net.cpp:287] fc1 needs backward computation.
I1031 11:17:01.749706 131454 net.cpp:287] pool4 needs backward computation.
I1031 11:17:01.750056 131454 net.cpp:287] dropout4 needs backward computation.
I1031 11:17:01.750455 131454 net.cpp:287] relu4 needs backward computation.
I1031 11:17:01.760800 131454 net.cpp:287] conv4 needs backward computation.
I1031 11:17:01.778633 131454 net.cpp:287] pool3 needs backward computation.
I1031 11:17:01.792783 131454 net.cpp:287] dropout3 needs backward computation.
I1031 11:17:01.797807 131454 net.cpp:287] relu3 needs backward computation.
I1031 11:17:01.798153 131454 net.cpp:287] conv3 needs backward computation.
I1031 11:17:01.798535 131454 net.cpp:287] pool2 needs backward computation.
I1031 11:17:01.798779 131454 net.cpp:287] dropout2 needs backward computation.
I1031 11:17:01.798995 131454 net.cpp:287] relu2 needs backward computation.
I1031 11:17:01.799201 131454 net.cpp:287] conv2 needs backward computation.
I1031 11:17:01.799410 131454 net.cpp:287] pool1 needs backward computation.
I1031 11:17:01.799618 131454 net.cpp:287] dropout1 needs backward computation.
I1031 11:17:01.799823 131454 net.cpp:287] relu1 needs backward computation.
I1031 11:17:01.800022 131454 net.cpp:287] conv1 needs backward computation.
I1031 11:17:01.820884 131454 net.cpp:289] data does not need backward computation.
I1031 11:17:01.882213 131454 net.cpp:345] Network initialization done.
I1031 11:17:02.073803 131454 caffe.cpp:452] Performing Forward
I1031 11:17:14.301928 131454 caffe.cpp:457] Initial loss: 0
I1031 11:17:14.334071 131454 caffe.cpp:459] Performing Backward
I1031 11:17:17.655109 131454 caffe.cpp:468] *** Benchmark begins ***
I1031 11:17:17.666870 131454 caffe.cpp:469] Testing for 1 iterations.
I1031 11:17:17.831027 131454 caffe.cpp:482] Profiling Layer: relu1 forward
I1031 11:17:19.816954 131454 caffe.cpp:512] Iteration: 1 forward-backward time: 1986 ms.
I1031 11:17:19.995107 131454 caffe.cpp:519] Average time per layer: 
I1031 11:17:20.011569 131454 caffe.cpp:522]       data	forward: 52.888 ms.
I1031 11:17:20.102520 131454 caffe.cpp:526]       data	backward: 7.969 ms.
I1031 11:17:20.127002 131454 caffe.cpp:522]      conv1	forward: 19.954 ms.
I1031 11:17:20.144608 131454 caffe.cpp:526]      conv1	backward: 41.766 ms.
I1031 11:17:20.151453 131454 caffe.cpp:522]      relu1	forward: 13.942 ms.
I1031 11:17:20.158179 131454 caffe.cpp:526]      relu1	backward: 63.635 ms.
I1031 11:17:20.162700 131454 caffe.cpp:522]   dropout1	forward: 35.991 ms.
I1031 11:17:20.175319 131454 caffe.cpp:526]   dropout1	backward: 63.527 ms.
I1031 11:17:20.181690 131454 caffe.cpp:522]      pool1	forward: 135.973 ms.
I1031 11:17:20.191890 131454 caffe.cpp:526]      pool1	backward: 134.156 ms.
I1031 11:17:20.193018 131454 caffe.cpp:522]      conv2	forward: 49.928 ms.
I1031 11:17:20.193238 131454 caffe.cpp:526]      conv2	backward: 69.779 ms.
I1031 11:17:20.194061 131454 caffe.cpp:522]      relu2	forward: 12.67 ms.
I1031 11:17:20.194510 131454 caffe.cpp:526]      relu2	backward: 39.68 ms.
I1031 11:17:20.194731 131454 caffe.cpp:522]   dropout2	forward: 50.604 ms.
I1031 11:17:20.197226 131454 caffe.cpp:526]   dropout2	backward: 36.599 ms.
I1031 11:17:20.197494 131454 caffe.cpp:522]      pool2	forward: 32.156 ms.
I1031 11:17:20.198346 131454 caffe.cpp:526]      pool2	backward: 54.931 ms.
I1031 11:17:20.198784 131454 caffe.cpp:522]      conv3	forward: 33.419 ms.
I1031 11:17:20.199070 131454 caffe.cpp:526]      conv3	backward: 91.686 ms.
I1031 11:17:20.199285 131454 caffe.cpp:522]      relu3	forward: 21.512 ms.
I1031 11:17:20.199492 131454 caffe.cpp:526]      relu3	backward: 29.306 ms.
I1031 11:17:20.199699 131454 caffe.cpp:522]   dropout3	forward: 61.95 ms.
I1031 11:17:20.199906 131454 caffe.cpp:526]   dropout3	backward: 26.378 ms.
I1031 11:17:20.200111 131454 caffe.cpp:522]      pool3	forward: 15.522 ms.
I1031 11:17:20.200316 131454 caffe.cpp:526]      pool3	backward: 58.905 ms.
I1031 11:17:20.200520 131454 caffe.cpp:522]      conv4	forward: 33.748 ms.
I1031 11:17:20.200724 131454 caffe.cpp:526]      conv4	backward: 76.42 ms.
I1031 11:17:20.200927 131454 caffe.cpp:522]      relu4	forward: 23.219 ms.
I1031 11:17:20.201129 131454 caffe.cpp:526]      relu4	backward: 50.673 ms.
I1031 11:17:20.201370 131454 caffe.cpp:522]   dropout4	forward: 54.338 ms.
I1031 11:17:20.201592 131454 caffe.cpp:526]   dropout4	backward: 41.426 ms.
I1031 11:17:20.201941 131454 caffe.cpp:522]      pool4	forward: 13.713 ms.
I1031 11:17:20.202229 131454 caffe.cpp:526]      pool4	backward: 51.056 ms.
I1031 11:17:20.202486 131454 caffe.cpp:522]        fc1	forward: 20.661 ms.
I1031 11:17:20.202695 131454 caffe.cpp:526]        fc1	backward: 50.695 ms.
I1031 11:17:20.202900 131454 caffe.cpp:522]   dropout5	forward: 20.454 ms.
I1031 11:17:20.203104 131454 caffe.cpp:526]   dropout5	backward: 24.883 ms.
I1031 11:17:20.203310 131454 caffe.cpp:522]        fc2	forward: 0.121 ms.
I1031 11:17:20.204167 131454 caffe.cpp:526]        fc2	backward: 0.214 ms.
I1031 11:17:20.204404 131454 caffe.cpp:522]       loss	forward: 124.034 ms.
I1031 11:17:20.204659 131454 caffe.cpp:526]       loss	backward: 33.168 ms.
I1031 11:17:20.210741 131454 caffe.cpp:532] Average Forward pass: 893.48 ms.
I1031 11:17:20.224634 131454 caffe.cpp:535] Average Backward pass: 1056.54 ms.
I1031 11:17:20.236631 131454 caffe.cpp:537] Average Forward-Backward: 2493 ms.
I1031 11:17:20.252679 131454 caffe.cpp:540] Total Time: 2493 ms.
I1031 11:17:20.265955 131454 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 119072
elements_fp_double_1 = 0
elements_fp_double_2 = 119072
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 1905153
--->Total double-precision FLOPs = 238144
--->Total FLOPs = 2143297
mem-read-1 = 516527
mem-read-2 = 34
mem-read-4 = 4136872
mem-read-8 = 5692040
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 238161
mem-write-1 = 50
mem-write-2 = 17
mem-write-4 = 552
mem-write-8 = 520837
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 119073
--->Total Bytes read = 77842739
--->Total Bytes written = 11789692
--->Total Bytes = 89632431

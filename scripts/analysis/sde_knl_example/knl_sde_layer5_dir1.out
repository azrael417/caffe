sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer5_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=5 -prof_forward_direction=1
I1031 11:58:07.063604 94815 caffe.cpp:444] Use CPU.
I1031 11:58:24.986229 94815 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 11:58:25.048516 94815 cpu_info.cpp:455] Total number of sockets: 1
I1031 11:58:25.061655 94815 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 11:58:25.073628 94815 cpu_info.cpp:461] Total number of processors: 256
I1031 11:58:25.090651 94815 cpu_info.cpp:464] GPU is used: no
I1031 11:58:25.099999 94815 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 11:58:25.109097 94815 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 11:58:25.121564 94815 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 11:58:34.245451 94815 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 11:58:34.937227 94815 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 11:58:37.374500 94815 layer_factory.hpp:114] Creating layer data
I1031 11:58:37.532130 94815 net.cpp:160] Creating Layer data
I1031 11:58:37.583253 94815 net.cpp:570] data -> data
I1031 11:58:38.081006 94815 net.cpp:570] data -> label
I1031 11:58:45.567219 94815 net.cpp:210] Setting up data
I1031 11:58:45.652714 94815 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 11:58:45.759357 94815 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 11:58:45.766696 94815 net.cpp:225] Memory required for data: 184516
I1031 11:58:45.845564 94815 layer_factory.hpp:114] Creating layer conv1
I1031 11:58:46.194892 94815 net.cpp:160] Creating Layer conv1
I1031 11:58:46.248386 94815 net.cpp:596] conv1 <- data
I1031 11:58:46.374507 94815 net.cpp:570] conv1 -> conv1
I1031 11:59:23.808547 94815 net.cpp:210] Setting up conv1
I1031 11:59:23.884866 94815 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:59:23.887806 94815 net.cpp:225] Memory required for data: 7805124
I1031 11:59:24.226336 94815 layer_factory.hpp:114] Creating layer relu1
I1031 11:59:24.360651 94815 net.cpp:160] Creating Layer relu1
I1031 11:59:24.365792 94815 net.cpp:596] relu1 <- conv1
I1031 11:59:24.401067 94815 net.cpp:557] relu1 -> conv1 (in-place)
I1031 11:59:24.618316 94815 net.cpp:210] Setting up relu1
I1031 11:59:24.621032 94815 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:59:24.621395 94815 net.cpp:225] Memory required for data: 15425732
I1031 11:59:24.621608 94815 layer_factory.hpp:114] Creating layer dropout1
I1031 11:59:24.654527 94815 net.cpp:160] Creating Layer dropout1
I1031 11:59:24.654860 94815 net.cpp:596] dropout1 <- conv1
I1031 11:59:24.657639 94815 net.cpp:570] dropout1 -> drop1
I1031 11:59:24.776216 94815 net.cpp:210] Setting up dropout1
I1031 11:59:24.790454 94815 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:59:24.790840 94815 net.cpp:225] Memory required for data: 23046340
I1031 11:59:24.791164 94815 layer_factory.hpp:114] Creating layer pool1
I1031 11:59:24.896234 94815 net.cpp:160] Creating Layer pool1
I1031 11:59:24.896584 94815 net.cpp:596] pool1 <- drop1
I1031 11:59:24.897002 94815 net.cpp:570] pool1 -> pool1
I1031 11:59:25.322477 94815 net.cpp:210] Setting up pool1
I1031 11:59:25.327451 94815 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 11:59:25.327836 94815 net.cpp:225] Memory required for data: 24951492
I1031 11:59:25.328155 94815 layer_factory.hpp:114] Creating layer conv2
I1031 11:59:25.390480 94815 net.cpp:160] Creating Layer conv2
I1031 11:59:25.394979 94815 net.cpp:596] conv2 <- pool1
I1031 11:59:25.410390 94815 net.cpp:570] conv2 -> conv2
I1031 11:59:32.294935 94815 net.cpp:210] Setting up conv2
I1031 11:59:32.295456 94815 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:59:32.301908 94815 net.cpp:225] Memory required for data: 26733764
I1031 11:59:32.364697 94815 layer_factory.hpp:114] Creating layer relu2
I1031 11:59:32.365841 94815 net.cpp:160] Creating Layer relu2
I1031 11:59:32.366190 94815 net.cpp:596] relu2 <- conv2
I1031 11:59:32.366485 94815 net.cpp:557] relu2 -> conv2 (in-place)
I1031 11:59:32.367205 94815 net.cpp:210] Setting up relu2
I1031 11:59:32.367568 94815 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:59:32.367851 94815 net.cpp:225] Memory required for data: 28516036
I1031 11:59:32.368070 94815 layer_factory.hpp:114] Creating layer dropout2
I1031 11:59:32.368393 94815 net.cpp:160] Creating Layer dropout2
I1031 11:59:32.368716 94815 net.cpp:596] dropout2 <- conv2
I1031 11:59:32.368995 94815 net.cpp:570] dropout2 -> drop2
I1031 11:59:32.369345 94815 net.cpp:210] Setting up dropout2
I1031 11:59:32.369595 94815 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:59:32.369848 94815 net.cpp:225] Memory required for data: 30298308
I1031 11:59:32.370067 94815 layer_factory.hpp:114] Creating layer pool2
I1031 11:59:32.370386 94815 net.cpp:160] Creating Layer pool2
I1031 11:59:32.370612 94815 net.cpp:596] pool2 <- drop2
I1031 11:59:32.370859 94815 net.cpp:570] pool2 -> pool2
I1031 11:59:32.371390 94815 net.cpp:210] Setting up pool2
I1031 11:59:32.371822 94815 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 11:59:32.372190 94815 net.cpp:225] Memory required for data: 30759108
I1031 11:59:32.372478 94815 layer_factory.hpp:114] Creating layer conv3
I1031 11:59:32.372972 94815 net.cpp:160] Creating Layer conv3
I1031 11:59:32.373332 94815 net.cpp:596] conv3 <- pool2
I1031 11:59:32.373699 94815 net.cpp:570] conv3 -> conv3
I1031 11:59:33.039557 94815 net.cpp:210] Setting up conv3
I1031 11:59:33.052961 94815 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:59:33.063549 94815 net.cpp:225] Memory required for data: 31160516
I1031 11:59:33.080204 94815 layer_factory.hpp:114] Creating layer relu3
I1031 11:59:33.090603 94815 net.cpp:160] Creating Layer relu3
I1031 11:59:33.097283 94815 net.cpp:596] relu3 <- conv3
I1031 11:59:33.102138 94815 net.cpp:557] relu3 -> conv3 (in-place)
I1031 11:59:33.106920 94815 net.cpp:210] Setting up relu3
I1031 11:59:33.125875 94815 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:59:33.134297 94815 net.cpp:225] Memory required for data: 31561924
I1031 11:59:33.138948 94815 layer_factory.hpp:114] Creating layer dropout3
I1031 11:59:33.141389 94815 net.cpp:160] Creating Layer dropout3
I1031 11:59:33.141669 94815 net.cpp:596] dropout3 <- conv3
I1031 11:59:33.141942 94815 net.cpp:570] dropout3 -> drop3
I1031 11:59:33.154260 94815 net.cpp:210] Setting up dropout3
I1031 11:59:33.160642 94815 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:59:33.169391 94815 net.cpp:225] Memory required for data: 31963332
I1031 11:59:33.171290 94815 layer_factory.hpp:114] Creating layer pool3
I1031 11:59:33.182667 94815 net.cpp:160] Creating Layer pool3
I1031 11:59:33.187419 94815 net.cpp:596] pool3 <- drop3
I1031 11:59:33.195590 94815 net.cpp:570] pool3 -> pool3
I1031 11:59:33.201551 94815 net.cpp:210] Setting up pool3
I1031 11:59:33.204620 94815 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 11:59:33.209287 94815 net.cpp:225] Memory required for data: 32063684
I1031 11:59:33.213922 94815 layer_factory.hpp:114] Creating layer conv4
I1031 11:59:33.219964 94815 net.cpp:160] Creating Layer conv4
I1031 11:59:33.226428 94815 net.cpp:596] conv4 <- pool3
I1031 11:59:33.234989 94815 net.cpp:570] conv4 -> conv4
I1031 11:59:33.576922 94815 net.cpp:210] Setting up conv4
I1031 11:59:33.579515 94815 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:59:33.587680 94815 net.cpp:225] Memory required for data: 32137412
I1031 11:59:33.590934 94815 layer_factory.hpp:114] Creating layer relu4
I1031 11:59:33.593612 94815 net.cpp:160] Creating Layer relu4
I1031 11:59:33.599959 94815 net.cpp:596] relu4 <- conv4
I1031 11:59:33.611922 94815 net.cpp:557] relu4 -> conv4 (in-place)
I1031 11:59:33.618253 94815 net.cpp:210] Setting up relu4
I1031 11:59:33.625023 94815 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:59:33.633436 94815 net.cpp:225] Memory required for data: 32211140
I1031 11:59:33.641964 94815 layer_factory.hpp:114] Creating layer dropout4
I1031 11:59:33.650518 94815 net.cpp:160] Creating Layer dropout4
I1031 11:59:33.658992 94815 net.cpp:596] dropout4 <- conv4
I1031 11:59:33.665561 94815 net.cpp:570] dropout4 -> drop4
I1031 11:59:33.671721 94815 net.cpp:210] Setting up dropout4
I1031 11:59:33.677933 94815 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:59:33.682310 94815 net.cpp:225] Memory required for data: 32284868
I1031 11:59:33.690790 94815 layer_factory.hpp:114] Creating layer pool4
I1031 11:59:33.692883 94815 net.cpp:160] Creating Layer pool4
I1031 11:59:33.699801 94815 net.cpp:596] pool4 <- drop4
I1031 11:59:33.704495 94815 net.cpp:570] pool4 -> pool4
I1031 11:59:33.722553 94815 net.cpp:210] Setting up pool4
I1031 11:59:33.733011 94815 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 11:59:33.738888 94815 net.cpp:225] Memory required for data: 32303300
I1031 11:59:33.743315 94815 layer_factory.hpp:114] Creating layer fc1
I1031 11:59:33.810225 94815 net.cpp:160] Creating Layer fc1
I1031 11:59:33.818676 94815 net.cpp:596] fc1 <- pool4
I1031 11:59:33.824854 94815 net.cpp:570] fc1 -> fc1
I1031 11:59:34.681159 94815 net.cpp:210] Setting up fc1
I1031 11:59:34.681483 94815 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:59:34.681852 94815 net.cpp:225] Memory required for data: 32307396
I1031 11:59:34.687082 94815 layer_factory.hpp:114] Creating layer dropout5
I1031 11:59:34.687538 94815 net.cpp:160] Creating Layer dropout5
I1031 11:59:34.687870 94815 net.cpp:596] dropout5 <- fc1
I1031 11:59:34.688175 94815 net.cpp:570] dropout5 -> drop5
I1031 11:59:34.688514 94815 net.cpp:210] Setting up dropout5
I1031 11:59:34.688756 94815 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:59:34.689009 94815 net.cpp:225] Memory required for data: 32311492
I1031 11:59:34.689221 94815 layer_factory.hpp:114] Creating layer fc2
I1031 11:59:34.689507 94815 net.cpp:160] Creating Layer fc2
I1031 11:59:34.689728 94815 net.cpp:596] fc2 <- drop5
I1031 11:59:34.689991 94815 net.cpp:570] fc2 -> fc2
I1031 11:59:34.701313 94815 net.cpp:210] Setting up fc2
I1031 11:59:34.702764 94815 net.cpp:217] Top shape: 1 2 (2)
I1031 11:59:34.705303 94815 net.cpp:225] Memory required for data: 32311500
I1031 11:59:34.705749 94815 layer_factory.hpp:114] Creating layer loss
I1031 11:59:34.735018 94815 net.cpp:160] Creating Layer loss
I1031 11:59:34.735388 94815 net.cpp:596] loss <- fc2
I1031 11:59:34.736418 94815 net.cpp:596] loss <- label
I1031 11:59:34.800269 94815 net.cpp:570] loss -> (automatic)
I1031 11:59:34.858463 94815 layer_factory.hpp:114] Creating layer loss
I1031 11:59:35.291507 94815 net.cpp:210] Setting up loss
I1031 11:59:35.302431 94815 net.cpp:217] Top shape: (1)
I1031 11:59:35.312731 94815 net.cpp:220]     with loss weight 1
I1031 11:59:35.452366 94815 net.cpp:225] Memory required for data: 32311504
I1031 11:59:35.507228 94815 net.cpp:287] loss needs backward computation.
I1031 11:59:35.611680 94815 net.cpp:287] fc2 needs backward computation.
I1031 11:59:35.626256 94815 net.cpp:287] dropout5 needs backward computation.
I1031 11:59:35.634759 94815 net.cpp:287] fc1 needs backward computation.
I1031 11:59:35.645885 94815 net.cpp:287] pool4 needs backward computation.
I1031 11:59:35.649137 94815 net.cpp:287] dropout4 needs backward computation.
I1031 11:59:35.650596 94815 net.cpp:287] relu4 needs backward computation.
I1031 11:59:35.660410 94815 net.cpp:287] conv4 needs backward computation.
I1031 11:59:35.677451 94815 net.cpp:287] pool3 needs backward computation.
I1031 11:59:35.692723 94815 net.cpp:287] dropout3 needs backward computation.
I1031 11:59:35.697929 94815 net.cpp:287] relu3 needs backward computation.
I1031 11:59:35.698282 94815 net.cpp:287] conv3 needs backward computation.
I1031 11:59:35.698663 94815 net.cpp:287] pool2 needs backward computation.
I1031 11:59:35.698946 94815 net.cpp:287] dropout2 needs backward computation.
I1031 11:59:35.699160 94815 net.cpp:287] relu2 needs backward computation.
I1031 11:59:35.699398 94815 net.cpp:287] conv2 needs backward computation.
I1031 11:59:35.699621 94815 net.cpp:287] pool1 needs backward computation.
I1031 11:59:35.699828 94815 net.cpp:287] dropout1 needs backward computation.
I1031 11:59:35.700031 94815 net.cpp:287] relu1 needs backward computation.
I1031 11:59:35.700225 94815 net.cpp:287] conv1 needs backward computation.
I1031 11:59:35.721526 94815 net.cpp:289] data does not need backward computation.
I1031 11:59:35.779949 94815 net.cpp:345] Network initialization done.
I1031 11:59:35.969447 94815 caffe.cpp:452] Performing Forward
I1031 11:59:47.800120 94815 caffe.cpp:457] Initial loss: 0
I1031 11:59:47.833073 94815 caffe.cpp:459] Performing Backward
I1031 11:59:51.200708 94815 caffe.cpp:468] *** Benchmark begins ***
I1031 11:59:51.218272 94815 caffe.cpp:469] Testing for 1 iterations.
I1031 11:59:51.372653 94815 caffe.cpp:482] Profiling Layer: conv2 forward
I1031 11:59:53.151976 94815 caffe.cpp:512] Iteration: 1 forward-backward time: 1777 ms.
I1031 11:59:53.320014 94815 caffe.cpp:519] Average time per layer: 
I1031 11:59:53.340636 94815 caffe.cpp:522]       data	forward: 54.841 ms.
I1031 11:59:53.422566 94815 caffe.cpp:526]       data	backward: 3.535 ms.
I1031 11:59:53.449136 94815 caffe.cpp:522]      conv1	forward: 70.029 ms.
I1031 11:59:53.474701 94815 caffe.cpp:526]      conv1	backward: 24.454 ms.
I1031 11:59:53.485699 94815 caffe.cpp:522]      relu1	forward: 20.089 ms.
I1031 11:59:53.492897 94815 caffe.cpp:526]      relu1	backward: 57.229 ms.
I1031 11:59:53.499524 94815 caffe.cpp:522]   dropout1	forward: 96.486 ms.
I1031 11:59:53.507983 94815 caffe.cpp:526]   dropout1	backward: 51.024 ms.
I1031 11:59:53.510651 94815 caffe.cpp:522]      pool1	forward: 128.033 ms.
I1031 11:59:53.515746 94815 caffe.cpp:526]      pool1	backward: 109.715 ms.
I1031 11:59:53.516144 94815 caffe.cpp:522]      conv2	forward: 81.533 ms.
I1031 11:59:53.516402 94815 caffe.cpp:526]      conv2	backward: 14.138 ms.
I1031 11:59:53.516611 94815 caffe.cpp:522]      relu2	forward: 28.609 ms.
I1031 11:59:53.516816 94815 caffe.cpp:526]      relu2	backward: 6.799 ms.
I1031 11:59:53.517016 94815 caffe.cpp:522]   dropout2	forward: 62.138 ms.
I1031 11:59:53.517998 94815 caffe.cpp:526]   dropout2	backward: 7.761 ms.
I1031 11:59:53.518254 94815 caffe.cpp:522]      pool2	forward: 29.497 ms.
I1031 11:59:53.518463 94815 caffe.cpp:526]      pool2	backward: 25.795 ms.
I1031 11:59:53.518699 94815 caffe.cpp:522]      conv3	forward: 59.485 ms.
I1031 11:59:53.518918 94815 caffe.cpp:526]      conv3	backward: 3.961 ms.
I1031 11:59:53.519178 94815 caffe.cpp:522]      relu3	forward: 15.204 ms.
I1031 11:59:53.519553 94815 caffe.cpp:526]      relu3	backward: 1.367 ms.
I1031 11:59:53.519906 94815 caffe.cpp:522]   dropout3	forward: 62.303 ms.
I1031 11:59:53.520144 94815 caffe.cpp:526]   dropout3	backward: 1.912 ms.
I1031 11:59:53.520342 94815 caffe.cpp:522]      pool3	forward: 12.793 ms.
I1031 11:59:53.520545 94815 caffe.cpp:526]      pool3	backward: 5.971 ms.
I1031 11:59:53.520741 94815 caffe.cpp:522]      conv4	forward: 60.368 ms.
I1031 11:59:53.520943 94815 caffe.cpp:526]      conv4	backward: 12.776 ms.
I1031 11:59:53.521145 94815 caffe.cpp:522]      relu4	forward: 16.083 ms.
I1031 11:59:53.521347 94815 caffe.cpp:526]      relu4	backward: 50.215 ms.
I1031 11:59:53.521549 94815 caffe.cpp:522]   dropout4	forward: 58.2 ms.
I1031 11:59:53.521751 94815 caffe.cpp:526]   dropout4	backward: 54.126 ms.
I1031 11:59:53.521953 94815 caffe.cpp:522]      pool4	forward: 19.368 ms.
I1031 11:59:53.522197 94815 caffe.cpp:526]      pool4	backward: 44.049 ms.
I1031 11:59:53.522431 94815 caffe.cpp:522]        fc1	forward: 34.938 ms.
I1031 11:59:53.522774 94815 caffe.cpp:526]        fc1	backward: 54.465 ms.
I1031 11:59:53.523036 94815 caffe.cpp:522]   dropout5	forward: 47.722 ms.
I1031 11:59:53.523242 94815 caffe.cpp:526]   dropout5	backward: 26.872 ms.
I1031 11:59:53.523484 94815 caffe.cpp:522]        fc2	forward: 17.695 ms.
I1031 11:59:53.523689 94815 caffe.cpp:526]        fc2	backward: 0.209 ms.
I1031 11:59:53.523891 94815 caffe.cpp:522]       loss	forward: 95.116 ms.
I1031 11:59:53.524096 94815 caffe.cpp:526]       loss	backward: 50.858 ms.
I1031 11:59:53.529901 94815 caffe.cpp:532] Average Forward pass: 1130.42 ms.
I1031 11:59:53.543463 94815 caffe.cpp:535] Average Backward pass: 616.641 ms.
I1031 11:59:53.554965 94815 caffe.cpp:537] Average Forward-Backward: 2264 ms.
I1031 11:59:53.570430 94815 caffe.cpp:540] Total Time: 2264 ms.
I1031 11:59:53.583475 94815 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 1
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 64384576
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 1030153217
--->Total double-precision FLOPs = 0
--->Total FLOPs = 1030153217
mem-read-1 = 84321
mem-read-2 = 110
mem-read-4 = 35085510
mem-read-8 = 7652712
mem-read-16 = 0
mem-read-32 = 39042
mem-read-64 = 64920524
mem-write-1 = 166
mem-write-2 = 51
mem-write-4 = 240246
mem-write-8 = 4006701
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 266486
--->Total Bytes read = 4357811157
--->Total Bytes written = 50070028
--->Total Bytes = 4407881185

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer12_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=12 -prof_forward_direction=0
I1031 14:50:56.822175 101170 caffe.cpp:444] Use CPU.
I1031 14:51:14.728039 101170 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:51:14.788949 101170 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:51:14.801163 101170 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:51:14.813050 101170 cpu_info.cpp:461] Total number of processors: 256
I1031 14:51:14.830850 101170 cpu_info.cpp:464] GPU is used: no
I1031 14:51:14.840250 101170 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:51:14.849059 101170 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:51:14.861233 101170 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:51:23.996079 101170 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:51:24.679581 101170 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:51:27.091132 101170 layer_factory.hpp:114] Creating layer data
I1031 14:51:27.265902 101170 net.cpp:160] Creating Layer data
I1031 14:51:27.316944 101170 net.cpp:570] data -> data
I1031 14:51:27.813231 101170 net.cpp:570] data -> label
I1031 14:51:35.258572 101170 net.cpp:210] Setting up data
I1031 14:51:35.342644 101170 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:51:35.449460 101170 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:51:35.456802 101170 net.cpp:225] Memory required for data: 184516
I1031 14:51:35.536321 101170 layer_factory.hpp:114] Creating layer conv1
I1031 14:51:35.885116 101170 net.cpp:160] Creating Layer conv1
I1031 14:51:35.938613 101170 net.cpp:596] conv1 <- data
I1031 14:51:36.066041 101170 net.cpp:570] conv1 -> conv1
I1031 14:52:13.400591 101170 net.cpp:210] Setting up conv1
I1031 14:52:13.516911 101170 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:52:13.523811 101170 net.cpp:225] Memory required for data: 7805124
I1031 14:52:13.890704 101170 layer_factory.hpp:114] Creating layer relu1
I1031 14:52:14.035485 101170 net.cpp:160] Creating Layer relu1
I1031 14:52:14.041024 101170 net.cpp:596] relu1 <- conv1
I1031 14:52:14.076175 101170 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:52:14.292090 101170 net.cpp:210] Setting up relu1
I1031 14:52:14.294767 101170 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:52:14.295801 101170 net.cpp:225] Memory required for data: 15425732
I1031 14:52:14.296094 101170 layer_factory.hpp:114] Creating layer dropout1
I1031 14:52:14.327999 101170 net.cpp:160] Creating Layer dropout1
I1031 14:52:14.328326 101170 net.cpp:596] dropout1 <- conv1
I1031 14:52:14.331023 101170 net.cpp:570] dropout1 -> drop1
I1031 14:52:14.441440 101170 net.cpp:210] Setting up dropout1
I1031 14:52:14.454888 101170 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:52:14.455291 101170 net.cpp:225] Memory required for data: 23046340
I1031 14:52:14.455691 101170 layer_factory.hpp:114] Creating layer pool1
I1031 14:52:14.561923 101170 net.cpp:160] Creating Layer pool1
I1031 14:52:14.562636 101170 net.cpp:596] pool1 <- drop1
I1031 14:52:14.562981 101170 net.cpp:570] pool1 -> pool1
I1031 14:52:14.973999 101170 net.cpp:210] Setting up pool1
I1031 14:52:14.978953 101170 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:52:14.979343 101170 net.cpp:225] Memory required for data: 24951492
I1031 14:52:14.979723 101170 layer_factory.hpp:114] Creating layer conv2
I1031 14:52:15.041587 101170 net.cpp:160] Creating Layer conv2
I1031 14:52:15.046030 101170 net.cpp:596] conv2 <- pool1
I1031 14:52:15.061388 101170 net.cpp:570] conv2 -> conv2
I1031 14:52:21.885535 101170 net.cpp:210] Setting up conv2
I1031 14:52:21.885982 101170 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:52:21.892244 101170 net.cpp:225] Memory required for data: 26733764
I1031 14:52:21.954598 101170 layer_factory.hpp:114] Creating layer relu2
I1031 14:52:21.958201 101170 net.cpp:160] Creating Layer relu2
I1031 14:52:21.962451 101170 net.cpp:596] relu2 <- conv2
I1031 14:52:21.967036 101170 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:52:21.976171 101170 net.cpp:210] Setting up relu2
I1031 14:52:21.982183 101170 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:52:21.990659 101170 net.cpp:225] Memory required for data: 28516036
I1031 14:52:22.001265 101170 layer_factory.hpp:114] Creating layer dropout2
I1031 14:52:22.007890 101170 net.cpp:160] Creating Layer dropout2
I1031 14:52:22.010335 101170 net.cpp:596] dropout2 <- conv2
I1031 14:52:22.012616 101170 net.cpp:570] dropout2 -> drop2
I1031 14:52:22.023346 101170 net.cpp:210] Setting up dropout2
I1031 14:52:22.030055 101170 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:52:22.034767 101170 net.cpp:225] Memory required for data: 30298308
I1031 14:52:22.039472 101170 layer_factory.hpp:114] Creating layer pool2
I1031 14:52:22.048066 101170 net.cpp:160] Creating Layer pool2
I1031 14:52:22.054219 101170 net.cpp:596] pool2 <- drop2
I1031 14:52:22.062813 101170 net.cpp:570] pool2 -> pool2
I1031 14:52:22.069526 101170 net.cpp:210] Setting up pool2
I1031 14:52:22.073951 101170 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:52:22.078202 101170 net.cpp:225] Memory required for data: 30759108
I1031 14:52:22.082648 101170 layer_factory.hpp:114] Creating layer conv3
I1031 14:52:22.091259 101170 net.cpp:160] Creating Layer conv3
I1031 14:52:22.095779 101170 net.cpp:596] conv3 <- pool2
I1031 14:52:22.106506 101170 net.cpp:570] conv3 -> conv3
I1031 14:52:22.738236 101170 net.cpp:210] Setting up conv3
I1031 14:52:22.752925 101170 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:52:22.761445 101170 net.cpp:225] Memory required for data: 31160516
I1031 14:52:22.778098 101170 layer_factory.hpp:114] Creating layer relu3
I1031 14:52:22.784468 101170 net.cpp:160] Creating Layer relu3
I1031 14:52:22.788769 101170 net.cpp:596] relu3 <- conv3
I1031 14:52:22.792801 101170 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:52:22.805057 101170 net.cpp:210] Setting up relu3
I1031 14:52:22.817394 101170 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:52:22.819670 101170 net.cpp:225] Memory required for data: 31561924
I1031 14:52:22.827926 101170 layer_factory.hpp:114] Creating layer dropout3
I1031 14:52:22.834640 101170 net.cpp:160] Creating Layer dropout3
I1031 14:52:22.836926 101170 net.cpp:596] dropout3 <- conv3
I1031 14:52:22.839124 101170 net.cpp:570] dropout3 -> drop3
I1031 14:52:22.845588 101170 net.cpp:210] Setting up dropout3
I1031 14:52:22.856067 101170 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:52:22.864629 101170 net.cpp:225] Memory required for data: 31963332
I1031 14:52:22.871000 101170 layer_factory.hpp:114] Creating layer pool3
I1031 14:52:22.879832 101170 net.cpp:160] Creating Layer pool3
I1031 14:52:22.895951 101170 net.cpp:596] pool3 <- drop3
I1031 14:52:22.904440 101170 net.cpp:570] pool3 -> pool3
I1031 14:52:22.913187 101170 net.cpp:210] Setting up pool3
I1031 14:52:22.919894 101170 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:52:22.930167 101170 net.cpp:225] Memory required for data: 32063684
I1031 14:52:22.938803 101170 layer_factory.hpp:114] Creating layer conv4
I1031 14:52:22.941042 101170 net.cpp:160] Creating Layer conv4
I1031 14:52:22.944017 101170 net.cpp:596] conv4 <- pool3
I1031 14:52:22.946537 101170 net.cpp:570] conv4 -> conv4
I1031 14:52:23.336403 101170 net.cpp:210] Setting up conv4
I1031 14:52:23.341028 101170 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:52:23.351433 101170 net.cpp:225] Memory required for data: 32137412
I1031 14:52:23.356276 101170 layer_factory.hpp:114] Creating layer relu4
I1031 14:52:23.358719 101170 net.cpp:160] Creating Layer relu4
I1031 14:52:23.360718 101170 net.cpp:596] relu4 <- conv4
I1031 14:52:23.365000 101170 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:52:23.372231 101170 net.cpp:210] Setting up relu4
I1031 14:52:23.380955 101170 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:52:23.389462 101170 net.cpp:225] Memory required for data: 32211140
I1031 14:52:23.397963 101170 layer_factory.hpp:114] Creating layer dropout4
I1031 14:52:23.402461 101170 net.cpp:160] Creating Layer dropout4
I1031 14:52:23.408491 101170 net.cpp:596] dropout4 <- conv4
I1031 14:52:23.421236 101170 net.cpp:570] dropout4 -> drop4
I1031 14:52:23.433801 101170 net.cpp:210] Setting up dropout4
I1031 14:52:23.441678 101170 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:52:23.452853 101170 net.cpp:225] Memory required for data: 32284868
I1031 14:52:23.454679 101170 layer_factory.hpp:114] Creating layer pool4
I1031 14:52:23.460168 101170 net.cpp:160] Creating Layer pool4
I1031 14:52:23.468688 101170 net.cpp:596] pool4 <- drop4
I1031 14:52:23.473121 101170 net.cpp:570] pool4 -> pool4
I1031 14:52:23.492095 101170 net.cpp:210] Setting up pool4
I1031 14:52:23.494603 101170 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:52:23.497037 101170 net.cpp:225] Memory required for data: 32303300
I1031 14:52:23.502676 101170 layer_factory.hpp:114] Creating layer fc1
I1031 14:52:23.572249 101170 net.cpp:160] Creating Layer fc1
I1031 14:52:23.586441 101170 net.cpp:596] fc1 <- pool4
I1031 14:52:23.592999 101170 net.cpp:570] fc1 -> fc1
I1031 14:52:24.471602 101170 net.cpp:210] Setting up fc1
I1031 14:52:24.483420 101170 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:52:24.488618 101170 net.cpp:225] Memory required for data: 32307396
I1031 14:52:24.504329 101170 layer_factory.hpp:114] Creating layer dropout5
I1031 14:52:24.514875 101170 net.cpp:160] Creating Layer dropout5
I1031 14:52:24.516878 101170 net.cpp:596] dropout5 <- fc1
I1031 14:52:24.525979 101170 net.cpp:570] dropout5 -> drop5
I1031 14:52:24.536507 101170 net.cpp:210] Setting up dropout5
I1031 14:52:24.543011 101170 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:52:24.549521 101170 net.cpp:225] Memory required for data: 32311492
I1031 14:52:24.557176 101170 layer_factory.hpp:114] Creating layer fc2
I1031 14:52:24.562633 101170 net.cpp:160] Creating Layer fc2
I1031 14:52:24.575661 101170 net.cpp:596] fc2 <- drop5
I1031 14:52:24.586102 101170 net.cpp:570] fc2 -> fc2
I1031 14:52:24.616478 101170 net.cpp:210] Setting up fc2
I1031 14:52:24.622443 101170 net.cpp:217] Top shape: 1 2 (2)
I1031 14:52:24.627086 101170 net.cpp:225] Memory required for data: 32311500
I1031 14:52:24.635624 101170 layer_factory.hpp:114] Creating layer loss
I1031 14:52:24.668298 101170 net.cpp:160] Creating Layer loss
I1031 14:52:24.675053 101170 net.cpp:596] loss <- fc2
I1031 14:52:24.692479 101170 net.cpp:596] loss <- label
I1031 14:52:24.757339 101170 net.cpp:570] loss -> (automatic)
I1031 14:52:24.811871 101170 layer_factory.hpp:114] Creating layer loss
I1031 14:52:25.224197 101170 net.cpp:210] Setting up loss
I1031 14:52:25.235561 101170 net.cpp:217] Top shape: (1)
I1031 14:52:25.250314 101170 net.cpp:220]     with loss weight 1
I1031 14:52:25.387981 101170 net.cpp:225] Memory required for data: 32311504
I1031 14:52:25.437798 101170 net.cpp:287] loss needs backward computation.
I1031 14:52:25.541391 101170 net.cpp:287] fc2 needs backward computation.
I1031 14:52:25.558671 101170 net.cpp:287] dropout5 needs backward computation.
I1031 14:52:25.573189 101170 net.cpp:287] fc1 needs backward computation.
I1031 14:52:25.582981 101170 net.cpp:287] pool4 needs backward computation.
I1031 14:52:25.591521 101170 net.cpp:287] dropout4 needs backward computation.
I1031 14:52:25.593899 101170 net.cpp:287] relu4 needs backward computation.
I1031 14:52:25.606052 101170 net.cpp:287] conv4 needs backward computation.
I1031 14:52:25.628222 101170 net.cpp:287] pool3 needs backward computation.
I1031 14:52:25.652367 101170 net.cpp:287] dropout3 needs backward computation.
I1031 14:52:25.664990 101170 net.cpp:287] relu3 needs backward computation.
I1031 14:52:25.665534 101170 net.cpp:287] conv3 needs backward computation.
I1031 14:52:25.665876 101170 net.cpp:287] pool2 needs backward computation.
I1031 14:52:25.666146 101170 net.cpp:287] dropout2 needs backward computation.
I1031 14:52:25.666347 101170 net.cpp:287] relu2 needs backward computation.
I1031 14:52:25.666538 101170 net.cpp:287] conv2 needs backward computation.
I1031 14:52:25.666733 101170 net.cpp:287] pool1 needs backward computation.
I1031 14:52:25.666925 101170 net.cpp:287] dropout1 needs backward computation.
I1031 14:52:25.667117 101170 net.cpp:287] relu1 needs backward computation.
I1031 14:52:25.667302 101170 net.cpp:287] conv1 needs backward computation.
I1031 14:52:25.687284 101170 net.cpp:289] data does not need backward computation.
I1031 14:52:25.744412 101170 net.cpp:345] Network initialization done.
I1031 14:52:25.925954 101170 caffe.cpp:452] Performing Forward
I1031 14:52:37.809173 101170 caffe.cpp:457] Initial loss: 87.3365
I1031 14:52:37.934478 101170 caffe.cpp:459] Performing Backward
I1031 14:52:41.329149 101170 caffe.cpp:468] *** Benchmark begins ***
I1031 14:52:41.343657 101170 caffe.cpp:469] Testing for 1 iterations.
I1031 14:52:41.501188 101170 caffe.cpp:485] Profiling Layer: pool3 backward
I1031 14:52:43.191678 101170 caffe.cpp:512] Iteration: 1 forward-backward time: 1688 ms.
I1031 14:52:43.293431 101170 caffe.cpp:519] Average time per layer: 
I1031 14:52:43.312410 101170 caffe.cpp:522]       data	forward: 49.56 ms.
I1031 14:52:43.375844 101170 caffe.cpp:526]       data	backward: 5.803 ms.
I1031 14:52:43.412024 101170 caffe.cpp:522]      conv1	forward: 96.017 ms.
I1031 14:52:43.419317 101170 caffe.cpp:526]      conv1	backward: 34.277 ms.
I1031 14:52:43.423813 101170 caffe.cpp:522]      relu1	forward: 28.636 ms.
I1031 14:52:43.428495 101170 caffe.cpp:526]      relu1	backward: 68.876 ms.
I1031 14:52:43.430622 101170 caffe.cpp:522]   dropout1	forward: 97.858 ms.
I1031 14:52:43.431478 101170 caffe.cpp:526]   dropout1	backward: 61.025 ms.
I1031 14:52:43.433915 101170 caffe.cpp:522]      pool1	forward: 128.582 ms.
I1031 14:52:43.437047 101170 caffe.cpp:526]      pool1	backward: 108.56 ms.
I1031 14:52:43.437364 101170 caffe.cpp:522]      conv2	forward: 75.492 ms.
I1031 14:52:43.437613 101170 caffe.cpp:526]      conv2	backward: 14.036 ms.
I1031 14:52:43.437993 101170 caffe.cpp:522]      relu2	forward: 17.895 ms.
I1031 14:52:43.438484 101170 caffe.cpp:526]      relu2	backward: 6.776 ms.
I1031 14:52:43.438702 101170 caffe.cpp:522]   dropout2	forward: 62.783 ms.
I1031 14:52:43.438910 101170 caffe.cpp:526]   dropout2	backward: 7.773 ms.
I1031 14:52:43.439110 101170 caffe.cpp:522]      pool2	forward: 29.43 ms.
I1031 14:52:43.439313 101170 caffe.cpp:526]      pool2	backward: 25.456 ms.
I1031 14:52:43.439563 101170 caffe.cpp:522]      conv3	forward: 56.014 ms.
I1031 14:52:43.439769 101170 caffe.cpp:526]      conv3	backward: 2.604 ms.
I1031 14:52:43.439967 101170 caffe.cpp:522]      relu3	forward: 22.275 ms.
I1031 14:52:43.440171 101170 caffe.cpp:526]      relu3	backward: 4.35 ms.
I1031 14:52:43.440407 101170 caffe.cpp:522]   dropout3	forward: 54.882 ms.
I1031 14:52:43.440634 101170 caffe.cpp:526]   dropout3	backward: 1.943 ms.
I1031 14:52:43.440980 101170 caffe.cpp:522]      pool3	forward: 18.31 ms.
I1031 14:52:43.441257 101170 caffe.cpp:526]      pool3	backward: 17.077 ms.
I1031 14:52:43.441468 101170 caffe.cpp:522]      conv4	forward: 51.362 ms.
I1031 14:52:43.441670 101170 caffe.cpp:526]      conv4	backward: 9.553 ms.
I1031 14:52:43.442531 101170 caffe.cpp:522]      relu4	forward: 25.342 ms.
I1031 14:52:43.444692 101170 caffe.cpp:526]      relu4	backward: 5.391 ms.
I1031 14:52:43.445003 101170 caffe.cpp:522]   dropout4	forward: 76.151 ms.
I1031 14:52:43.445230 101170 caffe.cpp:526]   dropout4	backward: 12.556 ms.
I1031 14:52:43.445441 101170 caffe.cpp:522]      pool4	forward: 17.783 ms.
I1031 14:52:43.445652 101170 caffe.cpp:526]      pool4	backward: 1.139 ms.
I1031 14:52:43.445853 101170 caffe.cpp:522]        fc1	forward: 53.246 ms.
I1031 14:52:43.446058 101170 caffe.cpp:526]        fc1	backward: 11.185 ms.
I1031 14:52:43.446264 101170 caffe.cpp:522]   dropout5	forward: 38.052 ms.
I1031 14:52:43.446509 101170 caffe.cpp:526]   dropout5	backward: 5.479 ms.
I1031 14:52:43.446780 101170 caffe.cpp:522]        fc2	forward: 21.146 ms.
I1031 14:52:43.447137 101170 caffe.cpp:526]        fc2	backward: 0.209 ms.
I1031 14:52:43.447541 101170 caffe.cpp:522]       loss	forward: 97.766 ms.
I1031 14:52:43.447798 101170 caffe.cpp:526]       loss	backward: 57.152 ms.
I1031 14:52:43.453667 101170 caffe.cpp:532] Average Forward pass: 1180.13 ms.
I1031 14:52:43.467267 101170 caffe.cpp:535] Average Backward pass: 470.515 ms.
I1031 14:52:43.479079 101170 caffe.cpp:537] Average Forward-Backward: 2062 ms.
I1031 14:52:43.494720 101170 caffe.cpp:540] Total Time: 2062 ms.
I1031 14:52:43.508993 101170 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 25088
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 25088
--->Total double-precision FLOPs = 0
--->Total FLOPs = 25088
mem-read-1 = 707504
mem-read-2 = 105
mem-read-4 = 5724890
mem-read-8 = 8024253
mem-read-16 = 0
mem-read-32 = 3
mem-read-64 = 4228
mem-write-1 = 284
mem-write-2 = 51
mem-write-4 = 129034
mem-write-8 = 732864
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 8066
--->Total Bytes read = 88071986
--->Total Bytes written = 6895722
--->Total Bytes = 94967708

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer8_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=8 -prof_forward_direction=1
I1031 12:17:20.995775 95652 caffe.cpp:444] Use CPU.
I1031 12:17:38.849391 95652 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 12:17:38.911640 95652 cpu_info.cpp:455] Total number of sockets: 1
I1031 12:17:38.924487 95652 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 12:17:38.936630 95652 cpu_info.cpp:461] Total number of processors: 256
I1031 12:17:38.953766 95652 cpu_info.cpp:464] GPU is used: no
I1031 12:17:38.963137 95652 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 12:17:38.971952 95652 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 12:17:38.984426 95652 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 12:17:48.098440 95652 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 12:17:48.801574 95652 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 12:17:51.219190 95652 layer_factory.hpp:114] Creating layer data
I1031 12:17:51.374613 95652 net.cpp:160] Creating Layer data
I1031 12:17:51.425225 95652 net.cpp:570] data -> data
I1031 12:17:51.926378 95652 net.cpp:570] data -> label
I1031 12:17:59.375533 95652 net.cpp:210] Setting up data
I1031 12:17:59.458982 95652 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 12:17:59.565517 95652 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 12:17:59.572916 95652 net.cpp:225] Memory required for data: 184516
I1031 12:17:59.655236 95652 layer_factory.hpp:114] Creating layer conv1
I1031 12:18:00.009678 95652 net.cpp:160] Creating Layer conv1
I1031 12:18:00.066537 95652 net.cpp:596] conv1 <- data
I1031 12:18:00.193644 95652 net.cpp:570] conv1 -> conv1
I1031 12:18:37.737457 95652 net.cpp:210] Setting up conv1
I1031 12:18:37.813128 95652 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:18:37.821476 95652 net.cpp:225] Memory required for data: 7805124
I1031 12:18:38.147166 95652 layer_factory.hpp:114] Creating layer relu1
I1031 12:18:38.288416 95652 net.cpp:160] Creating Layer relu1
I1031 12:18:38.296398 95652 net.cpp:596] relu1 <- conv1
I1031 12:18:38.330651 95652 net.cpp:557] relu1 -> conv1 (in-place)
I1031 12:18:38.546134 95652 net.cpp:210] Setting up relu1
I1031 12:18:38.549123 95652 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:18:38.549522 95652 net.cpp:225] Memory required for data: 15425732
I1031 12:18:38.549808 95652 layer_factory.hpp:114] Creating layer dropout1
I1031 12:18:38.583623 95652 net.cpp:160] Creating Layer dropout1
I1031 12:18:38.583968 95652 net.cpp:596] dropout1 <- conv1
I1031 12:18:38.586798 95652 net.cpp:570] dropout1 -> drop1
I1031 12:18:38.707170 95652 net.cpp:210] Setting up dropout1
I1031 12:18:38.721456 95652 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 12:18:38.721878 95652 net.cpp:225] Memory required for data: 23046340
I1031 12:18:38.722203 95652 layer_factory.hpp:114] Creating layer pool1
I1031 12:18:38.824934 95652 net.cpp:160] Creating Layer pool1
I1031 12:18:38.829308 95652 net.cpp:596] pool1 <- drop1
I1031 12:18:38.829646 95652 net.cpp:570] pool1 -> pool1
I1031 12:18:39.237520 95652 net.cpp:210] Setting up pool1
I1031 12:18:39.246361 95652 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 12:18:39.246737 95652 net.cpp:225] Memory required for data: 24951492
I1031 12:18:39.247036 95652 layer_factory.hpp:114] Creating layer conv2
I1031 12:18:39.308728 95652 net.cpp:160] Creating Layer conv2
I1031 12:18:39.313109 95652 net.cpp:596] conv2 <- pool1
I1031 12:18:39.328526 95652 net.cpp:570] conv2 -> conv2
I1031 12:18:46.156357 95652 net.cpp:210] Setting up conv2
I1031 12:18:46.161877 95652 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:18:46.169559 95652 net.cpp:225] Memory required for data: 26733764
I1031 12:18:46.238353 95652 layer_factory.hpp:114] Creating layer relu2
I1031 12:18:46.253479 95652 net.cpp:160] Creating Layer relu2
I1031 12:18:46.260864 95652 net.cpp:596] relu2 <- conv2
I1031 12:18:46.267282 95652 net.cpp:557] relu2 -> conv2 (in-place)
I1031 12:18:46.272291 95652 net.cpp:210] Setting up relu2
I1031 12:18:46.279021 95652 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:18:46.285087 95652 net.cpp:225] Memory required for data: 28516036
I1031 12:18:46.295624 95652 layer_factory.hpp:114] Creating layer dropout2
I1031 12:18:46.300097 95652 net.cpp:160] Creating Layer dropout2
I1031 12:18:46.300413 95652 net.cpp:596] dropout2 <- conv2
I1031 12:18:46.300695 95652 net.cpp:570] dropout2 -> drop2
I1031 12:18:46.307001 95652 net.cpp:210] Setting up dropout2
I1031 12:18:46.307309 95652 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 12:18:46.314029 95652 net.cpp:225] Memory required for data: 30298308
I1031 12:18:46.318404 95652 layer_factory.hpp:114] Creating layer pool2
I1031 12:18:46.327020 95652 net.cpp:160] Creating Layer pool2
I1031 12:18:46.333621 95652 net.cpp:596] pool2 <- drop2
I1031 12:18:46.349745 95652 net.cpp:570] pool2 -> pool2
I1031 12:18:46.360440 95652 net.cpp:210] Setting up pool2
I1031 12:18:46.372581 95652 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 12:18:46.379015 95652 net.cpp:225] Memory required for data: 30759108
I1031 12:18:46.389454 95652 layer_factory.hpp:114] Creating layer conv3
I1031 12:18:46.397753 95652 net.cpp:160] Creating Layer conv3
I1031 12:18:46.408145 95652 net.cpp:596] conv3 <- pool2
I1031 12:18:46.416951 95652 net.cpp:570] conv3 -> conv3
I1031 12:18:47.055420 95652 net.cpp:210] Setting up conv3
I1031 12:18:47.065958 95652 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:18:47.073935 95652 net.cpp:225] Memory required for data: 31160516
I1031 12:18:47.095055 95652 layer_factory.hpp:114] Creating layer relu3
I1031 12:18:47.101541 95652 net.cpp:160] Creating Layer relu3
I1031 12:18:47.111793 95652 net.cpp:596] relu3 <- conv3
I1031 12:18:47.116540 95652 net.cpp:557] relu3 -> conv3 (in-place)
I1031 12:18:47.127159 95652 net.cpp:210] Setting up relu3
I1031 12:18:47.137699 95652 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:18:47.144022 95652 net.cpp:225] Memory required for data: 31561924
I1031 12:18:47.150075 95652 layer_factory.hpp:114] Creating layer dropout3
I1031 12:18:47.155184 95652 net.cpp:160] Creating Layer dropout3
I1031 12:18:47.161494 95652 net.cpp:596] dropout3 <- conv3
I1031 12:18:47.168134 95652 net.cpp:570] dropout3 -> drop3
I1031 12:18:47.174195 95652 net.cpp:210] Setting up dropout3
I1031 12:18:47.176506 95652 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 12:18:47.183245 95652 net.cpp:225] Memory required for data: 31963332
I1031 12:18:47.191618 95652 layer_factory.hpp:114] Creating layer pool3
I1031 12:18:47.197216 95652 net.cpp:160] Creating Layer pool3
I1031 12:18:47.197551 95652 net.cpp:596] pool3 <- drop3
I1031 12:18:47.197813 95652 net.cpp:570] pool3 -> pool3
I1031 12:18:47.198246 95652 net.cpp:210] Setting up pool3
I1031 12:18:47.198503 95652 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 12:18:47.198746 95652 net.cpp:225] Memory required for data: 32063684
I1031 12:18:47.198963 95652 layer_factory.hpp:114] Creating layer conv4
I1031 12:18:47.199312 95652 net.cpp:160] Creating Layer conv4
I1031 12:18:47.199590 95652 net.cpp:596] conv4 <- pool3
I1031 12:18:47.199846 95652 net.cpp:570] conv4 -> conv4
I1031 12:18:47.547008 95652 net.cpp:210] Setting up conv4
I1031 12:18:47.563454 95652 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:18:47.566010 95652 net.cpp:225] Memory required for data: 32137412
I1031 12:18:47.579247 95652 layer_factory.hpp:114] Creating layer relu4
I1031 12:18:47.588930 95652 net.cpp:160] Creating Layer relu4
I1031 12:18:47.591334 95652 net.cpp:596] relu4 <- conv4
I1031 12:18:47.599658 95652 net.cpp:557] relu4 -> conv4 (in-place)
I1031 12:18:47.614025 95652 net.cpp:210] Setting up relu4
I1031 12:18:47.616695 95652 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:18:47.625391 95652 net.cpp:225] Memory required for data: 32211140
I1031 12:18:47.633720 95652 layer_factory.hpp:114] Creating layer dropout4
I1031 12:18:47.642493 95652 net.cpp:160] Creating Layer dropout4
I1031 12:18:47.646821 95652 net.cpp:596] dropout4 <- conv4
I1031 12:18:47.648771 95652 net.cpp:570] dropout4 -> drop4
I1031 12:18:47.659711 95652 net.cpp:210] Setting up dropout4
I1031 12:18:47.666229 95652 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 12:18:47.672335 95652 net.cpp:225] Memory required for data: 32284868
I1031 12:18:47.676610 95652 layer_factory.hpp:114] Creating layer pool4
I1031 12:18:47.681227 95652 net.cpp:160] Creating Layer pool4
I1031 12:18:47.683190 95652 net.cpp:596] pool4 <- drop4
I1031 12:18:47.685498 95652 net.cpp:570] pool4 -> pool4
I1031 12:18:47.708127 95652 net.cpp:210] Setting up pool4
I1031 12:18:47.722141 95652 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 12:18:47.732930 95652 net.cpp:225] Memory required for data: 32303300
I1031 12:18:47.737542 95652 layer_factory.hpp:114] Creating layer fc1
I1031 12:18:47.808192 95652 net.cpp:160] Creating Layer fc1
I1031 12:18:47.812531 95652 net.cpp:596] fc1 <- pool4
I1031 12:18:47.814564 95652 net.cpp:570] fc1 -> fc1
I1031 12:18:48.627935 95652 net.cpp:210] Setting up fc1
I1031 12:18:48.639114 95652 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:18:48.641693 95652 net.cpp:225] Memory required for data: 32307396
I1031 12:18:48.650967 95652 layer_factory.hpp:114] Creating layer dropout5
I1031 12:18:48.661828 95652 net.cpp:160] Creating Layer dropout5
I1031 12:18:48.672472 95652 net.cpp:596] dropout5 <- fc1
I1031 12:18:48.683104 95652 net.cpp:570] dropout5 -> drop5
I1031 12:18:48.691658 95652 net.cpp:210] Setting up dropout5
I1031 12:18:48.698309 95652 net.cpp:217] Top shape: 1 1024 (1024)
I1031 12:18:48.704761 95652 net.cpp:225] Memory required for data: 32311492
I1031 12:18:48.713229 95652 layer_factory.hpp:114] Creating layer fc2
I1031 12:18:48.715137 95652 net.cpp:160] Creating Layer fc2
I1031 12:18:48.717718 95652 net.cpp:596] fc2 <- drop5
I1031 12:18:48.724275 95652 net.cpp:570] fc2 -> fc2
I1031 12:18:48.761407 95652 net.cpp:210] Setting up fc2
I1031 12:18:48.770997 95652 net.cpp:217] Top shape: 1 2 (2)
I1031 12:18:48.781370 95652 net.cpp:225] Memory required for data: 32311500
I1031 12:18:48.788164 95652 layer_factory.hpp:114] Creating layer loss
I1031 12:18:48.816661 95652 net.cpp:160] Creating Layer loss
I1031 12:18:48.825435 95652 net.cpp:596] loss <- fc2
I1031 12:18:48.842749 95652 net.cpp:596] loss <- label
I1031 12:18:48.907174 95652 net.cpp:570] loss -> (automatic)
I1031 12:18:48.973968 95652 layer_factory.hpp:114] Creating layer loss
I1031 12:18:49.390985 95652 net.cpp:210] Setting up loss
I1031 12:18:49.401875 95652 net.cpp:217] Top shape: (1)
I1031 12:18:49.416386 95652 net.cpp:220]     with loss weight 1
I1031 12:18:49.552896 95652 net.cpp:225] Memory required for data: 32311504
I1031 12:18:49.603060 95652 net.cpp:287] loss needs backward computation.
I1031 12:18:49.711257 95652 net.cpp:287] fc2 needs backward computation.
I1031 12:18:49.719525 95652 net.cpp:287] dropout5 needs backward computation.
I1031 12:18:49.721899 95652 net.cpp:287] fc1 needs backward computation.
I1031 12:18:49.722756 95652 net.cpp:287] pool4 needs backward computation.
I1031 12:18:49.723059 95652 net.cpp:287] dropout4 needs backward computation.
I1031 12:18:49.723294 95652 net.cpp:287] relu4 needs backward computation.
I1031 12:18:49.734128 95652 net.cpp:287] conv4 needs backward computation.
I1031 12:18:49.753512 95652 net.cpp:287] pool3 needs backward computation.
I1031 12:18:49.770525 95652 net.cpp:287] dropout3 needs backward computation.
I1031 12:18:49.775655 95652 net.cpp:287] relu3 needs backward computation.
I1031 12:18:49.775984 95652 net.cpp:287] conv3 needs backward computation.
I1031 12:18:49.776312 95652 net.cpp:287] pool2 needs backward computation.
I1031 12:18:49.776583 95652 net.cpp:287] dropout2 needs backward computation.
I1031 12:18:49.776790 95652 net.cpp:287] relu2 needs backward computation.
I1031 12:18:49.776984 95652 net.cpp:287] conv2 needs backward computation.
I1031 12:18:49.777186 95652 net.cpp:287] pool1 needs backward computation.
I1031 12:18:49.777385 95652 net.cpp:287] dropout1 needs backward computation.
I1031 12:18:49.777580 95652 net.cpp:287] relu1 needs backward computation.
I1031 12:18:49.777770 95652 net.cpp:287] conv1 needs backward computation.
I1031 12:18:49.797636 95652 net.cpp:289] data does not need backward computation.
I1031 12:18:49.853996 95652 net.cpp:345] Network initialization done.
I1031 12:18:50.038270 95652 caffe.cpp:452] Performing Forward
I1031 12:19:01.929383 95652 caffe.cpp:457] Initial loss: 87.3365
I1031 12:19:02.070435 95652 caffe.cpp:459] Performing Backward
I1031 12:19:05.562455 95652 caffe.cpp:468] *** Benchmark begins ***
I1031 12:19:05.578239 95652 caffe.cpp:469] Testing for 1 iterations.
I1031 12:19:05.737125 95652 caffe.cpp:482] Profiling Layer: pool2 forward
I1031 12:19:07.780880 95652 caffe.cpp:512] Iteration: 1 forward-backward time: 2036 ms.
I1031 12:19:07.896469 95652 caffe.cpp:519] Average time per layer: 
I1031 12:19:07.922474 95652 caffe.cpp:522]       data	forward: 50.197 ms.
I1031 12:19:07.979302 95652 caffe.cpp:526]       data	backward: 9.261 ms.
I1031 12:19:08.020858 95652 caffe.cpp:522]      conv1	forward: 16.913 ms.
I1031 12:19:08.035588 95652 caffe.cpp:526]      conv1	backward: 30.04 ms.
I1031 12:19:08.044245 95652 caffe.cpp:522]      relu1	forward: 2.413 ms.
I1031 12:19:08.049989 95652 caffe.cpp:526]      relu1	backward: 67.063 ms.
I1031 12:19:08.052783 95652 caffe.cpp:522]   dropout1	forward: 38.674 ms.
I1031 12:19:08.053109 95652 caffe.cpp:526]   dropout1	backward: 61.099 ms.
I1031 12:19:08.053378 95652 caffe.cpp:522]      pool1	forward: 124.572 ms.
I1031 12:19:08.053742 95652 caffe.cpp:526]      pool1	backward: 132.116 ms.
I1031 12:19:08.053972 95652 caffe.cpp:522]      conv2	forward: 69.604 ms.
I1031 12:19:08.054183 95652 caffe.cpp:526]      conv2	backward: 69.432 ms.
I1031 12:19:08.054390 95652 caffe.cpp:522]      relu2	forward: 20.984 ms.
I1031 12:19:08.054597 95652 caffe.cpp:526]      relu2	backward: 35.271 ms.
I1031 12:19:08.054802 95652 caffe.cpp:522]   dropout2	forward: 58.269 ms.
I1031 12:19:08.055008 95652 caffe.cpp:526]   dropout2	backward: 32.715 ms.
I1031 12:19:08.055213 95652 caffe.cpp:522]      pool2	forward: 42.112 ms.
I1031 12:19:08.055464 95652 caffe.cpp:526]      pool2	backward: 55.23 ms.
I1031 12:19:08.055673 95652 caffe.cpp:522]      conv3	forward: 53.751 ms.
I1031 12:19:08.055878 95652 caffe.cpp:526]      conv3	backward: 64.343 ms.
I1031 12:19:08.056083 95652 caffe.cpp:522]      relu3	forward: 21.216 ms.
I1031 12:19:08.056321 95652 caffe.cpp:526]      relu3	backward: 33.051 ms.
I1031 12:19:08.056541 95652 caffe.cpp:522]   dropout3	forward: 54.347 ms.
I1031 12:19:08.056852 95652 caffe.cpp:526]   dropout3	backward: 38.627 ms.
I1031 12:19:08.057153 95652 caffe.cpp:522]      pool3	forward: 18.961 ms.
I1031 12:19:08.057410 95652 caffe.cpp:526]      pool3	backward: 61.744 ms.
I1031 12:19:08.057621 95652 caffe.cpp:522]      conv4	forward: 50.991 ms.
I1031 12:19:08.057828 95652 caffe.cpp:526]      conv4	backward: 75.065 ms.
I1031 12:19:08.058037 95652 caffe.cpp:522]      relu4	forward: 17.666 ms.
I1031 12:19:08.058241 95652 caffe.cpp:526]      relu4	backward: 51.671 ms.
I1031 12:19:08.058446 95652 caffe.cpp:522]   dropout4	forward: 57.713 ms.
I1031 12:19:08.058651 95652 caffe.cpp:526]   dropout4	backward: 50.264 ms.
I1031 12:19:08.058856 95652 caffe.cpp:522]      pool4	forward: 13.704 ms.
I1031 12:19:08.059061 95652 caffe.cpp:526]      pool4	backward: 30.088 ms.
I1031 12:19:08.059265 95652 caffe.cpp:522]        fc1	forward: 49.485 ms.
I1031 12:19:08.059540 95652 caffe.cpp:526]        fc1	backward: 46.371 ms.
I1031 12:19:08.059765 95652 caffe.cpp:522]   dropout5	forward: 30.071 ms.
I1031 12:19:08.060092 95652 caffe.cpp:526]   dropout5	backward: 16.343 ms.
I1031 12:19:08.060371 95652 caffe.cpp:522]        fc2	forward: 13.898 ms.
I1031 12:19:08.060621 95652 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 12:19:08.060830 95652 caffe.cpp:522]       loss	forward: 121.271 ms.
I1031 12:19:08.061038 95652 caffe.cpp:526]       loss	backward: 48.322 ms.
I1031 12:19:08.066797 95652 caffe.cpp:532] Average Forward pass: 990.716 ms.
I1031 12:19:08.080464 95652 caffe.cpp:535] Average Backward pass: 1017.62 ms.
I1031 12:19:08.091924 95652 caffe.cpp:537] Average Forward-Backward: 2437 ms.
I1031 12:19:08.107553 95652 caffe.cpp:540] Total Time: 2437 ms.
I1031 12:19:08.120667 95652 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 445593
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 445593
--->Total double-precision FLOPs = 0
--->Total FLOPs = 445593
mem-read-1 = 35155
mem-read-2 = 37
mem-read-4 = 1637995
mem-read-8 = 3323268
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 1
mem-write-1 = 56
mem-write-2 = 17
mem-write-4 = 201704
mem-write-8 = 1307551
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 1
--->Total Bytes read = 33173449
--->Total Bytes written = 11267410
--->Total Bytes = 44440859

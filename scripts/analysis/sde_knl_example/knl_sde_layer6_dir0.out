sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer6_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=6 -prof_forward_direction=0
I1031 14:15:15.639523 99880 caffe.cpp:444] Use CPU.
I1031 14:15:33.564496 99880 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:15:33.627324 99880 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:15:33.640497 99880 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:15:33.653702 99880 cpu_info.cpp:461] Total number of processors: 256
I1031 14:15:33.670799 99880 cpu_info.cpp:464] GPU is used: no
I1031 14:15:33.680609 99880 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:15:33.689864 99880 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:15:33.702473 99880 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:15:42.838063 99880 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:15:43.522784 99880 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:15:45.943724 99880 layer_factory.hpp:114] Creating layer data
I1031 14:15:46.101114 99880 net.cpp:160] Creating Layer data
I1031 14:15:46.152047 99880 net.cpp:570] data -> data
I1031 14:15:46.644745 99880 net.cpp:570] data -> label
I1031 14:15:54.176914 99880 net.cpp:210] Setting up data
I1031 14:15:54.260587 99880 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:15:54.367061 99880 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:15:54.375994 99880 net.cpp:225] Memory required for data: 184516
I1031 14:15:54.456805 99880 layer_factory.hpp:114] Creating layer conv1
I1031 14:15:54.802953 99880 net.cpp:160] Creating Layer conv1
I1031 14:15:54.858770 99880 net.cpp:596] conv1 <- data
I1031 14:15:54.990139 99880 net.cpp:570] conv1 -> conv1
I1031 14:16:32.430143 99880 net.cpp:210] Setting up conv1
I1031 14:16:32.501849 99880 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:16:32.511710 99880 net.cpp:225] Memory required for data: 7805124
I1031 14:16:32.847337 99880 layer_factory.hpp:114] Creating layer relu1
I1031 14:16:32.986631 99880 net.cpp:160] Creating Layer relu1
I1031 14:16:32.992321 99880 net.cpp:596] relu1 <- conv1
I1031 14:16:33.027227 99880 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:16:33.269503 99880 net.cpp:210] Setting up relu1
I1031 14:16:33.272444 99880 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:16:33.272852 99880 net.cpp:225] Memory required for data: 15425732
I1031 14:16:33.273119 99880 layer_factory.hpp:114] Creating layer dropout1
I1031 14:16:33.306900 99880 net.cpp:160] Creating Layer dropout1
I1031 14:16:33.307255 99880 net.cpp:596] dropout1 <- conv1
I1031 14:16:33.310250 99880 net.cpp:570] dropout1 -> drop1
I1031 14:16:33.424289 99880 net.cpp:210] Setting up dropout1
I1031 14:16:33.438531 99880 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:16:33.439324 99880 net.cpp:225] Memory required for data: 23046340
I1031 14:16:33.439752 99880 layer_factory.hpp:114] Creating layer pool1
I1031 14:16:33.540850 99880 net.cpp:160] Creating Layer pool1
I1031 14:16:33.541187 99880 net.cpp:596] pool1 <- drop1
I1031 14:16:33.541564 99880 net.cpp:570] pool1 -> pool1
I1031 14:16:33.947974 99880 net.cpp:210] Setting up pool1
I1031 14:16:33.952683 99880 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:16:33.953063 99880 net.cpp:225] Memory required for data: 24951492
I1031 14:16:33.953372 99880 layer_factory.hpp:114] Creating layer conv2
I1031 14:16:34.020668 99880 net.cpp:160] Creating Layer conv2
I1031 14:16:34.033170 99880 net.cpp:596] conv2 <- pool1
I1031 14:16:34.049010 99880 net.cpp:570] conv2 -> conv2
I1031 14:16:40.865947 99880 net.cpp:210] Setting up conv2
I1031 14:16:40.868662 99880 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:16:40.882551 99880 net.cpp:225] Memory required for data: 26733764
I1031 14:16:40.956663 99880 layer_factory.hpp:114] Creating layer relu2
I1031 14:16:40.964694 99880 net.cpp:160] Creating Layer relu2
I1031 14:16:40.968964 99880 net.cpp:596] relu2 <- conv2
I1031 14:16:40.975904 99880 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:16:40.986028 99880 net.cpp:210] Setting up relu2
I1031 14:16:40.988719 99880 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:16:40.989135 99880 net.cpp:225] Memory required for data: 28516036
I1031 14:16:40.993810 99880 layer_factory.hpp:114] Creating layer dropout2
I1031 14:16:41.007855 99880 net.cpp:160] Creating Layer dropout2
I1031 14:16:41.011726 99880 net.cpp:596] dropout2 <- conv2
I1031 14:16:41.024049 99880 net.cpp:570] dropout2 -> drop2
I1031 14:16:41.033529 99880 net.cpp:210] Setting up dropout2
I1031 14:16:41.037971 99880 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:16:41.046648 99880 net.cpp:225] Memory required for data: 30298308
I1031 14:16:41.055140 99880 layer_factory.hpp:114] Creating layer pool2
I1031 14:16:41.060004 99880 net.cpp:160] Creating Layer pool2
I1031 14:16:41.069928 99880 net.cpp:596] pool2 <- drop2
I1031 14:16:41.077194 99880 net.cpp:570] pool2 -> pool2
I1031 14:16:41.081670 99880 net.cpp:210] Setting up pool2
I1031 14:16:41.087959 99880 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:16:41.100205 99880 net.cpp:225] Memory required for data: 30759108
I1031 14:16:41.104959 99880 layer_factory.hpp:114] Creating layer conv3
I1031 14:16:41.111537 99880 net.cpp:160] Creating Layer conv3
I1031 14:16:41.119936 99880 net.cpp:596] conv3 <- pool2
I1031 14:16:41.121915 99880 net.cpp:570] conv3 -> conv3
I1031 14:16:41.752046 99880 net.cpp:210] Setting up conv3
I1031 14:16:41.762727 99880 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:16:41.767235 99880 net.cpp:225] Memory required for data: 31160516
I1031 14:16:41.787972 99880 layer_factory.hpp:114] Creating layer relu3
I1031 14:16:41.794770 99880 net.cpp:160] Creating Layer relu3
I1031 14:16:41.797080 99880 net.cpp:596] relu3 <- conv3
I1031 14:16:41.801800 99880 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:16:41.814216 99880 net.cpp:210] Setting up relu3
I1031 14:16:41.824988 99880 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:16:41.833588 99880 net.cpp:225] Memory required for data: 31561924
I1031 14:16:41.838331 99880 layer_factory.hpp:114] Creating layer dropout3
I1031 14:16:41.848515 99880 net.cpp:160] Creating Layer dropout3
I1031 14:16:41.860309 99880 net.cpp:596] dropout3 <- conv3
I1031 14:16:41.866703 99880 net.cpp:570] dropout3 -> drop3
I1031 14:16:41.869169 99880 net.cpp:210] Setting up dropout3
I1031 14:16:41.875943 99880 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:16:41.882109 99880 net.cpp:225] Memory required for data: 31963332
I1031 14:16:41.890283 99880 layer_factory.hpp:114] Creating layer pool3
I1031 14:16:41.894889 99880 net.cpp:160] Creating Layer pool3
I1031 14:16:41.896879 99880 net.cpp:596] pool3 <- drop3
I1031 14:16:41.906086 99880 net.cpp:570] pool3 -> pool3
I1031 14:16:41.916868 99880 net.cpp:210] Setting up pool3
I1031 14:16:41.924528 99880 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:16:41.927757 99880 net.cpp:225] Memory required for data: 32063684
I1031 14:16:41.930083 99880 layer_factory.hpp:114] Creating layer conv4
I1031 14:16:41.933213 99880 net.cpp:160] Creating Layer conv4
I1031 14:16:41.937237 99880 net.cpp:596] conv4 <- pool3
I1031 14:16:41.938256 99880 net.cpp:570] conv4 -> conv4
I1031 14:16:42.296066 99880 net.cpp:210] Setting up conv4
I1031 14:16:42.306269 99880 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:16:42.312930 99880 net.cpp:225] Memory required for data: 32137412
I1031 14:16:42.319541 99880 layer_factory.hpp:114] Creating layer relu4
I1031 14:16:42.323806 99880 net.cpp:160] Creating Layer relu4
I1031 14:16:42.326228 99880 net.cpp:596] relu4 <- conv4
I1031 14:16:42.334736 99880 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:16:42.339154 99880 net.cpp:210] Setting up relu4
I1031 14:16:42.345872 99880 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:16:42.352102 99880 net.cpp:225] Memory required for data: 32211140
I1031 14:16:42.358867 99880 layer_factory.hpp:114] Creating layer dropout4
I1031 14:16:42.364353 99880 net.cpp:160] Creating Layer dropout4
I1031 14:16:42.370753 99880 net.cpp:596] dropout4 <- conv4
I1031 14:16:42.381206 99880 net.cpp:570] dropout4 -> drop4
I1031 14:16:42.391681 99880 net.cpp:210] Setting up dropout4
I1031 14:16:42.393707 99880 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:16:42.396685 99880 net.cpp:225] Memory required for data: 32284868
I1031 14:16:42.408818 99880 layer_factory.hpp:114] Creating layer pool4
I1031 14:16:42.417282 99880 net.cpp:160] Creating Layer pool4
I1031 14:16:42.426165 99880 net.cpp:596] pool4 <- drop4
I1031 14:16:42.434586 99880 net.cpp:570] pool4 -> pool4
I1031 14:16:42.461107 99880 net.cpp:210] Setting up pool4
I1031 14:16:42.465401 99880 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:16:42.467804 99880 net.cpp:225] Memory required for data: 32303300
I1031 14:16:42.472450 99880 layer_factory.hpp:114] Creating layer fc1
I1031 14:16:42.540271 99880 net.cpp:160] Creating Layer fc1
I1031 14:16:42.546803 99880 net.cpp:596] fc1 <- pool4
I1031 14:16:42.553390 99880 net.cpp:570] fc1 -> fc1
I1031 14:16:43.431205 99880 net.cpp:210] Setting up fc1
I1031 14:16:43.445726 99880 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:16:43.456428 99880 net.cpp:225] Memory required for data: 32307396
I1031 14:16:43.471706 99880 layer_factory.hpp:114] Creating layer dropout5
I1031 14:16:43.481456 99880 net.cpp:160] Creating Layer dropout5
I1031 14:16:43.492478 99880 net.cpp:596] dropout5 <- fc1
I1031 14:16:43.494422 99880 net.cpp:570] dropout5 -> drop5
I1031 14:16:43.494817 99880 net.cpp:210] Setting up dropout5
I1031 14:16:43.500278 99880 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:16:43.510793 99880 net.cpp:225] Memory required for data: 32311492
I1031 14:16:43.518426 99880 layer_factory.hpp:114] Creating layer fc2
I1031 14:16:43.528749 99880 net.cpp:160] Creating Layer fc2
I1031 14:16:43.530870 99880 net.cpp:596] fc2 <- drop5
I1031 14:16:43.535758 99880 net.cpp:570] fc2 -> fc2
I1031 14:16:43.574461 99880 net.cpp:210] Setting up fc2
I1031 14:16:43.592170 99880 net.cpp:217] Top shape: 1 2 (2)
I1031 14:16:43.598567 99880 net.cpp:225] Memory required for data: 32311500
I1031 14:16:43.605839 99880 layer_factory.hpp:114] Creating layer loss
I1031 14:16:43.634181 99880 net.cpp:160] Creating Layer loss
I1031 14:16:43.638635 99880 net.cpp:596] loss <- fc2
I1031 14:16:43.650135 99880 net.cpp:596] loss <- label
I1031 14:16:43.716084 99880 net.cpp:570] loss -> (automatic)
I1031 14:16:43.773808 99880 layer_factory.hpp:114] Creating layer loss
I1031 14:16:44.238498 99880 net.cpp:210] Setting up loss
I1031 14:16:44.245548 99880 net.cpp:217] Top shape: (1)
I1031 14:16:44.257864 99880 net.cpp:220]     with loss weight 1
I1031 14:16:44.397071 99880 net.cpp:225] Memory required for data: 32311504
I1031 14:16:44.446436 99880 net.cpp:287] loss needs backward computation.
I1031 14:16:44.551836 99880 net.cpp:287] fc2 needs backward computation.
I1031 14:16:44.572160 99880 net.cpp:287] dropout5 needs backward computation.
I1031 14:16:44.579838 99880 net.cpp:287] fc1 needs backward computation.
I1031 14:16:44.589102 99880 net.cpp:287] pool4 needs backward computation.
I1031 14:16:44.595834 99880 net.cpp:287] dropout4 needs backward computation.
I1031 14:16:44.602198 99880 net.cpp:287] relu4 needs backward computation.
I1031 14:16:44.615329 99880 net.cpp:287] conv4 needs backward computation.
I1031 14:16:44.639350 99880 net.cpp:287] pool3 needs backward computation.
I1031 14:16:44.656083 99880 net.cpp:287] dropout3 needs backward computation.
I1031 14:16:44.660850 99880 net.cpp:287] relu3 needs backward computation.
I1031 14:16:44.661176 99880 net.cpp:287] conv3 needs backward computation.
I1031 14:16:44.661502 99880 net.cpp:287] pool2 needs backward computation.
I1031 14:16:44.661773 99880 net.cpp:287] dropout2 needs backward computation.
I1031 14:16:44.661972 99880 net.cpp:287] relu2 needs backward computation.
I1031 14:16:44.662163 99880 net.cpp:287] conv2 needs backward computation.
I1031 14:16:44.662355 99880 net.cpp:287] pool1 needs backward computation.
I1031 14:16:44.662545 99880 net.cpp:287] dropout1 needs backward computation.
I1031 14:16:44.662734 99880 net.cpp:287] relu1 needs backward computation.
I1031 14:16:44.662917 99880 net.cpp:287] conv1 needs backward computation.
I1031 14:16:44.683111 99880 net.cpp:289] data does not need backward computation.
I1031 14:16:44.740578 99880 net.cpp:345] Network initialization done.
I1031 14:16:44.926192 99880 caffe.cpp:452] Performing Forward
I1031 14:16:56.844266 99880 caffe.cpp:457] Initial loss: 0
I1031 14:16:56.923004 99880 caffe.cpp:459] Performing Backward
I1031 14:17:00.216514 99880 caffe.cpp:468] *** Benchmark begins ***
I1031 14:17:00.232362 99880 caffe.cpp:469] Testing for 1 iterations.
I1031 14:17:00.389130 99880 caffe.cpp:485] Profiling Layer: relu2 backward
I1031 14:17:02.442677 99880 caffe.cpp:512] Iteration: 1 forward-backward time: 2052 ms.
I1031 14:17:02.631431 99880 caffe.cpp:519] Average time per layer: 
I1031 14:17:02.651895 99880 caffe.cpp:522]       data	forward: 53.278 ms.
I1031 14:17:02.736248 99880 caffe.cpp:526]       data	backward: 4.093 ms.
I1031 14:17:02.757218 99880 caffe.cpp:522]      conv1	forward: 53.548 ms.
I1031 14:17:02.760481 99880 caffe.cpp:526]      conv1	backward: 1.457 ms.
I1031 14:17:02.760938 99880 caffe.cpp:522]      relu1	forward: 29.701 ms.
I1031 14:17:02.763327 99880 caffe.cpp:526]      relu1	backward: 30.744 ms.
I1031 14:17:02.763680 99880 caffe.cpp:522]   dropout1	forward: 85.114 ms.
I1031 14:17:02.766742 99880 caffe.cpp:526]   dropout1	backward: 33.144 ms.
I1031 14:17:02.767062 99880 caffe.cpp:522]      pool1	forward: 125.469 ms.
I1031 14:17:02.772244 99880 caffe.cpp:526]      pool1	backward: 109.578 ms.
I1031 14:17:02.772745 99880 caffe.cpp:522]      conv2	forward: 63.917 ms.
I1031 14:17:02.773038 99880 caffe.cpp:526]      conv2	backward: 14.264 ms.
I1031 14:17:02.773260 99880 caffe.cpp:522]      relu2	forward: 17.148 ms.
I1031 14:17:02.773474 99880 caffe.cpp:526]      relu2	backward: 27.701 ms.
I1031 14:17:02.773686 99880 caffe.cpp:522]   dropout2	forward: 46.865 ms.
I1031 14:17:02.773897 99880 caffe.cpp:526]   dropout2	backward: 36.895 ms.
I1031 14:17:02.774107 99880 caffe.cpp:522]      pool2	forward: 29.492 ms.
I1031 14:17:02.774314 99880 caffe.cpp:526]      pool2	backward: 64.265 ms.
I1031 14:17:02.774519 99880 caffe.cpp:522]      conv3	forward: 54.265 ms.
I1031 14:17:02.774724 99880 caffe.cpp:526]      conv3	backward: 82.566 ms.
I1031 14:17:02.774929 99880 caffe.cpp:522]      relu3	forward: 19.987 ms.
I1031 14:17:02.775163 99880 caffe.cpp:526]      relu3	backward: 40.434 ms.
I1031 14:17:02.775421 99880 caffe.cpp:522]   dropout3	forward: 54.414 ms.
I1031 14:17:02.775789 99880 caffe.cpp:526]   dropout3	backward: 35.385 ms.
I1031 14:17:02.776170 99880 caffe.cpp:522]      pool3	forward: 20.907 ms.
I1031 14:17:02.776427 99880 caffe.cpp:526]      pool3	backward: 49.335 ms.
I1031 14:17:02.776638 99880 caffe.cpp:522]      conv4	forward: 52.964 ms.
I1031 14:17:02.776846 99880 caffe.cpp:526]      conv4	backward: 96.984 ms.
I1031 14:17:02.777052 99880 caffe.cpp:522]      relu4	forward: 15.65 ms.
I1031 14:17:02.777256 99880 caffe.cpp:526]      relu4	backward: 39.122 ms.
I1031 14:17:02.777462 99880 caffe.cpp:522]   dropout4	forward: 58.212 ms.
I1031 14:17:02.777664 99880 caffe.cpp:526]   dropout4	backward: 62.902 ms.
I1031 14:17:02.777869 99880 caffe.cpp:522]      pool4	forward: 15.136 ms.
I1031 14:17:02.778072 99880 caffe.cpp:526]      pool4	backward: 35.336 ms.
I1031 14:17:02.778276 99880 caffe.cpp:522]        fc1	forward: 48.125 ms.
I1031 14:17:02.778481 99880 caffe.cpp:526]        fc1	backward: 44.304 ms.
I1031 14:17:02.778717 99880 caffe.cpp:522]   dropout5	forward: 46.134 ms.
I1031 14:17:02.778934 99880 caffe.cpp:526]   dropout5	backward: 31.364 ms.
I1031 14:17:02.779268 99880 caffe.cpp:522]        fc2	forward: 27.44 ms.
I1031 14:17:02.779646 99880 caffe.cpp:526]        fc2	backward: 0.211 ms.
I1031 14:17:02.779918 99880 caffe.cpp:522]       loss	forward: 129.056 ms.
I1031 14:17:02.780135 99880 caffe.cpp:526]       loss	backward: 62.065 ms.
I1031 14:17:02.785961 99880 caffe.cpp:532] Average Forward pass: 1106.11 ms.
I1031 14:17:02.799640 99880 caffe.cpp:535] Average Backward pass: 912.056 ms.
I1031 14:17:02.811050 99880 caffe.cpp:537] Average Forward-Backward: 2506 ms.
I1031 14:17:02.826810 99880 caffe.cpp:540] Total Time: 2506 ms.
I1031 14:17:02.840006 99880 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 27848
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 55696
--->Total FLOPs = 55696
mem-read-1 = 410340
mem-read-2 = 69
mem-read-4 = 3294741
mem-read-8 = 4816697
mem-read-16 = 0
mem-read-32 = 37762
mem-read-64 = 116146
mem-write-1 = 102
mem-write-2 = 34
mem-write-4 = 212571
mem-write-8 = 509770
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 42954
--->Total Bytes read = 60764746
--->Total Bytes written = 7677734
--->Total Bytes = 68442480

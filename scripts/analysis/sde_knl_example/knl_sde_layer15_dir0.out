sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer15_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=15 -prof_forward_direction=0
I1031 15:08:52.266635 101811 caffe.cpp:444] Use CPU.
I1031 15:09:10.072378 101811 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 15:09:10.133394 101811 cpu_info.cpp:455] Total number of sockets: 1
I1031 15:09:10.145925 101811 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 15:09:10.158125 101811 cpu_info.cpp:461] Total number of processors: 256
I1031 15:09:10.176103 101811 cpu_info.cpp:464] GPU is used: no
I1031 15:09:10.185478 101811 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 15:09:10.194608 101811 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 15:09:10.206919 101811 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 15:09:19.316244 101811 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 15:09:20.007599 101811 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 15:09:22.423449 101811 layer_factory.hpp:114] Creating layer data
I1031 15:09:22.579402 101811 net.cpp:160] Creating Layer data
I1031 15:09:22.630741 101811 net.cpp:570] data -> data
I1031 15:09:23.123850 101811 net.cpp:570] data -> label
I1031 15:09:30.581274 101811 net.cpp:210] Setting up data
I1031 15:09:30.665447 101811 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 15:09:30.771536 101811 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 15:09:30.778909 101811 net.cpp:225] Memory required for data: 184516
I1031 15:09:30.857722 101811 layer_factory.hpp:114] Creating layer conv1
I1031 15:09:31.208308 101811 net.cpp:160] Creating Layer conv1
I1031 15:09:31.262163 101811 net.cpp:596] conv1 <- data
I1031 15:09:31.393224 101811 net.cpp:570] conv1 -> conv1
I1031 15:10:08.850327 101811 net.cpp:210] Setting up conv1
I1031 15:10:08.925161 101811 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:10:08.932930 101811 net.cpp:225] Memory required for data: 7805124
I1031 15:10:09.256664 101811 layer_factory.hpp:114] Creating layer relu1
I1031 15:10:09.392810 101811 net.cpp:160] Creating Layer relu1
I1031 15:10:09.397828 101811 net.cpp:596] relu1 <- conv1
I1031 15:10:09.432888 101811 net.cpp:557] relu1 -> conv1 (in-place)
I1031 15:10:09.652573 101811 net.cpp:210] Setting up relu1
I1031 15:10:09.655238 101811 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:10:09.655656 101811 net.cpp:225] Memory required for data: 15425732
I1031 15:10:09.655874 101811 layer_factory.hpp:114] Creating layer dropout1
I1031 15:10:09.688346 101811 net.cpp:160] Creating Layer dropout1
I1031 15:10:09.688681 101811 net.cpp:596] dropout1 <- conv1
I1031 15:10:09.691577 101811 net.cpp:570] dropout1 -> drop1
I1031 15:10:09.818907 101811 net.cpp:210] Setting up dropout1
I1031 15:10:09.833745 101811 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 15:10:09.834194 101811 net.cpp:225] Memory required for data: 23046340
I1031 15:10:09.834583 101811 layer_factory.hpp:114] Creating layer pool1
I1031 15:10:09.939409 101811 net.cpp:160] Creating Layer pool1
I1031 15:10:09.940217 101811 net.cpp:596] pool1 <- drop1
I1031 15:10:09.940574 101811 net.cpp:570] pool1 -> pool1
I1031 15:10:10.368549 101811 net.cpp:210] Setting up pool1
I1031 15:10:10.378377 101811 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 15:10:10.378762 101811 net.cpp:225] Memory required for data: 24951492
I1031 15:10:10.379104 101811 layer_factory.hpp:114] Creating layer conv2
I1031 15:10:10.441648 101811 net.cpp:160] Creating Layer conv2
I1031 15:10:10.446182 101811 net.cpp:596] conv2 <- pool1
I1031 15:10:10.461777 101811 net.cpp:570] conv2 -> conv2
I1031 15:10:17.369858 101811 net.cpp:210] Setting up conv2
I1031 15:10:17.379952 101811 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:10:17.389287 101811 net.cpp:225] Memory required for data: 26733764
I1031 15:10:17.454212 101811 layer_factory.hpp:114] Creating layer relu2
I1031 15:10:17.467187 101811 net.cpp:160] Creating Layer relu2
I1031 15:10:17.477504 101811 net.cpp:596] relu2 <- conv2
I1031 15:10:17.479454 101811 net.cpp:557] relu2 -> conv2 (in-place)
I1031 15:10:17.484922 101811 net.cpp:210] Setting up relu2
I1031 15:10:17.491349 101811 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:10:17.494010 101811 net.cpp:225] Memory required for data: 28516036
I1031 15:10:17.500444 101811 layer_factory.hpp:114] Creating layer dropout2
I1031 15:10:17.510752 101811 net.cpp:160] Creating Layer dropout2
I1031 15:10:17.516770 101811 net.cpp:596] dropout2 <- conv2
I1031 15:10:17.527420 101811 net.cpp:570] dropout2 -> drop2
I1031 15:10:17.534097 101811 net.cpp:210] Setting up dropout2
I1031 15:10:17.538673 101811 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 15:10:17.541087 101811 net.cpp:225] Memory required for data: 30298308
I1031 15:10:17.545939 101811 layer_factory.hpp:114] Creating layer pool2
I1031 15:10:17.554286 101811 net.cpp:160] Creating Layer pool2
I1031 15:10:17.563169 101811 net.cpp:596] pool2 <- drop2
I1031 15:10:17.569335 101811 net.cpp:570] pool2 -> pool2
I1031 15:10:17.576148 101811 net.cpp:210] Setting up pool2
I1031 15:10:17.584720 101811 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 15:10:17.587338 101811 net.cpp:225] Memory required for data: 30759108
I1031 15:10:17.594013 101811 layer_factory.hpp:114] Creating layer conv3
I1031 15:10:17.602716 101811 net.cpp:160] Creating Layer conv3
I1031 15:10:17.607338 101811 net.cpp:596] conv3 <- pool2
I1031 15:10:17.611699 101811 net.cpp:570] conv3 -> conv3
I1031 15:10:18.189651 101811 net.cpp:210] Setting up conv3
I1031 15:10:18.192250 101811 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:10:18.192618 101811 net.cpp:225] Memory required for data: 31160516
I1031 15:10:18.201391 101811 layer_factory.hpp:114] Creating layer relu3
I1031 15:10:18.201828 101811 net.cpp:160] Creating Layer relu3
I1031 15:10:18.202239 101811 net.cpp:596] relu3 <- conv3
I1031 15:10:18.202533 101811 net.cpp:557] relu3 -> conv3 (in-place)
I1031 15:10:18.203222 101811 net.cpp:210] Setting up relu3
I1031 15:10:18.203573 101811 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:10:18.203843 101811 net.cpp:225] Memory required for data: 31561924
I1031 15:10:18.204057 101811 layer_factory.hpp:114] Creating layer dropout3
I1031 15:10:18.204331 101811 net.cpp:160] Creating Layer dropout3
I1031 15:10:18.204553 101811 net.cpp:596] dropout3 <- conv3
I1031 15:10:18.204807 101811 net.cpp:570] dropout3 -> drop3
I1031 15:10:18.205178 101811 net.cpp:210] Setting up dropout3
I1031 15:10:18.205535 101811 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 15:10:18.205801 101811 net.cpp:225] Memory required for data: 31963332
I1031 15:10:18.206017 101811 layer_factory.hpp:114] Creating layer pool3
I1031 15:10:18.206338 101811 net.cpp:160] Creating Layer pool3
I1031 15:10:18.206579 101811 net.cpp:596] pool3 <- drop3
I1031 15:10:18.206831 101811 net.cpp:570] pool3 -> pool3
I1031 15:10:18.207267 101811 net.cpp:210] Setting up pool3
I1031 15:10:18.207579 101811 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 15:10:18.207837 101811 net.cpp:225] Memory required for data: 32063684
I1031 15:10:18.208066 101811 layer_factory.hpp:114] Creating layer conv4
I1031 15:10:18.208549 101811 net.cpp:160] Creating Layer conv4
I1031 15:10:18.208906 101811 net.cpp:596] conv4 <- pool3
I1031 15:10:18.209208 101811 net.cpp:570] conv4 -> conv4
I1031 15:10:18.646198 101811 net.cpp:210] Setting up conv4
I1031 15:10:18.650817 101811 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:10:18.657088 101811 net.cpp:225] Memory required for data: 32137412
I1031 15:10:18.667557 101811 layer_factory.hpp:114] Creating layer relu4
I1031 15:10:18.671509 101811 net.cpp:160] Creating Layer relu4
I1031 15:10:18.673815 101811 net.cpp:596] relu4 <- conv4
I1031 15:10:18.676275 101811 net.cpp:557] relu4 -> conv4 (in-place)
I1031 15:10:18.678813 101811 net.cpp:210] Setting up relu4
I1031 15:10:18.683409 101811 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:10:18.689406 101811 net.cpp:225] Memory required for data: 32211140
I1031 15:10:18.695916 101811 layer_factory.hpp:114] Creating layer dropout4
I1031 15:10:18.702742 101811 net.cpp:160] Creating Layer dropout4
I1031 15:10:18.709087 101811 net.cpp:596] dropout4 <- conv4
I1031 15:10:18.715481 101811 net.cpp:570] dropout4 -> drop4
I1031 15:10:18.722106 101811 net.cpp:210] Setting up dropout4
I1031 15:10:18.724287 101811 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 15:10:18.732684 101811 net.cpp:225] Memory required for data: 32284868
I1031 15:10:18.737213 101811 layer_factory.hpp:114] Creating layer pool4
I1031 15:10:18.745749 101811 net.cpp:160] Creating Layer pool4
I1031 15:10:18.746094 101811 net.cpp:596] pool4 <- drop4
I1031 15:10:18.746379 101811 net.cpp:570] pool4 -> pool4
I1031 15:10:18.774801 101811 net.cpp:210] Setting up pool4
I1031 15:10:18.779104 101811 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 15:10:18.781498 101811 net.cpp:225] Memory required for data: 32303300
I1031 15:10:18.783998 101811 layer_factory.hpp:114] Creating layer fc1
I1031 15:10:18.853713 101811 net.cpp:160] Creating Layer fc1
I1031 15:10:18.860479 101811 net.cpp:596] fc1 <- pool4
I1031 15:10:18.871251 101811 net.cpp:570] fc1 -> fc1
I1031 15:10:19.703977 101811 net.cpp:210] Setting up fc1
I1031 15:10:19.714720 101811 net.cpp:217] Top shape: 1 1024 (1024)
I1031 15:10:19.721151 101811 net.cpp:225] Memory required for data: 32307396
I1031 15:10:19.735160 101811 layer_factory.hpp:114] Creating layer dropout5
I1031 15:10:19.741822 101811 net.cpp:160] Creating Layer dropout5
I1031 15:10:19.745916 101811 net.cpp:596] dropout5 <- fc1
I1031 15:10:19.752310 101811 net.cpp:570] dropout5 -> drop5
I1031 15:10:19.758559 101811 net.cpp:210] Setting up dropout5
I1031 15:10:19.761085 101811 net.cpp:217] Top shape: 1 1024 (1024)
I1031 15:10:19.771618 101811 net.cpp:225] Memory required for data: 32311492
I1031 15:10:19.777581 101811 layer_factory.hpp:114] Creating layer fc2
I1031 15:10:19.782827 101811 net.cpp:160] Creating Layer fc2
I1031 15:10:19.789861 101811 net.cpp:596] fc2 <- drop5
I1031 15:10:19.798487 101811 net.cpp:570] fc2 -> fc2
I1031 15:10:19.834038 101811 net.cpp:210] Setting up fc2
I1031 15:10:19.839928 101811 net.cpp:217] Top shape: 1 2 (2)
I1031 15:10:19.850266 101811 net.cpp:225] Memory required for data: 32311500
I1031 15:10:19.854890 101811 layer_factory.hpp:114] Creating layer loss
I1031 15:10:19.893211 101811 net.cpp:160] Creating Layer loss
I1031 15:10:19.895077 101811 net.cpp:596] loss <- fc2
I1031 15:10:19.902999 101811 net.cpp:596] loss <- label
I1031 15:10:19.970516 101811 net.cpp:570] loss -> (automatic)
I1031 15:10:20.022594 101811 layer_factory.hpp:114] Creating layer loss
I1031 15:10:20.457825 101811 net.cpp:210] Setting up loss
I1031 15:10:20.470847 101811 net.cpp:217] Top shape: (1)
I1031 15:10:20.483455 101811 net.cpp:220]     with loss weight 1
I1031 15:10:20.623071 101811 net.cpp:225] Memory required for data: 32311504
I1031 15:10:20.670337 101811 net.cpp:287] loss needs backward computation.
I1031 15:10:20.774960 101811 net.cpp:287] fc2 needs backward computation.
I1031 15:10:20.783313 101811 net.cpp:287] dropout5 needs backward computation.
I1031 15:10:20.785810 101811 net.cpp:287] fc1 needs backward computation.
I1031 15:10:20.786707 101811 net.cpp:287] pool4 needs backward computation.
I1031 15:10:20.787137 101811 net.cpp:287] dropout4 needs backward computation.
I1031 15:10:20.787415 101811 net.cpp:287] relu4 needs backward computation.
I1031 15:10:20.798202 101811 net.cpp:287] conv4 needs backward computation.
I1031 15:10:20.819172 101811 net.cpp:287] pool3 needs backward computation.
I1031 15:10:20.835912 101811 net.cpp:287] dropout3 needs backward computation.
I1031 15:10:20.841856 101811 net.cpp:287] relu3 needs backward computation.
I1031 15:10:20.842186 101811 net.cpp:287] conv3 needs backward computation.
I1031 15:10:20.842607 101811 net.cpp:287] pool2 needs backward computation.
I1031 15:10:20.842941 101811 net.cpp:287] dropout2 needs backward computation.
I1031 15:10:20.843144 101811 net.cpp:287] relu2 needs backward computation.
I1031 15:10:20.843336 101811 net.cpp:287] conv2 needs backward computation.
I1031 15:10:20.843583 101811 net.cpp:287] pool1 needs backward computation.
I1031 15:10:20.843781 101811 net.cpp:287] dropout1 needs backward computation.
I1031 15:10:20.843978 101811 net.cpp:287] relu1 needs backward computation.
I1031 15:10:20.844168 101811 net.cpp:287] conv1 needs backward computation.
I1031 15:10:20.864467 101811 net.cpp:289] data does not need backward computation.
I1031 15:10:20.923964 101811 net.cpp:345] Network initialization done.
I1031 15:10:21.110460 101811 caffe.cpp:452] Performing Forward
I1031 15:10:32.991076 101811 caffe.cpp:457] Initial loss: 72.1435
I1031 15:10:33.138618 101811 caffe.cpp:459] Performing Backward
I1031 15:10:36.615648 101811 caffe.cpp:468] *** Benchmark begins ***
I1031 15:10:36.635597 101811 caffe.cpp:469] Testing for 1 iterations.
I1031 15:10:36.792006 101811 caffe.cpp:485] Profiling Layer: dropout4 backward
I1031 15:10:38.819031 101811 caffe.cpp:512] Iteration: 1 forward-backward time: 2022 ms.
I1031 15:10:38.928828 101811 caffe.cpp:519] Average time per layer: 
I1031 15:10:38.953933 101811 caffe.cpp:522]       data	forward: 45.979 ms.
I1031 15:10:39.020853 101811 caffe.cpp:526]       data	backward: 5.62 ms.
I1031 15:10:39.046998 101811 caffe.cpp:522]      conv1	forward: 70.022 ms.
I1031 15:10:39.057544 101811 caffe.cpp:526]      conv1	backward: 40.831 ms.
I1031 15:10:39.069324 101811 caffe.cpp:522]      relu1	forward: 20.437 ms.
I1031 15:10:39.078337 101811 caffe.cpp:526]      relu1	backward: 61.28 ms.
I1031 15:10:39.082533 101811 caffe.cpp:522]   dropout1	forward: 47.43 ms.
I1031 15:10:39.089725 101811 caffe.cpp:526]   dropout1	backward: 67.091 ms.
I1031 15:10:39.093933 101811 caffe.cpp:522]      pool1	forward: 125.866 ms.
I1031 15:10:39.102313 101811 caffe.cpp:526]      pool1	backward: 137.654 ms.
I1031 15:10:39.102768 101811 caffe.cpp:522]      conv2	forward: 27.482 ms.
I1031 15:10:39.103080 101811 caffe.cpp:526]      conv2	backward: 74.262 ms.
I1031 15:10:39.103287 101811 caffe.cpp:522]      relu2	forward: 0.173 ms.
I1031 15:10:39.103546 101811 caffe.cpp:526]      relu2	backward: 49.12 ms.
I1031 15:10:39.103754 101811 caffe.cpp:522]   dropout2	forward: 8.207 ms.
I1031 15:10:39.104656 101811 caffe.cpp:526]   dropout2	backward: 32.761 ms.
I1031 15:10:39.104996 101811 caffe.cpp:522]      pool2	forward: 29.491 ms.
I1031 15:10:39.105404 101811 caffe.cpp:526]      pool2	backward: 50.923 ms.
I1031 15:10:39.105620 101811 caffe.cpp:522]      conv3	forward: 62.465 ms.
I1031 15:10:39.105826 101811 caffe.cpp:526]      conv3	backward: 61.389 ms.
I1031 15:10:39.106034 101811 caffe.cpp:522]      relu3	forward: 21.521 ms.
I1031 15:10:39.106240 101811 caffe.cpp:526]      relu3	backward: 33.889 ms.
I1031 15:10:39.106446 101811 caffe.cpp:522]   dropout3	forward: 67.211 ms.
I1031 15:10:39.106650 101811 caffe.cpp:526]   dropout3	backward: 36.93 ms.
I1031 15:10:39.106856 101811 caffe.cpp:522]      pool3	forward: 16.173 ms.
I1031 15:10:39.107061 101811 caffe.cpp:526]      pool3	backward: 45.419 ms.
I1031 15:10:39.107266 101811 caffe.cpp:522]      conv4	forward: 68.785 ms.
I1031 15:10:39.107558 101811 caffe.cpp:526]      conv4	backward: 84.3 ms.
I1031 15:10:39.107846 101811 caffe.cpp:522]      relu4	forward: 22.649 ms.
I1031 15:10:39.108232 101811 caffe.cpp:526]      relu4	backward: 44.746 ms.
I1031 15:10:39.108449 101811 caffe.cpp:522]   dropout4	forward: 47.76 ms.
I1031 15:10:39.108656 101811 caffe.cpp:526]   dropout4	backward: 67.173 ms.
I1031 15:10:39.108861 101811 caffe.cpp:522]      pool4	forward: 19.413 ms.
I1031 15:10:39.109066 101811 caffe.cpp:526]      pool4	backward: 39.1 ms.
I1031 15:10:39.109272 101811 caffe.cpp:522]        fc1	forward: 37.752 ms.
I1031 15:10:39.109477 101811 caffe.cpp:526]        fc1	backward: 56.361 ms.
I1031 15:10:39.109683 101811 caffe.cpp:522]   dropout5	forward: 36.258 ms.
I1031 15:10:39.109887 101811 caffe.cpp:526]   dropout5	backward: 16.767 ms.
I1031 15:10:39.110092 101811 caffe.cpp:522]        fc2	forward: 18.648 ms.
I1031 15:10:39.110335 101811 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 15:10:39.110556 101811 caffe.cpp:522]       loss	forward: 77.98 ms.
I1031 15:10:39.110941 101811 caffe.cpp:526]       loss	backward: 49.678 ms.
I1031 15:10:39.117198 101811 caffe.cpp:532] Average Forward pass: 928.588 ms.
I1031 15:10:39.130790 101811 caffe.cpp:535] Average Backward pass: 1064.93 ms.
I1031 15:10:39.142319 101811 caffe.cpp:537] Average Forward-Backward: 2434 ms.
I1031 15:10:39.158020 101811 caffe.cpp:540] Total Time: 2434 ms.
I1031 15:10:39.170994 101811 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 2304
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 36864
--->Total double-precision FLOPs = 0
--->Total FLOPs = 36864
mem-read-1 = 52378
mem-read-2 = 71
mem-read-4 = 422420
mem-read-8 = 599380
mem-read-16 = 0
mem-read-32 = 1
mem-read-64 = 6017
mem-write-1 = 106
mem-write-2 = 34
mem-write-4 = 1273
mem-write-8 = 59331
mem-write-16 = 0
mem-write-32 = 1
mem-write-64 = 2689
--->Total Bytes read = 6922360
--->Total Bytes written = 652042
--->Total Bytes = 7574402

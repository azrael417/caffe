sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer10_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=10 -prof_forward_direction=0
I1031 14:39:18.649768 100749 caffe.cpp:444] Use CPU.
I1031 14:39:36.656790 100749 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:39:36.718490 100749 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:39:36.730865 100749 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:39:36.742944 100749 cpu_info.cpp:461] Total number of processors: 256
I1031 14:39:36.760857 100749 cpu_info.cpp:464] GPU is used: no
I1031 14:39:36.770107 100749 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:39:36.779054 100749 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:39:36.791779 100749 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:39:45.968767 100749 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:39:46.652804 100749 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:39:49.075857 100749 layer_factory.hpp:114] Creating layer data
I1031 14:39:49.251948 100749 net.cpp:160] Creating Layer data
I1031 14:39:49.303606 100749 net.cpp:570] data -> data
I1031 14:39:49.801209 100749 net.cpp:570] data -> label
I1031 14:39:57.263200 100749 net.cpp:210] Setting up data
I1031 14:39:57.347836 100749 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:39:57.454689 100749 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:39:57.462095 100749 net.cpp:225] Memory required for data: 184516
I1031 14:39:57.541224 100749 layer_factory.hpp:114] Creating layer conv1
I1031 14:39:57.892729 100749 net.cpp:160] Creating Layer conv1
I1031 14:39:57.946274 100749 net.cpp:596] conv1 <- data
I1031 14:39:58.074082 100749 net.cpp:570] conv1 -> conv1
I1031 14:40:35.508481 100749 net.cpp:210] Setting up conv1
I1031 14:40:35.579800 100749 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:40:35.590461 100749 net.cpp:225] Memory required for data: 7805124
I1031 14:40:35.919487 100749 layer_factory.hpp:114] Creating layer relu1
I1031 14:40:36.062765 100749 net.cpp:160] Creating Layer relu1
I1031 14:40:36.068279 100749 net.cpp:596] relu1 <- conv1
I1031 14:40:36.103754 100749 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:40:36.325340 100749 net.cpp:210] Setting up relu1
I1031 14:40:36.328025 100749 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:40:36.328392 100749 net.cpp:225] Memory required for data: 15425732
I1031 14:40:36.328605 100749 layer_factory.hpp:114] Creating layer dropout1
I1031 14:40:36.361393 100749 net.cpp:160] Creating Layer dropout1
I1031 14:40:36.361723 100749 net.cpp:596] dropout1 <- conv1
I1031 14:40:36.364748 100749 net.cpp:570] dropout1 -> drop1
I1031 14:40:36.477069 100749 net.cpp:210] Setting up dropout1
I1031 14:40:36.490548 100749 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:40:36.490948 100749 net.cpp:225] Memory required for data: 23046340
I1031 14:40:36.491291 100749 layer_factory.hpp:114] Creating layer pool1
I1031 14:40:36.594925 100749 net.cpp:160] Creating Layer pool1
I1031 14:40:36.595464 100749 net.cpp:596] pool1 <- drop1
I1031 14:40:36.595808 100749 net.cpp:570] pool1 -> pool1
I1031 14:40:37.019042 100749 net.cpp:210] Setting up pool1
I1031 14:40:37.028422 100749 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:40:37.028841 100749 net.cpp:225] Memory required for data: 24951492
I1031 14:40:37.029201 100749 layer_factory.hpp:114] Creating layer conv2
I1031 14:40:37.094889 100749 net.cpp:160] Creating Layer conv2
I1031 14:40:37.099550 100749 net.cpp:596] conv2 <- pool1
I1031 14:40:37.115470 100749 net.cpp:570] conv2 -> conv2
I1031 14:40:43.977839 100749 net.cpp:210] Setting up conv2
I1031 14:40:43.986440 100749 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:40:43.995726 100749 net.cpp:225] Memory required for data: 26733764
I1031 14:40:44.068867 100749 layer_factory.hpp:114] Creating layer relu2
I1031 14:40:44.084066 100749 net.cpp:160] Creating Layer relu2
I1031 14:40:44.092739 100749 net.cpp:596] relu2 <- conv2
I1031 14:40:44.094585 100749 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:40:44.095523 100749 net.cpp:210] Setting up relu2
I1031 14:40:44.102644 100749 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:40:44.107030 100749 net.cpp:225] Memory required for data: 28516036
I1031 14:40:44.111661 100749 layer_factory.hpp:114] Creating layer dropout2
I1031 14:40:44.120049 100749 net.cpp:160] Creating Layer dropout2
I1031 14:40:44.125790 100749 net.cpp:596] dropout2 <- conv2
I1031 14:40:44.134351 100749 net.cpp:570] dropout2 -> drop2
I1031 14:40:44.145035 100749 net.cpp:210] Setting up dropout2
I1031 14:40:44.149804 100749 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:40:44.161881 100749 net.cpp:225] Memory required for data: 30298308
I1031 14:40:44.163728 100749 layer_factory.hpp:114] Creating layer pool2
I1031 14:40:44.169461 100749 net.cpp:160] Creating Layer pool2
I1031 14:40:44.173570 100749 net.cpp:596] pool2 <- drop2
I1031 14:40:44.176414 100749 net.cpp:570] pool2 -> pool2
I1031 14:40:44.184990 100749 net.cpp:210] Setting up pool2
I1031 14:40:44.189313 100749 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:40:44.198036 100749 net.cpp:225] Memory required for data: 30759108
I1031 14:40:44.206360 100749 layer_factory.hpp:114] Creating layer conv3
I1031 14:40:44.208341 100749 net.cpp:160] Creating Layer conv3
I1031 14:40:44.214948 100749 net.cpp:596] conv3 <- pool2
I1031 14:40:44.219506 100749 net.cpp:570] conv3 -> conv3
I1031 14:40:44.819859 100749 net.cpp:210] Setting up conv3
I1031 14:40:44.826423 100749 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:40:44.830957 100749 net.cpp:225] Memory required for data: 31160516
I1031 14:40:44.851052 100749 layer_factory.hpp:114] Creating layer relu3
I1031 14:40:44.855548 100749 net.cpp:160] Creating Layer relu3
I1031 14:40:44.857777 100749 net.cpp:596] relu3 <- conv3
I1031 14:40:44.867902 100749 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:40:44.872680 100749 net.cpp:210] Setting up relu3
I1031 14:40:44.877408 100749 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:40:44.881880 100749 net.cpp:225] Memory required for data: 31561924
I1031 14:40:44.886345 100749 layer_factory.hpp:114] Creating layer dropout3
I1031 14:40:44.888407 100749 net.cpp:160] Creating Layer dropout3
I1031 14:40:44.888713 100749 net.cpp:596] dropout3 <- conv3
I1031 14:40:44.888989 100749 net.cpp:570] dropout3 -> drop3
I1031 14:40:44.891286 100749 net.cpp:210] Setting up dropout3
I1031 14:40:44.896136 100749 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:40:44.904737 100749 net.cpp:225] Memory required for data: 31963332
I1031 14:40:44.913002 100749 layer_factory.hpp:114] Creating layer pool3
I1031 14:40:44.922886 100749 net.cpp:160] Creating Layer pool3
I1031 14:40:44.924890 100749 net.cpp:596] pool3 <- drop3
I1031 14:40:44.937302 100749 net.cpp:570] pool3 -> pool3
I1031 14:40:44.950439 100749 net.cpp:210] Setting up pool3
I1031 14:40:44.960708 100749 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:40:44.969377 100749 net.cpp:225] Memory required for data: 32063684
I1031 14:40:44.977377 100749 layer_factory.hpp:114] Creating layer conv4
I1031 14:40:44.986846 100749 net.cpp:160] Creating Layer conv4
I1031 14:40:45.008358 100749 net.cpp:596] conv4 <- pool3
I1031 14:40:45.029682 100749 net.cpp:570] conv4 -> conv4
I1031 14:40:45.377920 100749 net.cpp:210] Setting up conv4
I1031 14:40:45.378204 100749 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:40:45.378548 100749 net.cpp:225] Memory required for data: 32137412
I1031 14:40:45.378865 100749 layer_factory.hpp:114] Creating layer relu4
I1031 14:40:45.379143 100749 net.cpp:160] Creating Layer relu4
I1031 14:40:45.379351 100749 net.cpp:596] relu4 <- conv4
I1031 14:40:45.379652 100749 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:40:45.380105 100749 net.cpp:210] Setting up relu4
I1031 14:40:45.380362 100749 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:40:45.380605 100749 net.cpp:225] Memory required for data: 32211140
I1031 14:40:45.380810 100749 layer_factory.hpp:114] Creating layer dropout4
I1031 14:40:45.381048 100749 net.cpp:160] Creating Layer dropout4
I1031 14:40:45.381248 100749 net.cpp:596] dropout4 <- conv4
I1031 14:40:45.381500 100749 net.cpp:570] dropout4 -> drop4
I1031 14:40:45.381860 100749 net.cpp:210] Setting up dropout4
I1031 14:40:45.382138 100749 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:40:45.382403 100749 net.cpp:225] Memory required for data: 32284868
I1031 14:40:45.382608 100749 layer_factory.hpp:114] Creating layer pool4
I1031 14:40:45.382911 100749 net.cpp:160] Creating Layer pool4
I1031 14:40:45.383131 100749 net.cpp:596] pool4 <- drop4
I1031 14:40:45.383406 100749 net.cpp:570] pool4 -> pool4
I1031 14:40:45.397552 100749 net.cpp:210] Setting up pool4
I1031 14:40:45.397913 100749 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:40:45.400506 100749 net.cpp:225] Memory required for data: 32303300
I1031 14:40:45.400763 100749 layer_factory.hpp:114] Creating layer fc1
I1031 14:40:45.463508 100749 net.cpp:160] Creating Layer fc1
I1031 14:40:45.469841 100749 net.cpp:596] fc1 <- pool4
I1031 14:40:45.478456 100749 net.cpp:570] fc1 -> fc1
I1031 14:40:46.376562 100749 net.cpp:210] Setting up fc1
I1031 14:40:46.381734 100749 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:40:46.388988 100749 net.cpp:225] Memory required for data: 32307396
I1031 14:40:46.404393 100749 layer_factory.hpp:114] Creating layer dropout5
I1031 14:40:46.414793 100749 net.cpp:160] Creating Layer dropout5
I1031 14:40:46.422786 100749 net.cpp:596] dropout5 <- fc1
I1031 14:40:46.431627 100749 net.cpp:570] dropout5 -> drop5
I1031 14:40:46.433616 100749 net.cpp:210] Setting up dropout5
I1031 14:40:46.441099 100749 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:40:46.449617 100749 net.cpp:225] Memory required for data: 32311492
I1031 14:40:46.456214 100749 layer_factory.hpp:114] Creating layer fc2
I1031 14:40:46.462414 100749 net.cpp:160] Creating Layer fc2
I1031 14:40:46.498700 100749 net.cpp:596] fc2 <- drop5
I1031 14:40:46.507501 100749 net.cpp:570] fc2 -> fc2
I1031 14:40:46.546355 100749 net.cpp:210] Setting up fc2
I1031 14:40:46.556018 100749 net.cpp:217] Top shape: 1 2 (2)
I1031 14:40:46.566174 100749 net.cpp:225] Memory required for data: 32311500
I1031 14:40:46.575040 100749 layer_factory.hpp:114] Creating layer loss
I1031 14:40:46.607414 100749 net.cpp:160] Creating Layer loss
I1031 14:40:46.615726 100749 net.cpp:596] loss <- fc2
I1031 14:40:46.624828 100749 net.cpp:596] loss <- label
I1031 14:40:46.688966 100749 net.cpp:570] loss -> (automatic)
I1031 14:40:46.751340 100749 layer_factory.hpp:114] Creating layer loss
I1031 14:40:47.168956 100749 net.cpp:210] Setting up loss
I1031 14:40:47.180719 100749 net.cpp:217] Top shape: (1)
I1031 14:40:47.195276 100749 net.cpp:220]     with loss weight 1
I1031 14:40:47.332381 100749 net.cpp:225] Memory required for data: 32311504
I1031 14:40:47.385509 100749 net.cpp:287] loss needs backward computation.
I1031 14:40:47.489755 100749 net.cpp:287] fc2 needs backward computation.
I1031 14:40:47.505409 100749 net.cpp:287] dropout5 needs backward computation.
I1031 14:40:47.518187 100749 net.cpp:287] fc1 needs backward computation.
I1031 14:40:47.525303 100749 net.cpp:287] pool4 needs backward computation.
I1031 14:40:47.529968 100749 net.cpp:287] dropout4 needs backward computation.
I1031 14:40:47.531838 100749 net.cpp:287] relu4 needs backward computation.
I1031 14:40:47.546960 100749 net.cpp:287] conv4 needs backward computation.
I1031 14:40:47.577067 100749 net.cpp:287] pool3 needs backward computation.
I1031 14:40:47.593732 100749 net.cpp:287] dropout3 needs backward computation.
I1031 14:40:47.598881 100749 net.cpp:287] relu3 needs backward computation.
I1031 14:40:47.599212 100749 net.cpp:287] conv3 needs backward computation.
I1031 14:40:47.599601 100749 net.cpp:287] pool2 needs backward computation.
I1031 14:40:47.599901 100749 net.cpp:287] dropout2 needs backward computation.
I1031 14:40:47.600129 100749 net.cpp:287] relu2 needs backward computation.
I1031 14:40:47.600337 100749 net.cpp:287] conv2 needs backward computation.
I1031 14:40:47.600548 100749 net.cpp:287] pool1 needs backward computation.
I1031 14:40:47.600759 100749 net.cpp:287] dropout1 needs backward computation.
I1031 14:40:47.600965 100749 net.cpp:287] relu1 needs backward computation.
I1031 14:40:47.601166 100749 net.cpp:287] conv1 needs backward computation.
I1031 14:40:47.621666 100749 net.cpp:289] data does not need backward computation.
I1031 14:40:47.679826 100749 net.cpp:345] Network initialization done.
I1031 14:40:47.866771 100749 caffe.cpp:452] Performing Forward
I1031 14:40:59.865074 100749 caffe.cpp:457] Initial loss: 87.3365
I1031 14:40:59.998879 100749 caffe.cpp:459] Performing Backward
I1031 14:41:03.462306 100749 caffe.cpp:468] *** Benchmark begins ***
I1031 14:41:03.482952 100749 caffe.cpp:469] Testing for 1 iterations.
I1031 14:41:03.640972 100749 caffe.cpp:485] Profiling Layer: relu3 backward
I1031 14:41:04.975162 100749 caffe.cpp:512] Iteration: 1 forward-backward time: 1333 ms.
I1031 14:41:05.076874 100749 caffe.cpp:519] Average time per layer: 
I1031 14:41:05.098757 100749 caffe.cpp:522]       data	forward: 49.416 ms.
I1031 14:41:05.176136 100749 caffe.cpp:526]       data	backward: 11.675 ms.
I1031 14:41:05.206765 100749 caffe.cpp:522]      conv1	forward: 64.016 ms.
I1031 14:41:05.219890 100749 caffe.cpp:526]      conv1	backward: 30.099 ms.
I1031 14:41:05.228641 100749 caffe.cpp:522]      relu1	forward: 25.02 ms.
I1031 14:41:05.235026 100749 caffe.cpp:526]      relu1	backward: 59.724 ms.
I1031 14:41:05.243705 100749 caffe.cpp:522]   dropout1	forward: 85.571 ms.
I1031 14:41:05.254338 100749 caffe.cpp:526]   dropout1	backward: 68.546 ms.
I1031 14:41:05.260757 100749 caffe.cpp:522]      pool1	forward: 133.22 ms.
I1031 14:41:05.268664 100749 caffe.cpp:526]      pool1	backward: 134.87 ms.
I1031 14:41:05.269848 100749 caffe.cpp:522]      conv2	forward: 65.089 ms.
I1031 14:41:05.270272 100749 caffe.cpp:526]      conv2	backward: 79.338 ms.
I1031 14:41:05.270480 100749 caffe.cpp:522]      relu2	forward: 15.157 ms.
I1031 14:41:05.270823 100749 caffe.cpp:526]      relu2	backward: 27.659 ms.
I1031 14:41:05.271033 100749 caffe.cpp:522]   dropout2	forward: 36.908 ms.
I1031 14:41:05.271236 100749 caffe.cpp:526]   dropout2	backward: 39.785 ms.
I1031 14:41:05.271479 100749 caffe.cpp:522]      pool2	forward: 29.813 ms.
I1031 14:41:05.271684 100749 caffe.cpp:526]      pool2	backward: 61.009 ms.
I1031 14:41:05.271930 100749 caffe.cpp:522]      conv3	forward: 10.759 ms.
I1031 14:41:05.274549 100749 caffe.cpp:526]      conv3	backward: 62.177 ms.
I1031 14:41:05.274814 100749 caffe.cpp:522]      relu3	forward: 0.112 ms.
I1031 14:41:05.275774 100749 caffe.cpp:526]      relu3	backward: 13.112 ms.
I1031 14:41:05.276120 100749 caffe.cpp:522]   dropout3	forward: 2.122 ms.
I1031 14:41:05.276350 100749 caffe.cpp:526]   dropout3	backward: 1.877 ms.
I1031 14:41:05.276564 100749 caffe.cpp:522]      pool3	forward: 6.713 ms.
I1031 14:41:05.276778 100749 caffe.cpp:526]      pool3	backward: 5.871 ms.
I1031 14:41:05.276991 100749 caffe.cpp:522]      conv4	forward: 0.733 ms.
I1031 14:41:05.277206 100749 caffe.cpp:526]      conv4	backward: 9.74 ms.
I1031 14:41:05.278139 100749 caffe.cpp:522]      relu4	forward: 0.053 ms.
I1031 14:41:05.295600 100749 caffe.cpp:526]      relu4	backward: 5.548 ms.
I1031 14:41:05.296001 100749 caffe.cpp:522]   dropout4	forward: 0.533 ms.
I1031 14:41:05.296332 100749 caffe.cpp:526]   dropout4	backward: 12.736 ms.
I1031 14:41:05.296617 100749 caffe.cpp:522]      pool4	forward: 1.305 ms.
I1031 14:41:05.296819 100749 caffe.cpp:526]      pool4	backward: 1.138 ms.
I1031 14:41:05.297021 100749 caffe.cpp:522]        fc1	forward: 1.023 ms.
I1031 14:41:05.297221 100749 caffe.cpp:526]        fc1	backward: 11.421 ms.
I1031 14:41:05.297427 100749 caffe.cpp:522]   dropout5	forward: 0.171 ms.
I1031 14:41:05.297629 100749 caffe.cpp:526]   dropout5	backward: 0.066 ms.
I1031 14:41:05.297834 100749 caffe.cpp:522]        fc2	forward: 0.108 ms.
I1031 14:41:05.298038 100749 caffe.cpp:526]        fc2	backward: 0.206 ms.
I1031 14:41:05.298238 100749 caffe.cpp:522]       loss	forward: 31.658 ms.
I1031 14:41:05.298442 100749 caffe.cpp:526]       loss	backward: 34.131 ms.
I1031 14:41:05.304365 100749 caffe.cpp:532] Average Forward pass: 619.781 ms.
I1031 14:41:05.320046 100749 caffe.cpp:535] Average Backward pass: 680.594 ms.
I1031 14:41:05.331923 100749 caffe.cpp:537] Average Forward-Backward: 1774 ms.
I1031 14:41:05.347993 100749 caffe.cpp:540] Total Time: 1774 ms.
I1031 14:41:05.361081 100749 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 6272
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 12544
--->Total FLOPs = 12544
mem-read-1 = 364261
mem-read-2 = 69
mem-read-4 = 2918175
mem-read-8 = 4083199
mem-read-16 = 0
mem-read-32 = 17922
mem-read-64 = 23330
mem-write-1 = 102
mem-write-2 = 34
mem-write-4 = 101436
mem-write-8 = 376449
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 6274
--->Total Bytes read = 46769315
--->Total Bytes written = 3819106
--->Total Bytes = 50588421

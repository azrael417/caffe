sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer21_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=21 -prof_forward_direction=1
I1031 13:37:06.493229 98438 caffe.cpp:444] Use CPU.
I1031 13:37:24.480784 98438 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 13:37:24.544179 98438 cpu_info.cpp:455] Total number of sockets: 1
I1031 13:37:24.557363 98438 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 13:37:24.569483 98438 cpu_info.cpp:461] Total number of processors: 256
I1031 13:37:24.586735 98438 cpu_info.cpp:464] GPU is used: no
I1031 13:37:24.596189 98438 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 13:37:24.605182 98438 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 13:37:24.617225 98438 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 13:37:33.856840 98438 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 13:37:34.555526 98438 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 13:37:36.990612 98438 layer_factory.hpp:114] Creating layer data
I1031 13:37:37.149422 98438 net.cpp:160] Creating Layer data
I1031 13:37:37.201063 98438 net.cpp:570] data -> data
I1031 13:37:37.697278 98438 net.cpp:570] data -> label
I1031 13:37:45.174379 98438 net.cpp:210] Setting up data
I1031 13:37:45.259013 98438 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 13:37:45.366094 98438 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 13:37:45.373570 98438 net.cpp:225] Memory required for data: 184516
I1031 13:37:45.452693 98438 layer_factory.hpp:114] Creating layer conv1
I1031 13:37:45.802006 98438 net.cpp:160] Creating Layer conv1
I1031 13:37:45.855242 98438 net.cpp:596] conv1 <- data
I1031 13:37:45.982847 98438 net.cpp:570] conv1 -> conv1
I1031 13:38:23.296558 98438 net.cpp:210] Setting up conv1
I1031 13:38:23.447178 98438 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:38:23.451051 98438 net.cpp:225] Memory required for data: 7805124
I1031 13:38:23.761224 98438 layer_factory.hpp:114] Creating layer relu1
I1031 13:38:23.891505 98438 net.cpp:160] Creating Layer relu1
I1031 13:38:23.896548 98438 net.cpp:596] relu1 <- conv1
I1031 13:38:23.933480 98438 net.cpp:557] relu1 -> conv1 (in-place)
I1031 13:38:24.147526 98438 net.cpp:210] Setting up relu1
I1031 13:38:24.150506 98438 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:38:24.150897 98438 net.cpp:225] Memory required for data: 15425732
I1031 13:38:24.151114 98438 layer_factory.hpp:114] Creating layer dropout1
I1031 13:38:24.184367 98438 net.cpp:160] Creating Layer dropout1
I1031 13:38:24.184710 98438 net.cpp:596] dropout1 <- conv1
I1031 13:38:24.187544 98438 net.cpp:570] dropout1 -> drop1
I1031 13:38:24.298671 98438 net.cpp:210] Setting up dropout1
I1031 13:38:24.312191 98438 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:38:24.312585 98438 net.cpp:225] Memory required for data: 23046340
I1031 13:38:24.312921 98438 layer_factory.hpp:114] Creating layer pool1
I1031 13:38:24.416957 98438 net.cpp:160] Creating Layer pool1
I1031 13:38:24.417417 98438 net.cpp:596] pool1 <- drop1
I1031 13:38:24.417770 98438 net.cpp:570] pool1 -> pool1
I1031 13:38:24.830359 98438 net.cpp:210] Setting up pool1
I1031 13:38:24.835409 98438 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 13:38:24.835837 98438 net.cpp:225] Memory required for data: 24951492
I1031 13:38:24.836148 98438 layer_factory.hpp:114] Creating layer conv2
I1031 13:38:24.897893 98438 net.cpp:160] Creating Layer conv2
I1031 13:38:24.902400 98438 net.cpp:596] conv2 <- pool1
I1031 13:38:24.917714 98438 net.cpp:570] conv2 -> conv2
I1031 13:38:31.817569 98438 net.cpp:210] Setting up conv2
I1031 13:38:31.825975 98438 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:38:31.833751 98438 net.cpp:225] Memory required for data: 26733764
I1031 13:38:31.913141 98438 layer_factory.hpp:114] Creating layer relu2
I1031 13:38:31.930436 98438 net.cpp:160] Creating Layer relu2
I1031 13:38:31.938814 98438 net.cpp:596] relu2 <- conv2
I1031 13:38:31.943334 98438 net.cpp:557] relu2 -> conv2 (in-place)
I1031 13:38:31.949767 98438 net.cpp:210] Setting up relu2
I1031 13:38:31.958508 98438 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:38:31.964587 98438 net.cpp:225] Memory required for data: 28516036
I1031 13:38:31.973075 98438 layer_factory.hpp:114] Creating layer dropout2
I1031 13:38:31.977469 98438 net.cpp:160] Creating Layer dropout2
I1031 13:38:31.994335 98438 net.cpp:596] dropout2 <- conv2
I1031 13:38:31.997056 98438 net.cpp:570] dropout2 -> drop2
I1031 13:38:32.001719 98438 net.cpp:210] Setting up dropout2
I1031 13:38:32.006711 98438 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:38:32.009321 98438 net.cpp:225] Memory required for data: 30298308
I1031 13:38:32.011770 98438 layer_factory.hpp:114] Creating layer pool2
I1031 13:38:32.017765 98438 net.cpp:160] Creating Layer pool2
I1031 13:38:32.020797 98438 net.cpp:596] pool2 <- drop2
I1031 13:38:32.027470 98438 net.cpp:570] pool2 -> pool2
I1031 13:38:32.036612 98438 net.cpp:210] Setting up pool2
I1031 13:38:32.040978 98438 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 13:38:32.041399 98438 net.cpp:225] Memory required for data: 30759108
I1031 13:38:32.046165 98438 layer_factory.hpp:114] Creating layer conv3
I1031 13:38:32.048498 98438 net.cpp:160] Creating Layer conv3
I1031 13:38:32.056871 98438 net.cpp:596] conv3 <- pool2
I1031 13:38:32.061421 98438 net.cpp:570] conv3 -> conv3
I1031 13:38:32.700624 98438 net.cpp:210] Setting up conv3
I1031 13:38:32.713356 98438 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:38:32.721854 98438 net.cpp:225] Memory required for data: 31160516
I1031 13:38:32.740030 98438 layer_factory.hpp:114] Creating layer relu3
I1031 13:38:32.744597 98438 net.cpp:160] Creating Layer relu3
I1031 13:38:32.753005 98438 net.cpp:596] relu3 <- conv3
I1031 13:38:32.761498 98438 net.cpp:557] relu3 -> conv3 (in-place)
I1031 13:38:32.770068 98438 net.cpp:210] Setting up relu3
I1031 13:38:32.776137 98438 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:38:32.782598 98438 net.cpp:225] Memory required for data: 31561924
I1031 13:38:32.790280 98438 layer_factory.hpp:114] Creating layer dropout3
I1031 13:38:32.798804 98438 net.cpp:160] Creating Layer dropout3
I1031 13:38:32.806991 98438 net.cpp:596] dropout3 <- conv3
I1031 13:38:32.811529 98438 net.cpp:570] dropout3 -> drop3
I1031 13:38:32.815541 98438 net.cpp:210] Setting up dropout3
I1031 13:38:32.820675 98438 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:38:32.827131 98438 net.cpp:225] Memory required for data: 31963332
I1031 13:38:32.835568 98438 layer_factory.hpp:114] Creating layer pool3
I1031 13:38:32.842116 98438 net.cpp:160] Creating Layer pool3
I1031 13:38:32.844694 98438 net.cpp:596] pool3 <- drop3
I1031 13:38:32.849095 98438 net.cpp:570] pool3 -> pool3
I1031 13:38:32.891466 98438 net.cpp:210] Setting up pool3
I1031 13:38:32.901751 98438 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 13:38:32.906584 98438 net.cpp:225] Memory required for data: 32063684
I1031 13:38:32.912598 98438 layer_factory.hpp:114] Creating layer conv4
I1031 13:38:32.915932 98438 net.cpp:160] Creating Layer conv4
I1031 13:38:32.920024 98438 net.cpp:596] conv4 <- pool3
I1031 13:38:32.925153 98438 net.cpp:570] conv4 -> conv4
I1031 13:38:33.281740 98438 net.cpp:210] Setting up conv4
I1031 13:38:33.293925 98438 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:38:33.302289 98438 net.cpp:225] Memory required for data: 32137412
I1031 13:38:33.308945 98438 layer_factory.hpp:114] Creating layer relu4
I1031 13:38:33.315348 98438 net.cpp:160] Creating Layer relu4
I1031 13:38:33.319916 98438 net.cpp:596] relu4 <- conv4
I1031 13:38:33.328584 98438 net.cpp:557] relu4 -> conv4 (in-place)
I1031 13:38:33.341373 98438 net.cpp:210] Setting up relu4
I1031 13:38:33.347795 98438 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:38:33.356329 98438 net.cpp:225] Memory required for data: 32211140
I1031 13:38:33.362795 98438 layer_factory.hpp:114] Creating layer dropout4
I1031 13:38:33.366813 98438 net.cpp:160] Creating Layer dropout4
I1031 13:38:33.376288 98438 net.cpp:596] dropout4 <- conv4
I1031 13:38:33.386857 98438 net.cpp:570] dropout4 -> drop4
I1031 13:38:33.391252 98438 net.cpp:210] Setting up dropout4
I1031 13:38:33.393026 98438 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:38:33.398363 98438 net.cpp:225] Memory required for data: 32284868
I1031 13:38:33.410342 98438 layer_factory.hpp:114] Creating layer pool4
I1031 13:38:33.422965 98438 net.cpp:160] Creating Layer pool4
I1031 13:38:33.429421 98438 net.cpp:596] pool4 <- drop4
I1031 13:38:33.433609 98438 net.cpp:570] pool4 -> pool4
I1031 13:38:33.456689 98438 net.cpp:210] Setting up pool4
I1031 13:38:33.465078 98438 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 13:38:33.477327 98438 net.cpp:225] Memory required for data: 32303300
I1031 13:38:33.487830 98438 layer_factory.hpp:114] Creating layer fc1
I1031 13:38:33.558012 98438 net.cpp:160] Creating Layer fc1
I1031 13:38:33.560634 98438 net.cpp:596] fc1 <- pool4
I1031 13:38:33.566110 98438 net.cpp:570] fc1 -> fc1
I1031 13:38:34.381543 98438 net.cpp:210] Setting up fc1
I1031 13:38:34.386332 98438 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:38:34.399581 98438 net.cpp:225] Memory required for data: 32307396
I1031 13:38:34.417733 98438 layer_factory.hpp:114] Creating layer dropout5
I1031 13:38:34.430166 98438 net.cpp:160] Creating Layer dropout5
I1031 13:38:34.436022 98438 net.cpp:596] dropout5 <- fc1
I1031 13:38:34.446743 98438 net.cpp:570] dropout5 -> drop5
I1031 13:38:34.455258 98438 net.cpp:210] Setting up dropout5
I1031 13:38:34.463791 98438 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:38:34.472584 98438 net.cpp:225] Memory required for data: 32311492
I1031 13:38:34.479085 98438 layer_factory.hpp:114] Creating layer fc2
I1031 13:38:34.485708 98438 net.cpp:160] Creating Layer fc2
I1031 13:38:34.492167 98438 net.cpp:596] fc2 <- drop5
I1031 13:38:34.496316 98438 net.cpp:570] fc2 -> fc2
I1031 13:38:34.543920 98438 net.cpp:210] Setting up fc2
I1031 13:38:34.555320 98438 net.cpp:217] Top shape: 1 2 (2)
I1031 13:38:34.567953 98438 net.cpp:225] Memory required for data: 32311500
I1031 13:38:34.574479 98438 layer_factory.hpp:114] Creating layer loss
I1031 13:38:34.602843 98438 net.cpp:160] Creating Layer loss
I1031 13:38:34.607421 98438 net.cpp:596] loss <- fc2
I1031 13:38:34.616160 98438 net.cpp:596] loss <- label
I1031 13:38:34.676017 98438 net.cpp:570] loss -> (automatic)
I1031 13:38:34.724673 98438 layer_factory.hpp:114] Creating layer loss
I1031 13:38:35.165907 98438 net.cpp:210] Setting up loss
I1031 13:38:35.173249 98438 net.cpp:217] Top shape: (1)
I1031 13:38:35.185502 98438 net.cpp:220]     with loss weight 1
I1031 13:38:35.321949 98438 net.cpp:225] Memory required for data: 32311504
I1031 13:38:35.375543 98438 net.cpp:287] loss needs backward computation.
I1031 13:38:35.483659 98438 net.cpp:287] fc2 needs backward computation.
I1031 13:38:35.501237 98438 net.cpp:287] dropout5 needs backward computation.
I1031 13:38:35.511679 98438 net.cpp:287] fc1 needs backward computation.
I1031 13:38:35.518824 98438 net.cpp:287] pool4 needs backward computation.
I1031 13:38:35.527266 98438 net.cpp:287] dropout4 needs backward computation.
I1031 13:38:35.532097 98438 net.cpp:287] relu4 needs backward computation.
I1031 13:38:35.544620 98438 net.cpp:287] conv4 needs backward computation.
I1031 13:38:35.566815 98438 net.cpp:287] pool3 needs backward computation.
I1031 13:38:35.585319 98438 net.cpp:287] dropout3 needs backward computation.
I1031 13:38:35.591051 98438 net.cpp:287] relu3 needs backward computation.
I1031 13:38:35.591440 98438 net.cpp:287] conv3 needs backward computation.
I1031 13:38:35.591747 98438 net.cpp:287] pool2 needs backward computation.
I1031 13:38:35.591987 98438 net.cpp:287] dropout2 needs backward computation.
I1031 13:38:35.592196 98438 net.cpp:287] relu2 needs backward computation.
I1031 13:38:35.592397 98438 net.cpp:287] conv2 needs backward computation.
I1031 13:38:35.592603 98438 net.cpp:287] pool1 needs backward computation.
I1031 13:38:35.592806 98438 net.cpp:287] dropout1 needs backward computation.
I1031 13:38:35.593009 98438 net.cpp:287] relu1 needs backward computation.
I1031 13:38:35.593207 98438 net.cpp:287] conv1 needs backward computation.
I1031 13:38:35.613401 98438 net.cpp:289] data does not need backward computation.
I1031 13:38:35.671012 98438 net.cpp:345] Network initialization done.
I1031 13:38:35.857020 98438 caffe.cpp:452] Performing Forward
I1031 13:38:47.653806 98438 caffe.cpp:457] Initial loss: 0
I1031 13:38:47.684540 98438 caffe.cpp:459] Performing Backward
I1031 13:38:50.818171 98438 caffe.cpp:468] *** Benchmark begins ***
I1031 13:38:50.834033 98438 caffe.cpp:469] Testing for 1 iterations.
I1031 13:38:52.487656 98438 caffe.cpp:512] Iteration: 1 forward-backward time: 1516 ms.
I1031 13:38:52.652003 98438 caffe.cpp:519] Average time per layer: 
I1031 13:38:52.676203 98438 caffe.cpp:522]       data	forward: 49.253 ms.
I1031 13:38:52.759492 98438 caffe.cpp:526]       data	backward: 7.578 ms.
I1031 13:38:52.785409 98438 caffe.cpp:522]      conv1	forward: 74.255 ms.
I1031 13:38:52.806807 98438 caffe.cpp:526]      conv1	backward: 39.482 ms.
I1031 13:38:52.817404 98438 caffe.cpp:522]      relu1	forward: 33.218 ms.
I1031 13:38:52.826891 98438 caffe.cpp:526]      relu1	backward: 65.13 ms.
I1031 13:38:52.840378 98438 caffe.cpp:522]   dropout1	forward: 84.237 ms.
I1031 13:38:52.850008 98438 caffe.cpp:526]   dropout1	backward: 58.536 ms.
I1031 13:38:52.850407 98438 caffe.cpp:522]      pool1	forward: 126.409 ms.
I1031 13:38:52.853567 98438 caffe.cpp:526]      pool1	backward: 108.379 ms.
I1031 13:38:52.853837 98438 caffe.cpp:522]      conv2	forward: 66.652 ms.
I1031 13:38:52.854050 98438 caffe.cpp:526]      conv2	backward: 14.038 ms.
I1031 13:38:52.854261 98438 caffe.cpp:522]      relu2	forward: 10.638 ms.
I1031 13:38:52.857007 98438 caffe.cpp:526]      relu2	backward: 6.98 ms.
I1031 13:38:52.857267 98438 caffe.cpp:522]   dropout2	forward: 64.281 ms.
I1031 13:38:52.857487 98438 caffe.cpp:526]   dropout2	backward: 7.801 ms.
I1031 13:38:52.858422 98438 caffe.cpp:522]      pool2	forward: 31.036 ms.
I1031 13:38:52.858872 98438 caffe.cpp:526]      pool2	backward: 25.425 ms.
I1031 13:38:52.859102 98438 caffe.cpp:522]      conv3	forward: 54.025 ms.
I1031 13:38:52.859313 98438 caffe.cpp:526]      conv3	backward: 2.513 ms.
I1031 13:38:52.859557 98438 caffe.cpp:522]      relu3	forward: 23.694 ms.
I1031 13:38:52.859768 98438 caffe.cpp:526]      relu3	backward: 1.337 ms.
I1031 13:38:52.859968 98438 caffe.cpp:522]   dropout3	forward: 73.035 ms.
I1031 13:38:52.860175 98438 caffe.cpp:526]   dropout3	backward: 1.902 ms.
I1031 13:38:52.860374 98438 caffe.cpp:522]      pool3	forward: 13.212 ms.
I1031 13:38:52.860579 98438 caffe.cpp:526]      pool3	backward: 5.86 ms.
I1031 13:38:52.860807 98438 caffe.cpp:522]      conv4	forward: 62.695 ms.
I1031 13:38:52.861027 98438 caffe.cpp:526]      conv4	backward: 9.791 ms.
I1031 13:38:52.862062 98438 caffe.cpp:522]      relu4	forward: 18.354 ms.
I1031 13:38:52.862321 98438 caffe.cpp:526]      relu4	backward: 5.475 ms.
I1031 13:38:52.862529 98438 caffe.cpp:522]   dropout4	forward: 67.268 ms.
I1031 13:38:52.862738 98438 caffe.cpp:526]   dropout4	backward: 15.736 ms.
I1031 13:38:52.862943 98438 caffe.cpp:522]      pool4	forward: 23.895 ms.
I1031 13:38:52.863147 98438 caffe.cpp:526]      pool4	backward: 1.143 ms.
I1031 13:38:52.863345 98438 caffe.cpp:522]        fc1	forward: 48.41 ms.
I1031 13:38:52.863600 98438 caffe.cpp:526]        fc1	backward: 11.445 ms.
I1031 13:38:52.863840 98438 caffe.cpp:522]   dropout5	forward: 36.993 ms.
I1031 13:38:52.864059 98438 caffe.cpp:526]   dropout5	backward: 0.068 ms.
I1031 13:38:52.881474 98438 caffe.cpp:522]        fc2	forward: 1.625 ms.
I1031 13:38:52.881870 98438 caffe.cpp:526]        fc2	backward: 0.205 ms.
I1031 13:38:52.882145 98438 caffe.cpp:522]       loss	forward: 29.894 ms.
I1031 13:38:52.882370 98438 caffe.cpp:526]       loss	backward: 33.641 ms.
I1031 13:38:52.888319 98438 caffe.cpp:532] Average Forward pass: 1054.96 ms.
I1031 13:38:52.901873 98438 caffe.cpp:535] Average Backward pass: 433.62 ms.
I1031 13:38:52.913408 98438 caffe.cpp:537] Average Forward-Backward: 2008 ms.
I1031 13:38:52.928908 98438 caffe.cpp:540] Total Time: 2008 ms.
I1031 13:38:52.941690 98438 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 0
--->Total double-precision FLOPs = 0
--->Total FLOPs = 0
mem-read-1 = 0
mem-read-2 = 0
mem-read-4 = 0
mem-read-8 = 0
mem-read-16 = 0
mem-read-32 = 0
mem-read-64 = 0
mem-write-1 = 0
mem-write-2 = 0
mem-write-4 = 0
mem-write-8 = 0
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 0
--->Total Bytes read = 0
--->Total Bytes written = 0
--->Total Bytes = 0

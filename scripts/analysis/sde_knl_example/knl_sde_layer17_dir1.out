sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer17_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=17 -prof_forward_direction=1
I1031 13:12:42.675328 97572 caffe.cpp:444] Use CPU.
I1031 13:13:00.566609 97572 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 13:13:00.650099 97572 cpu_info.cpp:455] Total number of sockets: 1
I1031 13:13:00.666064 97572 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 13:13:00.677963 97572 cpu_info.cpp:461] Total number of processors: 256
I1031 13:13:00.694931 97572 cpu_info.cpp:464] GPU is used: no
I1031 13:13:00.704319 97572 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 13:13:00.713740 97572 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 13:13:00.726157 97572 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 13:13:09.871673 97572 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 13:13:10.562130 97572 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 13:13:12.994181 97572 layer_factory.hpp:114] Creating layer data
I1031 13:13:13.154235 97572 net.cpp:160] Creating Layer data
I1031 13:13:13.205708 97572 net.cpp:570] data -> data
I1031 13:13:13.699471 97572 net.cpp:570] data -> label
I1031 13:13:21.170392 97572 net.cpp:210] Setting up data
I1031 13:13:21.257194 97572 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 13:13:21.365597 97572 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 13:13:21.373142 97572 net.cpp:225] Memory required for data: 184516
I1031 13:13:21.455814 97572 layer_factory.hpp:114] Creating layer conv1
I1031 13:13:21.803745 97572 net.cpp:160] Creating Layer conv1
I1031 13:13:21.857023 97572 net.cpp:596] conv1 <- data
I1031 13:13:21.983932 97572 net.cpp:570] conv1 -> conv1
I1031 13:13:59.167474 97572 net.cpp:210] Setting up conv1
I1031 13:13:59.306711 97572 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:13:59.316794 97572 net.cpp:225] Memory required for data: 7805124
I1031 13:13:59.620947 97572 layer_factory.hpp:114] Creating layer relu1
I1031 13:13:59.754890 97572 net.cpp:160] Creating Layer relu1
I1031 13:13:59.760061 97572 net.cpp:596] relu1 <- conv1
I1031 13:13:59.795485 97572 net.cpp:557] relu1 -> conv1 (in-place)
I1031 13:14:00.012662 97572 net.cpp:210] Setting up relu1
I1031 13:14:00.015290 97572 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:14:00.015722 97572 net.cpp:225] Memory required for data: 15425732
I1031 13:14:00.015944 97572 layer_factory.hpp:114] Creating layer dropout1
I1031 13:14:00.048717 97572 net.cpp:160] Creating Layer dropout1
I1031 13:14:00.049062 97572 net.cpp:596] dropout1 <- conv1
I1031 13:14:00.051985 97572 net.cpp:570] dropout1 -> drop1
I1031 13:14:00.171828 97572 net.cpp:210] Setting up dropout1
I1031 13:14:00.185588 97572 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:14:00.185995 97572 net.cpp:225] Memory required for data: 23046340
I1031 13:14:00.186347 97572 layer_factory.hpp:114] Creating layer pool1
I1031 13:14:00.288584 97572 net.cpp:160] Creating Layer pool1
I1031 13:14:00.293295 97572 net.cpp:596] pool1 <- drop1
I1031 13:14:00.293649 97572 net.cpp:570] pool1 -> pool1
I1031 13:14:00.721915 97572 net.cpp:210] Setting up pool1
I1031 13:14:00.727180 97572 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 13:14:00.727659 97572 net.cpp:225] Memory required for data: 24951492
I1031 13:14:00.728041 97572 layer_factory.hpp:114] Creating layer conv2
I1031 13:14:00.791793 97572 net.cpp:160] Creating Layer conv2
I1031 13:14:00.796448 97572 net.cpp:596] conv2 <- pool1
I1031 13:14:00.812386 97572 net.cpp:570] conv2 -> conv2
I1031 13:14:07.650416 97572 net.cpp:210] Setting up conv2
I1031 13:14:07.658781 97572 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:14:07.668287 97572 net.cpp:225] Memory required for data: 26733764
I1031 13:14:07.742807 97572 layer_factory.hpp:114] Creating layer relu2
I1031 13:14:07.754554 97572 net.cpp:160] Creating Layer relu2
I1031 13:14:07.765060 97572 net.cpp:596] relu2 <- conv2
I1031 13:14:07.766949 97572 net.cpp:557] relu2 -> conv2 (in-place)
I1031 13:14:07.778720 97572 net.cpp:210] Setting up relu2
I1031 13:14:07.787416 97572 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:14:07.791872 97572 net.cpp:225] Memory required for data: 28516036
I1031 13:14:07.796573 97572 layer_factory.hpp:114] Creating layer dropout2
I1031 13:14:07.805268 97572 net.cpp:160] Creating Layer dropout2
I1031 13:14:07.813664 97572 net.cpp:596] dropout2 <- conv2
I1031 13:14:07.815968 97572 net.cpp:570] dropout2 -> drop2
I1031 13:14:07.831432 97572 net.cpp:210] Setting up dropout2
I1031 13:14:07.835862 97572 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:14:07.844552 97572 net.cpp:225] Memory required for data: 30298308
I1031 13:14:07.853289 97572 layer_factory.hpp:114] Creating layer pool2
I1031 13:14:07.863694 97572 net.cpp:160] Creating Layer pool2
I1031 13:14:07.868180 97572 net.cpp:596] pool2 <- drop2
I1031 13:14:07.870154 97572 net.cpp:570] pool2 -> pool2
I1031 13:14:07.877452 97572 net.cpp:210] Setting up pool2
I1031 13:14:07.882002 97572 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 13:14:07.884420 97572 net.cpp:225] Memory required for data: 30759108
I1031 13:14:07.886924 97572 layer_factory.hpp:114] Creating layer conv3
I1031 13:14:07.901229 97572 net.cpp:160] Creating Layer conv3
I1031 13:14:07.905194 97572 net.cpp:596] conv3 <- pool2
I1031 13:14:07.905580 97572 net.cpp:570] conv3 -> conv3
I1031 13:14:08.528719 97572 net.cpp:210] Setting up conv3
I1031 13:14:08.540684 97572 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:14:08.547389 97572 net.cpp:225] Memory required for data: 31160516
I1031 13:14:08.559571 97572 layer_factory.hpp:114] Creating layer relu3
I1031 13:14:08.570027 97572 net.cpp:160] Creating Layer relu3
I1031 13:14:08.572453 97572 net.cpp:596] relu3 <- conv3
I1031 13:14:08.574535 97572 net.cpp:557] relu3 -> conv3 (in-place)
I1031 13:14:08.583734 97572 net.cpp:210] Setting up relu3
I1031 13:14:08.594537 97572 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:14:08.604851 97572 net.cpp:225] Memory required for data: 31561924
I1031 13:14:08.610960 97572 layer_factory.hpp:114] Creating layer dropout3
I1031 13:14:08.615767 97572 net.cpp:160] Creating Layer dropout3
I1031 13:14:08.620343 97572 net.cpp:596] dropout3 <- conv3
I1031 13:14:08.626907 97572 net.cpp:570] dropout3 -> drop3
I1031 13:14:08.629416 97572 net.cpp:210] Setting up dropout3
I1031 13:14:08.639140 97572 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:14:08.643215 97572 net.cpp:225] Memory required for data: 31963332
I1031 13:14:08.647860 97572 layer_factory.hpp:114] Creating layer pool3
I1031 13:14:08.656492 97572 net.cpp:160] Creating Layer pool3
I1031 13:14:08.662436 97572 net.cpp:596] pool3 <- drop3
I1031 13:14:08.664628 97572 net.cpp:570] pool3 -> pool3
I1031 13:14:08.669749 97572 net.cpp:210] Setting up pool3
I1031 13:14:08.674535 97572 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 13:14:08.677002 97572 net.cpp:225] Memory required for data: 32063684
I1031 13:14:08.683698 97572 layer_factory.hpp:114] Creating layer conv4
I1031 13:14:08.694223 97572 net.cpp:160] Creating Layer conv4
I1031 13:14:08.702733 97572 net.cpp:596] conv4 <- pool3
I1031 13:14:08.707515 97572 net.cpp:570] conv4 -> conv4
I1031 13:14:09.059870 97572 net.cpp:210] Setting up conv4
I1031 13:14:09.066416 97572 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:14:09.066962 97572 net.cpp:225] Memory required for data: 32137412
I1031 13:14:09.083760 97572 layer_factory.hpp:114] Creating layer relu4
I1031 13:14:09.088459 97572 net.cpp:160] Creating Layer relu4
I1031 13:14:09.092924 97572 net.cpp:596] relu4 <- conv4
I1031 13:14:09.099336 97572 net.cpp:557] relu4 -> conv4 (in-place)
I1031 13:14:09.104264 97572 net.cpp:210] Setting up relu4
I1031 13:14:09.108767 97572 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:14:09.110997 97572 net.cpp:225] Memory required for data: 32211140
I1031 13:14:09.113539 97572 layer_factory.hpp:114] Creating layer dropout4
I1031 13:14:09.117974 97572 net.cpp:160] Creating Layer dropout4
I1031 13:14:09.120905 97572 net.cpp:596] dropout4 <- conv4
I1031 13:14:09.125376 97572 net.cpp:570] dropout4 -> drop4
I1031 13:14:09.133611 97572 net.cpp:210] Setting up dropout4
I1031 13:14:09.145546 97572 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:14:09.151675 97572 net.cpp:225] Memory required for data: 32284868
I1031 13:14:09.156059 97572 layer_factory.hpp:114] Creating layer pool4
I1031 13:14:09.162437 97572 net.cpp:160] Creating Layer pool4
I1031 13:14:09.169137 97572 net.cpp:596] pool4 <- drop4
I1031 13:14:09.175539 97572 net.cpp:570] pool4 -> pool4
I1031 13:14:09.193111 97572 net.cpp:210] Setting up pool4
I1031 13:14:09.197396 97572 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 13:14:09.209554 97572 net.cpp:225] Memory required for data: 32303300
I1031 13:14:09.218253 97572 layer_factory.hpp:114] Creating layer fc1
I1031 13:14:09.284667 97572 net.cpp:160] Creating Layer fc1
I1031 13:14:09.295274 97572 net.cpp:596] fc1 <- pool4
I1031 13:14:09.302072 97572 net.cpp:570] fc1 -> fc1
I1031 13:14:10.142333 97572 net.cpp:210] Setting up fc1
I1031 13:14:10.150367 97572 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:14:10.155457 97572 net.cpp:225] Memory required for data: 32307396
I1031 13:14:10.170639 97572 layer_factory.hpp:114] Creating layer dropout5
I1031 13:14:10.182847 97572 net.cpp:160] Creating Layer dropout5
I1031 13:14:10.185384 97572 net.cpp:596] dropout5 <- fc1
I1031 13:14:10.188220 97572 net.cpp:570] dropout5 -> drop5
I1031 13:14:10.194922 97572 net.cpp:210] Setting up dropout5
I1031 13:14:10.197257 97572 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:14:10.203817 97572 net.cpp:225] Memory required for data: 32311492
I1031 13:14:10.208262 97572 layer_factory.hpp:114] Creating layer fc2
I1031 13:14:10.210242 97572 net.cpp:160] Creating Layer fc2
I1031 13:14:10.215857 97572 net.cpp:596] fc2 <- drop5
I1031 13:14:10.218375 97572 net.cpp:570] fc2 -> fc2
I1031 13:14:10.252770 97572 net.cpp:210] Setting up fc2
I1031 13:14:10.262187 97572 net.cpp:217] Top shape: 1 2 (2)
I1031 13:14:10.272649 97572 net.cpp:225] Memory required for data: 32311500
I1031 13:14:10.281363 97572 layer_factory.hpp:114] Creating layer loss
I1031 13:14:10.320730 97572 net.cpp:160] Creating Layer loss
I1031 13:14:10.335582 97572 net.cpp:596] loss <- fc2
I1031 13:14:10.346827 97572 net.cpp:596] loss <- label
I1031 13:14:10.406663 97572 net.cpp:570] loss -> (automatic)
I1031 13:14:10.462913 97572 layer_factory.hpp:114] Creating layer loss
I1031 13:14:10.871579 97572 net.cpp:210] Setting up loss
I1031 13:14:10.879407 97572 net.cpp:217] Top shape: (1)
I1031 13:14:10.894125 97572 net.cpp:220]     with loss weight 1
I1031 13:14:11.036250 97572 net.cpp:225] Memory required for data: 32311504
I1031 13:14:11.091223 97572 net.cpp:287] loss needs backward computation.
I1031 13:14:11.200685 97572 net.cpp:287] fc2 needs backward computation.
I1031 13:14:11.209137 97572 net.cpp:287] dropout5 needs backward computation.
I1031 13:14:11.211638 97572 net.cpp:287] fc1 needs backward computation.
I1031 13:14:11.212523 97572 net.cpp:287] pool4 needs backward computation.
I1031 13:14:11.212915 97572 net.cpp:287] dropout4 needs backward computation.
I1031 13:14:11.213240 97572 net.cpp:287] relu4 needs backward computation.
I1031 13:14:11.224197 97572 net.cpp:287] conv4 needs backward computation.
I1031 13:14:11.243619 97572 net.cpp:287] pool3 needs backward computation.
I1031 13:14:11.259047 97572 net.cpp:287] dropout3 needs backward computation.
I1031 13:14:11.264408 97572 net.cpp:287] relu3 needs backward computation.
I1031 13:14:11.264753 97572 net.cpp:287] conv3 needs backward computation.
I1031 13:14:11.265139 97572 net.cpp:287] pool2 needs backward computation.
I1031 13:14:11.265394 97572 net.cpp:287] dropout2 needs backward computation.
I1031 13:14:11.265612 97572 net.cpp:287] relu2 needs backward computation.
I1031 13:14:11.265821 97572 net.cpp:287] conv2 needs backward computation.
I1031 13:14:11.266036 97572 net.cpp:287] pool1 needs backward computation.
I1031 13:14:11.266243 97572 net.cpp:287] dropout1 needs backward computation.
I1031 13:14:11.266451 97572 net.cpp:287] relu1 needs backward computation.
I1031 13:14:11.266654 97572 net.cpp:287] conv1 needs backward computation.
I1031 13:14:11.289392 97572 net.cpp:289] data does not need backward computation.
I1031 13:14:11.350308 97572 net.cpp:345] Network initialization done.
I1031 13:14:11.531179 97572 caffe.cpp:452] Performing Forward
I1031 13:14:23.189297 97572 caffe.cpp:457] Initial loss: 29.8987
I1031 13:14:23.323632 97572 caffe.cpp:459] Performing Backward
I1031 13:14:26.795644 97572 caffe.cpp:468] *** Benchmark begins ***
I1031 13:14:26.817405 97572 caffe.cpp:469] Testing for 1 iterations.
I1031 13:14:26.967674 97572 caffe.cpp:482] Profiling Layer: fc1 forward
I1031 13:14:29.200100 97572 caffe.cpp:512] Iteration: 1 forward-backward time: 2231 ms.
I1031 13:14:29.315198 97572 caffe.cpp:519] Average time per layer: 
I1031 13:14:29.339440 97572 caffe.cpp:522]       data	forward: 51.745 ms.
I1031 13:14:29.412475 97572 caffe.cpp:526]       data	backward: 5.744 ms.
I1031 13:14:29.440254 97572 caffe.cpp:522]      conv1	forward: 69.09 ms.
I1031 13:14:29.453639 97572 caffe.cpp:526]      conv1	backward: 43.104 ms.
I1031 13:14:29.459990 97572 caffe.cpp:522]      relu1	forward: 23.684 ms.
I1031 13:14:29.466831 97572 caffe.cpp:526]      relu1	backward: 69.159 ms.
I1031 13:14:29.475512 97572 caffe.cpp:522]   dropout1	forward: 42.447 ms.
I1031 13:14:29.481858 97572 caffe.cpp:526]   dropout1	backward: 55.174 ms.
I1031 13:14:29.484604 97572 caffe.cpp:522]      pool1	forward: 123.609 ms.
I1031 13:14:29.497745 97572 caffe.cpp:526]      pool1	backward: 231.102 ms.
I1031 13:14:29.505147 97572 caffe.cpp:522]      conv2	forward: 27.508 ms.
I1031 13:14:29.513577 97572 caffe.cpp:526]      conv2	backward: 78.731 ms.
I1031 13:14:29.522107 97572 caffe.cpp:522]      relu2	forward: 0.136 ms.
I1031 13:14:29.525166 97572 caffe.cpp:526]      relu2	backward: 38.404 ms.
I1031 13:14:29.525610 97572 caffe.cpp:522]   dropout2	forward: 8.354 ms.
I1031 13:14:29.526556 97572 caffe.cpp:526]   dropout2	backward: 30.563 ms.
I1031 13:14:29.526813 97572 caffe.cpp:522]      pool2	forward: 29.406 ms.
I1031 13:14:29.527036 97572 caffe.cpp:526]      pool2	backward: 60.087 ms.
I1031 13:14:29.527257 97572 caffe.cpp:522]      conv3	forward: 67.445 ms.
I1031 13:14:29.527539 97572 caffe.cpp:526]      conv3	backward: 83.634 ms.
I1031 13:14:29.527760 97572 caffe.cpp:522]      relu3	forward: 11.502 ms.
I1031 13:14:29.527979 97572 caffe.cpp:526]      relu3	backward: 54.641 ms.
I1031 13:14:29.528208 97572 caffe.cpp:522]   dropout3	forward: 61.275 ms.
I1031 13:14:29.528528 97572 caffe.cpp:526]   dropout3	backward: 31.089 ms.
I1031 13:14:29.528812 97572 caffe.cpp:522]      pool3	forward: 17.099 ms.
I1031 13:14:29.529036 97572 caffe.cpp:526]      pool3	backward: 56.402 ms.
I1031 13:14:29.529256 97572 caffe.cpp:522]      conv4	forward: 53.155 ms.
I1031 13:14:29.529476 97572 caffe.cpp:526]      conv4	backward: 95.291 ms.
I1031 13:14:29.529697 97572 caffe.cpp:522]      relu4	forward: 21.272 ms.
I1031 13:14:29.529917 97572 caffe.cpp:526]      relu4	backward: 46.755 ms.
I1031 13:14:29.530138 97572 caffe.cpp:522]   dropout4	forward: 62.244 ms.
I1031 13:14:29.530357 97572 caffe.cpp:526]   dropout4	backward: 60.094 ms.
I1031 13:14:29.530577 97572 caffe.cpp:522]      pool4	forward: 16.185 ms.
I1031 13:14:29.530797 97572 caffe.cpp:526]      pool4	backward: 45.781 ms.
I1031 13:14:29.531018 97572 caffe.cpp:522]        fc1	forward: 62.415 ms.
I1031 13:14:29.531244 97572 caffe.cpp:526]        fc1	backward: 51.447 ms.
I1031 13:14:29.531597 97572 caffe.cpp:522]   dropout5	forward: 45.712 ms.
I1031 13:14:29.531962 97572 caffe.cpp:526]   dropout5	backward: 24.444 ms.
I1031 13:14:29.532217 97572 caffe.cpp:522]        fc2	forward: 21.6 ms.
I1031 13:14:29.532440 97572 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 13:14:29.532661 97572 caffe.cpp:522]       loss	forward: 88.223 ms.
I1031 13:14:29.532882 97572 caffe.cpp:526]       loss	backward: 65.97 ms.
I1031 13:14:29.538892 97572 caffe.cpp:532] Average Forward pass: 960.121 ms.
I1031 13:14:29.552551 97572 caffe.cpp:535] Average Backward pass: 1237.87 ms.
I1031 13:14:29.563951 97572 caffe.cpp:537] Average Forward-Backward: 2678 ms.
I1031 13:14:29.579488 97572 caffe.cpp:540] Total Time: 2678 ms.
I1031 13:14:29.592321 97572 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3125
elements_fp_single_4 = 0
elements_fp_single_8 = 4096
elements_fp_single_16 = 589953
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 9475141
--->Total double-precision FLOPs = 0
--->Total FLOPs = 9475141
mem-read-1 = 62468
mem-read-2 = 81
mem-read-4 = 502476
mem-read-8 = 699087
mem-read-16 = 1
mem-read-32 = 0
mem-read-64 = 331907
mem-write-1 = 132
mem-write-2 = 37
mem-write-4 = 3605
mem-write-8 = 69569
mem-write-16 = 1
mem-write-32 = 6
mem-write-64 = 66
--->Total Bytes read = 28907294
--->Total Bytes written = 575610
--->Total Bytes = 29482904

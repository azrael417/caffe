sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer8_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=8 -prof_forward_direction=0
I1031 14:27:08.300062 100319 caffe.cpp:444] Use CPU.
I1031 14:27:26.142300 100319 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:27:26.203276 100319 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:27:26.215647 100319 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:27:26.227497 100319 cpu_info.cpp:461] Total number of processors: 256
I1031 14:27:26.245182 100319 cpu_info.cpp:464] GPU is used: no
I1031 14:27:26.254465 100319 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:27:26.263265 100319 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:27:26.275115 100319 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:27:35.410084 100319 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:27:36.100095 100319 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:27:38.527714 100319 layer_factory.hpp:114] Creating layer data
I1031 14:27:38.684165 100319 net.cpp:160] Creating Layer data
I1031 14:27:38.734890 100319 net.cpp:570] data -> data
I1031 14:27:39.230649 100319 net.cpp:570] data -> label
I1031 14:27:46.698555 100319 net.cpp:210] Setting up data
I1031 14:27:46.782568 100319 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:27:46.889137 100319 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:27:46.896562 100319 net.cpp:225] Memory required for data: 184516
I1031 14:27:46.975512 100319 layer_factory.hpp:114] Creating layer conv1
I1031 14:27:47.323055 100319 net.cpp:160] Creating Layer conv1
I1031 14:27:47.381978 100319 net.cpp:596] conv1 <- data
I1031 14:27:47.510831 100319 net.cpp:570] conv1 -> conv1
I1031 14:28:25.041111 100319 net.cpp:210] Setting up conv1
I1031 14:28:25.110386 100319 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:28:25.128449 100319 net.cpp:225] Memory required for data: 7805124
I1031 14:28:25.461812 100319 layer_factory.hpp:114] Creating layer relu1
I1031 14:28:25.616147 100319 net.cpp:160] Creating Layer relu1
I1031 14:28:25.624033 100319 net.cpp:596] relu1 <- conv1
I1031 14:28:25.659606 100319 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:28:25.877355 100319 net.cpp:210] Setting up relu1
I1031 14:28:25.880085 100319 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:28:25.880450 100319 net.cpp:225] Memory required for data: 15425732
I1031 14:28:25.880668 100319 layer_factory.hpp:114] Creating layer dropout1
I1031 14:28:25.913018 100319 net.cpp:160] Creating Layer dropout1
I1031 14:28:25.913353 100319 net.cpp:596] dropout1 <- conv1
I1031 14:28:25.916136 100319 net.cpp:570] dropout1 -> drop1
I1031 14:28:26.038332 100319 net.cpp:210] Setting up dropout1
I1031 14:28:26.052220 100319 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:28:26.052628 100319 net.cpp:225] Memory required for data: 23046340
I1031 14:28:26.053020 100319 layer_factory.hpp:114] Creating layer pool1
I1031 14:28:26.155228 100319 net.cpp:160] Creating Layer pool1
I1031 14:28:26.155710 100319 net.cpp:596] pool1 <- drop1
I1031 14:28:26.156064 100319 net.cpp:570] pool1 -> pool1
I1031 14:28:26.565793 100319 net.cpp:210] Setting up pool1
I1031 14:28:26.570760 100319 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:28:26.571144 100319 net.cpp:225] Memory required for data: 24951492
I1031 14:28:26.571512 100319 layer_factory.hpp:114] Creating layer conv2
I1031 14:28:26.632592 100319 net.cpp:160] Creating Layer conv2
I1031 14:28:26.636993 100319 net.cpp:596] conv2 <- pool1
I1031 14:28:26.652139 100319 net.cpp:570] conv2 -> conv2
I1031 14:28:33.550995 100319 net.cpp:210] Setting up conv2
I1031 14:28:33.559447 100319 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:28:33.567126 100319 net.cpp:225] Memory required for data: 26733764
I1031 14:28:33.636171 100319 layer_factory.hpp:114] Creating layer relu2
I1031 14:28:33.646986 100319 net.cpp:160] Creating Layer relu2
I1031 14:28:33.656080 100319 net.cpp:596] relu2 <- conv2
I1031 14:28:33.660581 100319 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:28:33.665633 100319 net.cpp:210] Setting up relu2
I1031 14:28:33.669983 100319 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:28:33.676565 100319 net.cpp:225] Memory required for data: 28516036
I1031 14:28:33.689079 100319 layer_factory.hpp:114] Creating layer dropout2
I1031 14:28:33.693070 100319 net.cpp:160] Creating Layer dropout2
I1031 14:28:33.699975 100319 net.cpp:596] dropout2 <- conv2
I1031 14:28:33.712771 100319 net.cpp:570] dropout2 -> drop2
I1031 14:28:33.719349 100319 net.cpp:210] Setting up dropout2
I1031 14:28:33.719794 100319 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:28:33.734139 100319 net.cpp:225] Memory required for data: 30298308
I1031 14:28:33.740586 100319 layer_factory.hpp:114] Creating layer pool2
I1031 14:28:33.745048 100319 net.cpp:160] Creating Layer pool2
I1031 14:28:33.757493 100319 net.cpp:596] pool2 <- drop2
I1031 14:28:33.761925 100319 net.cpp:570] pool2 -> pool2
I1031 14:28:33.766633 100319 net.cpp:210] Setting up pool2
I1031 14:28:33.776998 100319 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:28:33.789391 100319 net.cpp:225] Memory required for data: 30759108
I1031 14:28:33.799790 100319 layer_factory.hpp:114] Creating layer conv3
I1031 14:28:33.812579 100319 net.cpp:160] Creating Layer conv3
I1031 14:28:33.823210 100319 net.cpp:596] conv3 <- pool2
I1031 14:28:33.825248 100319 net.cpp:570] conv3 -> conv3
I1031 14:28:34.417487 100319 net.cpp:210] Setting up conv3
I1031 14:28:34.426276 100319 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:28:34.434342 100319 net.cpp:225] Memory required for data: 31160516
I1031 14:28:34.453413 100319 layer_factory.hpp:114] Creating layer relu3
I1031 14:28:34.457892 100319 net.cpp:160] Creating Layer relu3
I1031 14:28:34.466238 100319 net.cpp:596] relu3 <- conv3
I1031 14:28:34.474443 100319 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:28:34.477746 100319 net.cpp:210] Setting up relu3
I1031 14:28:34.482156 100319 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:28:34.487030 100319 net.cpp:225] Memory required for data: 31561924
I1031 14:28:34.495546 100319 layer_factory.hpp:114] Creating layer dropout3
I1031 14:28:34.506264 100319 net.cpp:160] Creating Layer dropout3
I1031 14:28:34.516563 100319 net.cpp:596] dropout3 <- conv3
I1031 14:28:34.525230 100319 net.cpp:570] dropout3 -> drop3
I1031 14:28:34.531621 100319 net.cpp:210] Setting up dropout3
I1031 14:28:34.536118 100319 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:28:34.542188 100319 net.cpp:225] Memory required for data: 31963332
I1031 14:28:34.544716 100319 layer_factory.hpp:114] Creating layer pool3
I1031 14:28:34.551319 100319 net.cpp:160] Creating Layer pool3
I1031 14:28:34.563980 100319 net.cpp:596] pool3 <- drop3
I1031 14:28:34.568734 100319 net.cpp:570] pool3 -> pool3
I1031 14:28:34.570976 100319 net.cpp:210] Setting up pool3
I1031 14:28:34.575630 100319 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:28:34.580464 100319 net.cpp:225] Memory required for data: 32063684
I1031 14:28:34.586750 100319 layer_factory.hpp:114] Creating layer conv4
I1031 14:28:34.591892 100319 net.cpp:160] Creating Layer conv4
I1031 14:28:34.596221 100319 net.cpp:596] conv4 <- pool3
I1031 14:28:34.600980 100319 net.cpp:570] conv4 -> conv4
I1031 14:28:34.998720 100319 net.cpp:210] Setting up conv4
I1031 14:28:34.999012 100319 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:28:34.999409 100319 net.cpp:225] Memory required for data: 32137412
I1031 14:28:34.999749 100319 layer_factory.hpp:114] Creating layer relu4
I1031 14:28:35.000037 100319 net.cpp:160] Creating Layer relu4
I1031 14:28:35.005290 100319 net.cpp:596] relu4 <- conv4
I1031 14:28:35.008028 100319 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:28:35.008546 100319 net.cpp:210] Setting up relu4
I1031 14:28:35.008846 100319 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:28:35.009114 100319 net.cpp:225] Memory required for data: 32211140
I1031 14:28:35.009336 100319 layer_factory.hpp:114] Creating layer dropout4
I1031 14:28:35.009682 100319 net.cpp:160] Creating Layer dropout4
I1031 14:28:35.009970 100319 net.cpp:596] dropout4 <- conv4
I1031 14:28:35.010259 100319 net.cpp:570] dropout4 -> drop4
I1031 14:28:35.010581 100319 net.cpp:210] Setting up dropout4
I1031 14:28:35.010812 100319 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:28:35.011061 100319 net.cpp:225] Memory required for data: 32284868
I1031 14:28:35.011270 100319 layer_factory.hpp:114] Creating layer pool4
I1031 14:28:35.011626 100319 net.cpp:160] Creating Layer pool4
I1031 14:28:35.011862 100319 net.cpp:596] pool4 <- drop4
I1031 14:28:35.012115 100319 net.cpp:570] pool4 -> pool4
I1031 14:28:35.026208 100319 net.cpp:210] Setting up pool4
I1031 14:28:35.026576 100319 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:28:35.029137 100319 net.cpp:225] Memory required for data: 32303300
I1031 14:28:35.029399 100319 layer_factory.hpp:114] Creating layer fc1
I1031 14:28:35.094645 100319 net.cpp:160] Creating Layer fc1
I1031 14:28:35.094986 100319 net.cpp:596] fc1 <- pool4
I1031 14:28:35.095440 100319 net.cpp:570] fc1 -> fc1
I1031 14:28:36.005784 100319 net.cpp:210] Setting up fc1
I1031 14:28:36.012392 100319 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:28:36.018859 100319 net.cpp:225] Memory required for data: 32307396
I1031 14:28:36.033794 100319 layer_factory.hpp:114] Creating layer dropout5
I1031 14:28:36.041889 100319 net.cpp:160] Creating Layer dropout5
I1031 14:28:36.044775 100319 net.cpp:596] dropout5 <- fc1
I1031 14:28:36.051570 100319 net.cpp:570] dropout5 -> drop5
I1031 14:28:36.056133 100319 net.cpp:210] Setting up dropout5
I1031 14:28:36.060035 100319 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:28:36.070585 100319 net.cpp:225] Memory required for data: 32311492
I1031 14:28:36.078405 100319 layer_factory.hpp:114] Creating layer fc2
I1031 14:28:36.088209 100319 net.cpp:160] Creating Layer fc2
I1031 14:28:36.094820 100319 net.cpp:596] fc2 <- drop5
I1031 14:28:36.101377 100319 net.cpp:570] fc2 -> fc2
I1031 14:28:36.128557 100319 net.cpp:210] Setting up fc2
I1031 14:28:36.138206 100319 net.cpp:217] Top shape: 1 2 (2)
I1031 14:28:36.148818 100319 net.cpp:225] Memory required for data: 32311500
I1031 14:28:36.155481 100319 layer_factory.hpp:114] Creating layer loss
I1031 14:28:36.191704 100319 net.cpp:160] Creating Layer loss
I1031 14:28:36.200156 100319 net.cpp:596] loss <- fc2
I1031 14:28:36.217099 100319 net.cpp:596] loss <- label
I1031 14:28:36.279657 100319 net.cpp:570] loss -> (automatic)
I1031 14:28:36.339300 100319 layer_factory.hpp:114] Creating layer loss
I1031 14:28:36.745400 100319 net.cpp:210] Setting up loss
I1031 14:28:36.755791 100319 net.cpp:217] Top shape: (1)
I1031 14:28:36.772727 100319 net.cpp:220]     with loss weight 1
I1031 14:28:36.909399 100319 net.cpp:225] Memory required for data: 32311504
I1031 14:28:36.961508 100319 net.cpp:287] loss needs backward computation.
I1031 14:28:37.068569 100319 net.cpp:287] fc2 needs backward computation.
I1031 14:28:37.079208 100319 net.cpp:287] dropout5 needs backward computation.
I1031 14:28:37.081503 100319 net.cpp:287] fc1 needs backward computation.
I1031 14:28:37.082298 100319 net.cpp:287] pool4 needs backward computation.
I1031 14:28:37.082577 100319 net.cpp:287] dropout4 needs backward computation.
I1031 14:28:37.082809 100319 net.cpp:287] relu4 needs backward computation.
I1031 14:28:37.092541 100319 net.cpp:287] conv4 needs backward computation.
I1031 14:28:37.109685 100319 net.cpp:287] pool3 needs backward computation.
I1031 14:28:37.123661 100319 net.cpp:287] dropout3 needs backward computation.
I1031 14:28:37.128463 100319 net.cpp:287] relu3 needs backward computation.
I1031 14:28:37.128809 100319 net.cpp:287] conv3 needs backward computation.
I1031 14:28:37.129124 100319 net.cpp:287] pool2 needs backward computation.
I1031 14:28:37.129376 100319 net.cpp:287] dropout2 needs backward computation.
I1031 14:28:37.129670 100319 net.cpp:287] relu2 needs backward computation.
I1031 14:28:37.129859 100319 net.cpp:287] conv2 needs backward computation.
I1031 14:28:37.130053 100319 net.cpp:287] pool1 needs backward computation.
I1031 14:28:37.130244 100319 net.cpp:287] dropout1 needs backward computation.
I1031 14:28:37.130435 100319 net.cpp:287] relu1 needs backward computation.
I1031 14:28:37.130620 100319 net.cpp:287] conv1 needs backward computation.
I1031 14:28:37.151069 100319 net.cpp:289] data does not need backward computation.
I1031 14:28:37.210800 100319 net.cpp:345] Network initialization done.
I1031 14:28:37.391211 100319 caffe.cpp:452] Performing Forward
I1031 14:28:49.225601 100319 caffe.cpp:457] Initial loss: 0
I1031 14:28:49.259732 100319 caffe.cpp:459] Performing Backward
I1031 14:28:52.432204 100319 caffe.cpp:468] *** Benchmark begins ***
I1031 14:28:52.446328 100319 caffe.cpp:469] Testing for 1 iterations.
I1031 14:28:52.603211 100319 caffe.cpp:485] Profiling Layer: pool2 backward
I1031 14:28:54.317467 100319 caffe.cpp:512] Iteration: 1 forward-backward time: 1705 ms.
I1031 14:28:54.489622 100319 caffe.cpp:519] Average time per layer: 
I1031 14:28:54.508039 100319 caffe.cpp:522]       data	forward: 50.822 ms.
I1031 14:28:54.582340 100319 caffe.cpp:526]       data	backward: 7.685 ms.
I1031 14:28:54.623003 100319 caffe.cpp:522]      conv1	forward: 69.223 ms.
I1031 14:28:54.638123 100319 caffe.cpp:526]      conv1	backward: 41.344 ms.
I1031 14:28:54.644789 100319 caffe.cpp:522]      relu1	forward: 25.07 ms.
I1031 14:28:54.651923 100319 caffe.cpp:526]      relu1	backward: 65.052 ms.
I1031 14:28:54.661795 100319 caffe.cpp:522]   dropout1	forward: 84.977 ms.
I1031 14:28:54.671061 100319 caffe.cpp:526]   dropout1	backward: 73.219 ms.
I1031 14:28:54.679159 100319 caffe.cpp:522]      pool1	forward: 130.24 ms.
I1031 14:28:54.682199 100319 caffe.cpp:526]      pool1	backward: 109.89 ms.
I1031 14:28:54.682637 100319 caffe.cpp:522]      conv2	forward: 69.56 ms.
I1031 14:28:54.682953 100319 caffe.cpp:526]      conv2	backward: 14.219 ms.
I1031 14:28:54.683194 100319 caffe.cpp:522]      relu2	forward: 17.491 ms.
I1031 14:28:54.683596 100319 caffe.cpp:526]      relu2	backward: 6.871 ms.
I1031 14:28:54.683812 100319 caffe.cpp:522]   dropout2	forward: 69.821 ms.
I1031 14:28:54.684023 100319 caffe.cpp:526]   dropout2	backward: 7.812 ms.
I1031 14:28:54.684224 100319 caffe.cpp:522]      pool2	forward: 29.88 ms.
I1031 14:28:54.684430 100319 caffe.cpp:526]      pool2	backward: 38.735 ms.
I1031 14:28:54.684635 100319 caffe.cpp:522]      conv3	forward: 70.365 ms.
I1031 14:28:54.684839 100319 caffe.cpp:526]      conv3	backward: 2.54 ms.
I1031 14:28:54.685037 100319 caffe.cpp:522]      relu3	forward: 23.14 ms.
I1031 14:28:54.685276 100319 caffe.cpp:526]      relu3	backward: 1.333 ms.
I1031 14:28:54.685492 100319 caffe.cpp:522]   dropout3	forward: 65.431 ms.
I1031 14:28:54.685822 100319 caffe.cpp:526]   dropout3	backward: 1.895 ms.
I1031 14:28:54.686103 100319 caffe.cpp:522]      pool3	forward: 27.657 ms.
I1031 14:28:54.686316 100319 caffe.cpp:526]      pool3	backward: 5.931 ms.
I1031 14:28:54.686514 100319 caffe.cpp:522]      conv4	forward: 55.074 ms.
I1031 14:28:54.686719 100319 caffe.cpp:526]      conv4	backward: 9.798 ms.
I1031 14:28:54.687621 100319 caffe.cpp:522]      relu4	forward: 19.862 ms.
I1031 14:28:54.687867 100319 caffe.cpp:526]      relu4	backward: 5.507 ms.
I1031 14:28:54.688071 100319 caffe.cpp:522]   dropout4	forward: 57.637 ms.
I1031 14:28:54.688278 100319 caffe.cpp:526]   dropout4	backward: 12.69 ms.
I1031 14:28:54.688482 100319 caffe.cpp:522]      pool4	forward: 13.319 ms.
I1031 14:28:54.688724 100319 caffe.cpp:526]      pool4	backward: 1.205 ms.
I1031 14:28:54.688946 100319 caffe.cpp:522]        fc1	forward: 46.246 ms.
I1031 14:28:54.689273 100319 caffe.cpp:526]        fc1	backward: 11.586 ms.
I1031 14:28:54.689564 100319 caffe.cpp:522]   dropout5	forward: 40.534 ms.
I1031 14:28:54.689777 100319 caffe.cpp:526]   dropout5	backward: 0.071 ms.
I1031 14:28:54.709127 100319 caffe.cpp:522]        fc2	forward: 24.161 ms.
I1031 14:28:54.709544 100319 caffe.cpp:526]        fc2	backward: 0.206 ms.
I1031 14:28:54.709825 100319 caffe.cpp:522]       loss	forward: 162.215 ms.
I1031 14:28:54.712157 100319 caffe.cpp:526]       loss	backward: 33.991 ms.
I1031 14:28:54.718160 100319 caffe.cpp:532] Average Forward pass: 1212.9 ms.
I1031 14:28:54.731967 100319 caffe.cpp:535] Average Backward pass: 461.368 ms.
I1031 14:28:54.745746 100319 caffe.cpp:537] Average Forward-Backward: 2225 ms.
I1031 14:28:54.761389 100319 caffe.cpp:540] Total Time: 2225 ms.
I1031 14:28:54.774335 100319 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 115200
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 115200
--->Total double-precision FLOPs = 0
--->Total FLOPs = 115200
mem-read-1 = 2055593
mem-read-2 = 105
mem-read-4 = 16712410
mem-read-8 = 23560477
mem-read-16 = 0
mem-read-32 = 3
mem-read-64 = 12180
mem-write-1 = 284
mem-write-2 = 51
mem-write-4 = 566486
mem-write-8 = 2102610
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 35530
--->Total Bytes read = 258168875
--->Total Bytes written = 21361194
--->Total Bytes = 279530069

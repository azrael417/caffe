sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer18_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=18 -prof_forward_direction=1
I1031 13:18:55.821437 97800 caffe.cpp:444] Use CPU.
I1031 13:19:13.708077 97800 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 13:19:13.769016 97800 cpu_info.cpp:455] Total number of sockets: 1
I1031 13:19:13.781916 97800 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 13:19:13.794064 97800 cpu_info.cpp:461] Total number of processors: 256
I1031 13:19:13.810967 97800 cpu_info.cpp:464] GPU is used: no
I1031 13:19:13.820654 97800 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 13:19:13.829411 97800 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 13:19:13.841295 97800 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 13:19:23.024811 97800 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 13:19:23.725589 97800 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 13:19:26.166820 97800 layer_factory.hpp:114] Creating layer data
I1031 13:19:26.324038 97800 net.cpp:160] Creating Layer data
I1031 13:19:26.375694 97800 net.cpp:570] data -> data
I1031 13:19:26.872241 97800 net.cpp:570] data -> label
I1031 13:19:34.336117 97800 net.cpp:210] Setting up data
I1031 13:19:34.420054 97800 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 13:19:34.526772 97800 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 13:19:34.535717 97800 net.cpp:225] Memory required for data: 184516
I1031 13:19:34.617239 97800 layer_factory.hpp:114] Creating layer conv1
I1031 13:19:34.964135 97800 net.cpp:160] Creating Layer conv1
I1031 13:19:35.017206 97800 net.cpp:596] conv1 <- data
I1031 13:19:35.146903 97800 net.cpp:570] conv1 -> conv1
I1031 13:20:12.852859 97800 net.cpp:210] Setting up conv1
I1031 13:20:12.930629 97800 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:20:12.939528 97800 net.cpp:225] Memory required for data: 7805124
I1031 13:20:13.267258 97800 layer_factory.hpp:114] Creating layer relu1
I1031 13:20:13.398457 97800 net.cpp:160] Creating Layer relu1
I1031 13:20:13.403517 97800 net.cpp:596] relu1 <- conv1
I1031 13:20:13.438347 97800 net.cpp:557] relu1 -> conv1 (in-place)
I1031 13:20:13.654314 97800 net.cpp:210] Setting up relu1
I1031 13:20:13.656956 97800 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:20:13.657320 97800 net.cpp:225] Memory required for data: 15425732
I1031 13:20:13.657534 97800 layer_factory.hpp:114] Creating layer dropout1
I1031 13:20:13.690062 97800 net.cpp:160] Creating Layer dropout1
I1031 13:20:13.690393 97800 net.cpp:596] dropout1 <- conv1
I1031 13:20:13.693207 97800 net.cpp:570] dropout1 -> drop1
I1031 13:20:13.815950 97800 net.cpp:210] Setting up dropout1
I1031 13:20:13.830020 97800 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 13:20:13.830451 97800 net.cpp:225] Memory required for data: 23046340
I1031 13:20:13.830824 97800 layer_factory.hpp:114] Creating layer pool1
I1031 13:20:13.933861 97800 net.cpp:160] Creating Layer pool1
I1031 13:20:13.934207 97800 net.cpp:596] pool1 <- drop1
I1031 13:20:13.934607 97800 net.cpp:570] pool1 -> pool1
I1031 13:20:14.351650 97800 net.cpp:210] Setting up pool1
I1031 13:20:14.356735 97800 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 13:20:14.357120 97800 net.cpp:225] Memory required for data: 24951492
I1031 13:20:14.357422 97800 layer_factory.hpp:114] Creating layer conv2
I1031 13:20:14.420490 97800 net.cpp:160] Creating Layer conv2
I1031 13:20:14.426342 97800 net.cpp:596] conv2 <- pool1
I1031 13:20:14.441886 97800 net.cpp:570] conv2 -> conv2
I1031 13:20:21.314450 97800 net.cpp:210] Setting up conv2
I1031 13:20:21.316967 97800 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:20:21.327853 97800 net.cpp:225] Memory required for data: 26733764
I1031 13:20:21.392395 97800 layer_factory.hpp:114] Creating layer relu2
I1031 13:20:21.398999 97800 net.cpp:160] Creating Layer relu2
I1031 13:20:21.401362 97800 net.cpp:596] relu2 <- conv2
I1031 13:20:21.409047 97800 net.cpp:557] relu2 -> conv2 (in-place)
I1031 13:20:21.413545 97800 net.cpp:210] Setting up relu2
I1031 13:20:21.415812 97800 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:20:21.418419 97800 net.cpp:225] Memory required for data: 28516036
I1031 13:20:21.426718 97800 layer_factory.hpp:114] Creating layer dropout2
I1031 13:20:21.431226 97800 net.cpp:160] Creating Layer dropout2
I1031 13:20:21.437331 97800 net.cpp:596] dropout2 <- conv2
I1031 13:20:21.443717 97800 net.cpp:570] dropout2 -> drop2
I1031 13:20:21.448176 97800 net.cpp:210] Setting up dropout2
I1031 13:20:21.458644 97800 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 13:20:21.463084 97800 net.cpp:225] Memory required for data: 30298308
I1031 13:20:21.467852 97800 layer_factory.hpp:114] Creating layer pool2
I1031 13:20:21.474293 97800 net.cpp:160] Creating Layer pool2
I1031 13:20:21.480984 97800 net.cpp:596] pool2 <- drop2
I1031 13:20:21.485348 97800 net.cpp:570] pool2 -> pool2
I1031 13:20:21.485891 97800 net.cpp:210] Setting up pool2
I1031 13:20:21.488142 97800 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 13:20:21.496809 97800 net.cpp:225] Memory required for data: 30759108
I1031 13:20:21.506680 97800 layer_factory.hpp:114] Creating layer conv3
I1031 13:20:21.511318 97800 net.cpp:160] Creating Layer conv3
I1031 13:20:21.515086 97800 net.cpp:596] conv3 <- pool2
I1031 13:20:21.523551 97800 net.cpp:570] conv3 -> conv3
I1031 13:20:22.123953 97800 net.cpp:210] Setting up conv3
I1031 13:20:22.132205 97800 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:20:22.134680 97800 net.cpp:225] Memory required for data: 31160516
I1031 13:20:22.150416 97800 layer_factory.hpp:114] Creating layer relu3
I1031 13:20:22.154788 97800 net.cpp:160] Creating Layer relu3
I1031 13:20:22.157207 97800 net.cpp:596] relu3 <- conv3
I1031 13:20:22.161861 97800 net.cpp:557] relu3 -> conv3 (in-place)
I1031 13:20:22.170405 97800 net.cpp:210] Setting up relu3
I1031 13:20:22.182731 97800 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:20:22.189438 97800 net.cpp:225] Memory required for data: 31561924
I1031 13:20:22.198098 97800 layer_factory.hpp:114] Creating layer dropout3
I1031 13:20:22.200121 97800 net.cpp:160] Creating Layer dropout3
I1031 13:20:22.200429 97800 net.cpp:596] dropout3 <- conv3
I1031 13:20:22.200708 97800 net.cpp:570] dropout3 -> drop3
I1031 13:20:22.205653 97800 net.cpp:210] Setting up dropout3
I1031 13:20:22.207553 97800 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 13:20:22.212249 97800 net.cpp:225] Memory required for data: 31963332
I1031 13:20:22.216938 97800 layer_factory.hpp:114] Creating layer pool3
I1031 13:20:22.224941 97800 net.cpp:160] Creating Layer pool3
I1031 13:20:22.229466 97800 net.cpp:596] pool3 <- drop3
I1031 13:20:22.231958 97800 net.cpp:570] pool3 -> pool3
I1031 13:20:22.236421 97800 net.cpp:210] Setting up pool3
I1031 13:20:22.242141 97800 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 13:20:22.251225 97800 net.cpp:225] Memory required for data: 32063684
I1031 13:20:22.259693 97800 layer_factory.hpp:114] Creating layer conv4
I1031 13:20:22.265997 97800 net.cpp:160] Creating Layer conv4
I1031 13:20:22.268508 97800 net.cpp:596] conv4 <- pool3
I1031 13:20:22.275001 97800 net.cpp:570] conv4 -> conv4
I1031 13:20:22.678911 97800 net.cpp:210] Setting up conv4
I1031 13:20:22.689286 97800 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:20:22.699256 97800 net.cpp:225] Memory required for data: 32137412
I1031 13:20:22.709733 97800 layer_factory.hpp:114] Creating layer relu4
I1031 13:20:22.715839 97800 net.cpp:160] Creating Layer relu4
I1031 13:20:22.725844 97800 net.cpp:596] relu4 <- conv4
I1031 13:20:22.732872 97800 net.cpp:557] relu4 -> conv4 (in-place)
I1031 13:20:22.739339 97800 net.cpp:210] Setting up relu4
I1031 13:20:22.751662 97800 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:20:22.760036 97800 net.cpp:225] Memory required for data: 32211140
I1031 13:20:22.768640 97800 layer_factory.hpp:114] Creating layer dropout4
I1031 13:20:22.776738 97800 net.cpp:160] Creating Layer dropout4
I1031 13:20:22.785318 97800 net.cpp:596] dropout4 <- conv4
I1031 13:20:22.791669 97800 net.cpp:570] dropout4 -> drop4
I1031 13:20:22.796351 97800 net.cpp:210] Setting up dropout4
I1031 13:20:22.798405 97800 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 13:20:22.809474 97800 net.cpp:225] Memory required for data: 32284868
I1031 13:20:22.811578 97800 layer_factory.hpp:114] Creating layer pool4
I1031 13:20:22.817790 97800 net.cpp:160] Creating Layer pool4
I1031 13:20:22.821802 97800 net.cpp:596] pool4 <- drop4
I1031 13:20:22.832281 97800 net.cpp:570] pool4 -> pool4
I1031 13:20:22.855173 97800 net.cpp:210] Setting up pool4
I1031 13:20:22.861562 97800 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 13:20:22.867357 97800 net.cpp:225] Memory required for data: 32303300
I1031 13:20:22.870579 97800 layer_factory.hpp:114] Creating layer fc1
I1031 13:20:22.936432 97800 net.cpp:160] Creating Layer fc1
I1031 13:20:22.940474 97800 net.cpp:596] fc1 <- pool4
I1031 13:20:22.942247 97800 net.cpp:570] fc1 -> fc1
I1031 13:20:23.821467 97800 net.cpp:210] Setting up fc1
I1031 13:20:23.825789 97800 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:20:23.828253 97800 net.cpp:225] Memory required for data: 32307396
I1031 13:20:23.840733 97800 layer_factory.hpp:114] Creating layer dropout5
I1031 13:20:23.849998 97800 net.cpp:160] Creating Layer dropout5
I1031 13:20:23.856346 97800 net.cpp:596] dropout5 <- fc1
I1031 13:20:23.862776 97800 net.cpp:570] dropout5 -> drop5
I1031 13:20:23.874938 97800 net.cpp:210] Setting up dropout5
I1031 13:20:23.881655 97800 net.cpp:217] Top shape: 1 1024 (1024)
I1031 13:20:23.885929 97800 net.cpp:225] Memory required for data: 32311492
I1031 13:20:23.891799 97800 layer_factory.hpp:114] Creating layer fc2
I1031 13:20:23.898756 97800 net.cpp:160] Creating Layer fc2
I1031 13:20:23.900928 97800 net.cpp:596] fc2 <- drop5
I1031 13:20:23.903779 97800 net.cpp:570] fc2 -> fc2
I1031 13:20:23.929939 97800 net.cpp:210] Setting up fc2
I1031 13:20:23.945402 97800 net.cpp:217] Top shape: 1 2 (2)
I1031 13:20:23.957815 97800 net.cpp:225] Memory required for data: 32311500
I1031 13:20:23.965966 97800 layer_factory.hpp:114] Creating layer loss
I1031 13:20:23.994557 97800 net.cpp:160] Creating Layer loss
I1031 13:20:24.005233 97800 net.cpp:596] loss <- fc2
I1031 13:20:24.013943 97800 net.cpp:596] loss <- label
I1031 13:20:24.083989 97800 net.cpp:570] loss -> (automatic)
I1031 13:20:24.140110 97800 layer_factory.hpp:114] Creating layer loss
I1031 13:20:24.549824 97800 net.cpp:210] Setting up loss
I1031 13:20:24.562608 97800 net.cpp:217] Top shape: (1)
I1031 13:20:24.581035 97800 net.cpp:220]     with loss weight 1
I1031 13:20:24.718305 97800 net.cpp:225] Memory required for data: 32311504
I1031 13:20:24.771591 97800 net.cpp:287] loss needs backward computation.
I1031 13:20:24.874763 97800 net.cpp:287] fc2 needs backward computation.
I1031 13:20:24.890553 97800 net.cpp:287] dropout5 needs backward computation.
I1031 13:20:24.900988 97800 net.cpp:287] fc1 needs backward computation.
I1031 13:20:24.910478 97800 net.cpp:287] pool4 needs backward computation.
I1031 13:20:24.920689 97800 net.cpp:287] dropout4 needs backward computation.
I1031 13:20:24.925457 97800 net.cpp:287] relu4 needs backward computation.
I1031 13:20:24.936261 97800 net.cpp:287] conv4 needs backward computation.
I1031 13:20:24.953346 97800 net.cpp:287] pool3 needs backward computation.
I1031 13:20:24.967284 97800 net.cpp:287] dropout3 needs backward computation.
I1031 13:20:24.972198 97800 net.cpp:287] relu3 needs backward computation.
I1031 13:20:24.972532 97800 net.cpp:287] conv3 needs backward computation.
I1031 13:20:24.972872 97800 net.cpp:287] pool2 needs backward computation.
I1031 13:20:24.973152 97800 net.cpp:287] dropout2 needs backward computation.
I1031 13:20:24.973359 97800 net.cpp:287] relu2 needs backward computation.
I1031 13:20:24.973557 97800 net.cpp:287] conv2 needs backward computation.
I1031 13:20:24.973759 97800 net.cpp:287] pool1 needs backward computation.
I1031 13:20:24.973955 97800 net.cpp:287] dropout1 needs backward computation.
I1031 13:20:24.974151 97800 net.cpp:287] relu1 needs backward computation.
I1031 13:20:24.974344 97800 net.cpp:287] conv1 needs backward computation.
I1031 13:20:24.994392 97800 net.cpp:289] data does not need backward computation.
I1031 13:20:25.051666 97800 net.cpp:345] Network initialization done.
I1031 13:20:25.236717 97800 caffe.cpp:452] Performing Forward
I1031 13:20:37.459134 97800 caffe.cpp:457] Initial loss: 0
I1031 13:20:37.490587 97800 caffe.cpp:459] Performing Backward
I1031 13:20:40.858968 97800 caffe.cpp:468] *** Benchmark begins ***
I1031 13:20:40.880847 97800 caffe.cpp:469] Testing for 1 iterations.
I1031 13:20:41.032341 97800 caffe.cpp:482] Profiling Layer: dropout5 forward
I1031 13:20:42.787400 97800 caffe.cpp:512] Iteration: 1 forward-backward time: 1749 ms.
I1031 13:20:42.955541 97800 caffe.cpp:519] Average time per layer: 
I1031 13:20:42.975563 97800 caffe.cpp:522]       data	forward: 46.734 ms.
I1031 13:20:43.054342 97800 caffe.cpp:526]       data	backward: 5.581 ms.
I1031 13:20:43.081955 97800 caffe.cpp:522]      conv1	forward: 81.252 ms.
I1031 13:20:43.110810 97800 caffe.cpp:526]      conv1	backward: 42.703 ms.
I1031 13:20:43.116955 97800 caffe.cpp:522]      relu1	forward: 19.466 ms.
I1031 13:20:43.121894 97800 caffe.cpp:526]      relu1	backward: 62.586 ms.
I1031 13:20:43.132549 97800 caffe.cpp:522]   dropout1	forward: 94.652 ms.
I1031 13:20:43.138854 97800 caffe.cpp:526]   dropout1	backward: 60.376 ms.
I1031 13:20:43.147032 97800 caffe.cpp:522]      pool1	forward: 130.942 ms.
I1031 13:20:43.153928 97800 caffe.cpp:526]      pool1	backward: 133.106 ms.
I1031 13:20:43.163403 97800 caffe.cpp:522]      conv2	forward: 28.873 ms.
I1031 13:20:43.167260 97800 caffe.cpp:526]      conv2	backward: 67.622 ms.
I1031 13:20:43.168920 97800 caffe.cpp:522]      relu2	forward: 0.141 ms.
I1031 13:20:43.169435 97800 caffe.cpp:526]      relu2	backward: 28.306 ms.
I1031 13:20:43.169648 97800 caffe.cpp:522]   dropout2	forward: 8.218 ms.
I1031 13:20:43.170594 97800 caffe.cpp:526]   dropout2	backward: 35.343 ms.
I1031 13:20:43.171000 97800 caffe.cpp:522]      pool2	forward: 30.043 ms.
I1031 13:20:43.171285 97800 caffe.cpp:526]      pool2	backward: 62.968 ms.
I1031 13:20:43.171530 97800 caffe.cpp:522]      conv3	forward: 4.884 ms.
I1031 13:20:43.171735 97800 caffe.cpp:526]      conv3	backward: 81.886 ms.
I1031 13:20:43.171939 97800 caffe.cpp:522]      relu3	forward: 0.088 ms.
I1031 13:20:43.188725 97800 caffe.cpp:526]      relu3	backward: 35.413 ms.
I1031 13:20:43.189004 97800 caffe.cpp:522]   dropout3	forward: 2.023 ms.
I1031 13:20:43.189216 97800 caffe.cpp:526]   dropout3	backward: 39.112 ms.
I1031 13:20:43.189430 97800 caffe.cpp:522]      pool3	forward: 6.773 ms.
I1031 13:20:43.189633 97800 caffe.cpp:526]      pool3	backward: 66.909 ms.
I1031 13:20:43.189841 97800 caffe.cpp:522]      conv4	forward: 3.433 ms.
I1031 13:20:43.190042 97800 caffe.cpp:526]      conv4	backward: 78.278 ms.
I1031 13:20:43.190246 97800 caffe.cpp:522]      relu4	forward: 0.065 ms.
I1031 13:20:43.192819 97800 caffe.cpp:526]      relu4	backward: 52.154 ms.
I1031 13:20:43.193089 97800 caffe.cpp:522]   dropout4	forward: 0.52 ms.
I1031 13:20:43.193298 97800 caffe.cpp:526]   dropout4	backward: 53.381 ms.
I1031 13:20:43.193507 97800 caffe.cpp:522]      pool4	forward: 1.33 ms.
I1031 13:20:43.193706 97800 caffe.cpp:526]      pool4	backward: 31.738 ms.
I1031 13:20:43.193910 97800 caffe.cpp:522]        fc1	forward: 1.075 ms.
I1031 13:20:43.194109 97800 caffe.cpp:526]        fc1	backward: 53.416 ms.
I1031 13:20:43.194314 97800 caffe.cpp:522]   dropout5	forward: 11.719 ms.
I1031 13:20:43.194516 97800 caffe.cpp:526]   dropout5	backward: 26.152 ms.
I1031 13:20:43.194718 97800 caffe.cpp:522]        fc2	forward: 0.176 ms.
I1031 13:20:43.194957 97800 caffe.cpp:526]        fc2	backward: 0.208 ms.
I1031 13:20:43.195178 97800 caffe.cpp:522]       loss	forward: 113.338 ms.
I1031 13:20:43.195580 97800 caffe.cpp:526]       loss	backward: 48.383 ms.
I1031 13:20:43.201572 97800 caffe.cpp:532] Average Forward pass: 645.741 ms.
I1031 13:20:43.215167 97800 caffe.cpp:535] Average Backward pass: 1075.02 ms.
I1031 13:20:43.226969 97800 caffe.cpp:537] Average Forward-Backward: 2277 ms.
I1031 13:20:43.242418 97800 caffe.cpp:540] Total Time: 2277 ms.
I1031 13:20:43.255159 97800 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 128
elements_fp_double_1 = 33
elements_fp_double_2 = 1760
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2051
--->Total double-precision FLOPs = 3553
--->Total FLOPs = 5604
mem-read-1 = 370613
mem-read-2 = 71
mem-read-4 = 2969897
mem-read-8 = 4089801
mem-read-16 = 5136
mem-read-32 = 0
mem-read-64 = 208
mem-write-1 = 138
mem-write-2 = 50
mem-write-4 = 1867
mem-write-8 = 378183
mem-write-16 = 32
mem-write-32 = 0
mem-write-64 = 128
--->Total Bytes read = 45064239
--->Total Bytes written = 3041874
--->Total Bytes = 48106113

sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer0_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=0 -prof_forward_direction=1
I1031 11:04:52.649212 131134 caffe.cpp:444] Use CPU.
I1031 11:05:11.219799 131134 cpu_info.cpp:452] Processor speed [MHz]: 1300
I1031 11:05:11.283193 131134 cpu_info.cpp:455] Total number of sockets: 1
I1031 11:05:11.296283 131134 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 11:05:11.308881 131134 cpu_info.cpp:461] Total number of processors: 256
I1031 11:05:11.327227 131134 cpu_info.cpp:464] GPU is used: no
I1031 11:05:11.336949 131134 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 11:05:11.347254 131134 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 11:05:11.360932 131134 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 11:05:20.819982 131134 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 11:05:21.534569 131134 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 11:05:24.044718 131134 layer_factory.hpp:114] Creating layer data
I1031 11:05:24.206931 131134 net.cpp:160] Creating Layer data
I1031 11:05:24.260076 131134 net.cpp:570] data -> data
I1031 11:05:24.773228 131134 net.cpp:570] data -> label
I1031 11:05:32.493144 131134 net.cpp:210] Setting up data
I1031 11:05:32.580651 131134 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 11:05:32.691246 131134 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 11:05:32.699018 131134 net.cpp:225] Memory required for data: 184516
I1031 11:05:32.782227 131134 layer_factory.hpp:114] Creating layer conv1
I1031 11:05:33.145414 131134 net.cpp:160] Creating Layer conv1
I1031 11:05:33.200836 131134 net.cpp:596] conv1 <- data
I1031 11:05:33.338003 131134 net.cpp:570] conv1 -> conv1
I1031 11:06:11.718866 131134 net.cpp:210] Setting up conv1
I1031 11:06:11.788750 131134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:06:11.803941 131134 net.cpp:225] Memory required for data: 7805124
I1031 11:06:12.136831 131134 layer_factory.hpp:114] Creating layer relu1
I1031 11:06:12.287078 131134 net.cpp:160] Creating Layer relu1
I1031 11:06:12.298408 131134 net.cpp:596] relu1 <- conv1
I1031 11:06:12.345721 131134 net.cpp:557] relu1 -> conv1 (in-place)
I1031 11:06:12.583017 131134 net.cpp:210] Setting up relu1
I1031 11:06:12.585782 131134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:06:12.586148 131134 net.cpp:225] Memory required for data: 15425732
I1031 11:06:12.586412 131134 layer_factory.hpp:114] Creating layer dropout1
I1031 11:06:12.620095 131134 net.cpp:160] Creating Layer dropout1
I1031 11:06:12.620438 131134 net.cpp:596] dropout1 <- conv1
I1031 11:06:12.623311 131134 net.cpp:570] dropout1 -> drop1
I1031 11:06:12.739442 131134 net.cpp:210] Setting up dropout1
I1031 11:06:12.753693 131134 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:06:12.754536 131134 net.cpp:225] Memory required for data: 23046340
I1031 11:06:12.754866 131134 layer_factory.hpp:114] Creating layer pool1
I1031 11:06:12.858902 131134 net.cpp:160] Creating Layer pool1
I1031 11:06:12.859236 131134 net.cpp:596] pool1 <- drop1
I1031 11:06:12.859622 131134 net.cpp:570] pool1 -> pool1
I1031 11:06:13.294708 131134 net.cpp:210] Setting up pool1
I1031 11:06:13.299893 131134 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 11:06:13.300282 131134 net.cpp:225] Memory required for data: 24951492
I1031 11:06:13.300588 131134 layer_factory.hpp:114] Creating layer conv2
I1031 11:06:13.364464 131134 net.cpp:160] Creating Layer conv2
I1031 11:06:13.368990 131134 net.cpp:596] conv2 <- pool1
I1031 11:06:13.386232 131134 net.cpp:570] conv2 -> conv2
I1031 11:06:20.433609 131134 net.cpp:210] Setting up conv2
I1031 11:06:20.433970 131134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:06:20.440604 131134 net.cpp:225] Memory required for data: 26733764
I1031 11:06:20.500780 131134 layer_factory.hpp:114] Creating layer relu2
I1031 11:06:20.501237 131134 net.cpp:160] Creating Layer relu2
I1031 11:06:20.501680 131134 net.cpp:596] relu2 <- conv2
I1031 11:06:20.501983 131134 net.cpp:557] relu2 -> conv2 (in-place)
I1031 11:06:20.502558 131134 net.cpp:210] Setting up relu2
I1031 11:06:20.502899 131134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:06:20.503157 131134 net.cpp:225] Memory required for data: 28516036
I1031 11:06:20.503365 131134 layer_factory.hpp:114] Creating layer dropout2
I1031 11:06:20.503605 131134 net.cpp:160] Creating Layer dropout2
I1031 11:06:20.503823 131134 net.cpp:596] dropout2 <- conv2
I1031 11:06:20.504063 131134 net.cpp:570] dropout2 -> drop2
I1031 11:06:20.504350 131134 net.cpp:210] Setting up dropout2
I1031 11:06:20.504575 131134 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:06:20.504808 131134 net.cpp:225] Memory required for data: 30298308
I1031 11:06:20.505002 131134 layer_factory.hpp:114] Creating layer pool2
I1031 11:06:20.505331 131134 net.cpp:160] Creating Layer pool2
I1031 11:06:20.505635 131134 net.cpp:596] pool2 <- drop2
I1031 11:06:20.506085 131134 net.cpp:570] pool2 -> pool2
I1031 11:06:20.506666 131134 net.cpp:210] Setting up pool2
I1031 11:06:20.506943 131134 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 11:06:20.507184 131134 net.cpp:225] Memory required for data: 30759108
I1031 11:06:20.507383 131134 layer_factory.hpp:114] Creating layer conv3
I1031 11:06:20.507726 131134 net.cpp:160] Creating Layer conv3
I1031 11:06:20.507961 131134 net.cpp:596] conv3 <- pool2
I1031 11:06:20.508204 131134 net.cpp:570] conv3 -> conv3
I1031 11:06:21.107020 131134 net.cpp:210] Setting up conv3
I1031 11:06:21.109558 131134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:06:21.109932 131134 net.cpp:225] Memory required for data: 31160516
I1031 11:06:21.118652 131134 layer_factory.hpp:114] Creating layer relu3
I1031 11:06:21.119124 131134 net.cpp:160] Creating Layer relu3
I1031 11:06:21.119496 131134 net.cpp:596] relu3 <- conv3
I1031 11:06:21.119815 131134 net.cpp:557] relu3 -> conv3 (in-place)
I1031 11:06:21.120476 131134 net.cpp:210] Setting up relu3
I1031 11:06:21.120796 131134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:06:21.121055 131134 net.cpp:225] Memory required for data: 31561924
I1031 11:06:21.121260 131134 layer_factory.hpp:114] Creating layer dropout3
I1031 11:06:21.121502 131134 net.cpp:160] Creating Layer dropout3
I1031 11:06:21.121718 131134 net.cpp:596] dropout3 <- conv3
I1031 11:06:21.121961 131134 net.cpp:570] dropout3 -> drop3
I1031 11:06:21.122265 131134 net.cpp:210] Setting up dropout3
I1031 11:06:21.122625 131134 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:06:21.122901 131134 net.cpp:225] Memory required for data: 31963332
I1031 11:06:21.123127 131134 layer_factory.hpp:114] Creating layer pool3
I1031 11:06:21.123579 131134 net.cpp:160] Creating Layer pool3
I1031 11:06:21.123875 131134 net.cpp:596] pool3 <- drop3
I1031 11:06:21.124140 131134 net.cpp:570] pool3 -> pool3
I1031 11:06:21.124582 131134 net.cpp:210] Setting up pool3
I1031 11:06:21.124858 131134 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 11:06:21.125093 131134 net.cpp:225] Memory required for data: 32063684
I1031 11:06:21.125303 131134 layer_factory.hpp:114] Creating layer conv4
I1031 11:06:21.125654 131134 net.cpp:160] Creating Layer conv4
I1031 11:06:21.125892 131134 net.cpp:596] conv4 <- pool3
I1031 11:06:21.126142 131134 net.cpp:570] conv4 -> conv4
I1031 11:06:21.443331 131134 net.cpp:210] Setting up conv4
I1031 11:06:21.443646 131134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:06:21.444087 131134 net.cpp:225] Memory required for data: 32137412
I1031 11:06:21.444452 131134 layer_factory.hpp:114] Creating layer relu4
I1031 11:06:21.444773 131134 net.cpp:160] Creating Layer relu4
I1031 11:06:21.445011 131134 net.cpp:596] relu4 <- conv4
I1031 11:06:21.445255 131134 net.cpp:557] relu4 -> conv4 (in-place)
I1031 11:06:21.445721 131134 net.cpp:210] Setting up relu4
I1031 11:06:21.446012 131134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:06:21.446256 131134 net.cpp:225] Memory required for data: 32211140
I1031 11:06:21.446578 131134 layer_factory.hpp:114] Creating layer dropout4
I1031 11:06:21.446822 131134 net.cpp:160] Creating Layer dropout4
I1031 11:06:21.447036 131134 net.cpp:596] dropout4 <- conv4
I1031 11:06:21.447273 131134 net.cpp:570] dropout4 -> drop4
I1031 11:06:21.447610 131134 net.cpp:210] Setting up dropout4
I1031 11:06:21.447845 131134 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:06:21.448092 131134 net.cpp:225] Memory required for data: 32284868
I1031 11:06:21.448324 131134 layer_factory.hpp:114] Creating layer pool4
I1031 11:06:21.448621 131134 net.cpp:160] Creating Layer pool4
I1031 11:06:21.448839 131134 net.cpp:596] pool4 <- drop4
I1031 11:06:21.449072 131134 net.cpp:570] pool4 -> pool4
I1031 11:06:21.462546 131134 net.cpp:210] Setting up pool4
I1031 11:06:21.462913 131134 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 11:06:21.465301 131134 net.cpp:225] Memory required for data: 32303300
I1031 11:06:21.465546 131134 layer_factory.hpp:114] Creating layer fc1
I1031 11:06:21.527490 131134 net.cpp:160] Creating Layer fc1
I1031 11:06:21.527827 131134 net.cpp:596] fc1 <- pool4
I1031 11:06:21.528257 131134 net.cpp:570] fc1 -> fc1
I1031 11:06:22.409759 131134 net.cpp:210] Setting up fc1
I1031 11:06:22.410081 131134 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:06:22.410603 131134 net.cpp:225] Memory required for data: 32307396
I1031 11:06:22.415473 131134 layer_factory.hpp:114] Creating layer dropout5
I1031 11:06:22.415884 131134 net.cpp:160] Creating Layer dropout5
I1031 11:06:22.416115 131134 net.cpp:596] dropout5 <- fc1
I1031 11:06:22.416362 131134 net.cpp:570] dropout5 -> drop5
I1031 11:06:22.416663 131134 net.cpp:210] Setting up dropout5
I1031 11:06:22.416894 131134 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:06:22.417140 131134 net.cpp:225] Memory required for data: 32311492
I1031 11:06:22.417343 131134 layer_factory.hpp:114] Creating layer fc2
I1031 11:06:22.417636 131134 net.cpp:160] Creating Layer fc2
I1031 11:06:22.418021 131134 net.cpp:596] fc2 <- drop5
I1031 11:06:22.418349 131134 net.cpp:570] fc2 -> fc2
I1031 11:06:22.428272 131134 net.cpp:210] Setting up fc2
I1031 11:06:22.429754 131134 net.cpp:217] Top shape: 1 2 (2)
I1031 11:06:22.432270 131134 net.cpp:225] Memory required for data: 32311500
I1031 11:06:22.432724 131134 layer_factory.hpp:114] Creating layer loss
I1031 11:06:22.460448 131134 net.cpp:160] Creating Layer loss
I1031 11:06:22.460788 131134 net.cpp:596] loss <- fc2
I1031 11:06:22.461784 131134 net.cpp:596] loss <- label
I1031 11:06:22.516093 131134 net.cpp:570] loss -> (automatic)
I1031 11:06:22.552224 131134 layer_factory.hpp:114] Creating layer loss
I1031 11:06:22.878522 131134 net.cpp:210] Setting up loss
I1031 11:06:22.881798 131134 net.cpp:217] Top shape: (1)
I1031 11:06:22.889462 131134 net.cpp:220]     with loss weight 1
I1031 11:06:23.024341 131134 net.cpp:225] Memory required for data: 32311504
I1031 11:06:23.067477 131134 net.cpp:287] loss needs backward computation.
I1031 11:06:23.169783 131134 net.cpp:287] fc2 needs backward computation.
I1031 11:06:23.178136 131134 net.cpp:287] dropout5 needs backward computation.
I1031 11:06:23.180588 131134 net.cpp:287] fc1 needs backward computation.
I1031 11:06:23.181473 131134 net.cpp:287] pool4 needs backward computation.
I1031 11:06:23.181787 131134 net.cpp:287] dropout4 needs backward computation.
I1031 11:06:23.182006 131134 net.cpp:287] relu4 needs backward computation.
I1031 11:06:23.192769 131134 net.cpp:287] conv4 needs backward computation.
I1031 11:06:23.211473 131134 net.cpp:287] pool3 needs backward computation.
I1031 11:06:23.226413 131134 net.cpp:287] dropout3 needs backward computation.
I1031 11:06:23.231515 131134 net.cpp:287] relu3 needs backward computation.
I1031 11:06:23.231878 131134 net.cpp:287] conv3 needs backward computation.
I1031 11:06:23.232219 131134 net.cpp:287] pool2 needs backward computation.
I1031 11:06:23.232468 131134 net.cpp:287] dropout2 needs backward computation.
I1031 11:06:23.232682 131134 net.cpp:287] relu2 needs backward computation.
I1031 11:06:23.232887 131134 net.cpp:287] conv2 needs backward computation.
I1031 11:06:23.233099 131134 net.cpp:287] pool1 needs backward computation.
I1031 11:06:23.233306 131134 net.cpp:287] dropout1 needs backward computation.
I1031 11:06:23.233513 131134 net.cpp:287] relu1 needs backward computation.
I1031 11:06:23.233714 131134 net.cpp:287] conv1 needs backward computation.
I1031 11:06:23.255728 131134 net.cpp:289] data does not need backward computation.
I1031 11:06:23.315392 131134 net.cpp:345] Network initialization done.
I1031 11:06:23.514523 131134 caffe.cpp:452] Performing Forward
I1031 11:06:35.371989 131134 caffe.cpp:457] Initial loss: 28.0672
I1031 11:06:35.523484 131134 caffe.cpp:459] Performing Backward
I1031 11:06:38.851586 131134 caffe.cpp:468] *** Benchmark begins ***
I1031 11:06:38.864065 131134 caffe.cpp:469] Testing for 1 iterations.
I1031 11:06:39.027421 131134 caffe.cpp:482] Profiling Layer: data forward
I1031 11:06:40.958267 131134 caffe.cpp:512] Iteration: 1 forward-backward time: 1932 ms.
I1031 11:06:41.057417 131134 caffe.cpp:519] Average time per layer: 
I1031 11:06:41.076431 131134 caffe.cpp:522]       data	forward: 58.381 ms.
I1031 11:06:41.147934 131134 caffe.cpp:526]       data	backward: 6.934 ms.
I1031 11:06:41.175328 131134 caffe.cpp:522]      conv1	forward: 74.966 ms.
I1031 11:06:41.191068 131134 caffe.cpp:526]      conv1	backward: 40.798 ms.
I1031 11:06:41.200048 131134 caffe.cpp:522]      relu1	forward: 2.35 ms.
I1031 11:06:41.209008 131134 caffe.cpp:526]      relu1	backward: 62.497 ms.
I1031 11:06:41.218042 131134 caffe.cpp:522]   dropout1	forward: 35.966 ms.
I1031 11:06:41.224841 131134 caffe.cpp:526]   dropout1	backward: 61.24 ms.
I1031 11:06:41.233774 131134 caffe.cpp:522]      pool1	forward: 125.651 ms.
I1031 11:06:41.240564 131134 caffe.cpp:526]      pool1	backward: 135.787 ms.
I1031 11:06:41.247447 131134 caffe.cpp:522]      conv2	forward: 27.28 ms.
I1031 11:06:41.256376 131134 caffe.cpp:526]      conv2	backward: 66.229 ms.
I1031 11:06:41.258998 131134 caffe.cpp:522]      relu2	forward: 0.135 ms.
I1031 11:06:41.265871 131134 caffe.cpp:526]      relu2	backward: 38.928 ms.
I1031 11:06:41.269959 131134 caffe.cpp:522]   dropout2	forward: 8.212 ms.
I1031 11:06:41.277429 131134 caffe.cpp:526]   dropout2	backward: 45.217 ms.
I1031 11:06:41.281723 131134 caffe.cpp:522]      pool2	forward: 29.803 ms.
I1031 11:06:41.290511 131134 caffe.cpp:526]      pool2	backward: 74.971 ms.
I1031 11:06:41.299049 131134 caffe.cpp:522]      conv3	forward: 33.224 ms.
I1031 11:06:41.301622 131134 caffe.cpp:526]      conv3	backward: 69.641 ms.
I1031 11:06:41.309830 131134 caffe.cpp:522]      relu3	forward: 16.636 ms.
I1031 11:06:41.317006 131134 caffe.cpp:526]      relu3	backward: 34.163 ms.
I1031 11:06:41.325630 131134 caffe.cpp:522]   dropout3	forward: 60.038 ms.
I1031 11:06:41.328322 131134 caffe.cpp:526]   dropout3	backward: 30.426 ms.
I1031 11:06:41.336990 131134 caffe.cpp:522]      pool3	forward: 22.079 ms.
I1031 11:06:41.341521 131134 caffe.cpp:526]      pool3	backward: 46.579 ms.
I1031 11:06:41.349933 131134 caffe.cpp:522]      conv4	forward: 32.131 ms.
I1031 11:06:41.350916 131134 caffe.cpp:526]      conv4	backward: 71.549 ms.
I1031 11:06:41.351142 131134 caffe.cpp:522]      relu4	forward: 19.481 ms.
I1031 11:06:41.351352 131134 caffe.cpp:526]      relu4	backward: 53.932 ms.
I1031 11:06:41.351560 131134 caffe.cpp:522]   dropout4	forward: 60.276 ms.
I1031 11:06:41.351781 131134 caffe.cpp:526]   dropout4	backward: 48.531 ms.
I1031 11:06:41.351989 131134 caffe.cpp:522]      pool4	forward: 29.75 ms.
I1031 11:06:41.352193 131134 caffe.cpp:526]      pool4	backward: 32.117 ms.
I1031 11:06:41.352401 131134 caffe.cpp:522]        fc1	forward: 23.764 ms.
I1031 11:06:41.352612 131134 caffe.cpp:526]        fc1	backward: 46.051 ms.
I1031 11:06:41.352859 131134 caffe.cpp:522]   dropout5	forward: 22.176 ms.
I1031 11:06:41.353080 131134 caffe.cpp:526]   dropout5	backward: 20.164 ms.
I1031 11:06:41.353493 131134 caffe.cpp:522]        fc2	forward: 0.117 ms.
I1031 11:06:41.354590 131134 caffe.cpp:526]        fc2	backward: 0.251 ms.
I1031 11:06:41.354842 131134 caffe.cpp:522]       loss	forward: 117.191 ms.
I1031 11:06:41.355067 131134 caffe.cpp:526]       loss	backward: 37.299 ms.
I1031 11:06:41.361266 131134 caffe.cpp:532] Average Forward pass: 863.662 ms.
I1031 11:06:41.375526 131134 caffe.cpp:535] Average Backward pass: 1033.31 ms.
I1031 11:06:41.387619 131134 caffe.cpp:537] Average Forward-Backward: 2445 ms.
I1031 11:06:41.404126 131134 caffe.cpp:540] Total Time: 2445 ms.
I1031 11:06:41.419302 131134 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 288155
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 3783
elements_fp_double_1 = 1741
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 348683
--->Total double-precision FLOPs = 1741
--->Total FLOPs = 350424
mem-read-1 = 53652
mem-read-2 = 1293
mem-read-4 = 346750
mem-read-8 = 367232
mem-read-16 = 1381
mem-read-32 = 5468
mem-read-64 = 20630
mem-write-1 = 46737
mem-write-2 = 1
mem-write-4 = 139836
mem-write-8 = 148681
mem-write-16 = 0
mem-write-32 = 0
mem-write-64 = 3080
--->Total Bytes read = 5898486
--->Total Bytes written = 1992651
--->Total Bytes = 7891137

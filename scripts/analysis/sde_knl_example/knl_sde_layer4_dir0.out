sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer4_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=4 -prof_forward_direction=0
I1031 14:02:42.542104 99483 caffe.cpp:444] Use CPU.
I1031 14:03:00.381593 99483 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:03:00.446735 99483 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:03:00.459826 99483 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:03:00.471673 99483 cpu_info.cpp:461] Total number of processors: 256
I1031 14:03:00.488701 99483 cpu_info.cpp:464] GPU is used: no
I1031 14:03:00.498107 99483 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:03:00.507319 99483 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:03:00.519748 99483 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:03:09.650789 99483 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:03:10.337402 99483 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:03:12.747779 99483 layer_factory.hpp:114] Creating layer data
I1031 14:03:12.904923 99483 net.cpp:160] Creating Layer data
I1031 14:03:12.955997 99483 net.cpp:570] data -> data
I1031 14:03:13.451599 99483 net.cpp:570] data -> label
I1031 14:03:20.976938 99483 net.cpp:210] Setting up data
I1031 14:03:21.061818 99483 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:03:21.168321 99483 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:03:21.175703 99483 net.cpp:225] Memory required for data: 184516
I1031 14:03:21.254338 99483 layer_factory.hpp:114] Creating layer conv1
I1031 14:03:21.601771 99483 net.cpp:160] Creating Layer conv1
I1031 14:03:21.655057 99483 net.cpp:596] conv1 <- data
I1031 14:03:21.781965 99483 net.cpp:570] conv1 -> conv1
I1031 14:03:59.149814 99483 net.cpp:210] Setting up conv1
I1031 14:03:59.224055 99483 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:03:59.232393 99483 net.cpp:225] Memory required for data: 7805124
I1031 14:03:59.548830 99483 layer_factory.hpp:114] Creating layer relu1
I1031 14:03:59.694912 99483 net.cpp:160] Creating Layer relu1
I1031 14:03:59.700521 99483 net.cpp:596] relu1 <- conv1
I1031 14:03:59.737141 99483 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:03:59.953574 99483 net.cpp:210] Setting up relu1
I1031 14:03:59.956308 99483 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:03:59.956676 99483 net.cpp:225] Memory required for data: 15425732
I1031 14:03:59.956890 99483 layer_factory.hpp:114] Creating layer dropout1
I1031 14:03:59.990617 99483 net.cpp:160] Creating Layer dropout1
I1031 14:03:59.990957 99483 net.cpp:596] dropout1 <- conv1
I1031 14:03:59.993736 99483 net.cpp:570] dropout1 -> drop1
I1031 14:04:00.105172 99483 net.cpp:210] Setting up dropout1
I1031 14:04:00.118748 99483 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:04:00.119153 99483 net.cpp:225] Memory required for data: 23046340
I1031 14:04:00.119544 99483 layer_factory.hpp:114] Creating layer pool1
I1031 14:04:00.220458 99483 net.cpp:160] Creating Layer pool1
I1031 14:04:00.221158 99483 net.cpp:596] pool1 <- drop1
I1031 14:04:00.221551 99483 net.cpp:570] pool1 -> pool1
I1031 14:04:00.645737 99483 net.cpp:210] Setting up pool1
I1031 14:04:00.655514 99483 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:04:00.655957 99483 net.cpp:225] Memory required for data: 24951492
I1031 14:04:00.656294 99483 layer_factory.hpp:114] Creating layer conv2
I1031 14:04:00.722385 99483 net.cpp:160] Creating Layer conv2
I1031 14:04:00.726994 99483 net.cpp:596] conv2 <- pool1
I1031 14:04:00.742988 99483 net.cpp:570] conv2 -> conv2
I1031 14:04:07.627956 99483 net.cpp:210] Setting up conv2
I1031 14:04:07.638744 99483 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:04:07.648448 99483 net.cpp:225] Memory required for data: 26733764
I1031 14:04:07.718749 99483 layer_factory.hpp:114] Creating layer relu2
I1031 14:04:07.732019 99483 net.cpp:160] Creating Layer relu2
I1031 14:04:07.740327 99483 net.cpp:596] relu2 <- conv2
I1031 14:04:07.747031 99483 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:04:07.754088 99483 net.cpp:210] Setting up relu2
I1031 14:04:07.758034 99483 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:04:07.766815 99483 net.cpp:225] Memory required for data: 28516036
I1031 14:04:07.779505 99483 layer_factory.hpp:114] Creating layer dropout2
I1031 14:04:07.784194 99483 net.cpp:160] Creating Layer dropout2
I1031 14:04:07.790551 99483 net.cpp:596] dropout2 <- conv2
I1031 14:04:07.797096 99483 net.cpp:570] dropout2 -> drop2
I1031 14:04:07.804446 99483 net.cpp:210] Setting up dropout2
I1031 14:04:07.812889 99483 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:04:07.819305 99483 net.cpp:225] Memory required for data: 30298308
I1031 14:04:07.823833 99483 layer_factory.hpp:114] Creating layer pool2
I1031 14:04:07.825772 99483 net.cpp:160] Creating Layer pool2
I1031 14:04:07.835058 99483 net.cpp:596] pool2 <- drop2
I1031 14:04:07.841070 99483 net.cpp:570] pool2 -> pool2
I1031 14:04:07.849930 99483 net.cpp:210] Setting up pool2
I1031 14:04:07.856334 99483 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:04:07.866538 99483 net.cpp:225] Memory required for data: 30759108
I1031 14:04:07.872748 99483 layer_factory.hpp:114] Creating layer conv3
I1031 14:04:07.877835 99483 net.cpp:160] Creating Layer conv3
I1031 14:04:07.885407 99483 net.cpp:596] conv3 <- pool2
I1031 14:04:07.894511 99483 net.cpp:570] conv3 -> conv3
I1031 14:04:08.482607 99483 net.cpp:210] Setting up conv3
I1031 14:04:08.489374 99483 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:04:08.493605 99483 net.cpp:225] Memory required for data: 31160516
I1031 14:04:08.510344 99483 layer_factory.hpp:114] Creating layer relu3
I1031 14:04:08.517025 99483 net.cpp:160] Creating Layer relu3
I1031 14:04:08.530993 99483 net.cpp:596] relu3 <- conv3
I1031 14:04:08.539008 99483 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:04:08.547621 99483 net.cpp:210] Setting up relu3
I1031 14:04:08.557495 99483 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:04:08.570097 99483 net.cpp:225] Memory required for data: 31561924
I1031 14:04:08.576190 99483 layer_factory.hpp:114] Creating layer dropout3
I1031 14:04:08.580739 99483 net.cpp:160] Creating Layer dropout3
I1031 14:04:08.589212 99483 net.cpp:596] dropout3 <- conv3
I1031 14:04:08.599642 99483 net.cpp:570] dropout3 -> drop3
I1031 14:04:08.610031 99483 net.cpp:210] Setting up dropout3
I1031 14:04:08.616348 99483 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:04:08.624866 99483 net.cpp:225] Memory required for data: 31963332
I1031 14:04:08.631317 99483 layer_factory.hpp:114] Creating layer pool3
I1031 14:04:08.635617 99483 net.cpp:160] Creating Layer pool3
I1031 14:04:08.642293 99483 net.cpp:596] pool3 <- drop3
I1031 14:04:08.646528 99483 net.cpp:570] pool3 -> pool3
I1031 14:04:08.647124 99483 net.cpp:210] Setting up pool3
I1031 14:04:08.652257 99483 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:04:08.658596 99483 net.cpp:225] Memory required for data: 32063684
I1031 14:04:08.667122 99483 layer_factory.hpp:114] Creating layer conv4
I1031 14:04:08.675479 99483 net.cpp:160] Creating Layer conv4
I1031 14:04:08.680140 99483 net.cpp:596] conv4 <- pool3
I1031 14:04:08.692708 99483 net.cpp:570] conv4 -> conv4
I1031 14:04:09.048198 99483 net.cpp:210] Setting up conv4
I1031 14:04:09.056659 99483 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:04:09.065299 99483 net.cpp:225] Memory required for data: 32137412
I1031 14:04:09.073812 99483 layer_factory.hpp:114] Creating layer relu4
I1031 14:04:09.080078 99483 net.cpp:160] Creating Layer relu4
I1031 14:04:09.086287 99483 net.cpp:596] relu4 <- conv4
I1031 14:04:09.092823 99483 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:04:09.099226 99483 net.cpp:210] Setting up relu4
I1031 14:04:09.103703 99483 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:04:09.104115 99483 net.cpp:225] Memory required for data: 32211140
I1031 14:04:09.108376 99483 layer_factory.hpp:114] Creating layer dropout4
I1031 14:04:09.112565 99483 net.cpp:160] Creating Layer dropout4
I1031 14:04:09.114856 99483 net.cpp:596] dropout4 <- conv4
I1031 14:04:09.123137 99483 net.cpp:570] dropout4 -> drop4
I1031 14:04:09.127434 99483 net.cpp:210] Setting up dropout4
I1031 14:04:09.129324 99483 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:04:09.137913 99483 net.cpp:225] Memory required for data: 32284868
I1031 14:04:09.142889 99483 layer_factory.hpp:114] Creating layer pool4
I1031 14:04:09.147860 99483 net.cpp:160] Creating Layer pool4
I1031 14:04:09.151540 99483 net.cpp:596] pool4 <- drop4
I1031 14:04:09.156549 99483 net.cpp:570] pool4 -> pool4
I1031 14:04:09.173307 99483 net.cpp:210] Setting up pool4
I1031 14:04:09.175732 99483 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:04:09.178097 99483 net.cpp:225] Memory required for data: 32303300
I1031 14:04:09.182646 99483 layer_factory.hpp:114] Creating layer fc1
I1031 14:04:09.245019 99483 net.cpp:160] Creating Layer fc1
I1031 14:04:09.251684 99483 net.cpp:596] fc1 <- pool4
I1031 14:04:09.256191 99483 net.cpp:570] fc1 -> fc1
I1031 14:04:10.136044 99483 net.cpp:210] Setting up fc1
I1031 14:04:10.144556 99483 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:04:10.151218 99483 net.cpp:225] Memory required for data: 32307396
I1031 14:04:10.163902 99483 layer_factory.hpp:114] Creating layer dropout5
I1031 14:04:10.174377 99483 net.cpp:160] Creating Layer dropout5
I1031 14:04:10.176650 99483 net.cpp:596] dropout5 <- fc1
I1031 14:04:10.178874 99483 net.cpp:570] dropout5 -> drop5
I1031 14:04:10.185629 99483 net.cpp:210] Setting up dropout5
I1031 14:04:10.189864 99483 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:04:10.202332 99483 net.cpp:225] Memory required for data: 32311492
I1031 14:04:10.205425 99483 layer_factory.hpp:114] Creating layer fc2
I1031 14:04:10.211992 99483 net.cpp:160] Creating Layer fc2
I1031 14:04:10.222559 99483 net.cpp:596] fc2 <- drop5
I1031 14:04:10.228647 99483 net.cpp:570] fc2 -> fc2
I1031 14:04:10.257321 99483 net.cpp:210] Setting up fc2
I1031 14:04:10.271078 99483 net.cpp:217] Top shape: 1 2 (2)
I1031 14:04:10.277721 99483 net.cpp:225] Memory required for data: 32311500
I1031 14:04:10.284590 99483 layer_factory.hpp:114] Creating layer loss
I1031 14:04:10.317108 99483 net.cpp:160] Creating Layer loss
I1031 14:04:10.336498 99483 net.cpp:596] loss <- fc2
I1031 14:04:10.353627 99483 net.cpp:596] loss <- label
I1031 14:04:10.415632 99483 net.cpp:570] loss -> (automatic)
I1031 14:04:10.467499 99483 layer_factory.hpp:114] Creating layer loss
I1031 14:04:10.918143 99483 net.cpp:210] Setting up loss
I1031 14:04:10.929349 99483 net.cpp:217] Top shape: (1)
I1031 14:04:10.945811 99483 net.cpp:220]     with loss weight 1
I1031 14:04:11.099851 99483 net.cpp:225] Memory required for data: 32311504
I1031 14:04:11.148171 99483 net.cpp:287] loss needs backward computation.
I1031 14:04:11.258508 99483 net.cpp:287] fc2 needs backward computation.
I1031 14:04:11.268743 99483 net.cpp:287] dropout5 needs backward computation.
I1031 14:04:11.272078 99483 net.cpp:287] fc1 needs backward computation.
I1031 14:04:11.272868 99483 net.cpp:287] pool4 needs backward computation.
I1031 14:04:11.273169 99483 net.cpp:287] dropout4 needs backward computation.
I1031 14:04:11.273386 99483 net.cpp:287] relu4 needs backward computation.
I1031 14:04:11.283341 99483 net.cpp:287] conv4 needs backward computation.
I1031 14:04:11.300369 99483 net.cpp:287] pool3 needs backward computation.
I1031 14:04:11.314105 99483 net.cpp:287] dropout3 needs backward computation.
I1031 14:04:11.318912 99483 net.cpp:287] relu3 needs backward computation.
I1031 14:04:11.319245 99483 net.cpp:287] conv3 needs backward computation.
I1031 14:04:11.319635 99483 net.cpp:287] pool2 needs backward computation.
I1031 14:04:11.319896 99483 net.cpp:287] dropout2 needs backward computation.
I1031 14:04:11.320119 99483 net.cpp:287] relu2 needs backward computation.
I1031 14:04:11.320328 99483 net.cpp:287] conv2 needs backward computation.
I1031 14:04:11.320540 99483 net.cpp:287] pool1 needs backward computation.
I1031 14:04:11.320751 99483 net.cpp:287] dropout1 needs backward computation.
I1031 14:04:11.320960 99483 net.cpp:287] relu1 needs backward computation.
I1031 14:04:11.321162 99483 net.cpp:287] conv1 needs backward computation.
I1031 14:04:11.341395 99483 net.cpp:289] data does not need backward computation.
I1031 14:04:11.400616 99483 net.cpp:345] Network initialization done.
I1031 14:04:11.581532 99483 caffe.cpp:452] Performing Forward
I1031 14:04:23.216511 99483 caffe.cpp:457] Initial loss: 21.6342
I1031 14:04:23.348335 99483 caffe.cpp:459] Performing Backward
I1031 14:04:26.828789 99483 caffe.cpp:468] *** Benchmark begins ***
I1031 14:04:26.852704 99483 caffe.cpp:469] Testing for 1 iterations.
I1031 14:04:27.010061 99483 caffe.cpp:485] Profiling Layer: pool1 backward
I1031 14:04:29.323663 99483 caffe.cpp:512] Iteration: 1 forward-backward time: 2308 ms.
I1031 14:04:29.419993 99483 caffe.cpp:519] Average time per layer: 
I1031 14:04:29.430860 99483 caffe.cpp:522]       data	forward: 49.589 ms.
I1031 14:04:29.505367 99483 caffe.cpp:526]       data	backward: 3.997 ms.
I1031 14:04:29.531198 99483 caffe.cpp:522]      conv1	forward: 16.945 ms.
I1031 14:04:29.538385 99483 caffe.cpp:526]      conv1	backward: 1.683 ms.
I1031 14:04:29.546574 99483 caffe.cpp:522]      relu1	forward: 2.363 ms.
I1031 14:04:29.551220 99483 caffe.cpp:526]      relu1	backward: 80.835 ms.
I1031 14:04:29.560865 99483 caffe.cpp:522]   dropout1	forward: 35.926 ms.
I1031 14:04:29.571557 99483 caffe.cpp:526]   dropout1	backward: 63.359 ms.
I1031 14:04:29.577544 99483 caffe.cpp:522]      pool1	forward: 123.772 ms.
I1031 14:04:29.595187 99483 caffe.cpp:526]      pool1	backward: 152.292 ms.
I1031 14:04:29.604106 99483 caffe.cpp:522]      conv2	forward: 62.046 ms.
I1031 14:04:29.622716 99483 caffe.cpp:526]      conv2	backward: 73.882 ms.
I1031 14:04:29.627614 99483 caffe.cpp:522]      relu2	forward: 50.641 ms.
I1031 14:04:29.634354 99483 caffe.cpp:526]      relu2	backward: 38.271 ms.
I1031 14:04:29.638541 99483 caffe.cpp:522]   dropout2	forward: 58.785 ms.
I1031 14:04:29.643221 99483 caffe.cpp:526]   dropout2	backward: 44.197 ms.
I1031 14:04:29.647884 99483 caffe.cpp:522]      pool2	forward: 29.464 ms.
I1031 14:04:29.654206 99483 caffe.cpp:526]      pool2	backward: 72.522 ms.
I1031 14:04:29.658833 99483 caffe.cpp:522]      conv3	forward: 57.354 ms.
I1031 14:04:29.663691 99483 caffe.cpp:526]      conv3	backward: 78.612 ms.
I1031 14:04:29.668555 99483 caffe.cpp:522]      relu3	forward: 15.01 ms.
I1031 14:04:29.676976 99483 caffe.cpp:526]      relu3	backward: 66.163 ms.
I1031 14:04:29.685636 99483 caffe.cpp:522]   dropout3	forward: 44.727 ms.
I1031 14:04:29.691897 99483 caffe.cpp:526]   dropout3	backward: 64.721 ms.
I1031 14:04:29.696461 99483 caffe.cpp:522]      pool3	forward: 15.294 ms.
I1031 14:04:29.700614 99483 caffe.cpp:526]      pool3	backward: 56.509 ms.
I1031 14:04:29.712851 99483 caffe.cpp:522]      conv4	forward: 66.366 ms.
I1031 14:04:29.715438 99483 caffe.cpp:526]      conv4	backward: 100.584 ms.
I1031 14:04:29.718148 99483 caffe.cpp:522]      relu4	forward: 26.675 ms.
I1031 14:04:29.718411 99483 caffe.cpp:526]      relu4	backward: 61.912 ms.
I1031 14:04:29.718621 99483 caffe.cpp:522]   dropout4	forward: 57.337 ms.
I1031 14:04:29.718827 99483 caffe.cpp:526]   dropout4	backward: 69.136 ms.
I1031 14:04:29.719033 99483 caffe.cpp:522]      pool4	forward: 18.931 ms.
I1031 14:04:29.719280 99483 caffe.cpp:526]      pool4	backward: 37.504 ms.
I1031 14:04:29.719565 99483 caffe.cpp:522]        fc1	forward: 37.003 ms.
I1031 14:04:29.719888 99483 caffe.cpp:526]        fc1	backward: 53.843 ms.
I1031 14:04:29.720134 99483 caffe.cpp:522]   dropout5	forward: 51.991 ms.
I1031 14:04:29.720356 99483 caffe.cpp:526]   dropout5	backward: 18.022 ms.
I1031 14:04:29.720577 99483 caffe.cpp:522]        fc2	forward: 16.991 ms.
I1031 14:04:29.720800 99483 caffe.cpp:526]        fc2	backward: 0.21 ms.
I1031 14:04:29.721020 99483 caffe.cpp:522]       loss	forward: 185.965 ms.
I1031 14:04:29.721245 99483 caffe.cpp:526]       loss	backward: 48.239 ms.
I1031 14:04:29.727088 99483 caffe.cpp:532] Average Forward pass: 1086.55 ms.
I1031 14:04:29.740655 99483 caffe.cpp:535] Average Backward pass: 1196.06 ms.
I1031 14:04:29.752138 99483 caffe.cpp:537] Average Forward-Backward: 2827 ms.
I1031 14:04:29.767606 99483 caffe.cpp:540] Total Time: 2827 ms.
I1031 14:04:29.780439 99483 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 476288
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 0
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 476288
--->Total double-precision FLOPs = 0
--->Total FLOPs = 476288
mem-read-1 = 155881
mem-read-2 = 105
mem-read-4 = 2265476
mem-read-8 = 5370559
mem-read-16 = 0
mem-read-32 = 3
mem-read-64 = 47492
mem-write-1 = 284
mem-write-2 = 51
mem-write-4 = 2391140
mem-write-8 = 266323
mem-write-16 = 0
mem-write-32 = 2
mem-write-64 = 150306
--->Total Bytes read = 55222051
--->Total Bytes written = 21315178
--->Total Bytes = 76537229

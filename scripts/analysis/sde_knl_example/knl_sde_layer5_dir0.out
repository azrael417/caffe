sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer5_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=5 -prof_forward_direction=0
I1031 14:08:39.032168 99682 caffe.cpp:444] Use CPU.
I1031 14:08:57.008723 99682 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:08:57.075003 99682 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:08:57.088232 99682 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:08:57.100165 99682 cpu_info.cpp:461] Total number of processors: 256
I1031 14:08:57.117583 99682 cpu_info.cpp:464] GPU is used: no
I1031 14:08:57.127068 99682 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:08:57.136209 99682 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:08:57.148798 99682 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:09:06.317469 99682 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:09:07.004331 99682 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:09:09.417047 99682 layer_factory.hpp:114] Creating layer data
I1031 14:09:09.574945 99682 net.cpp:160] Creating Layer data
I1031 14:09:09.625589 99682 net.cpp:570] data -> data
I1031 14:09:10.117372 99682 net.cpp:570] data -> label
I1031 14:09:17.571758 99682 net.cpp:210] Setting up data
I1031 14:09:17.657737 99682 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:09:17.765398 99682 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:09:17.772759 99682 net.cpp:225] Memory required for data: 184516
I1031 14:09:17.851109 99682 layer_factory.hpp:114] Creating layer conv1
I1031 14:09:18.200093 99682 net.cpp:160] Creating Layer conv1
I1031 14:09:18.253208 99682 net.cpp:596] conv1 <- data
I1031 14:09:18.379020 99682 net.cpp:570] conv1 -> conv1
I1031 14:09:55.621778 99682 net.cpp:210] Setting up conv1
I1031 14:09:55.703513 99682 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:09:55.708806 99682 net.cpp:225] Memory required for data: 7805124
I1031 14:09:56.027565 99682 layer_factory.hpp:114] Creating layer relu1
I1031 14:09:56.168601 99682 net.cpp:160] Creating Layer relu1
I1031 14:09:56.173804 99682 net.cpp:596] relu1 <- conv1
I1031 14:09:56.208842 99682 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:09:56.425036 99682 net.cpp:210] Setting up relu1
I1031 14:09:56.427712 99682 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:09:56.428089 99682 net.cpp:225] Memory required for data: 15425732
I1031 14:09:56.428313 99682 layer_factory.hpp:114] Creating layer dropout1
I1031 14:09:56.460949 99682 net.cpp:160] Creating Layer dropout1
I1031 14:09:56.461284 99682 net.cpp:596] dropout1 <- conv1
I1031 14:09:56.464138 99682 net.cpp:570] dropout1 -> drop1
I1031 14:09:56.582682 99682 net.cpp:210] Setting up dropout1
I1031 14:09:56.596828 99682 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:09:56.597249 99682 net.cpp:225] Memory required for data: 23046340
I1031 14:09:56.597579 99682 layer_factory.hpp:114] Creating layer pool1
I1031 14:09:56.701184 99682 net.cpp:160] Creating Layer pool1
I1031 14:09:56.701521 99682 net.cpp:596] pool1 <- drop1
I1031 14:09:56.701917 99682 net.cpp:570] pool1 -> pool1
I1031 14:09:57.128414 99682 net.cpp:210] Setting up pool1
I1031 14:09:57.137377 99682 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:09:57.137778 99682 net.cpp:225] Memory required for data: 24951492
I1031 14:09:57.138113 99682 layer_factory.hpp:114] Creating layer conv2
I1031 14:09:57.201066 99682 net.cpp:160] Creating Layer conv2
I1031 14:09:57.205505 99682 net.cpp:596] conv2 <- pool1
I1031 14:09:57.221233 99682 net.cpp:570] conv2 -> conv2
I1031 14:10:04.065392 99682 net.cpp:210] Setting up conv2
I1031 14:10:04.068476 99682 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:10:04.083714 99682 net.cpp:225] Memory required for data: 26733764
I1031 14:10:04.145915 99682 layer_factory.hpp:114] Creating layer relu2
I1031 14:10:04.163928 99682 net.cpp:160] Creating Layer relu2
I1031 14:10:04.169677 99682 net.cpp:596] relu2 <- conv2
I1031 14:10:04.176168 99682 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:10:04.188758 99682 net.cpp:210] Setting up relu2
I1031 14:10:04.190711 99682 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:10:04.202296 99682 net.cpp:225] Memory required for data: 28516036
I1031 14:10:04.204897 99682 layer_factory.hpp:114] Creating layer dropout2
I1031 14:10:04.209883 99682 net.cpp:160] Creating Layer dropout2
I1031 14:10:04.212312 99682 net.cpp:596] dropout2 <- conv2
I1031 14:10:04.214644 99682 net.cpp:570] dropout2 -> drop2
I1031 14:10:04.220909 99682 net.cpp:210] Setting up dropout2
I1031 14:10:04.221223 99682 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:10:04.227073 99682 net.cpp:225] Memory required for data: 30298308
I1031 14:10:04.239138 99682 layer_factory.hpp:114] Creating layer pool2
I1031 14:10:04.245582 99682 net.cpp:160] Creating Layer pool2
I1031 14:10:04.252446 99682 net.cpp:596] pool2 <- drop2
I1031 14:10:04.254266 99682 net.cpp:570] pool2 -> pool2
I1031 14:10:04.254822 99682 net.cpp:210] Setting up pool2
I1031 14:10:04.263723 99682 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:10:04.264152 99682 net.cpp:225] Memory required for data: 30759108
I1031 14:10:04.270227 99682 layer_factory.hpp:114] Creating layer conv3
I1031 14:10:04.277196 99682 net.cpp:160] Creating Layer conv3
I1031 14:10:04.285856 99682 net.cpp:596] conv3 <- pool2
I1031 14:10:04.288173 99682 net.cpp:570] conv3 -> conv3
I1031 14:10:04.904513 99682 net.cpp:210] Setting up conv3
I1031 14:10:04.913074 99682 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:10:04.919453 99682 net.cpp:225] Memory required for data: 31160516
I1031 14:10:04.938865 99682 layer_factory.hpp:114] Creating layer relu3
I1031 14:10:04.947154 99682 net.cpp:160] Creating Layer relu3
I1031 14:10:04.949558 99682 net.cpp:596] relu3 <- conv3
I1031 14:10:04.956003 99682 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:10:04.964359 99682 net.cpp:210] Setting up relu3
I1031 14:10:04.974853 99682 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:10:04.977288 99682 net.cpp:225] Memory required for data: 31561924
I1031 14:10:04.981660 99682 layer_factory.hpp:114] Creating layer dropout3
I1031 14:10:04.983347 99682 net.cpp:160] Creating Layer dropout3
I1031 14:10:04.991220 99682 net.cpp:596] dropout3 <- conv3
I1031 14:10:04.997824 99682 net.cpp:570] dropout3 -> drop3
I1031 14:10:04.998280 99682 net.cpp:210] Setting up dropout3
I1031 14:10:05.006395 99682 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:10:05.008920 99682 net.cpp:225] Memory required for data: 31963332
I1031 14:10:05.019445 99682 layer_factory.hpp:114] Creating layer pool3
I1031 14:10:05.029953 99682 net.cpp:160] Creating Layer pool3
I1031 14:10:05.034054 99682 net.cpp:596] pool3 <- drop3
I1031 14:10:05.042762 99682 net.cpp:570] pool3 -> pool3
I1031 14:10:05.047418 99682 net.cpp:210] Setting up pool3
I1031 14:10:05.049172 99682 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:10:05.053938 99682 net.cpp:225] Memory required for data: 32063684
I1031 14:10:05.058722 99682 layer_factory.hpp:114] Creating layer conv4
I1031 14:10:05.063597 99682 net.cpp:160] Creating Layer conv4
I1031 14:10:05.071694 99682 net.cpp:596] conv4 <- pool3
I1031 14:10:05.076005 99682 net.cpp:570] conv4 -> conv4
I1031 14:10:05.450444 99682 net.cpp:210] Setting up conv4
I1031 14:10:05.459447 99682 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:10:05.464943 99682 net.cpp:225] Memory required for data: 32137412
I1031 14:10:05.471817 99682 layer_factory.hpp:114] Creating layer relu4
I1031 14:10:05.477865 99682 net.cpp:160] Creating Layer relu4
I1031 14:10:05.490536 99682 net.cpp:596] relu4 <- conv4
I1031 14:10:05.494957 99682 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:10:05.498952 99682 net.cpp:210] Setting up relu4
I1031 14:10:05.510244 99682 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:10:05.517274 99682 net.cpp:225] Memory required for data: 32211140
I1031 14:10:05.517576 99682 layer_factory.hpp:114] Creating layer dropout4
I1031 14:10:05.517855 99682 net.cpp:160] Creating Layer dropout4
I1031 14:10:05.518074 99682 net.cpp:596] dropout4 <- conv4
I1031 14:10:05.518345 99682 net.cpp:570] dropout4 -> drop4
I1031 14:10:05.518656 99682 net.cpp:210] Setting up dropout4
I1031 14:10:05.518869 99682 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:10:05.519117 99682 net.cpp:225] Memory required for data: 32284868
I1031 14:10:05.519320 99682 layer_factory.hpp:114] Creating layer pool4
I1031 14:10:05.519667 99682 net.cpp:160] Creating Layer pool4
I1031 14:10:05.519881 99682 net.cpp:596] pool4 <- drop4
I1031 14:10:05.520119 99682 net.cpp:570] pool4 -> pool4
I1031 14:10:05.533818 99682 net.cpp:210] Setting up pool4
I1031 14:10:05.534178 99682 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:10:05.536696 99682 net.cpp:225] Memory required for data: 32303300
I1031 14:10:05.536958 99682 layer_factory.hpp:114] Creating layer fc1
I1031 14:10:05.600778 99682 net.cpp:160] Creating Layer fc1
I1031 14:10:05.601115 99682 net.cpp:596] fc1 <- pool4
I1031 14:10:05.601534 99682 net.cpp:570] fc1 -> fc1
I1031 14:10:06.481273 99682 net.cpp:210] Setting up fc1
I1031 14:10:06.489807 99682 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:10:06.498723 99682 net.cpp:225] Memory required for data: 32307396
I1031 14:10:06.517801 99682 layer_factory.hpp:114] Creating layer dropout5
I1031 14:10:06.521793 99682 net.cpp:160] Creating Layer dropout5
I1031 14:10:06.530097 99682 net.cpp:596] dropout5 <- fc1
I1031 14:10:06.538539 99682 net.cpp:570] dropout5 -> drop5
I1031 14:10:06.544155 99682 net.cpp:210] Setting up dropout5
I1031 14:10:06.549230 99682 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:10:06.563081 99682 net.cpp:225] Memory required for data: 32311492
I1031 14:10:06.571887 99682 layer_factory.hpp:114] Creating layer fc2
I1031 14:10:06.576117 99682 net.cpp:160] Creating Layer fc2
I1031 14:10:06.580476 99682 net.cpp:596] fc2 <- drop5
I1031 14:10:06.590948 99682 net.cpp:570] fc2 -> fc2
I1031 14:10:06.629247 99682 net.cpp:210] Setting up fc2
I1031 14:10:06.642144 99682 net.cpp:217] Top shape: 1 2 (2)
I1031 14:10:06.653498 99682 net.cpp:225] Memory required for data: 32311500
I1031 14:10:06.657851 99682 layer_factory.hpp:114] Creating layer loss
I1031 14:10:06.690336 99682 net.cpp:160] Creating Layer loss
I1031 14:10:06.694774 99682 net.cpp:596] loss <- fc2
I1031 14:10:06.699573 99682 net.cpp:596] loss <- label
I1031 14:10:06.766064 99682 net.cpp:570] loss -> (automatic)
I1031 14:10:06.834967 99682 layer_factory.hpp:114] Creating layer loss
I1031 14:10:07.246446 99682 net.cpp:210] Setting up loss
I1031 14:10:07.253605 99682 net.cpp:217] Top shape: (1)
I1031 14:10:07.268893 99682 net.cpp:220]     with loss weight 1
I1031 14:10:07.412266 99682 net.cpp:225] Memory required for data: 32311504
I1031 14:10:07.468972 99682 net.cpp:287] loss needs backward computation.
I1031 14:10:07.576136 99682 net.cpp:287] fc2 needs backward computation.
I1031 14:10:07.591652 99682 net.cpp:287] dropout5 needs backward computation.
I1031 14:10:07.604298 99682 net.cpp:287] fc1 needs backward computation.
I1031 14:10:07.612722 99682 net.cpp:287] pool4 needs backward computation.
I1031 14:10:07.613035 99682 net.cpp:287] dropout4 needs backward computation.
I1031 14:10:07.613234 99682 net.cpp:287] relu4 needs backward computation.
I1031 14:10:07.622905 99682 net.cpp:287] conv4 needs backward computation.
I1031 14:10:07.639874 99682 net.cpp:287] pool3 needs backward computation.
I1031 14:10:07.653455 99682 net.cpp:287] dropout3 needs backward computation.
I1031 14:10:07.658232 99682 net.cpp:287] relu3 needs backward computation.
I1031 14:10:07.658568 99682 net.cpp:287] conv3 needs backward computation.
I1031 14:10:07.658912 99682 net.cpp:287] pool2 needs backward computation.
I1031 14:10:07.659193 99682 net.cpp:287] dropout2 needs backward computation.
I1031 14:10:07.659440 99682 net.cpp:287] relu2 needs backward computation.
I1031 14:10:07.659652 99682 net.cpp:287] conv2 needs backward computation.
I1031 14:10:07.659854 99682 net.cpp:287] pool1 needs backward computation.
I1031 14:10:07.660050 99682 net.cpp:287] dropout1 needs backward computation.
I1031 14:10:07.660246 99682 net.cpp:287] relu1 needs backward computation.
I1031 14:10:07.660434 99682 net.cpp:287] conv1 needs backward computation.
I1031 14:10:07.680419 99682 net.cpp:289] data does not need backward computation.
I1031 14:10:07.738128 99682 net.cpp:345] Network initialization done.
I1031 14:10:07.924571 99682 caffe.cpp:452] Performing Forward
I1031 14:10:20.933073 99682 caffe.cpp:457] Initial loss: 87.3365
I1031 14:10:21.062628 99682 caffe.cpp:459] Performing Backward
I1031 14:10:24.466070 99682 caffe.cpp:468] *** Benchmark begins ***
I1031 14:10:24.491351 99682 caffe.cpp:469] Testing for 1 iterations.
I1031 14:10:24.646617 99682 caffe.cpp:485] Profiling Layer: conv2 backward
I1031 14:10:26.288075 99682 caffe.cpp:512] Iteration: 1 forward-backward time: 1633 ms.
I1031 14:10:26.389768 99682 caffe.cpp:519] Average time per layer: 
I1031 14:10:26.407999 99682 caffe.cpp:522]       data	forward: 47.194 ms.
I1031 14:10:26.471530 99682 caffe.cpp:526]       data	backward: 5.601 ms.
I1031 14:10:26.509276 99682 caffe.cpp:522]      conv1	forward: 72.831 ms.
I1031 14:10:26.513896 99682 caffe.cpp:526]      conv1	backward: 39.173 ms.
I1031 14:10:26.514283 99682 caffe.cpp:522]      relu1	forward: 25.634 ms.
I1031 14:10:26.514550 99682 caffe.cpp:526]      relu1	backward: 57.431 ms.
I1031 14:10:26.514760 99682 caffe.cpp:522]   dropout1	forward: 82.291 ms.
I1031 14:10:26.514968 99682 caffe.cpp:526]   dropout1	backward: 58.072 ms.
I1031 14:10:26.517668 99682 caffe.cpp:522]      pool1	forward: 129.558 ms.
I1031 14:10:26.520856 99682 caffe.cpp:526]      pool1	backward: 140.699 ms.
I1031 14:10:26.521178 99682 caffe.cpp:522]      conv2	forward: 27.468 ms.
I1031 14:10:26.521535 99682 caffe.cpp:526]      conv2	backward: 89.9 ms.
I1031 14:10:26.521831 99682 caffe.cpp:522]      relu2	forward: 0.132 ms.
I1031 14:10:26.522078 99682 caffe.cpp:526]      relu2	backward: 43.677 ms.
I1031 14:10:26.522290 99682 caffe.cpp:522]   dropout2	forward: 8.192 ms.
I1031 14:10:26.523138 99682 caffe.cpp:526]   dropout2	backward: 39.486 ms.
I1031 14:10:26.523459 99682 caffe.cpp:522]      pool2	forward: 29.196 ms.
I1031 14:10:26.523690 99682 caffe.cpp:526]      pool2	backward: 49.13 ms.
I1031 14:10:26.523931 99682 caffe.cpp:522]      conv3	forward: 2.162 ms.
I1031 14:10:26.524133 99682 caffe.cpp:526]      conv3	backward: 64.339 ms.
I1031 14:10:26.524340 99682 caffe.cpp:522]      relu3	forward: 0.08 ms.
I1031 14:10:26.541213 99682 caffe.cpp:526]      relu3	backward: 35.801 ms.
I1031 14:10:26.541617 99682 caffe.cpp:522]   dropout3	forward: 2.019 ms.
I1031 14:10:26.541889 99682 caffe.cpp:526]   dropout3	backward: 44.368 ms.
I1031 14:10:26.542107 99682 caffe.cpp:522]      pool3	forward: 6.608 ms.
I1031 14:10:26.542312 99682 caffe.cpp:526]      pool3	backward: 50.149 ms.
I1031 14:10:26.542522 99682 caffe.cpp:522]      conv4	forward: 0.707 ms.
I1031 14:10:26.542731 99682 caffe.cpp:526]      conv4	backward: 77.937 ms.
I1031 14:10:26.542937 99682 caffe.cpp:522]      relu4	forward: 0.053 ms.
I1031 14:10:26.545784 99682 caffe.cpp:526]      relu4	backward: 47.907 ms.
I1031 14:10:26.546053 99682 caffe.cpp:522]   dropout4	forward: 0.506 ms.
I1031 14:10:26.546267 99682 caffe.cpp:526]   dropout4	backward: 58.876 ms.
I1031 14:10:26.546478 99682 caffe.cpp:522]      pool4	forward: 1.317 ms.
I1031 14:10:26.546681 99682 caffe.cpp:526]      pool4	backward: 35.038 ms.
I1031 14:10:26.546888 99682 caffe.cpp:522]        fc1	forward: 1.086 ms.
I1031 14:10:26.547088 99682 caffe.cpp:526]        fc1	backward: 54.738 ms.
I1031 14:10:26.547293 99682 caffe.cpp:522]   dropout5	forward: 0.185 ms.
I1031 14:10:26.547546 99682 caffe.cpp:526]   dropout5	backward: 21.943 ms.
I1031 14:10:26.547756 99682 caffe.cpp:522]        fc2	forward: 0.103 ms.
I1031 14:10:26.548600 99682 caffe.cpp:526]        fc2	backward: 0.205 ms.
I1031 14:10:26.548909 99682 caffe.cpp:522]       loss	forward: 46.978 ms.
I1031 14:10:26.549257 99682 caffe.cpp:526]       loss	backward: 33.761 ms.
I1031 14:10:26.555186 99682 caffe.cpp:532] Average Forward pass: 544.375 ms.
I1031 14:10:26.568792 99682 caffe.cpp:535] Average Backward pass: 1058.44 ms.
I1031 14:10:26.580219 99682 caffe.cpp:537] Average Forward-Backward: 2017 ms.
I1031 14:10:26.595726 99682 caffe.cpp:540] Total Time: 2017 ms.
I1031 14:10:26.608350 99682 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 128351432
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 2053622912
--->Total double-precision FLOPs = 0
--->Total FLOPs = 2053622912
mem-read-1 = 794680
mem-read-2 = 171
mem-read-4 = 71263725
mem-read-8 = 3256465
mem-read-16 = 1
mem-read-32 = 21
mem-read-64 = 37159102
mem-write-1 = 691210
mem-write-2 = 68
mem-write-4 = 3930097
mem-write-8 = 125120
mem-write-16 = 5
mem-write-32 = 5
mem-write-64 = 2379894
--->Total Bytes read = 2690084858
--->Total Bytes written = 169726150
--->Total Bytes = 2859811008

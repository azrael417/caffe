sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer3_dir1.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=3 -prof_forward_direction=1
I1031 11:44:54.824338 94382 caffe.cpp:444] Use CPU.
I1031 11:45:12.819201 94382 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 11:45:12.882514 94382 cpu_info.cpp:455] Total number of sockets: 1
I1031 11:45:12.895501 94382 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 11:45:12.907460 94382 cpu_info.cpp:461] Total number of processors: 256
I1031 11:45:12.924706 94382 cpu_info.cpp:464] GPU is used: no
I1031 11:45:12.934236 94382 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 11:45:12.943091 94382 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 11:45:12.955868 94382 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 11:45:22.178131 94382 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 11:45:22.872498 94382 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 11:45:25.298151 94382 layer_factory.hpp:114] Creating layer data
I1031 11:45:25.455812 94382 net.cpp:160] Creating Layer data
I1031 11:45:25.507760 94382 net.cpp:570] data -> data
I1031 11:45:26.003978 94382 net.cpp:570] data -> label
I1031 11:45:33.512233 94382 net.cpp:210] Setting up data
I1031 11:45:33.595511 94382 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 11:45:33.701711 94382 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 11:45:33.709069 94382 net.cpp:225] Memory required for data: 184516
I1031 11:45:33.791158 94382 layer_factory.hpp:114] Creating layer conv1
I1031 11:45:34.138856 94382 net.cpp:160] Creating Layer conv1
I1031 11:45:34.195190 94382 net.cpp:596] conv1 <- data
I1031 11:45:34.322720 94382 net.cpp:570] conv1 -> conv1
I1031 11:46:11.887812 94382 net.cpp:210] Setting up conv1
I1031 11:46:11.966328 94382 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:46:11.973368 94382 net.cpp:225] Memory required for data: 7805124
I1031 11:46:12.307164 94382 layer_factory.hpp:114] Creating layer relu1
I1031 11:46:12.445276 94382 net.cpp:160] Creating Layer relu1
I1031 11:46:12.450975 94382 net.cpp:596] relu1 <- conv1
I1031 11:46:12.486527 94382 net.cpp:557] relu1 -> conv1 (in-place)
I1031 11:46:12.709480 94382 net.cpp:210] Setting up relu1
I1031 11:46:12.712604 94382 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:46:12.713062 94382 net.cpp:225] Memory required for data: 15425732
I1031 11:46:12.713325 94382 layer_factory.hpp:114] Creating layer dropout1
I1031 11:46:12.747992 94382 net.cpp:160] Creating Layer dropout1
I1031 11:46:12.748347 94382 net.cpp:596] dropout1 <- conv1
I1031 11:46:12.751298 94382 net.cpp:570] dropout1 -> drop1
I1031 11:46:12.866997 94382 net.cpp:210] Setting up dropout1
I1031 11:46:12.881063 94382 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 11:46:12.881423 94382 net.cpp:225] Memory required for data: 23046340
I1031 11:46:12.881644 94382 layer_factory.hpp:114] Creating layer pool1
I1031 11:46:12.992532 94382 net.cpp:160] Creating Layer pool1
I1031 11:46:12.992872 94382 net.cpp:596] pool1 <- drop1
I1031 11:46:12.993284 94382 net.cpp:570] pool1 -> pool1
I1031 11:46:13.420816 94382 net.cpp:210] Setting up pool1
I1031 11:46:13.429993 94382 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 11:46:13.430388 94382 net.cpp:225] Memory required for data: 24951492
I1031 11:46:13.430685 94382 layer_factory.hpp:114] Creating layer conv2
I1031 11:46:13.493283 94382 net.cpp:160] Creating Layer conv2
I1031 11:46:13.497773 94382 net.cpp:596] conv2 <- pool1
I1031 11:46:13.513358 94382 net.cpp:570] conv2 -> conv2
I1031 11:46:20.351287 94382 net.cpp:210] Setting up conv2
I1031 11:46:20.353514 94382 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:46:20.366255 94382 net.cpp:225] Memory required for data: 26733764
I1031 11:46:20.440137 94382 layer_factory.hpp:114] Creating layer relu2
I1031 11:46:20.451767 94382 net.cpp:160] Creating Layer relu2
I1031 11:46:20.453562 94382 net.cpp:596] relu2 <- conv2
I1031 11:46:20.463004 94382 net.cpp:557] relu2 -> conv2 (in-place)
I1031 11:46:20.466037 94382 net.cpp:210] Setting up relu2
I1031 11:46:20.468637 94382 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:46:20.470971 94382 net.cpp:225] Memory required for data: 28516036
I1031 11:46:20.477677 94382 layer_factory.hpp:114] Creating layer dropout2
I1031 11:46:20.484035 94382 net.cpp:160] Creating Layer dropout2
I1031 11:46:20.486461 94382 net.cpp:596] dropout2 <- conv2
I1031 11:46:20.501018 94382 net.cpp:570] dropout2 -> drop2
I1031 11:46:20.503162 94382 net.cpp:210] Setting up dropout2
I1031 11:46:20.512480 94382 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 11:46:20.519058 94382 net.cpp:225] Memory required for data: 30298308
I1031 11:46:20.523882 94382 layer_factory.hpp:114] Creating layer pool2
I1031 11:46:20.525800 94382 net.cpp:160] Creating Layer pool2
I1031 11:46:20.528465 94382 net.cpp:596] pool2 <- drop2
I1031 11:46:20.530867 94382 net.cpp:570] pool2 -> pool2
I1031 11:46:20.533756 94382 net.cpp:210] Setting up pool2
I1031 11:46:20.538375 94382 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 11:46:20.549087 94382 net.cpp:225] Memory required for data: 30759108
I1031 11:46:20.554757 94382 layer_factory.hpp:114] Creating layer conv3
I1031 11:46:20.563976 94382 net.cpp:160] Creating Layer conv3
I1031 11:46:20.570336 94382 net.cpp:596] conv3 <- pool2
I1031 11:46:20.574322 94382 net.cpp:570] conv3 -> conv3
I1031 11:46:21.188629 94382 net.cpp:210] Setting up conv3
I1031 11:46:21.195294 94382 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:46:21.204421 94382 net.cpp:225] Memory required for data: 31160516
I1031 11:46:21.222597 94382 layer_factory.hpp:114] Creating layer relu3
I1031 11:46:21.231721 94382 net.cpp:160] Creating Layer relu3
I1031 11:46:21.236032 94382 net.cpp:596] relu3 <- conv3
I1031 11:46:21.246968 94382 net.cpp:557] relu3 -> conv3 (in-place)
I1031 11:46:21.251333 94382 net.cpp:210] Setting up relu3
I1031 11:46:21.262142 94382 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:46:21.270017 94382 net.cpp:225] Memory required for data: 31561924
I1031 11:46:21.277510 94382 layer_factory.hpp:114] Creating layer dropout3
I1031 11:46:21.289702 94382 net.cpp:160] Creating Layer dropout3
I1031 11:46:21.294184 94382 net.cpp:596] dropout3 <- conv3
I1031 11:46:21.304986 94382 net.cpp:570] dropout3 -> drop3
I1031 11:46:21.309617 94382 net.cpp:210] Setting up dropout3
I1031 11:46:21.318054 94382 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 11:46:21.326679 94382 net.cpp:225] Memory required for data: 31963332
I1031 11:46:21.334784 94382 layer_factory.hpp:114] Creating layer pool3
I1031 11:46:21.341513 94382 net.cpp:160] Creating Layer pool3
I1031 11:46:21.343685 94382 net.cpp:596] pool3 <- drop3
I1031 11:46:21.347723 94382 net.cpp:570] pool3 -> pool3
I1031 11:46:21.350848 94382 net.cpp:210] Setting up pool3
I1031 11:46:21.353174 94382 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 11:46:21.359707 94382 net.cpp:225] Memory required for data: 32063684
I1031 11:46:21.370740 94382 layer_factory.hpp:114] Creating layer conv4
I1031 11:46:21.379039 94382 net.cpp:160] Creating Layer conv4
I1031 11:46:21.380672 94382 net.cpp:596] conv4 <- pool3
I1031 11:46:21.389400 94382 net.cpp:570] conv4 -> conv4
I1031 11:46:21.774493 94382 net.cpp:210] Setting up conv4
I1031 11:46:21.779682 94382 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:46:21.780076 94382 net.cpp:225] Memory required for data: 32137412
I1031 11:46:21.780375 94382 layer_factory.hpp:114] Creating layer relu4
I1031 11:46:21.780653 94382 net.cpp:160] Creating Layer relu4
I1031 11:46:21.780864 94382 net.cpp:596] relu4 <- conv4
I1031 11:46:21.781116 94382 net.cpp:557] relu4 -> conv4 (in-place)
I1031 11:46:21.781574 94382 net.cpp:210] Setting up relu4
I1031 11:46:21.781849 94382 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:46:21.782093 94382 net.cpp:225] Memory required for data: 32211140
I1031 11:46:21.782295 94382 layer_factory.hpp:114] Creating layer dropout4
I1031 11:46:21.782531 94382 net.cpp:160] Creating Layer dropout4
I1031 11:46:21.782732 94382 net.cpp:596] dropout4 <- conv4
I1031 11:46:21.782980 94382 net.cpp:570] dropout4 -> drop4
I1031 11:46:21.783299 94382 net.cpp:210] Setting up dropout4
I1031 11:46:21.783665 94382 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 11:46:21.783931 94382 net.cpp:225] Memory required for data: 32284868
I1031 11:46:21.784137 94382 layer_factory.hpp:114] Creating layer pool4
I1031 11:46:21.784443 94382 net.cpp:160] Creating Layer pool4
I1031 11:46:21.784664 94382 net.cpp:596] pool4 <- drop4
I1031 11:46:21.784904 94382 net.cpp:570] pool4 -> pool4
I1031 11:46:21.798957 94382 net.cpp:210] Setting up pool4
I1031 11:46:21.799322 94382 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 11:46:21.801856 94382 net.cpp:225] Memory required for data: 32303300
I1031 11:46:21.802114 94382 layer_factory.hpp:114] Creating layer fc1
I1031 11:46:21.866698 94382 net.cpp:160] Creating Layer fc1
I1031 11:46:21.867043 94382 net.cpp:596] fc1 <- pool4
I1031 11:46:21.867496 94382 net.cpp:570] fc1 -> fc1
I1031 11:46:22.746739 94382 net.cpp:210] Setting up fc1
I1031 11:46:22.749990 94382 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:46:22.752774 94382 net.cpp:225] Memory required for data: 32307396
I1031 11:46:22.764089 94382 layer_factory.hpp:114] Creating layer dropout5
I1031 11:46:22.774648 94382 net.cpp:160] Creating Layer dropout5
I1031 11:46:22.785574 94382 net.cpp:596] dropout5 <- fc1
I1031 11:46:22.787675 94382 net.cpp:570] dropout5 -> drop5
I1031 11:46:22.792317 94382 net.cpp:210] Setting up dropout5
I1031 11:46:22.794551 94382 net.cpp:217] Top shape: 1 1024 (1024)
I1031 11:46:22.803339 94382 net.cpp:225] Memory required for data: 32311492
I1031 11:46:22.816267 94382 layer_factory.hpp:114] Creating layer fc2
I1031 11:46:22.825119 94382 net.cpp:160] Creating Layer fc2
I1031 11:46:22.833245 94382 net.cpp:596] fc2 <- drop5
I1031 11:46:22.839958 94382 net.cpp:570] fc2 -> fc2
I1031 11:46:22.874837 94382 net.cpp:210] Setting up fc2
I1031 11:46:22.900712 94382 net.cpp:217] Top shape: 1 2 (2)
I1031 11:46:22.915313 94382 net.cpp:225] Memory required for data: 32311500
I1031 11:46:22.923920 94382 layer_factory.hpp:114] Creating layer loss
I1031 11:46:22.956205 94382 net.cpp:160] Creating Layer loss
I1031 11:46:22.967519 94382 net.cpp:596] loss <- fc2
I1031 11:46:22.982341 94382 net.cpp:596] loss <- label
I1031 11:46:23.040838 94382 net.cpp:570] loss -> (automatic)
I1031 11:46:23.083132 94382 layer_factory.hpp:114] Creating layer loss
I1031 11:46:23.487879 94382 net.cpp:210] Setting up loss
I1031 11:46:23.492990 94382 net.cpp:217] Top shape: (1)
I1031 11:46:23.506006 94382 net.cpp:220]     with loss weight 1
I1031 11:46:23.647948 94382 net.cpp:225] Memory required for data: 32311504
I1031 11:46:23.700973 94382 net.cpp:287] loss needs backward computation.
I1031 11:46:23.805287 94382 net.cpp:287] fc2 needs backward computation.
I1031 11:46:23.817679 94382 net.cpp:287] dropout5 needs backward computation.
I1031 11:46:23.819973 94382 net.cpp:287] fc1 needs backward computation.
I1031 11:46:23.820804 94382 net.cpp:287] pool4 needs backward computation.
I1031 11:46:23.821101 94382 net.cpp:287] dropout4 needs backward computation.
I1031 11:46:23.821439 94382 net.cpp:287] relu4 needs backward computation.
I1031 11:46:23.831547 94382 net.cpp:287] conv4 needs backward computation.
I1031 11:46:23.848764 94382 net.cpp:287] pool3 needs backward computation.
I1031 11:46:23.862463 94382 net.cpp:287] dropout3 needs backward computation.
I1031 11:46:23.868896 94382 net.cpp:287] relu3 needs backward computation.
I1031 11:46:23.869266 94382 net.cpp:287] conv3 needs backward computation.
I1031 11:46:23.869652 94382 net.cpp:287] pool2 needs backward computation.
I1031 11:46:23.869946 94382 net.cpp:287] dropout2 needs backward computation.
I1031 11:46:23.870158 94382 net.cpp:287] relu2 needs backward computation.
I1031 11:46:23.870357 94382 net.cpp:287] conv2 needs backward computation.
I1031 11:46:23.870558 94382 net.cpp:287] pool1 needs backward computation.
I1031 11:46:23.870755 94382 net.cpp:287] dropout1 needs backward computation.
I1031 11:46:23.870951 94382 net.cpp:287] relu1 needs backward computation.
I1031 11:46:23.871143 94382 net.cpp:287] conv1 needs backward computation.
I1031 11:46:23.891964 94382 net.cpp:289] data does not need backward computation.
I1031 11:46:23.949308 94382 net.cpp:345] Network initialization done.
I1031 11:46:24.136626 94382 caffe.cpp:452] Performing Forward
I1031 11:46:36.022305 94382 caffe.cpp:457] Initial loss: 87.3365
I1031 11:46:36.145675 94382 caffe.cpp:459] Performing Backward
I1031 11:46:39.298357 94382 caffe.cpp:468] *** Benchmark begins ***
I1031 11:46:39.313897 94382 caffe.cpp:469] Testing for 1 iterations.
I1031 11:46:39.471604 94382 caffe.cpp:482] Profiling Layer: dropout1 forward
I1031 11:46:40.998101 94382 caffe.cpp:512] Iteration: 1 forward-backward time: 1510 ms.
I1031 11:46:41.099146 94382 caffe.cpp:519] Average time per layer: 
I1031 11:46:41.117781 94382 caffe.cpp:522]       data	forward: 45.132 ms.
I1031 11:46:41.190399 94382 caffe.cpp:526]       data	backward: 7.783 ms.
I1031 11:46:41.218245 94382 caffe.cpp:522]      conv1	forward: 63.885 ms.
I1031 11:46:41.223116 94382 caffe.cpp:526]      conv1	backward: 38.516 ms.
I1031 11:46:41.227797 94382 caffe.cpp:522]      relu1	forward: 28.328 ms.
I1031 11:46:41.232343 94382 caffe.cpp:526]      relu1	backward: 53.912 ms.
I1031 11:46:41.243475 94382 caffe.cpp:522]   dropout1	forward: 97.825 ms.
I1031 11:46:41.248237 94382 caffe.cpp:526]   dropout1	backward: 63.568 ms.
I1031 11:46:41.257115 94382 caffe.cpp:522]      pool1	forward: 126 ms.
I1031 11:46:41.268885 94382 caffe.cpp:526]      pool1	backward: 108.421 ms.
I1031 11:46:41.279816 94382 caffe.cpp:522]      conv2	forward: 70.865 ms.
I1031 11:46:41.284320 94382 caffe.cpp:526]      conv2	backward: 14.167 ms.
I1031 11:46:41.291043 94382 caffe.cpp:522]      relu2	forward: 14.386 ms.
I1031 11:46:41.299685 94382 caffe.cpp:526]      relu2	backward: 6.79 ms.
I1031 11:46:41.304244 94382 caffe.cpp:522]   dropout2	forward: 48.095 ms.
I1031 11:46:41.311172 94382 caffe.cpp:526]   dropout2	backward: 7.744 ms.
I1031 11:46:41.311645 94382 caffe.cpp:522]      pool2	forward: 35.734 ms.
I1031 11:46:41.314369 94382 caffe.cpp:526]      pool2	backward: 25.442 ms.
I1031 11:46:41.318950 94382 caffe.cpp:522]      conv3	forward: 56.68 ms.
I1031 11:46:41.325479 94382 caffe.cpp:526]      conv3	backward: 2.491 ms.
I1031 11:46:41.330247 94382 caffe.cpp:522]      relu3	forward: 19.237 ms.
I1031 11:46:41.335093 94382 caffe.cpp:526]      relu3	backward: 1.345 ms.
I1031 11:46:41.341579 94382 caffe.cpp:522]   dropout3	forward: 48.38 ms.
I1031 11:46:41.348181 94382 caffe.cpp:526]   dropout3	backward: 1.87 ms.
I1031 11:46:41.350400 94382 caffe.cpp:522]      pool3	forward: 21.721 ms.
I1031 11:46:41.357321 94382 caffe.cpp:526]      pool3	backward: 5.888 ms.
I1031 11:46:41.362020 94382 caffe.cpp:522]      conv4	forward: 65.005 ms.
I1031 11:46:41.368348 94382 caffe.cpp:526]      conv4	backward: 9.663 ms.
I1031 11:46:41.373859 94382 caffe.cpp:522]      relu4	forward: 13.475 ms.
I1031 11:46:41.381975 94382 caffe.cpp:526]      relu4	backward: 8.242 ms.
I1031 11:46:41.386754 94382 caffe.cpp:522]   dropout4	forward: 59.594 ms.
I1031 11:46:41.391160 94382 caffe.cpp:526]   dropout4	backward: 12.602 ms.
I1031 11:46:41.400135 94382 caffe.cpp:522]      pool4	forward: 26.11 ms.
I1031 11:46:41.407748 94382 caffe.cpp:526]      pool4	backward: 1.207 ms.
I1031 11:46:41.408135 94382 caffe.cpp:522]        fc1	forward: 43.669 ms.
I1031 11:46:41.408356 94382 caffe.cpp:526]        fc1	backward: 11.423 ms.
I1031 11:46:41.408562 94382 caffe.cpp:522]   dropout5	forward: 37.788 ms.
I1031 11:46:41.408766 94382 caffe.cpp:526]   dropout5	backward: 0.073 ms.
I1031 11:46:41.428211 94382 caffe.cpp:522]        fc2	forward: 12.433 ms.
I1031 11:46:41.428623 94382 caffe.cpp:526]        fc2	backward: 0.206 ms.
I1031 11:46:41.428900 94382 caffe.cpp:522]       loss	forward: 66.654 ms.
I1031 11:46:41.429111 94382 caffe.cpp:526]       loss	backward: 33.365 ms.
I1031 11:46:41.434918 94382 caffe.cpp:532] Average Forward pass: 1057.79 ms.
I1031 11:46:41.450569 94382 caffe.cpp:535] Average Backward pass: 424.414 ms.
I1031 11:46:41.461880 94382 caffe.cpp:537] Average Forward-Backward: 2071 ms.
I1031 11:46:41.477391 94382 caffe.cpp:540] Total Time: 2071 ms.
I1031 11:46:41.490546 94382 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 3
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 238144
elements_fp_double_1 = 33
elements_fp_double_2 = 2857952
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 3810307
--->Total double-precision FLOPs = 5715937
--->Total FLOPs = 9526244
mem-read-1 = 74520
mem-read-2 = 105
mem-read-4 = 978184
mem-read-8 = 1209877
mem-read-16 = 9525776
mem-read-32 = 1
mem-read-64 = 514033
mem-write-1 = 188
mem-write-2 = 67
mem-write-4 = 2494
mem-write-8 = 1130052
mem-write-16 = 32
mem-write-32 = 1
mem-write-64 = 363073
--->Total Bytes read = 198977042
--->Total Bytes written = 32287930
--->Total Bytes = 231264972

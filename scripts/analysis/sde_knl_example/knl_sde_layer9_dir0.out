sde64 -knl -d -iform 1 -omix sde_knl/knl_sde_layer9_dir0.out.mix -global_region -start_ssc_mark 111:repeat -stop_ssc_mark 222:repeat -- /project/projectdirs/mpccc/tmalas/intelcaffe/install_carl/bin/caffe time -model=train_val.prototxt -iterations=1 -prof_layer=9 -prof_forward_direction=0
I1031 14:32:58.366235 100548 caffe.cpp:444] Use CPU.
I1031 14:33:16.305099 100548 cpu_info.cpp:452] Processor speed [MHz]: 0
I1031 14:33:16.366938 100548 cpu_info.cpp:455] Total number of sockets: 1
I1031 14:33:16.379199 100548 cpu_info.cpp:458] Total number of CPU cores: 64
I1031 14:33:16.391355 100548 cpu_info.cpp:461] Total number of processors: 256
I1031 14:33:16.409258 100548 cpu_info.cpp:464] GPU is used: no
I1031 14:33:16.418653 100548 cpu_info.cpp:467] OpenMP environmental variables are specified: yes
I1031 14:33:16.427573 100548 cpu_info.cpp:470] OpenMP thread bind allowed: no
I1031 14:33:16.439589 100548 cpu_info.cpp:473] Number of OpenMP threads: 16
I1031 14:33:25.623682 100548 net.cpp:484] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1031 14:33:26.315194 100548 net.cpp:120] Initializing net from parameters: 
name: "HEP_CLASSIFIER"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "DummyData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "gaussian"
      std: 1
    }
    data_filler {
      type: "constant"
      value: 0
    }
    shape {
      dim: 1
      dim: 3
      dim: 124
      dim: 124
    }
    shape {
      dim: 1
      dim: 1
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout1"
  type: "Dropout"
  bottom: "conv1"
  top: "drop1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout2"
  type: "Dropout"
  bottom: "conv2"
  top: "drop2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout3"
  type: "Dropout"
  bottom: "conv3"
  top: "drop3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "dropout4"
  type: "Dropout"
  bottom: "conv4"
  top: "drop4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool4"
  top: "fc1"
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "dropout5"
  type: "Dropout"
  bottom: "fc1"
  top: "drop5"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop5"
  top: "fc2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
}
I1031 14:33:28.760174 100548 layer_factory.hpp:114] Creating layer data
I1031 14:33:28.920090 100548 net.cpp:160] Creating Layer data
I1031 14:33:28.971863 100548 net.cpp:570] data -> data
I1031 14:33:29.471549 100548 net.cpp:570] data -> label
I1031 14:33:37.090647 100548 net.cpp:210] Setting up data
I1031 14:33:37.196301 100548 net.cpp:217] Top shape: 1 3 124 124 (46128)
I1031 14:33:37.303895 100548 net.cpp:217] Top shape: 1 1 1 1 (1)
I1031 14:33:37.312175 100548 net.cpp:225] Memory required for data: 184516
I1031 14:33:37.395484 100548 layer_factory.hpp:114] Creating layer conv1
I1031 14:33:37.744091 100548 net.cpp:160] Creating Layer conv1
I1031 14:33:37.797615 100548 net.cpp:596] conv1 <- data
I1031 14:33:37.924216 100548 net.cpp:570] conv1 -> conv1
I1031 14:34:15.165024 100548 net.cpp:210] Setting up conv1
I1031 14:34:15.241351 100548 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:34:15.255102 100548 net.cpp:225] Memory required for data: 7805124
I1031 14:34:15.580826 100548 layer_factory.hpp:114] Creating layer relu1
I1031 14:34:15.730731 100548 net.cpp:160] Creating Layer relu1
I1031 14:34:15.736402 100548 net.cpp:596] relu1 <- conv1
I1031 14:34:15.771036 100548 net.cpp:557] relu1 -> conv1 (in-place)
I1031 14:34:15.993715 100548 net.cpp:210] Setting up relu1
I1031 14:34:15.996322 100548 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:34:15.996675 100548 net.cpp:225] Memory required for data: 15425732
I1031 14:34:15.996877 100548 layer_factory.hpp:114] Creating layer dropout1
I1031 14:34:16.028985 100548 net.cpp:160] Creating Layer dropout1
I1031 14:34:16.032542 100548 net.cpp:596] dropout1 <- conv1
I1031 14:34:16.035317 100548 net.cpp:570] dropout1 -> drop1
I1031 14:34:16.146981 100548 net.cpp:210] Setting up dropout1
I1031 14:34:16.160770 100548 net.cpp:217] Top shape: 1 128 122 122 (1905152)
I1031 14:34:16.161171 100548 net.cpp:225] Memory required for data: 23046340
I1031 14:34:16.161531 100548 layer_factory.hpp:114] Creating layer pool1
I1031 14:34:16.267274 100548 net.cpp:160] Creating Layer pool1
I1031 14:34:16.267882 100548 net.cpp:596] pool1 <- drop1
I1031 14:34:16.268203 100548 net.cpp:570] pool1 -> pool1
I1031 14:34:16.696954 100548 net.cpp:210] Setting up pool1
I1031 14:34:16.706058 100548 net.cpp:217] Top shape: 1 128 61 61 (476288)
I1031 14:34:16.706477 100548 net.cpp:225] Memory required for data: 24951492
I1031 14:34:16.706816 100548 layer_factory.hpp:114] Creating layer conv2
I1031 14:34:16.770874 100548 net.cpp:160] Creating Layer conv2
I1031 14:34:16.775535 100548 net.cpp:596] conv2 <- pool1
I1031 14:34:16.791404 100548 net.cpp:570] conv2 -> conv2
I1031 14:34:23.657261 100548 net.cpp:210] Setting up conv2
I1031 14:34:23.660089 100548 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:34:23.671667 100548 net.cpp:225] Memory required for data: 26733764
I1031 14:34:23.749927 100548 layer_factory.hpp:114] Creating layer relu2
I1031 14:34:23.760890 100548 net.cpp:160] Creating Layer relu2
I1031 14:34:23.769358 100548 net.cpp:596] relu2 <- conv2
I1031 14:34:23.778189 100548 net.cpp:557] relu2 -> conv2 (in-place)
I1031 14:34:23.781157 100548 net.cpp:210] Setting up relu2
I1031 14:34:23.787263 100548 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:34:23.799553 100548 net.cpp:225] Memory required for data: 28516036
I1031 14:34:23.806041 100548 layer_factory.hpp:114] Creating layer dropout2
I1031 14:34:23.810580 100548 net.cpp:160] Creating Layer dropout2
I1031 14:34:23.812755 100548 net.cpp:596] dropout2 <- conv2
I1031 14:34:23.819093 100548 net.cpp:570] dropout2 -> drop2
I1031 14:34:23.829584 100548 net.cpp:210] Setting up dropout2
I1031 14:34:23.831971 100548 net.cpp:217] Top shape: 1 128 59 59 (445568)
I1031 14:34:23.842366 100548 net.cpp:225] Memory required for data: 30298308
I1031 14:34:23.848933 100548 layer_factory.hpp:114] Creating layer pool2
I1031 14:34:23.857738 100548 net.cpp:160] Creating Layer pool2
I1031 14:34:23.862579 100548 net.cpp:596] pool2 <- drop2
I1031 14:34:23.871249 100548 net.cpp:570] pool2 -> pool2
I1031 14:34:23.877852 100548 net.cpp:210] Setting up pool2
I1031 14:34:23.879678 100548 net.cpp:217] Top shape: 1 128 30 30 (115200)
I1031 14:34:23.886965 100548 net.cpp:225] Memory required for data: 30759108
I1031 14:34:23.893291 100548 layer_factory.hpp:114] Creating layer conv3
I1031 14:34:23.897840 100548 net.cpp:160] Creating Layer conv3
I1031 14:34:23.900614 100548 net.cpp:596] conv3 <- pool2
I1031 14:34:23.907418 100548 net.cpp:570] conv3 -> conv3
I1031 14:34:24.486589 100548 net.cpp:210] Setting up conv3
I1031 14:34:24.494787 100548 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:34:24.506781 100548 net.cpp:225] Memory required for data: 31160516
I1031 14:34:24.521183 100548 layer_factory.hpp:114] Creating layer relu3
I1031 14:34:24.525697 100548 net.cpp:160] Creating Layer relu3
I1031 14:34:24.531479 100548 net.cpp:596] relu3 <- conv3
I1031 14:34:24.538306 100548 net.cpp:557] relu3 -> conv3 (in-place)
I1031 14:34:24.545142 100548 net.cpp:210] Setting up relu3
I1031 14:34:24.554896 100548 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:34:24.559113 100548 net.cpp:225] Memory required for data: 31561924
I1031 14:34:24.567342 100548 layer_factory.hpp:114] Creating layer dropout3
I1031 14:34:24.577823 100548 net.cpp:160] Creating Layer dropout3
I1031 14:34:24.586109 100548 net.cpp:596] dropout3 <- conv3
I1031 14:34:24.594503 100548 net.cpp:570] dropout3 -> drop3
I1031 14:34:24.600872 100548 net.cpp:210] Setting up dropout3
I1031 14:34:24.609184 100548 net.cpp:217] Top shape: 1 128 28 28 (100352)
I1031 14:34:24.615567 100548 net.cpp:225] Memory required for data: 31963332
I1031 14:34:24.617789 100548 layer_factory.hpp:114] Creating layer pool3
I1031 14:34:24.624358 100548 net.cpp:160] Creating Layer pool3
I1031 14:34:24.628445 100548 net.cpp:596] pool3 <- drop3
I1031 14:34:24.636405 100548 net.cpp:570] pool3 -> pool3
I1031 14:34:24.636976 100548 net.cpp:210] Setting up pool3
I1031 14:34:24.643699 100548 net.cpp:217] Top shape: 1 128 14 14 (25088)
I1031 14:34:24.653198 100548 net.cpp:225] Memory required for data: 32063684
I1031 14:34:24.660477 100548 layer_factory.hpp:114] Creating layer conv4
I1031 14:34:24.662497 100548 net.cpp:160] Creating Layer conv4
I1031 14:34:24.665254 100548 net.cpp:596] conv4 <- pool3
I1031 14:34:24.673928 100548 net.cpp:570] conv4 -> conv4
I1031 14:34:25.061959 100548 net.cpp:210] Setting up conv4
I1031 14:34:25.063719 100548 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:34:25.068831 100548 net.cpp:225] Memory required for data: 32137412
I1031 14:34:25.075418 100548 layer_factory.hpp:114] Creating layer relu4
I1031 14:34:25.079825 100548 net.cpp:160] Creating Layer relu4
I1031 14:34:25.083884 100548 net.cpp:596] relu4 <- conv4
I1031 14:34:25.094595 100548 net.cpp:557] relu4 -> conv4 (in-place)
I1031 14:34:25.103431 100548 net.cpp:210] Setting up relu4
I1031 14:34:25.109381 100548 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:34:25.118139 100548 net.cpp:225] Memory required for data: 32211140
I1031 14:34:25.126437 100548 layer_factory.hpp:114] Creating layer dropout4
I1031 14:34:25.132794 100548 net.cpp:160] Creating Layer dropout4
I1031 14:34:25.135155 100548 net.cpp:596] dropout4 <- conv4
I1031 14:34:25.137235 100548 net.cpp:570] dropout4 -> drop4
I1031 14:34:25.143869 100548 net.cpp:210] Setting up dropout4
I1031 14:34:25.150318 100548 net.cpp:217] Top shape: 1 128 12 12 (18432)
I1031 14:34:25.160727 100548 net.cpp:225] Memory required for data: 32284868
I1031 14:34:25.169070 100548 layer_factory.hpp:114] Creating layer pool4
I1031 14:34:25.177160 100548 net.cpp:160] Creating Layer pool4
I1031 14:34:25.179702 100548 net.cpp:596] pool4 <- drop4
I1031 14:34:25.184563 100548 net.cpp:570] pool4 -> pool4
I1031 14:34:25.202463 100548 net.cpp:210] Setting up pool4
I1031 14:34:25.202811 100548 net.cpp:217] Top shape: 1 128 6 6 (4608)
I1031 14:34:25.205317 100548 net.cpp:225] Memory required for data: 32303300
I1031 14:34:25.205569 100548 layer_factory.hpp:114] Creating layer fc1
I1031 14:34:25.270577 100548 net.cpp:160] Creating Layer fc1
I1031 14:34:25.270918 100548 net.cpp:596] fc1 <- pool4
I1031 14:34:25.271342 100548 net.cpp:570] fc1 -> fc1
I1031 14:34:26.176923 100548 net.cpp:210] Setting up fc1
I1031 14:34:26.185344 100548 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:34:26.202325 100548 net.cpp:225] Memory required for data: 32307396
I1031 14:34:26.218139 100548 layer_factory.hpp:114] Creating layer dropout5
I1031 14:34:26.224649 100548 net.cpp:160] Creating Layer dropout5
I1031 14:34:26.229473 100548 net.cpp:596] dropout5 <- fc1
I1031 14:34:26.235882 100548 net.cpp:570] dropout5 -> drop5
I1031 14:34:26.238466 100548 net.cpp:210] Setting up dropout5
I1031 14:34:26.240816 100548 net.cpp:217] Top shape: 1 1024 (1024)
I1031 14:34:26.243119 100548 net.cpp:225] Memory required for data: 32311492
I1031 14:34:26.251791 100548 layer_factory.hpp:114] Creating layer fc2
I1031 14:34:26.261168 100548 net.cpp:160] Creating Layer fc2
I1031 14:34:26.270551 100548 net.cpp:596] fc2 <- drop5
I1031 14:34:26.274870 100548 net.cpp:570] fc2 -> fc2
I1031 14:34:26.306231 100548 net.cpp:210] Setting up fc2
I1031 14:34:26.317719 100548 net.cpp:217] Top shape: 1 2 (2)
I1031 14:34:26.324165 100548 net.cpp:225] Memory required for data: 32311500
I1031 14:34:26.334697 100548 layer_factory.hpp:114] Creating layer loss
I1031 14:34:26.369982 100548 net.cpp:160] Creating Layer loss
I1031 14:34:26.378793 100548 net.cpp:596] loss <- fc2
I1031 14:34:26.387646 100548 net.cpp:596] loss <- label
I1031 14:34:26.448034 100548 net.cpp:570] loss -> (automatic)
I1031 14:34:26.507776 100548 layer_factory.hpp:114] Creating layer loss
I1031 14:34:26.933357 100548 net.cpp:210] Setting up loss
I1031 14:34:26.941597 100548 net.cpp:217] Top shape: (1)
I1031 14:34:26.954480 100548 net.cpp:220]     with loss weight 1
I1031 14:34:27.090750 100548 net.cpp:225] Memory required for data: 32311504
I1031 14:34:27.143596 100548 net.cpp:287] loss needs backward computation.
I1031 14:34:27.250706 100548 net.cpp:287] fc2 needs backward computation.
I1031 14:34:27.261746 100548 net.cpp:287] dropout5 needs backward computation.
I1031 14:34:27.263986 100548 net.cpp:287] fc1 needs backward computation.
I1031 14:34:27.264772 100548 net.cpp:287] pool4 needs backward computation.
I1031 14:34:27.265091 100548 net.cpp:287] dropout4 needs backward computation.
I1031 14:34:27.265365 100548 net.cpp:287] relu4 needs backward computation.
I1031 14:34:27.275449 100548 net.cpp:287] conv4 needs backward computation.
I1031 14:34:27.292373 100548 net.cpp:287] pool3 needs backward computation.
I1031 14:34:27.306016 100548 net.cpp:287] dropout3 needs backward computation.
I1031 14:34:27.310839 100548 net.cpp:287] relu3 needs backward computation.
I1031 14:34:27.311164 100548 net.cpp:287] conv3 needs backward computation.
I1031 14:34:27.311549 100548 net.cpp:287] pool2 needs backward computation.
I1031 14:34:27.311875 100548 net.cpp:287] dropout2 needs backward computation.
I1031 14:34:27.312109 100548 net.cpp:287] relu2 needs backward computation.
I1031 14:34:27.312299 100548 net.cpp:287] conv2 needs backward computation.
I1031 14:34:27.312492 100548 net.cpp:287] pool1 needs backward computation.
I1031 14:34:27.312682 100548 net.cpp:287] dropout1 needs backward computation.
I1031 14:34:27.312871 100548 net.cpp:287] relu1 needs backward computation.
I1031 14:34:27.313056 100548 net.cpp:287] conv1 needs backward computation.
I1031 14:34:27.334774 100548 net.cpp:289] data does not need backward computation.
I1031 14:34:27.394129 100548 net.cpp:345] Network initialization done.
I1031 14:34:27.573340 100548 caffe.cpp:452] Performing Forward
I1031 14:34:39.463732 100548 caffe.cpp:457] Initial loss: 66.2042
I1031 14:34:39.609585 100548 caffe.cpp:459] Performing Backward
I1031 14:34:43.102448 100548 caffe.cpp:468] *** Benchmark begins ***
I1031 14:34:43.116269 100548 caffe.cpp:469] Testing for 1 iterations.
I1031 14:34:43.271976 100548 caffe.cpp:485] Profiling Layer: conv3 backward
I1031 14:34:45.462515 100548 caffe.cpp:512] Iteration: 1 forward-backward time: 2188 ms.
I1031 14:34:45.560467 100548 caffe.cpp:519] Average time per layer: 
I1031 14:34:45.570940 100548 caffe.cpp:522]       data	forward: 49.68 ms.
I1031 14:34:45.630280 100548 caffe.cpp:526]       data	backward: 7.539 ms.
I1031 14:34:45.649755 100548 caffe.cpp:522]      conv1	forward: 16.934 ms.
I1031 14:34:45.653139 100548 caffe.cpp:526]      conv1	backward: 51.475 ms.
I1031 14:34:45.657980 100548 caffe.cpp:522]      relu1	forward: 2.305 ms.
I1031 14:34:45.658375 100548 caffe.cpp:526]      relu1	backward: 63.619 ms.
I1031 14:34:45.658654 100548 caffe.cpp:522]   dropout1	forward: 38.542 ms.
I1031 14:34:45.658895 100548 caffe.cpp:526]   dropout1	backward: 62.131 ms.
I1031 14:34:45.659801 100548 caffe.cpp:522]      pool1	forward: 125.408 ms.
I1031 14:34:45.660620 100548 caffe.cpp:526]      pool1	backward: 142.654 ms.
I1031 14:34:45.660887 100548 caffe.cpp:522]      conv2	forward: 71.421 ms.
I1031 14:34:45.661120 100548 caffe.cpp:526]      conv2	backward: 70.959 ms.
I1031 14:34:45.661407 100548 caffe.cpp:522]      relu2	forward: 22.93 ms.
I1031 14:34:45.661731 100548 caffe.cpp:526]      relu2	backward: 40.463 ms.
I1031 14:34:45.661976 100548 caffe.cpp:522]   dropout2	forward: 51.696 ms.
I1031 14:34:45.662204 100548 caffe.cpp:526]   dropout2	backward: 48.476 ms.
I1031 14:34:45.662428 100548 caffe.cpp:522]      pool2	forward: 29.463 ms.
I1031 14:34:45.662649 100548 caffe.cpp:526]      pool2	backward: 50.771 ms.
I1031 14:34:45.662868 100548 caffe.cpp:522]      conv3	forward: 52.286 ms.
I1031 14:34:45.663085 100548 caffe.cpp:526]      conv3	backward: 89.256 ms.
I1031 14:34:45.663301 100548 caffe.cpp:522]      relu3	forward: 19.962 ms.
I1031 14:34:45.663563 100548 caffe.cpp:526]      relu3	backward: 36.924 ms.
I1031 14:34:45.663784 100548 caffe.cpp:522]   dropout3	forward: 48.073 ms.
I1031 14:34:45.664002 100548 caffe.cpp:526]   dropout3	backward: 37.874 ms.
I1031 14:34:45.664219 100548 caffe.cpp:522]      pool3	forward: 13.071 ms.
I1031 14:34:45.664436 100548 caffe.cpp:526]      pool3	backward: 62.115 ms.
I1031 14:34:45.664657 100548 caffe.cpp:522]      conv4	forward: 64.862 ms.
I1031 14:34:45.664960 100548 caffe.cpp:526]      conv4	backward: 74.982 ms.
I1031 14:34:45.665235 100548 caffe.cpp:522]      relu4	forward: 23.911 ms.
I1031 14:34:45.665462 100548 caffe.cpp:526]      relu4	backward: 52.488 ms.
I1031 14:34:45.665680 100548 caffe.cpp:522]   dropout4	forward: 66.583 ms.
I1031 14:34:45.665897 100548 caffe.cpp:526]   dropout4	backward: 59.539 ms.
I1031 14:34:45.666113 100548 caffe.cpp:522]      pool4	forward: 11.833 ms.
I1031 14:34:45.666327 100548 caffe.cpp:526]      pool4	backward: 45.486 ms.
I1031 14:34:45.666543 100548 caffe.cpp:522]        fc1	forward: 46.127 ms.
I1031 14:34:45.666756 100548 caffe.cpp:526]        fc1	backward: 40.265 ms.
I1031 14:34:45.666971 100548 caffe.cpp:522]   dropout5	forward: 38.503 ms.
I1031 14:34:45.667186 100548 caffe.cpp:526]   dropout5	backward: 27.455 ms.
I1031 14:34:45.667435 100548 caffe.cpp:522]        fc2	forward: 16.589 ms.
I1031 14:34:45.667659 100548 caffe.cpp:526]        fc2	backward: 0.207 ms.
I1031 14:34:45.667876 100548 caffe.cpp:522]       loss	forward: 157.401 ms.
I1031 14:34:45.668125 100548 caffe.cpp:526]       loss	backward: 54.306 ms.
I1031 14:34:45.674443 100548 caffe.cpp:532] Average Forward pass: 1031.25 ms.
I1031 14:34:45.689615 100548 caffe.cpp:535] Average Backward pass: 1128.32 ms.
I1031 14:34:45.702561 100548 caffe.cpp:537] Average Forward-Backward: 2511 ms.
I1031 14:34:45.720067 100548 caffe.cpp:540] Total Time: 2511 ms.
I1031 14:34:45.734333 100548 caffe.cpp:541] *** Benchmark ends ***
Search stanza is "EMIT_GLOBAL_DYNAMIC_STATS"
elements_fp_single_1 = 0
elements_fp_single_4 = 0
elements_fp_single_8 = 0
elements_fp_single_16 = 28907648
elements_fp_double_1 = 0
elements_fp_double_2 = 0
elements_fp_double_4 = 0
elements_fp_double_8 = 0
--->Total single-precision FLOPs = 462522368
--->Total double-precision FLOPs = 0
--->Total FLOPs = 462522368
mem-read-1 = 102189
mem-read-2 = 138
mem-read-4 = 15300068
mem-read-8 = 1265057
mem-read-16 = 0
mem-read-32 = 268
mem-read-64 = 1295501
mem-write-1 = 202
mem-write-2 = 68
mem-write-4 = 3748
mem-write-8 = 210872
mem-write-16 = 4
mem-write-32 = 4
mem-write-64 = 461637
--->Total Bytes read = 154343833
--->Total Bytes written = 31247266
--->Total Bytes = 185591099
